{"meta":{"version":1,"warehouse":"5.0.1"},"models":{"Asset":[{"_id":"themes/ZenMind/source/404.html","path":"404.html","modified":0,"renderable":1},{"_id":"themes/ZenMind/source/css/404.css","path":"css/404.css","modified":0,"renderable":1},{"_id":"themes/ZenMind/source/css/a11y-dark.min.css","path":"css/a11y-dark.min.css","modified":0,"renderable":1},{"_id":"themes/ZenMind/source/css/markdown.css","path":"css/markdown.css","modified":0,"renderable":1},{"_id":"themes/ZenMind/source/css/fonts.css","path":"css/fonts.css","modified":0,"renderable":1},{"_id":"themes/ZenMind/source/css/reset.css","path":"css/reset.css","modified":0,"renderable":1},{"_id":"themes/ZenMind/source/css/style.css","path":"css/style.css","modified":0,"renderable":1},{"_id":"themes/ZenMind/source/img/favicon.png","path":"img/favicon.png","modified":0,"renderable":1},{"_id":"themes/ZenMind/source/img/Telegram.png","path":"img/Telegram.png","modified":0,"renderable":1},{"_id":"themes/ZenMind/source/img/github.png","path":"img/github.png","modified":0,"renderable":1},{"_id":"themes/ZenMind/source/img/mail.png","path":"img/mail.png","modified":0,"renderable":1},{"_id":"themes/ZenMind/source/img/rss-fill.png","path":"img/rss-fill.png","modified":0,"renderable":1},{"_id":"themes/ZenMind/source/js/highlight.min.js","path":"js/highlight.min.js","modified":0,"renderable":1},{"_id":"themes/ZenMind/source/img/home.png","path":"img/home.png","modified":0,"renderable":1},{"_id":"themes/ZenMind/source/js/highlightjs-line-numbers.js","path":"js/highlightjs-line-numbers.js","modified":0,"renderable":1},{"_id":"themes/ZenMind/source/js/toc.js","path":"js/toc.js","modified":0,"renderable":1},{"_id":"themes/ZenMind/source/js/main.js","path":"js/main.js","modified":0,"renderable":1},{"_id":"themes/ZenMind/source/img/outwebsite.png","path":"img/outwebsite.png","modified":0,"renderable":1},{"_id":"source/img/0b37a3b751ec9aa08efa75ace30e23c4_MD5.png","path":"img/0b37a3b751ec9aa08efa75ace30e23c4_MD5.png","modified":0,"renderable":0},{"_id":"source/img/0d87f8ba4e770fbdcd6c6fc61fb84862_MD5.png","path":"img/0d87f8ba4e770fbdcd6c6fc61fb84862_MD5.png","modified":0,"renderable":0},{"_id":"source/img/0fb77c535fcbf8f4264b6eff292fd210_MD5.png","path":"img/0fb77c535fcbf8f4264b6eff292fd210_MD5.png","modified":0,"renderable":0},{"_id":"source/img/20200901135402519.png","path":"img/20200901135402519.png","modified":0,"renderable":0},{"_id":"source/img/20200901134621820.png","path":"img/20200901134621820.png","modified":0,"renderable":0},{"_id":"source/img/20200901160002516.png","path":"img/20200901160002516.png","modified":0,"renderable":0},{"_id":"source/img/2ca562d1dc3a2d8d06c7c2bfe2c394c8_MD5.png","path":"img/2ca562d1dc3a2d8d06c7c2bfe2c394c8_MD5.png","modified":0,"renderable":0},{"_id":"source/img/2ff37cd0e1f5f734f8d6209396a08897_MD5.png","path":"img/2ff37cd0e1f5f734f8d6209396a08897_MD5.png","modified":0,"renderable":0},{"_id":"source/img/20200901160256824.png","path":"img/20200901160256824.png","modified":0,"renderable":0},{"_id":"source/img/37b1874d4aabb48cd6b511cba09fa70b_MD5.png","path":"img/37b1874d4aabb48cd6b511cba09fa70b_MD5.png","modified":0,"renderable":0},{"_id":"source/img/466a6f44f4b183a6bae184c90378b300_MD5.png","path":"img/466a6f44f4b183a6bae184c90378b300_MD5.png","modified":0,"renderable":0},{"_id":"source/img/10d0080498aba2649f1c04067965b579_MD5.png","path":"img/10d0080498aba2649f1c04067965b579_MD5.png","modified":0,"renderable":0},{"_id":"source/img/4cc119f98ed02df15c264d1cf428d32b_MD5.png","path":"img/4cc119f98ed02df15c264d1cf428d32b_MD5.png","modified":0,"renderable":0},{"_id":"source/img/546b99e807733344235b0b668c3c9e7e_MD5.jpeg","path":"img/546b99e807733344235b0b668c3c9e7e_MD5.jpeg","modified":0,"renderable":0},{"_id":"source/img/5711d6da84f2000a181c356e080deec4_MD5.png","path":"img/5711d6da84f2000a181c356e080deec4_MD5.png","modified":0,"renderable":0},{"_id":"source/img/5c376d6d6186292ebc461285ce0ac879_MD5.png","path":"img/5c376d6d6186292ebc461285ce0ac879_MD5.png","modified":0,"renderable":0},{"_id":"source/img/5cd2995739f1b0e1f4b355a2471c38aa_MD5.png","path":"img/5cd2995739f1b0e1f4b355a2471c38aa_MD5.png","modified":0,"renderable":0},{"_id":"source/img/5ee1af7a6012fd34b62704d5b2867320_MD5.png","path":"img/5ee1af7a6012fd34b62704d5b2867320_MD5.png","modified":0,"renderable":0},{"_id":"source/img/3a01157436842562f7f21f8b4c4549d4_MD5.png","path":"img/3a01157436842562f7f21f8b4c4549d4_MD5.png","modified":0,"renderable":0},{"_id":"source/img/68d9aaa9dd34dbc9d516201de1f2ab55_MD5.png","path":"img/68d9aaa9dd34dbc9d516201de1f2ab55_MD5.png","modified":0,"renderable":0},{"_id":"source/img/6aaf06740442599b6c52bb586545dfb8_MD5.png","path":"img/6aaf06740442599b6c52bb586545dfb8_MD5.png","modified":0,"renderable":0},{"_id":"source/img/870a39b7312d1d18324d3aefa613ab37_MD5.png","path":"img/870a39b7312d1d18324d3aefa613ab37_MD5.png","modified":0,"renderable":0},{"_id":"source/img/882565aff441558b043b911c7c240f29_MD5.png","path":"img/882565aff441558b043b911c7c240f29_MD5.png","modified":0,"renderable":0},{"_id":"source/img/93681a72e52523561d8f052cb74d6da0_MD5.png","path":"img/93681a72e52523561d8f052cb74d6da0_MD5.png","modified":0,"renderable":0},{"_id":"source/img/94530647a3be7da4d2de055fff8bacaf_MD5.png","path":"img/94530647a3be7da4d2de055fff8bacaf_MD5.png","modified":0,"renderable":0},{"_id":"source/img/IMG_4594.JPG","path":"img/IMG_4594.JPG","modified":0,"renderable":0},{"_id":"source/img/35a289c650094738966c332480bc7da5.png","path":"img/35a289c650094738966c332480bc7da5.png","modified":0,"renderable":0},{"_id":"source/img/584082192807448bb4db57a334ebb740.png","path":"img/584082192807448bb4db57a334ebb740.png","modified":0,"renderable":0},{"_id":"source/img/6576c5fe4a184619b7fe4897d6ea30af.png","path":"img/6576c5fe4a184619b7fe4897d6ea30af.png","modified":0,"renderable":0},{"_id":"source/img/IMG_4794.HEIC","path":"img/IMG_4794.HEIC","modified":0,"renderable":0},{"_id":"source/img/IMG_4790.png","path":"img/IMG_4790.png","modified":0,"renderable":0},{"_id":"source/img/IMG_4788.png","path":"img/IMG_4788.png","modified":0,"renderable":0},{"_id":"source/img/IMG_4788.webp","path":"img/IMG_4788.webp","modified":0,"renderable":0},{"_id":"source/img/IMG_4808.png","path":"img/IMG_4808.png","modified":0,"renderable":0},{"_id":"source/img/IMG_4809.png","path":"img/IMG_4809.png","modified":0,"renderable":0},{"_id":"source/img/IMG_4809.webp","path":"img/IMG_4809.webp","modified":0,"renderable":0},{"_id":"source/img/IMG_4810.webp","path":"img/IMG_4810.webp","modified":0,"renderable":0},{"_id":"source/img/IMG_4794.png","path":"img/IMG_4794.png","modified":0,"renderable":0},{"_id":"source/img/IMG_4811.png","path":"img/IMG_4811.png","modified":0,"renderable":0},{"_id":"source/img/IMG_4807.png","path":"img/IMG_4807.png","modified":0,"renderable":0},{"_id":"source/img/IMG_4810.png","path":"img/IMG_4810.png","modified":0,"renderable":0},{"_id":"source/img/IMG_4815.png","path":"img/IMG_4815.png","modified":0,"renderable":0},{"_id":"source/img/IMG_4815.webp","path":"img/IMG_4815.webp","modified":0,"renderable":0},{"_id":"source/img/Pastedimage20250520090726.png","path":"img/Pastedimage20250520090726.png","modified":0,"renderable":0},{"_id":"source/img/Pastedimage20250514161308.png","path":"img/Pastedimage20250514161308.png","modified":0,"renderable":0},{"_id":"source/img/a8f0d4502adb087892e11866bdac7d57_MD5.png","path":"img/a8f0d4502adb087892e11866bdac7d57_MD5.png","modified":0,"renderable":0},{"_id":"source/img/acea8af4268c8d552741ccebcb2d34ec_MD5.png","path":"img/acea8af4268c8d552741ccebcb2d34ec_MD5.png","modified":0,"renderable":0},{"_id":"source/img/bb94c4025a04733be2eb858d968eaffd_MD5.png","path":"img/bb94c4025a04733be2eb858d968eaffd_MD5.png","modified":0,"renderable":0},{"_id":"source/img/adc9951c2edb1fba60deea2d87fb2d44_MD5.png","path":"img/adc9951c2edb1fba60deea2d87fb2d44_MD5.png","modified":0,"renderable":0},{"_id":"source/img/c17560b740940d095c678b2769092f11_MD5.jpeg","path":"img/c17560b740940d095c678b2769092f11_MD5.jpeg","modified":0,"renderable":0},{"_id":"source/img/c3276b5f713b8b0641463b496c196ce2_MD5.png","path":"img/c3276b5f713b8b0641463b496c196ce2_MD5.png","modified":0,"renderable":0},{"_id":"source/img/ce77dd7ccc11dc7642aad16560000cb9_MD5.png","path":"img/ce77dd7ccc11dc7642aad16560000cb9_MD5.png","modified":0,"renderable":0},{"_id":"source/img/Pastedimage20250514170304.png","path":"img/Pastedimage20250514170304.png","modified":0,"renderable":0},{"_id":"source/img/d81d47f1a51cc2ecfe16e8966e7949b8_MD5.jpeg","path":"img/d81d47f1a51cc2ecfe16e8966e7949b8_MD5.jpeg","modified":0,"renderable":0},{"_id":"source/img/Pastedimage20250514170358.png","path":"img/Pastedimage20250514170358.png","modified":0,"renderable":0},{"_id":"source/img/d9e50eff06b436f7621152f2739a05c5_MD5.png","path":"img/d9e50eff06b436f7621152f2739a05c5_MD5.png","modified":0,"renderable":0},{"_id":"source/img/ed84ace61748c9dbdaf3f9718f21ff21_MD5.png","path":"img/ed84ace61748c9dbdaf3f9718f21ff21_MD5.png","modified":0,"renderable":0},{"_id":"source/img/f3627e8bb0dc4f0b8e589df10f6fe863.png","path":"img/f3627e8bb0dc4f0b8e589df10f6fe863.png","modified":0,"renderable":0},{"_id":"source/img/f6ef08bdd8b4ff67a419bfe9b7dbc0f2_MD5.png","path":"img/f6ef08bdd8b4ff67a419bfe9b7dbc0f2_MD5.png","modified":0,"renderable":0},{"_id":"source/img/ff0fd5af97f5f5ad3a954f3ffa4076d0_MD5.png","path":"img/ff0fd5af97f5f5ad3a954f3ffa4076d0_MD5.png","modified":0,"renderable":0},{"_id":"source/img/image-202588319698.png","path":"img/image-202588319698.png","modified":0,"renderable":0},{"_id":"source/img/image-2025882636315.png","path":"img/image-2025882636315.png","modified":0,"renderable":0},{"_id":"source/img/image-2025884737529.png","path":"img/image-2025884737529.png","modified":0,"renderable":0},{"_id":"source/img/image-202588559199.png","path":"img/image-202588559199.png","modified":0,"renderable":0},{"_id":"source/img/image-202588839176.png","path":"img/image-202588839176.png","modified":0,"renderable":0},{"_id":"source/img/telegram-cloud-photo-size-5-6098227393199198658-y.jpg","path":"img/telegram-cloud-photo-size-5-6098227393199198658-y.jpg","modified":0,"renderable":0},{"_id":"source/img/柱子.jpg","path":"img/柱子.jpg","modified":0,"renderable":0},{"_id":"source/use/img/airpods3.jpg","path":"use/img/airpods3.jpg","modified":0,"renderable":0},{"_id":"source/use/img/airpodspro.jpg","path":"use/img/airpodspro.jpg","modified":0,"renderable":0},{"_id":"source/use/img/bosemini2.png","path":"use/img/bosemini2.png","modified":0,"renderable":0},{"_id":"source/use/img/dellp2419h.png","path":"use/img/dellp2419h.png","modified":0,"renderable":0},{"_id":"source/use/img/athim70.jpg","path":"use/img/athim70.jpg","modified":0,"renderable":0},{"_id":"source/use/img/boseqc352.jpg","path":"use/img/boseqc352.jpg","modified":0,"renderable":0},{"_id":"source/use/img/gpw.jpg","path":"use/img/gpw.jpg","modified":0,"renderable":0},{"_id":"source/use/img/iphone13pro.jpg","path":"use/img/iphone13pro.jpg","modified":0,"renderable":0},{"_id":"source/use/img/fg830.webp","path":"use/img/fg830.webp","modified":0,"renderable":0},{"_id":"source/use/img/g102.webp","path":"use/img/g102.webp","modified":0,"renderable":0},{"_id":"source/use/img/macbookpro.jpg","path":"use/img/macbookpro.jpg","modified":0,"renderable":0},{"_id":"source/use/img/mxkeys.jpg","path":"use/img/mxkeys.jpg","modified":0,"renderable":0},{"_id":"source/use/img/kindlepaperwhite5.jpg","path":"use/img/kindlepaperwhite5.jpg","modified":0,"renderable":0},{"_id":"source/use/img/ktch27v22s.jpg","path":"use/img/ktch27v22s.jpg","modified":0,"renderable":0},{"_id":"source/use/img/mxmaster3.jpg","path":"use/img/mxmaster3.jpg","modified":0,"renderable":0},{"_id":"source/use/img/vgn98pro.jpeg","path":"use/img/vgn98pro.jpeg","modified":0,"renderable":0},{"_id":"source/use/img/sonyzv1.jpg","path":"use/img/sonyzv1.jpg","modified":0,"renderable":0},{"_id":"source/use/img/kindle4.jpeg","path":"use/img/kindle4.jpeg","modified":0,"renderable":0}],"Cache":[{"_id":"source/.DS_Store","hash":"199fcedee1e61cef3003297112dd28f4e35ed6b5","modified":1747732891756},{"_id":"source/about/index.md","hash":"583c9f034222e698e411ec7627674cb43fbfb396","modified":1758506936810},{"_id":"source/novel/index.md","hash":"53782b3322ef24f092245848b84aeb0beed18584","modified":1745459206170},{"_id":"source/novel/三、笛碎.md","hash":"be59c6f32f5b9b08f1128d28957951c5eb86bf04","modified":1720778446178},{"_id":"source/novel/二、清读笛、赋.md","hash":"c44b112d7e41219b079e8d3b8a6accdd11c5e5b5","modified":1720768904011},{"_id":"source/novel/一、炼体.md","hash":"68a250623486ebd457ce5fbbfcc09787ddc4228a","modified":1721037797937},{"_id":"source/novel/五、秘密.md","hash":"1d6c50ce700455f5192e71dab9b3067874b54a84","modified":1721036921544},{"_id":"source/img/0b37a3b751ec9aa08efa75ace30e23c4_MD5.png","hash":"06d7c8620054d00ea20084ee94f248137f0da88e","modified":1745480873085},{"_id":"source/img/0d87f8ba4e770fbdcd6c6fc61fb84862_MD5.png","hash":"2b034048afe7efc03d84ee07443d80d3b72fc618","modified":1745480873087},{"_id":"source/img/20200901135402519.png","hash":"38a83a9eb0ea285082cbde0f6e24afc21002c2b3","modified":1745480873146},{"_id":"source/novel/四、通诀师和拓诀师.md","hash":"a187335371669fe80c554c3b93b4b5ad7cb77411","modified":1721029255640},{"_id":"source/img/20200901134621820.png","hash":"000e23c72862c41e303bb060c6edeb5aacfb3bbe","modified":1745480873144},{"_id":"source/about/.DS_Store","hash":"df2fbeb1400acda0909a32c1cf6bf492f1121e07","modified":1754710599944},{"_id":"source/img/20200901160256824.png","hash":"1d9aef9a407dd0dd01e332ff4d10576ac8df0c9c","modified":1745480873153},{"_id":"source/img/5cd2995739f1b0e1f4b355a2471c38aa_MD5.png","hash":"cfa05c6c11d02c735cf937f7b7baec226003a17a","modified":1745480873105},{"_id":"source/img/5ee1af7a6012fd34b62704d5b2867320_MD5.png","hash":"eeee2e0654e5c40ae7030ea65c6a9bc96a02309c","modified":1745480873108},{"_id":"source/img/3a01157436842562f7f21f8b4c4549d4_MD5.png","hash":"69b72555c1af8e5c30037d77bc9205e36dcdf630","modified":1745480873097},{"_id":"source/img/94530647a3be7da4d2de055fff8bacaf_MD5.png","hash":"f3fae3d909513774d6fb58db06cc55d5af195855","modified":1745480873142},{"_id":"source/img/6576c5fe4a184619b7fe4897d6ea30af.png","hash":"e8460234134fd234dd36f6ca82f8c5617cd47dd4","modified":1686388360482},{"_id":"source/img/584082192807448bb4db57a334ebb740.png","hash":"5774c5649024fcf8ceb7f2df945c87a3fb97671f","modified":1686388360455},{"_id":"source/img/35a289c650094738966c332480bc7da5.png","hash":"e6eb91ab8ae3dad12c3c698c6bb2277f508ecc46","modified":1686388360420},{"_id":"source/img/a8f0d4502adb087892e11866bdac7d57_MD5.png","hash":"4784342b0cbc343b35c39e63bc3f2920cb5ed9f6","modified":1745480873154},{"_id":"source/img/acea8af4268c8d552741ccebcb2d34ec_MD5.png","hash":"90d219c5cdf1b0fc9dc81b5b53fc3b96fc728a75","modified":1745480873156},{"_id":"source/img/ce77dd7ccc11dc7642aad16560000cb9_MD5.png","hash":"b4290bb53b128ecb79b355e5bea7bec8db448482","modified":1745480873172},{"_id":"source/img/c3276b5f713b8b0641463b496c196ce2_MD5.png","hash":"2c98b106d4eb0abe356e8a4833ba6d4d701e2913","modified":1745480873169},{"_id":"source/img/c17560b740940d095c678b2769092f11_MD5.jpeg","hash":"28e973591a66607baedda2c30bc493af0fcfbb14","modified":1745480873171},{"_id":"source/img/f3627e8bb0dc4f0b8e589df10f6fe863.png","hash":"4354064d4eb2f17fcd877c00eb9c4df68c507f39","modified":1686388360603},{"_id":"source/img/d81d47f1a51cc2ecfe16e8966e7949b8_MD5.jpeg","hash":"295d6463c79e70633d3e92538da40799a6da55d6","modified":1703472690000},{"_id":"source/img/f6ef08bdd8b4ff67a419bfe9b7dbc0f2_MD5.png","hash":"5693e1c19aeda79e372f492d280e4a5d4cac09ef","modified":1745480873179},{"_id":"source/use/index.md","hash":"f869a14e6b9f6a2ae8b0c93ee66e03acf0d5ee7b","modified":1755226560519},{"_id":"source/img/telegram-cloud-photo-size-5-6098227393199198658-y.jpg","hash":"81a6d2a465ec8d82908eadb0c57f3088aceadcd8","modified":1754710780668},{"_id":"source/_posts/md/「持续更新」AI辅助编程使用心得.md","hash":"9560e4564e9a8969283277255b2c947e796bcc32","modified":1747725666990},{"_id":"source/_posts/md/Planet配置Web3域名.md","hash":"c0be28643390f816479446479c9a42d4f4883532","modified":1755768565589},{"_id":"source/_posts/md/为什么总是乱码？来看看编码格式吧.md","hash":"405afd1d0de052a2c70f017f50479d7128870f58","modified":1747725720347},{"_id":"source/_posts/md/关于oracle中以Blob字段查找重复值问题.md","hash":"b3075e5eb3e6056a623177fec26e21346d2736ce","modified":1747725680742},{"_id":"source/_posts/md/万字详解，Kafka这一篇就够了！.md","hash":"8c38a46959c5f167f017a7451382a3f0696cde6f","modified":1755768467433},{"_id":"source/_posts/md/晋城游记.md","hash":"6a5048e68c1d51e63e011deead56167cab0aad6e","modified":1756692142610},{"_id":"source/_posts/md/类加载器以及双亲委派模型.md","hash":"57bc4a464aa76f0b3afb2704e172114e94c82a76","modified":1747725690943},{"_id":"source/_posts/md/为什么一定要有一个个人网站？.md","hash":"9e8d338890b6de1dccd50f2d8af8b416f869bd09","modified":1753235029781},{"_id":"source/_posts/md/聊聊JavaIO的那些事.md","hash":"7822bdb3c17285f572ca52666784bb2f646a2d04","modified":1755683737258},{"_id":"source/_posts/md/详解：JavaScript中const，var，let的区别.md","hash":"18cc50c8072fe53bc6fb7018fb014593472dce19","modified":1755768532716},{"_id":"source/use/img/airpodspro.jpg","hash":"b8a9a2ec6e6a62e85891f43daaf62752046898ee","modified":1748512787832},{"_id":"source/_posts/md/详解：JavaScript创建执行释放过程.md","hash":"1387033a19fe9d495be6f55f88eca82eb608130b","modified":1748248269761},{"_id":"source/use/img/airpods3.jpg","hash":"c8a7ad411b12e08763fb7d5e787dd0bc946ec179","modified":1748512803276},{"_id":"source/use/img/gpw.jpg","hash":"73eab52afbcd533b630c61ad1d4baf62162e9538","modified":1748512759741},{"_id":"source/use/img/g102.webp","hash":"5a02eb8020ca009b397135bee54ec87dc00bd9a6","modified":1748515446979},{"_id":"source/use/img/vgn98pro.jpeg","hash":"dc205fcf7e41c7e3c7bf4c699914cbbd8511fbd2","modified":1748512743990},{"_id":"source/img/2ca562d1dc3a2d8d06c7c2bfe2c394c8_MD5.png","hash":"03de57d56cea8d38eebecf894aee46122593b7a3","modified":1745480873093},{"_id":"source/img/0fb77c535fcbf8f4264b6eff292fd210_MD5.png","hash":"f3d3acf2a95607fef318b3d0ff59bef96c88c69b","modified":1745480873089},{"_id":"source/img/20200901160002516.png","hash":"d03f5e3c669b7c7c0d6e5a3f54b73cdff95d1b0c","modified":1745480873151},{"_id":"source/img/37b1874d4aabb48cd6b511cba09fa70b_MD5.png","hash":"4ac0a89c6a0c5d518062210e8be0c86b08ac19ff","modified":1745480873114},{"_id":"source/img/466a6f44f4b183a6bae184c90378b300_MD5.png","hash":"669bd70864e4a18b20a3e76f4367ae14d66b16c6","modified":1745480873119},{"_id":"source/img/5c376d6d6186292ebc461285ce0ac879_MD5.png","hash":"01ff5a3be774ac0a0b5c2ec34cefe1e2035a85ee","modified":1745480873103},{"_id":"source/img/870a39b7312d1d18324d3aefa613ab37_MD5.png","hash":"88fe8373138557b30663f41fd972110f68057db3","modified":1745480873123},{"_id":"source/img/6aaf06740442599b6c52bb586545dfb8_MD5.png","hash":"817a5bc5f10d506cf9f4cb032f0853d8628a7d0c","modified":1745480873110},{"_id":"source/img/Pastedimage20250520090726.png","hash":"3a5a80064354d7ce9ef1113d8b88be7de625aa2d","modified":1747704118847},{"_id":"source/img/ed84ace61748c9dbdaf3f9718f21ff21_MD5.png","hash":"c9063a64f62f40b122ef0ea0505b37c4bd362bd4","modified":1745480873178},{"_id":"source/use/img/boseqc352.jpg","hash":"9dc9d1dfdf2597dc996666fcfbbcb812c54f7847","modified":1748514248680},{"_id":"source/use/img/fg830.webp","hash":"156257677bbe3c6b7cc82443a10b27e93ec20168","modified":1748515570923},{"_id":"source/use/img/athim70.jpg","hash":"60c6637c048d51bb4c7606aec6ead2b863e27e49","modified":1748513516699},{"_id":"source/use/img/macbookpro.jpg","hash":"f4e53d651daa6b6de6cb2f0dede6bb828869da5b","modified":1748513636243},{"_id":"source/use/img/kindlepaperwhite5.jpg","hash":"445d2cef1c0042093d5b47267104cd1dbc7a8edf","modified":1748513941622},{"_id":"source/use/img/iphone13pro.jpg","hash":"9b63f1aaa935cd2dcbfa85d24a4513c4cc940ea8","modified":1748513680022},{"_id":"source/img/2ff37cd0e1f5f734f8d6209396a08897_MD5.png","hash":"0d51e08d78d913b7bda84b320f63965c510511f9","modified":1745480873095},{"_id":"source/img/10d0080498aba2649f1c04067965b579_MD5.png","hash":"b40a8140eabacdad2090813d0f377251fbae3135","modified":1745480873113},{"_id":"source/use/img/mxmaster3.jpg","hash":"319ea9043cc5c9004ab1c925ae1920c2799026fc","modified":1748514170984},{"_id":"themes/ZenMind/README.md","hash":"c6aea279c1fe4e4c08ce6b749b816d4012f18444","modified":1745474290085},{"_id":"themes/ZenMind/_config.yml","hash":"ac44461e16049322469fcce6947837b9bc33bbe8","modified":1761214426570},{"_id":"themes/ZenMind/LICENSE.txt","hash":"4b1829044a6d453d26a6759272398e85574d9b8b","modified":1745393812082},{"_id":"themes/ZenMind/scripts/lazy-load.js","hash":"5712c61af347efe1983ff6040ee278dbab40552c","modified":1759109515794},{"_id":"themes/ZenMind/layout/index.ejs","hash":"c4b023a583c53a05cd8f5740791220de07ae62f2","modified":1761122459025},{"_id":"themes/ZenMind/layout/archive.ejs","hash":"b02c319adcfedd7499fb3f3bd71a9a410c9ce9a5","modified":1754717026182},{"_id":"themes/ZenMind/source/404.html","hash":"1fc4221709e5ad4cf7de699b8e865d397ec0798d","modified":1753843493808},{"_id":"themes/ZenMind/.DS_Store","hash":"f09a86bb4ce7d04901ec1bb4cb55bee99909840c","modified":1754299455562},{"_id":"themes/ZenMind/source/.DS_Store","hash":"5775c36cbfd635d4aa9b4495b2b3bb03b08923f7","modified":1754299455563},{"_id":"themes/ZenMind/layout/_partial/footer.ejs","hash":"a0d29851af6e2bfa71fb03d842b3dac4ef8111a7","modified":1760170287253},{"_id":"themes/ZenMind/layout/layout.ejs","hash":"10b68964aef2af2bc38ccea98e2d66b92f45bb25","modified":1761733156507},{"_id":"themes/ZenMind/layout/_partial/giscus.ejs","hash":"0634a545b8a52b5ac9394564b61314de37dc9f16","modified":1759200048236},{"_id":"themes/ZenMind/layout/_partial/head.ejs","hash":"2209d3c090828173eca01f0585cebdf50707950e","modified":1759109515794},{"_id":"themes/ZenMind/layout/post.ejs","hash":"38129bb1fa3e24133ffcc85283372e2232cc9935","modified":1761365535291},{"_id":"themes/ZenMind/source/css/404.css","hash":"9c1b0ab3b16a4b9fd13aa61721e009fad6d8248a","modified":1753843493809},{"_id":"themes/ZenMind/layout/_partial/paginator.ejs","hash":"980bf0a0be798c19df4b0827aa4b90b35c872425","modified":1760170287246},{"_id":"themes/ZenMind/layout/_partial/header.ejs","hash":"3ad5a27197478503a2cbcd98addf24735cb252ba","modified":1761730643280},{"_id":"themes/ZenMind/source/css/fonts.css","hash":"2fd1f7fd15328d361283e463454e76c11a8b79e4","modified":1761193336862},{"_id":"themes/ZenMind/source/css/reset.css","hash":"f6184d3f74dc704f077ca4e0b91003652a9db978","modified":1753843493814},{"_id":"themes/ZenMind/source/css/markdown.css","hash":"8dbbeccbbd25822605bac373667c90e379b67cd9","modified":1761156363580},{"_id":"themes/ZenMind/source/css/style.css","hash":"ef6f4adc2d91deec032d6bd1f9c11fe01ff58598","modified":1761733288352},{"_id":"themes/ZenMind/source/img/.DS_Store","hash":"df2fbeb1400acda0909a32c1cf6bf492f1121e07","modified":1754709943109},{"_id":"themes/ZenMind/source/fonts/.DS_Store","hash":"df2fbeb1400acda0909a32c1cf6bf492f1121e07","modified":1754710446911},{"_id":"themes/ZenMind/source/img/github.png","hash":"bdd07e5390fac8f6c63f28db74934a39c5cd6dc2","modified":1754712685370},{"_id":"themes/ZenMind/source/css/a11y-dark.min.css","hash":"e0a3294faa7dfa1eae300caea5a01f438b643b93","modified":1753843493809},{"_id":"themes/ZenMind/source/img/home.png","hash":"dbfc61ffe1fd594dce0d5e8cc5982d8b1e884684","modified":1759114291830},{"_id":"themes/ZenMind/source/img/rss-fill.png","hash":"a7b944c47f45258a5e21c9f9b36086010c8cf046","modified":1754712441575},{"_id":"themes/ZenMind/source/img/Telegram.png","hash":"0ae6cd96f4e31fcc1988cf5b8e0727c1e7f94b2e","modified":1754969459466},{"_id":"themes/ZenMind/source/img/mail.png","hash":"01712208d881158245a3932fdf25c83033886343","modified":1754712441572},{"_id":"themes/ZenMind/source/img/outwebsite.png","hash":"07265b30cabb28b86188ce9604fe14c94bc2cbe3","modified":1754713959247},{"_id":"themes/ZenMind/source/js/main.js","hash":"ef9fcb2a32023f04bd235177810798f106ab3a45","modified":1754705395822},{"_id":"themes/ZenMind/source/js/highlightjs-line-numbers.js","hash":"690e96133591495fa847d828573bd0576b2d168a","modified":1753843493836},{"_id":"themes/ZenMind/source/js/toc.js","hash":"e0061e575fd0408592abf19e9e1b288c98b8d26f","modified":1754705512582},{"_id":"source/img/IMG_4815.webp","hash":"0670b52f1dcf8b1b73fd2618651fa0472cacf807","modified":1759109626660},{"_id":"source/img/Pastedimage20250514161308.png","hash":"6cd91c6a07f65a99ea182e795596766a95636224","modified":1747704118841},{"_id":"source/use/img/mxkeys.jpg","hash":"4bfeb459eebb3ae4a426c3a387af2a8e3dcc8859","modified":1748515212141},{"_id":"source/use/img/ktch27v22s.jpg","hash":"78457de569d48ef3e1d98038a5f809e6c107ebb2","modified":1748513859597},{"_id":"source/img/546b99e807733344235b0b668c3c9e7e_MD5.jpeg","hash":"568710d0aa6ca67821bf23c44d91546ecf024e71","modified":1745480873121},{"_id":"source/img/68d9aaa9dd34dbc9d516201de1f2ab55_MD5.png","hash":"43e6be2f401a2cb7844268faa44ea2ab567c23b9","modified":1745480873117},{"_id":"source/img/882565aff441558b043b911c7c240f29_MD5.png","hash":"d383373f07ffcf8ae269bb76086975f1748c7752","modified":1745480873138},{"_id":"source/use/img/sonyzv1.jpg","hash":"3cbc012fd5289bd8f6ad2d303979150948794a66","modified":1748513770057},{"_id":"themes/ZenMind/source/js/highlight.min.js","hash":"d264ad16bdf39cfec2b06c20223b87fcb37ad27b","modified":1753843493835},{"_id":"source/img/IMG_4810.webp","hash":"92a729dbb412e679206d4d262c20336960addea5","modified":1759109621085},{"_id":"source/img/ff0fd5af97f5f5ad3a954f3ffa4076d0_MD5.png","hash":"4b1823bd665f0d9ec184e0f64e7aa56f31da4cc5","modified":1745480873181},{"_id":"source/img/d9e50eff06b436f7621152f2739a05c5_MD5.png","hash":"15a4cf70d06e91390f0bd1b170fdcc9151fc3db9","modified":1745480873176},{"_id":"source/img/image-202588839176.png","hash":"483749bedabf7dee53eb2af4186d2bf2dfccb27d","modified":1754710780676},{"_id":"themes/ZenMind/source/img/favicon.png","hash":"eeaaba8f125912ad665d6cf331ec466df351487a","modified":1754022899806},{"_id":"source/img/IMG_4809.webp","hash":"eab142714a18efc26541403296bdd7257ec995bd","modified":1759109614344},{"_id":"source/img/bb94c4025a04733be2eb858d968eaffd_MD5.png","hash":"1777480ac9804d9dbf8a63cfa98824ad8234bc9e","modified":1745480873166},{"_id":"source/img/image-202588559199.png","hash":"2b756fd45ebb611ea338b82ee90a51d7f0e397b6","modified":1754710780675},{"_id":"source/img/IMG_4788.webp","hash":"f7e1dda78b3b60626e5402260a27d00bb3ab57fa","modified":1759109602023},{"_id":"source/img/柱子.jpg","hash":"cf9417319ae8cf1b8942408b0fde3880127b5f9f","modified":1756274881220},{"_id":"source/img/Pastedimage20250514170358.png","hash":"620b92b4f6a673b5508eed17d5d567946f9e5563","modified":1748228306089},{"_id":"source/img/4cc119f98ed02df15c264d1cf428d32b_MD5.png","hash":"d1d65e192b766edc6ea4d5f5222e65d693278839","modified":1745480873101},{"_id":"source/img/Pastedimage20250514170304.png","hash":"7ed2f8ae27924f0d50f813da4204e2d014c35435","modified":1748228306095},{"_id":"source/use/img/bosemini2.png","hash":"de667dfdbde21d606d05862613372eb37b4ffaf7","modified":1748515083011},{"_id":"source/img/image-2025882636315.png","hash":"9f6bc200b5e79eceb4fc47e74654005a80dff6ce","modified":1754710780671},{"_id":"source/img/93681a72e52523561d8f052cb74d6da0_MD5.png","hash":"8bb8a57e2d44b167db437e73674422f1c9136175","modified":1745480873135},{"_id":"source/img/IMG_4815.png","hash":"cbc60d1b7d02fedb1b6296a6d4395d17eff18319","modified":1759109628027},{"_id":"source/img/IMG_4810.png","hash":"ce76830649a47cf88262d6778bcf2ffea0b097df","modified":1759109622306},{"_id":"source/img/adc9951c2edb1fba60deea2d87fb2d44_MD5.png","hash":"781ad9ad653aa74d84d8f12bd5b00ed8a41e5f45","modified":1745480873163},{"_id":"source/img/image-2025884737529.png","hash":"4ad20a00c5a230c744765aeaf5303aa989693e95","modified":1754710780668},{"_id":"source/img/5711d6da84f2000a181c356e080deec4_MD5.png","hash":"34a28c40d97c835ed8b046a660f2c8c40812c457","modified":1745480873129},{"_id":"source/use/img/kindle4.jpeg","hash":"e064f18fb76eda666c8cd810b8932b62ffde3931","modified":1748516040841},{"_id":"source/img/IMG_4788.png","hash":"bcd45a4e9795da7f22be8ddd6f3ffc38f8fc3ba7","modified":1759109603730},{"_id":"source/use/img/dellp2419h.png","hash":"e17a51a4aa8e53aa7243c60e3897e8c58f61aa82","modified":1748515144650},{"_id":"source/img/IMG_4809.png","hash":"a039a64b70dfd86fea053938257e97bcf357bdf1","modified":1759109615814},{"_id":"source/img/IMG_4794.HEIC","hash":"4eee2360a0f1f763e83804ed07c0e9b2a34e8ae7","modified":1756274881452},{"_id":"source/img/image-202588319698.png","hash":"3615ccd22aa2262ba826538fa0c88a9502df4193","modified":1754710780691},{"_id":"source/img/IMG_4594.JPG","hash":"08fb065eb76b84c3ef432f3fe634019bb561e134","modified":1756687326026},{"_id":"source/img/IMG_4790.png","hash":"fd17c73a7812fe27e88011a858185606100d7915","modified":1756274881317},{"_id":"source/img/IMG_4807.png","hash":"d170141080cbf2bf43dcd79a39f796d9635cb4c7","modified":1756274881269},{"_id":"source/img/IMG_4794.png","hash":"a8a2d0a1e3a6ce835a51606ff5fee583c3524a74","modified":1756274881247},{"_id":"source/img/IMG_4808.png","hash":"864e817c869c366153a042c38699545cf9334378","modified":1756274881341},{"_id":"source/img/IMG_4811.png","hash":"184f62bcbad54d60ade9456dd05a2a81b7d3bfd6","modified":1756274881293},{"_id":"public/atom.xml","hash":"7f672349dc922938ed5246ac6d1c8e433e5dd0dc","modified":1761748573755},{"_id":"public/about/index.html","hash":"1d212661d8f707cf6fa5d6ed2d04a7bf8a4f03ec","modified":1761748573755},{"_id":"public/novel/index.html","hash":"95d7350396fd66ffbd0f8c94141138ec29c9558e","modified":1761748573755},{"_id":"public/novel/三、笛碎.html","hash":"556a5207115b0e1ea6513e27f52e63fe86e32278","modified":1761748573755},{"_id":"public/novel/一、炼体.html","hash":"dfee546468f02d13c468ce9ea4654c48b2db43f3","modified":1761748573755},{"_id":"public/novel/二、清读笛、赋.html","hash":"207e3fbc85d13a8149b38a23a314b1fe97f7997c","modified":1761748573755},{"_id":"public/novel/五、秘密.html","hash":"d67dcb398cae2a7b6dcb7645bad8d03fc77c6258","modified":1761748573755},{"_id":"public/novel/四、通诀师和拓诀师.html","hash":"624fbe7fe1c0d9afe7e25749812e90c8ff1159d4","modified":1761748573755},{"_id":"public/use/index.html","hash":"cd624d8993df8ca405878f0ecaa824c5568540c4","modified":1761748573755},{"_id":"public/712386768996883/index.html","hash":"a858f4c30640576a10f549b55691e2df5d3fc74f","modified":1761748573755},{"_id":"public/6885322357796359/index.html","hash":"a63f4781a1249883e46c3cceb5bdb209eb59add0","modified":1761748573755},{"_id":"public/761386768996888/index.html","hash":"874e970ca0e11615000f0c78c9420439574d5448","modified":1761748573755},{"_id":"public/176138676899684/index.html","hash":"a2c0e930e039dbb4cf84ffe10089ab3698631181","modified":1761748573755},{"_id":"public/761386768996832/index.html","hash":"92a01c1a3f833403fa0d2df90f99ee9d6dad0f7b","modified":1761748573755},{"_id":"public/761386768996831/index.html","hash":"02d289bcac23dd4744c6a74708178ed6a277f046","modified":1761748573755},{"_id":"public/761386768996841/index.html","hash":"d14c6e075f290ca75aa8dab52fec3a3709d7082b","modified":1761748573755},{"_id":"public/761386768996885/index.html","hash":"276c94a3bf18bf8da244417544678225fbb1222c","modified":1761748573755},{"_id":"public/761386768996512/index.html","hash":"19777d42763244833eed2a17e40ce2713471148b","modified":1761748573755},{"_id":"public/7613867548996883/index.html","hash":"41cdc65ca072c5e281a32f5989a7350d15fd3038","modified":1761748573755},{"_id":"public/761386768996883/index.html","hash":"026ccc80e38331b28d2f2651588b6a8707e926c0","modified":1761748573755},{"_id":"public/categories/AI/index.html","hash":"a97934d419d57c51147244c85a34ee0025ba35c8","modified":1761748573755},{"_id":"public/categories/生活/index.html","hash":"ce14201310cfe13a7915b1131fd18f8957de3842","modified":1761748573755},{"_id":"public/categories/中间件/index.html","hash":"0cf26be556e6eb53b261225a49b54f0263769357","modified":1761748573755},{"_id":"public/categories/Web3/index.html","hash":"53e177b12ae0143fb73c9139eff18389a9e321b8","modified":1761748573755},{"_id":"public/categories/后端/index.html","hash":"243d45086def199b1a7dab1918906bdaf02ee369","modified":1761748573755},{"_id":"public/categories/前端/index.html","hash":"1ee9e538e7151605496153c2b115798cd6d97961","modified":1761748573755},{"_id":"public/archives/page/2/index.html","hash":"501ff78e33e10caea15c3ecc574057e9899fd585","modified":1761748573755},{"_id":"public/categories/数据库/index.html","hash":"c0c63c4f010ab36e947033b23714e789abd5ef32","modified":1761748573755},{"_id":"public/archives/2020/index.html","hash":"58768fd2c486703d07ca518e73e5eaee89c84bcd","modified":1761748573755},{"_id":"public/archives/2024/index.html","hash":"a4b84c88d5fd7e8c60320cb5e6f5de940e655025","modified":1761748573755},{"_id":"public/archives/index.html","hash":"094604751b9786cf974aefbc064faae5b350b47c","modified":1761748573755},{"_id":"public/archives/2024/03/index.html","hash":"292c5b7107dfe8d73c7916a12efabccaa68b19ee","modified":1761748573755},{"_id":"public/archives/2024/07/index.html","hash":"fb2357239caca9d790f143628c62afecebec1894","modified":1761748573755},{"_id":"public/archives/2024/09/index.html","hash":"cc8ca7cc2da9f8c3e853ae72fa93095b8c3eab32","modified":1761748573755},{"_id":"public/archives/2020/09/index.html","hash":"f3f1bd4cc5de8145190fa1776862dc96db4aba67","modified":1761748573755},{"_id":"public/archives/2024/12/index.html","hash":"d0ede3b557acaabb352cfcded0548ad1a9723d0a","modified":1761748573755},{"_id":"public/archives/2025/index.html","hash":"2bd76b0a350c4789a513296b2457d965993a1ad9","modified":1761748573755},{"_id":"public/archives/2025/03/index.html","hash":"e7c148488fe0782dbf405f34a809d9e832fda950","modified":1761748573755},{"_id":"public/archives/2025/04/index.html","hash":"aa083322d553181e5d4d6f38787feb4c304a9f68","modified":1761748573755},{"_id":"public/archives/2025/05/index.html","hash":"9995fcf94d338337830eafce275fcf1e9b1638f6","modified":1761748573755},{"_id":"public/archives/2025/08/index.html","hash":"d569c9c150ace958b8145a830e4ffd96a31eb596","modified":1761748573755},{"_id":"public/index.html","hash":"4f323d700148195d5ad3386c105f4811350d11f5","modified":1761748573755},{"_id":"public/tags/Cursor/index.html","hash":"325c396fde870dc4c653b266c25b020a5b398528","modified":1761748573755},{"_id":"public/tags/随笔/index.html","hash":"4747b7d2806f3fcdce6bcdb09df570e81dd06f81","modified":1761748573755},{"_id":"public/tags/Kafka/index.html","hash":"b9edca75ab6c24cc4ba1e483e3b240d80dafc93b","modified":1761748573755},{"_id":"public/tags/Planet/index.html","hash":"6867125ce9c862f19747c8084da4cf0a1477e533","modified":1761748573755},{"_id":"public/tags/编码/index.html","hash":"ff94a6090eec09126defd487b78ec4ac12af457c","modified":1761748573755},{"_id":"public/tags/oracle/index.html","hash":"d20c168c6a6e5aaed0871c46a4fb69e49dfe63d2","modified":1761748573755},{"_id":"public/page/2/index.html","hash":"5a7e41d95bf880e83464fd487d1f03330ffecfc8","modified":1761748573755},{"_id":"public/tags/开发问题/index.html","hash":"e15af2c910b6de622428d37f881e2c0b6286ab07","modified":1761748573755},{"_id":"public/tags/游记/index.html","hash":"897537f2d82e15c608f77bff7528be03e091e08c","modified":1761748573755},{"_id":"public/tags/郑州/index.html","hash":"6fc57f8c905538641565df299b2c07122b171bff","modified":1761748573755},{"_id":"public/tags/java/index.html","hash":"116055c4ef1ddaf1e1fc45ca06000333df1d0a10","modified":1761748573755},{"_id":"public/tags/类加载器/index.html","hash":"4ae90fd42c79fcb536a8557d1151f42957371aea","modified":1761748573755},{"_id":"public/tags/双亲委派模型/index.html","hash":"cc7bc3e21d148bf2289008ed24f7f08e2ad0cc31","modified":1761748573755},{"_id":"public/tags/javascript/index.html","hash":"45fbae8566854829fce4a128a05ffd33df74d01d","modified":1761748573755},{"_id":"public/tags/IO/index.html","hash":"a96c14c16f4e58b366ff7f0d050cb28fdeda9e83","modified":1761748573755},{"_id":"public/tags/NIO/index.html","hash":"d112fd96199245ecec31071275f29179d47da280","modified":1761748573755},{"_id":"public/tags/BIO/index.html","hash":"8fad01d7f335ff7f870107655169aacb058432bc","modified":1761748573755},{"_id":"public/img/rss-fill.png","hash":"a7b944c47f45258a5e21c9f9b36086010c8cf046","modified":1761748573755},{"_id":"public/img/Telegram.png","hash":"0ae6cd96f4e31fcc1988cf5b8e0727c1e7f94b2e","modified":1761748573755},{"_id":"public/img/github.png","hash":"bdd07e5390fac8f6c63f28db74934a39c5cd6dc2","modified":1761748573755},{"_id":"public/img/outwebsite.png","hash":"07265b30cabb28b86188ce9604fe14c94bc2cbe3","modified":1761748573755},{"_id":"public/img/home.png","hash":"dbfc61ffe1fd594dce0d5e8cc5982d8b1e884684","modified":1761748573755},{"_id":"public/img/mail.png","hash":"01712208d881158245a3932fdf25c83033886343","modified":1761748573755},{"_id":"public/img/20200901135402519.png","hash":"38a83a9eb0ea285082cbde0f6e24afc21002c2b3","modified":1761748573755},{"_id":"public/img/0b37a3b751ec9aa08efa75ace30e23c4_MD5.png","hash":"06d7c8620054d00ea20084ee94f248137f0da88e","modified":1761748573755},{"_id":"public/img/0d87f8ba4e770fbdcd6c6fc61fb84862_MD5.png","hash":"2b034048afe7efc03d84ee07443d80d3b72fc618","modified":1761748573755},{"_id":"public/img/20200901134621820.png","hash":"000e23c72862c41e303bb060c6edeb5aacfb3bbe","modified":1761748573755},{"_id":"public/img/20200901160256824.png","hash":"1d9aef9a407dd0dd01e332ff4d10576ac8df0c9c","modified":1761748573755},{"_id":"public/img/5cd2995739f1b0e1f4b355a2471c38aa_MD5.png","hash":"cfa05c6c11d02c735cf937f7b7baec226003a17a","modified":1761748573755},{"_id":"public/img/3a01157436842562f7f21f8b4c4549d4_MD5.png","hash":"69b72555c1af8e5c30037d77bc9205e36dcdf630","modified":1761748573755},{"_id":"public/img/5ee1af7a6012fd34b62704d5b2867320_MD5.png","hash":"eeee2e0654e5c40ae7030ea65c6a9bc96a02309c","modified":1761748573755},{"_id":"public/img/35a289c650094738966c332480bc7da5.png","hash":"e6eb91ab8ae3dad12c3c698c6bb2277f508ecc46","modified":1761748573755},{"_id":"public/img/94530647a3be7da4d2de055fff8bacaf_MD5.png","hash":"f3fae3d909513774d6fb58db06cc55d5af195855","modified":1761748573755},{"_id":"public/img/584082192807448bb4db57a334ebb740.png","hash":"5774c5649024fcf8ceb7f2df945c87a3fb97671f","modified":1761748573755},{"_id":"public/img/6576c5fe4a184619b7fe4897d6ea30af.png","hash":"e8460234134fd234dd36f6ca82f8c5617cd47dd4","modified":1761748573755},{"_id":"public/img/a8f0d4502adb087892e11866bdac7d57_MD5.png","hash":"4784342b0cbc343b35c39e63bc3f2920cb5ed9f6","modified":1761748573755},{"_id":"public/img/c17560b740940d095c678b2769092f11_MD5.jpeg","hash":"28e973591a66607baedda2c30bc493af0fcfbb14","modified":1761748573755},{"_id":"public/img/acea8af4268c8d552741ccebcb2d34ec_MD5.png","hash":"90d219c5cdf1b0fc9dc81b5b53fc3b96fc728a75","modified":1761748573755},{"_id":"public/img/c3276b5f713b8b0641463b496c196ce2_MD5.png","hash":"2c98b106d4eb0abe356e8a4833ba6d4d701e2913","modified":1761748573755},{"_id":"public/img/ce77dd7ccc11dc7642aad16560000cb9_MD5.png","hash":"b4290bb53b128ecb79b355e5bea7bec8db448482","modified":1761748573755},{"_id":"public/img/d81d47f1a51cc2ecfe16e8966e7949b8_MD5.jpeg","hash":"295d6463c79e70633d3e92538da40799a6da55d6","modified":1761748573755},{"_id":"public/img/f3627e8bb0dc4f0b8e589df10f6fe863.png","hash":"4354064d4eb2f17fcd877c00eb9c4df68c507f39","modified":1761748573755},{"_id":"public/img/f6ef08bdd8b4ff67a419bfe9b7dbc0f2_MD5.png","hash":"5693e1c19aeda79e372f492d280e4a5d4cac09ef","modified":1761748573755},{"_id":"public/img/telegram-cloud-photo-size-5-6098227393199198658-y.jpg","hash":"81a6d2a465ec8d82908eadb0c57f3088aceadcd8","modified":1761748573755},{"_id":"public/use/img/airpods3.jpg","hash":"c8a7ad411b12e08763fb7d5e787dd0bc946ec179","modified":1761748573755},{"_id":"public/use/img/airpodspro.jpg","hash":"b8a9a2ec6e6a62e85891f43daaf62752046898ee","modified":1761748573755},{"_id":"public/use/img/g102.webp","hash":"5a02eb8020ca009b397135bee54ec87dc00bd9a6","modified":1761748573755},{"_id":"public/use/img/gpw.jpg","hash":"73eab52afbcd533b630c61ad1d4baf62162e9538","modified":1761748573755},{"_id":"public/use/img/vgn98pro.jpeg","hash":"dc205fcf7e41c7e3c7bf4c699914cbbd8511fbd2","modified":1761748573755},{"_id":"public/img/0fb77c535fcbf8f4264b6eff292fd210_MD5.png","hash":"f3d3acf2a95607fef318b3d0ff59bef96c88c69b","modified":1761748573755},{"_id":"public/img/20200901160002516.png","hash":"d03f5e3c669b7c7c0d6e5a3f54b73cdff95d1b0c","modified":1761748573755},{"_id":"public/img/2ca562d1dc3a2d8d06c7c2bfe2c394c8_MD5.png","hash":"03de57d56cea8d38eebecf894aee46122593b7a3","modified":1761748573755},{"_id":"public/img/37b1874d4aabb48cd6b511cba09fa70b_MD5.png","hash":"4ac0a89c6a0c5d518062210e8be0c86b08ac19ff","modified":1761748573755},{"_id":"public/img/466a6f44f4b183a6bae184c90378b300_MD5.png","hash":"669bd70864e4a18b20a3e76f4367ae14d66b16c6","modified":1761748573755},{"_id":"public/img/5c376d6d6186292ebc461285ce0ac879_MD5.png","hash":"01ff5a3be774ac0a0b5c2ec34cefe1e2035a85ee","modified":1761748573755},{"_id":"public/img/6aaf06740442599b6c52bb586545dfb8_MD5.png","hash":"817a5bc5f10d506cf9f4cb032f0853d8628a7d0c","modified":1761748573755},{"_id":"public/img/870a39b7312d1d18324d3aefa613ab37_MD5.png","hash":"88fe8373138557b30663f41fd972110f68057db3","modified":1761748573755},{"_id":"public/img/Pastedimage20250520090726.png","hash":"3a5a80064354d7ce9ef1113d8b88be7de625aa2d","modified":1761748573755},{"_id":"public/img/ed84ace61748c9dbdaf3f9718f21ff21_MD5.png","hash":"c9063a64f62f40b122ef0ea0505b37c4bd362bd4","modified":1761748573755},{"_id":"public/use/img/boseqc352.jpg","hash":"9dc9d1dfdf2597dc996666fcfbbcb812c54f7847","modified":1761748573755},{"_id":"public/use/img/athim70.jpg","hash":"60c6637c048d51bb4c7606aec6ead2b863e27e49","modified":1761748573755},{"_id":"public/use/img/iphone13pro.jpg","hash":"9b63f1aaa935cd2dcbfa85d24a4513c4cc940ea8","modified":1761748573755},{"_id":"public/use/img/fg830.webp","hash":"156257677bbe3c6b7cc82443a10b27e93ec20168","modified":1761748573755},{"_id":"public/use/img/macbookpro.jpg","hash":"f4e53d651daa6b6de6cb2f0dede6bb828869da5b","modified":1761748573755},{"_id":"public/use/img/kindlepaperwhite5.jpg","hash":"445d2cef1c0042093d5b47267104cd1dbc7a8edf","modified":1761748573755},{"_id":"public/use/img/mxmaster3.jpg","hash":"319ea9043cc5c9004ab1c925ae1920c2799026fc","modified":1761748573755},{"_id":"public/css/a11y-dark.min.css","hash":"e0a3294faa7dfa1eae300caea5a01f438b643b93","modified":1761748573755},{"_id":"public/css/markdown.css","hash":"8dbbeccbbd25822605bac373667c90e379b67cd9","modified":1761748573755},{"_id":"public/css/reset.css","hash":"f6184d3f74dc704f077ca4e0b91003652a9db978","modified":1761748573755},{"_id":"public/css/fonts.css","hash":"2fd1f7fd15328d361283e463454e76c11a8b79e4","modified":1761748573755},{"_id":"public/css/style.css","hash":"ef6f4adc2d91deec032d6bd1f9c11fe01ff58598","modified":1761748573755},{"_id":"public/404.html","hash":"d6f8b9f7e0eb3b489fdf74092f1e65653c5fc83a","modified":1761748573755},{"_id":"public/css/404.css","hash":"9c1b0ab3b16a4b9fd13aa61721e009fad6d8248a","modified":1761748573755},{"_id":"public/js/highlight.min.js","hash":"d264ad16bdf39cfec2b06c20223b87fcb37ad27b","modified":1761748573755},{"_id":"public/js/toc.js","hash":"e0061e575fd0408592abf19e9e1b288c98b8d26f","modified":1761748573755},{"_id":"public/js/main.js","hash":"78cf68ec946c30afefdb65a1521672f9ea33691b","modified":1761748573755},{"_id":"public/js/highlightjs-line-numbers.js","hash":"690e96133591495fa847d828573bd0576b2d168a","modified":1761748573755},{"_id":"public/img/favicon.png","hash":"eeaaba8f125912ad665d6cf331ec466df351487a","modified":1761748573755},{"_id":"public/img/2ff37cd0e1f5f734f8d6209396a08897_MD5.png","hash":"0d51e08d78d913b7bda84b320f63965c510511f9","modified":1761748573755},{"_id":"public/img/10d0080498aba2649f1c04067965b579_MD5.png","hash":"b40a8140eabacdad2090813d0f377251fbae3135","modified":1761748573755},{"_id":"public/img/IMG_4815.webp","hash":"0670b52f1dcf8b1b73fd2618651fa0472cacf807","modified":1761748573755},{"_id":"public/img/Pastedimage20250514161308.png","hash":"6cd91c6a07f65a99ea182e795596766a95636224","modified":1761748573755},{"_id":"public/use/img/mxkeys.jpg","hash":"4bfeb459eebb3ae4a426c3a387af2a8e3dcc8859","modified":1761748573755},{"_id":"public/use/img/ktch27v22s.jpg","hash":"78457de569d48ef3e1d98038a5f809e6c107ebb2","modified":1761748573755},{"_id":"public/use/img/sonyzv1.jpg","hash":"3cbc012fd5289bd8f6ad2d303979150948794a66","modified":1761748573755},{"_id":"public/img/546b99e807733344235b0b668c3c9e7e_MD5.jpeg","hash":"568710d0aa6ca67821bf23c44d91546ecf024e71","modified":1761748573755},{"_id":"public/img/68d9aaa9dd34dbc9d516201de1f2ab55_MD5.png","hash":"43e6be2f401a2cb7844268faa44ea2ab567c23b9","modified":1761748573755},{"_id":"public/img/882565aff441558b043b911c7c240f29_MD5.png","hash":"d383373f07ffcf8ae269bb76086975f1748c7752","modified":1761748573755},{"_id":"public/img/IMG_4810.webp","hash":"92a729dbb412e679206d4d262c20336960addea5","modified":1761748573755},{"_id":"public/img/d9e50eff06b436f7621152f2739a05c5_MD5.png","hash":"15a4cf70d06e91390f0bd1b170fdcc9151fc3db9","modified":1761748573755},{"_id":"public/img/ff0fd5af97f5f5ad3a954f3ffa4076d0_MD5.png","hash":"4b1823bd665f0d9ec184e0f64e7aa56f31da4cc5","modified":1761748573755},{"_id":"public/img/image-202588839176.png","hash":"483749bedabf7dee53eb2af4186d2bf2dfccb27d","modified":1761748573755},{"_id":"public/img/IMG_4809.webp","hash":"eab142714a18efc26541403296bdd7257ec995bd","modified":1761748573755},{"_id":"public/img/bb94c4025a04733be2eb858d968eaffd_MD5.png","hash":"1777480ac9804d9dbf8a63cfa98824ad8234bc9e","modified":1761748573755},{"_id":"public/img/image-202588559199.png","hash":"2b756fd45ebb611ea338b82ee90a51d7f0e397b6","modified":1761748573755},{"_id":"public/img/IMG_4788.webp","hash":"f7e1dda78b3b60626e5402260a27d00bb3ab57fa","modified":1761748573755},{"_id":"public/img/柱子.jpg","hash":"cf9417319ae8cf1b8942408b0fde3880127b5f9f","modified":1761748573755},{"_id":"public/img/Pastedimage20250514170358.png","hash":"620b92b4f6a673b5508eed17d5d567946f9e5563","modified":1761748573755},{"_id":"public/img/4cc119f98ed02df15c264d1cf428d32b_MD5.png","hash":"d1d65e192b766edc6ea4d5f5222e65d693278839","modified":1761748573755},{"_id":"public/img/Pastedimage20250514170304.png","hash":"7ed2f8ae27924f0d50f813da4204e2d014c35435","modified":1761748573755},{"_id":"public/use/img/bosemini2.png","hash":"de667dfdbde21d606d05862613372eb37b4ffaf7","modified":1761748573755},{"_id":"public/img/image-2025882636315.png","hash":"9f6bc200b5e79eceb4fc47e74654005a80dff6ce","modified":1761748573755},{"_id":"public/img/93681a72e52523561d8f052cb74d6da0_MD5.png","hash":"8bb8a57e2d44b167db437e73674422f1c9136175","modified":1761748573755},{"_id":"public/img/IMG_4815.png","hash":"cbc60d1b7d02fedb1b6296a6d4395d17eff18319","modified":1761748573755},{"_id":"public/img/adc9951c2edb1fba60deea2d87fb2d44_MD5.png","hash":"781ad9ad653aa74d84d8f12bd5b00ed8a41e5f45","modified":1761748573755},{"_id":"public/img/image-2025884737529.png","hash":"4ad20a00c5a230c744765aeaf5303aa989693e95","modified":1761748573755},{"_id":"public/use/img/kindle4.jpeg","hash":"e064f18fb76eda666c8cd810b8932b62ffde3931","modified":1761748573755},{"_id":"public/img/IMG_4810.png","hash":"ce76830649a47cf88262d6778bcf2ffea0b097df","modified":1761748573755},{"_id":"public/img/5711d6da84f2000a181c356e080deec4_MD5.png","hash":"34a28c40d97c835ed8b046a660f2c8c40812c457","modified":1761748573755},{"_id":"public/img/IMG_4788.png","hash":"bcd45a4e9795da7f22be8ddd6f3ffc38f8fc3ba7","modified":1761748573755},{"_id":"public/use/img/dellp2419h.png","hash":"e17a51a4aa8e53aa7243c60e3897e8c58f61aa82","modified":1761748573755},{"_id":"public/img/IMG_4809.png","hash":"a039a64b70dfd86fea053938257e97bcf357bdf1","modified":1761748573755},{"_id":"public/img/IMG_4794.HEIC","hash":"4eee2360a0f1f763e83804ed07c0e9b2a34e8ae7","modified":1761748573755},{"_id":"public/img/image-202588319698.png","hash":"3615ccd22aa2262ba826538fa0c88a9502df4193","modified":1761748573755},{"_id":"public/img/IMG_4594.JPG","hash":"08fb065eb76b84c3ef432f3fe634019bb561e134","modified":1761748573755},{"_id":"public/img/IMG_4790.png","hash":"fd17c73a7812fe27e88011a858185606100d7915","modified":1761748573755},{"_id":"public/img/IMG_4807.png","hash":"d170141080cbf2bf43dcd79a39f796d9635cb4c7","modified":1761748573755},{"_id":"public/img/IMG_4808.png","hash":"864e817c869c366153a042c38699545cf9334378","modified":1761748573755},{"_id":"public/img/IMG_4794.png","hash":"a8a2d0a1e3a6ce835a51606ff5fee583c3524a74","modified":1761748573755},{"_id":"public/img/IMG_4811.png","hash":"184f62bcbad54d60ade9456dd05a2a81b7d3bfd6","modified":1761748573755}],"Category":[{"name":"Web3","_id":"cmhc3m3ua0004xdp8elae8x3s"},{"name":"AI","_id":"cmhc3m3uc000cxdp8ed6g1nmg"},{"name":"生活","_id":"cmhc3m3ud000kxdp80o0qafhe"},{"name":"中间件","_id":"cmhc3m3ue000rxdp8d7x47db4"},{"name":"后端","_id":"cmhc3m3ue000wxdp88akobhkc"},{"name":"数据库","_id":"cmhc3m3uf0010xdp83gy5divh"},{"name":"前端","_id":"cmhc3m3uf001axdp8a4mj6g9m"}],"Data":[],"Page":[{"title":"关于我","_content":"\n<!-- <center><img src=\"img/icon1.png\" alt=\"logo\" style=\"zoom:70%;border:0px\"  /></center> -->\n\n\n\n\n## 关于我   \n\n大家好，我是子规。\n\n如果在这里能帮到你，那将是我最大的荣幸！\n\n\n\n\n\n## 关于本站\n\n> 子规入梧桐，对杯惊暮钟。挥手笑别过，泪眼影三重。\n>                                                                                                                                          ——《相别》\n\n2014年高中毕业之际所作，之后一直就用 **「子规入梧桐」** 在为自己博客命名。在这里，你也可以叫我**子规**。建立这个网站的原因是我喜欢写作和思考，希望把我的思考和经验分享给需要帮助的人。\n\n您可以免费阅读本站所有内容，如果本站文章对你有帮助，欢迎留言赞赏！当然，最简单的方式是发送一封感谢信到我的 Email [「leon6line@gmail.com」](mailto:leon6line@gmail.com)。\n\n\n### 功能内容\n- [x] RSS 订阅（页脚右下角图标）\n- [x] 分类、标签功能及搜索跳转\n- [x] 文章目录，上下篇切换\n- [x] 分类列表\n- [x] 优化归档页面\n- [x] 文章页面图片懒加载\n- [x] 添加评论\n- [ ] 全站内容搜索\n\n  \n### 支持 & 版权\n\n本站使用 [Hexo](https://hexo.io/) 搭建，使用 [hexo-theme-ZenMind-Pro](https://github.com/z1gui/hexo-theme-ZenMind-Pro) 主题搭建。\n\n**hexo-theme-ZenMind-Pro** 是本人在 [hexo-theme-ZenMind](https://github.com/zhoulianglen/hexo-theme-ZenMind) 主题上做了修改优化。如有问题，可以联系我或在 issues 中提出您的问题。**在此感谢 [@周良粥凉](https://github.com/zhoulianglen) 的主题以及其博客样式参考**。\n\n\n本站所有文章除了特别声明外，均采用 [知识共享 署名-非商业性使用-相同方式共享 4.0 国际许可协议 CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/) 进行授权。**转载请在文中明显位置注明出处**。\n\n### 历史版本\n\n<div class=\"timeline\">\n<div class=\"timeline-item\">\n    <div class=\"timeline-dot\"></div>\n    <div class=\"timeline-content\">\n      <div class=\"timeline-date\">2025年7月</div>\n      <div class=\"timeline-title\">Planet</div>\n      <div class=\"timeline-desc\"> 用Planet搭建IPFS版Web内容接入该网站，详情点击『碎碎念🔗』或者访问Web3域名  <a herf=\"https://uhufoundme.sol.build\">https://uhufoundme.sol.build</a>  </div>\n    </div>\n  </div>\n  <div class=\"timeline-item\">\n    <div class=\"timeline-dot\"></div>\n    <div class=\"timeline-content\">\n      <div class=\"timeline-date\">2024年 - 2025年</div>\n      <div class=\"timeline-title\">Hexo</div>\n      <div class=\"timeline-desc\">改用 Hexo 进行博客搭建，由于个人云服务器不容易管理，重新改用Github Pages托管。</div>\n    </div>\n  </div>\n\n  <div class=\"timeline-item\">\n    <div class=\"timeline-dot\"></div>\n    <div class=\"timeline-content\">\n      <div class=\"timeline-date\">2024年</div>\n      <div class=\"timeline-title\">绑定域名</div>\n      <div class=\"timeline-desc\">将博客网站绑定在 <a herf=\"www.lazydaily.cn\">www.lazydaily.cn</a> 域名上。</div>\n    </div>\n  </div>\n\n  <div class=\"timeline-item\">\n    <div class=\"timeline-dot\"></div>\n    <div class=\"timeline-content\">\n      <div class=\"timeline-date\">2023年 - 2024年</div>\n      <div class=\"timeline-title\">Docsify + 云服务器</div>\n      <div class=\"timeline-desc\">将博客网站迁移到个人云服务器上。</div>\n    </div>\n  </div>\n\n  <div class=\"timeline-item\">\n    <div class=\"timeline-dot\"></div>\n    <div class=\"timeline-content\">\n      <div class=\"timeline-date\">2022年 - 2023年</div>\n      <div class=\"timeline-title\">Docsify + Github</div>\n      <div class=\"timeline-desc\">改用 Docsify 搭建博客，迁移内容，并开始使用Github Pages进行博客托管。</div>\n    </div>\n  </div>\n  \n  <div class=\"timeline-item\">\n    <div class=\"timeline-dot\"></div>\n    <div class=\"timeline-content\">\n      <div class=\"timeline-date\">2018年 - 2022年</div>\n      <div class=\"timeline-title\">CSDN博客</div>\n      <div class=\"timeline-desc\">在CSDN上以<a href=\"https://blog.csdn.net/weixin_34570718?spm=1018.2226.3001.10640\">「子规入梧桐」</a>为名输出博客内容，目前已不更新。</div>\n    </div>\n  </div>\n</div>\n\n\n\n## 声明 & 条款 & 须知\n\n### 1、信息免责条款\n本站所载全部内容（包括但不限于文字、图片、多媒体信息及外部链接）均基于善意原则提供参考信息。尽管我致力于确保内容的准确性，但不对信息的完整性、时效性及适用性作任何担保。**使用者应自行判断相关内容可靠性，本站对因使用或无法使用博客信息导致的任何直接或间接损失不承担法律责任**。\n\n### 2、内容更新条款\n本站保留在不预先通知的情况下对博客内容进行修改、删除或更新的权利。建议您定期访问以获取最新资讯，所有变更自发布之日起自动生效，不另行追溯通知。\n\n### 3、第三方内容声明\n本站所涉第三方服务信息（包括但不限于商品、服务及链接）仅供信息参考之目的，相关呈现不构成任何形式的担保、推荐或合作承诺。第三方内容之真实性、合法性应由提供者承担全部责任。\n\n### 4、使用须知\n访问者理解并同意，使用本博客内容即视为接受本声明全部条款。我们保留对本声明的最终解释权及修订权，建议定期查阅最新版本声明。\n\n","source":"about/index.md","raw":"---\ntitle: 关于我\n---\n\n<!-- <center><img src=\"img/icon1.png\" alt=\"logo\" style=\"zoom:70%;border:0px\"  /></center> -->\n\n\n\n\n## 关于我   \n\n大家好，我是子规。\n\n如果在这里能帮到你，那将是我最大的荣幸！\n\n\n\n\n\n## 关于本站\n\n> 子规入梧桐，对杯惊暮钟。挥手笑别过，泪眼影三重。\n>                                                                                                                                          ——《相别》\n\n2014年高中毕业之际所作，之后一直就用 **「子规入梧桐」** 在为自己博客命名。在这里，你也可以叫我**子规**。建立这个网站的原因是我喜欢写作和思考，希望把我的思考和经验分享给需要帮助的人。\n\n您可以免费阅读本站所有内容，如果本站文章对你有帮助，欢迎留言赞赏！当然，最简单的方式是发送一封感谢信到我的 Email [「leon6line@gmail.com」](mailto:leon6line@gmail.com)。\n\n\n### 功能内容\n- [x] RSS 订阅（页脚右下角图标）\n- [x] 分类、标签功能及搜索跳转\n- [x] 文章目录，上下篇切换\n- [x] 分类列表\n- [x] 优化归档页面\n- [x] 文章页面图片懒加载\n- [x] 添加评论\n- [ ] 全站内容搜索\n\n  \n### 支持 & 版权\n\n本站使用 [Hexo](https://hexo.io/) 搭建，使用 [hexo-theme-ZenMind-Pro](https://github.com/z1gui/hexo-theme-ZenMind-Pro) 主题搭建。\n\n**hexo-theme-ZenMind-Pro** 是本人在 [hexo-theme-ZenMind](https://github.com/zhoulianglen/hexo-theme-ZenMind) 主题上做了修改优化。如有问题，可以联系我或在 issues 中提出您的问题。**在此感谢 [@周良粥凉](https://github.com/zhoulianglen) 的主题以及其博客样式参考**。\n\n\n本站所有文章除了特别声明外，均采用 [知识共享 署名-非商业性使用-相同方式共享 4.0 国际许可协议 CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/) 进行授权。**转载请在文中明显位置注明出处**。\n\n### 历史版本\n\n<div class=\"timeline\">\n<div class=\"timeline-item\">\n    <div class=\"timeline-dot\"></div>\n    <div class=\"timeline-content\">\n      <div class=\"timeline-date\">2025年7月</div>\n      <div class=\"timeline-title\">Planet</div>\n      <div class=\"timeline-desc\"> 用Planet搭建IPFS版Web内容接入该网站，详情点击『碎碎念🔗』或者访问Web3域名  <a herf=\"https://uhufoundme.sol.build\">https://uhufoundme.sol.build</a>  </div>\n    </div>\n  </div>\n  <div class=\"timeline-item\">\n    <div class=\"timeline-dot\"></div>\n    <div class=\"timeline-content\">\n      <div class=\"timeline-date\">2024年 - 2025年</div>\n      <div class=\"timeline-title\">Hexo</div>\n      <div class=\"timeline-desc\">改用 Hexo 进行博客搭建，由于个人云服务器不容易管理，重新改用Github Pages托管。</div>\n    </div>\n  </div>\n\n  <div class=\"timeline-item\">\n    <div class=\"timeline-dot\"></div>\n    <div class=\"timeline-content\">\n      <div class=\"timeline-date\">2024年</div>\n      <div class=\"timeline-title\">绑定域名</div>\n      <div class=\"timeline-desc\">将博客网站绑定在 <a herf=\"www.lazydaily.cn\">www.lazydaily.cn</a> 域名上。</div>\n    </div>\n  </div>\n\n  <div class=\"timeline-item\">\n    <div class=\"timeline-dot\"></div>\n    <div class=\"timeline-content\">\n      <div class=\"timeline-date\">2023年 - 2024年</div>\n      <div class=\"timeline-title\">Docsify + 云服务器</div>\n      <div class=\"timeline-desc\">将博客网站迁移到个人云服务器上。</div>\n    </div>\n  </div>\n\n  <div class=\"timeline-item\">\n    <div class=\"timeline-dot\"></div>\n    <div class=\"timeline-content\">\n      <div class=\"timeline-date\">2022年 - 2023年</div>\n      <div class=\"timeline-title\">Docsify + Github</div>\n      <div class=\"timeline-desc\">改用 Docsify 搭建博客，迁移内容，并开始使用Github Pages进行博客托管。</div>\n    </div>\n  </div>\n  \n  <div class=\"timeline-item\">\n    <div class=\"timeline-dot\"></div>\n    <div class=\"timeline-content\">\n      <div class=\"timeline-date\">2018年 - 2022年</div>\n      <div class=\"timeline-title\">CSDN博客</div>\n      <div class=\"timeline-desc\">在CSDN上以<a href=\"https://blog.csdn.net/weixin_34570718?spm=1018.2226.3001.10640\">「子规入梧桐」</a>为名输出博客内容，目前已不更新。</div>\n    </div>\n  </div>\n</div>\n\n\n\n## 声明 & 条款 & 须知\n\n### 1、信息免责条款\n本站所载全部内容（包括但不限于文字、图片、多媒体信息及外部链接）均基于善意原则提供参考信息。尽管我致力于确保内容的准确性，但不对信息的完整性、时效性及适用性作任何担保。**使用者应自行判断相关内容可靠性，本站对因使用或无法使用博客信息导致的任何直接或间接损失不承担法律责任**。\n\n### 2、内容更新条款\n本站保留在不预先通知的情况下对博客内容进行修改、删除或更新的权利。建议您定期访问以获取最新资讯，所有变更自发布之日起自动生效，不另行追溯通知。\n\n### 3、第三方内容声明\n本站所涉第三方服务信息（包括但不限于商品、服务及链接）仅供信息参考之目的，相关呈现不构成任何形式的担保、推荐或合作承诺。第三方内容之真实性、合法性应由提供者承担全部责任。\n\n### 4、使用须知\n访问者理解并同意，使用本博客内容即视为接受本声明全部条款。我们保留对本声明的最终解释权及修订权，建议定期查阅最新版本声明。\n\n","date":"2025-09-22T02:08:56.810Z","updated":"2025-09-22T02:08:56.810Z","path":"about/index.html","comments":1,"layout":"page","_id":"cmhc3m3u60000xdp8278c8re9","content":"<!-- <center><img src=\"img/icon1.png\" alt=\"logo\" style=\"zoom:70%;border:0px\"  /></center> -->\n\n\n\n\n<h2 id=\"关于我\"><a href=\"#关于我\" class=\"headerlink\" title=\"关于我\"></a>关于我</h2><p>大家好，我是子规。</p>\n<p>如果在这里能帮到你，那将是我最大的荣幸！</p>\n<h2 id=\"关于本站\"><a href=\"#关于本站\" class=\"headerlink\" title=\"关于本站\"></a>关于本站</h2><blockquote>\n<p>子规入梧桐，对杯惊暮钟。挥手笑别过，泪眼影三重。<br>                                                                                                                                         ——《相别》</p>\n</blockquote>\n<p>2014年高中毕业之际所作，之后一直就用 <strong>「子规入梧桐」</strong> 在为自己博客命名。在这里，你也可以叫我<strong>子规</strong>。建立这个网站的原因是我喜欢写作和思考，希望把我的思考和经验分享给需要帮助的人。</p>\n<p>您可以免费阅读本站所有内容，如果本站文章对你有帮助，欢迎留言赞赏！当然，最简单的方式是发送一封感谢信到我的 Email <a href=\"mailto:&#x6c;&#x65;&#x6f;&#110;&#54;&#108;&#x69;&#x6e;&#101;&#x40;&#x67;&#x6d;&#x61;&#105;&#x6c;&#46;&#x63;&#x6f;&#109;\">「leon6line@gmail.com」</a>。</p>\n<h3 id=\"功能内容\"><a href=\"#功能内容\" class=\"headerlink\" title=\"功能内容\"></a>功能内容</h3><ul>\n<li><input checked=\"\" disabled=\"\" type=\"checkbox\"> RSS 订阅（页脚右下角图标）</li>\n<li><input checked=\"\" disabled=\"\" type=\"checkbox\"> 分类、标签功能及搜索跳转</li>\n<li><input checked=\"\" disabled=\"\" type=\"checkbox\"> 文章目录，上下篇切换</li>\n<li><input checked=\"\" disabled=\"\" type=\"checkbox\"> 分类列表</li>\n<li><input checked=\"\" disabled=\"\" type=\"checkbox\"> 优化归档页面</li>\n<li><input checked=\"\" disabled=\"\" type=\"checkbox\"> 文章页面图片懒加载</li>\n<li><input checked=\"\" disabled=\"\" type=\"checkbox\"> 添加评论</li>\n<li><input disabled=\"\" type=\"checkbox\"> 全站内容搜索</li>\n</ul>\n<h3 id=\"支持-版权\"><a href=\"#支持-版权\" class=\"headerlink\" title=\"支持 &amp; 版权\"></a>支持 &amp; 版权</h3><p>本站使用 <a href=\"https://hexo.io/\">Hexo</a> 搭建，使用 <a href=\"https://github.com/z1gui/hexo-theme-ZenMind-Pro\">hexo-theme-ZenMind-Pro</a> 主题搭建。</p>\n<p><strong>hexo-theme-ZenMind-Pro</strong> 是本人在 <a href=\"https://github.com/zhoulianglen/hexo-theme-ZenMind\">hexo-theme-ZenMind</a> 主题上做了修改优化。如有问题，可以联系我或在 issues 中提出您的问题。<strong>在此感谢 <a href=\"https://github.com/zhoulianglen\">@周良粥凉</a> 的主题以及其博客样式参考</strong>。</p>\n<p>本站所有文章除了特别声明外，均采用 <a href=\"https://creativecommons.org/licenses/by-nc-sa/4.0/\">知识共享 署名-非商业性使用-相同方式共享 4.0 国际许可协议 CC BY-NC-SA 4.0</a> 进行授权。<strong>转载请在文中明显位置注明出处</strong>。</p>\n<h3 id=\"历史版本\"><a href=\"#历史版本\" class=\"headerlink\" title=\"历史版本\"></a>历史版本</h3><div class=\"timeline\">\n<div class=\"timeline-item\">\n    <div class=\"timeline-dot\"></div>\n    <div class=\"timeline-content\">\n      <div class=\"timeline-date\">2025年7月</div>\n      <div class=\"timeline-title\">Planet</div>\n      <div class=\"timeline-desc\"> 用Planet搭建IPFS版Web内容接入该网站，详情点击『碎碎念🔗』或者访问Web3域名  <a herf=\"https://uhufoundme.sol.build\">https://uhufoundme.sol.build</a>  </div>\n    </div>\n  </div>\n  <div class=\"timeline-item\">\n    <div class=\"timeline-dot\"></div>\n    <div class=\"timeline-content\">\n      <div class=\"timeline-date\">2024年 - 2025年</div>\n      <div class=\"timeline-title\">Hexo</div>\n      <div class=\"timeline-desc\">改用 Hexo 进行博客搭建，由于个人云服务器不容易管理，重新改用Github Pages托管。</div>\n    </div>\n  </div>\n\n  <div class=\"timeline-item\">\n    <div class=\"timeline-dot\"></div>\n    <div class=\"timeline-content\">\n      <div class=\"timeline-date\">2024年</div>\n      <div class=\"timeline-title\">绑定域名</div>\n      <div class=\"timeline-desc\">将博客网站绑定在 <a herf=\"www.lazydaily.cn\">www.lazydaily.cn</a> 域名上。</div>\n    </div>\n  </div>\n\n  <div class=\"timeline-item\">\n    <div class=\"timeline-dot\"></div>\n    <div class=\"timeline-content\">\n      <div class=\"timeline-date\">2023年 - 2024年</div>\n      <div class=\"timeline-title\">Docsify + 云服务器</div>\n      <div class=\"timeline-desc\">将博客网站迁移到个人云服务器上。</div>\n    </div>\n  </div>\n\n  <div class=\"timeline-item\">\n    <div class=\"timeline-dot\"></div>\n    <div class=\"timeline-content\">\n      <div class=\"timeline-date\">2022年 - 2023年</div>\n      <div class=\"timeline-title\">Docsify + Github</div>\n      <div class=\"timeline-desc\">改用 Docsify 搭建博客，迁移内容，并开始使用Github Pages进行博客托管。</div>\n    </div>\n  </div>\n  \n  <div class=\"timeline-item\">\n    <div class=\"timeline-dot\"></div>\n    <div class=\"timeline-content\">\n      <div class=\"timeline-date\">2018年 - 2022年</div>\n      <div class=\"timeline-title\">CSDN博客</div>\n      <div class=\"timeline-desc\">在CSDN上以<a href=\"https://blog.csdn.net/weixin_34570718?spm=1018.2226.3001.10640\">「子规入梧桐」</a>为名输出博客内容，目前已不更新。</div>\n    </div>\n  </div>\n</div>\n\n\n\n<h2 id=\"声明-条款-须知\"><a href=\"#声明-条款-须知\" class=\"headerlink\" title=\"声明 &amp; 条款 &amp; 须知\"></a>声明 &amp; 条款 &amp; 须知</h2><h3 id=\"1、信息免责条款\"><a href=\"#1、信息免责条款\" class=\"headerlink\" title=\"1、信息免责条款\"></a>1、信息免责条款</h3><p>本站所载全部内容（包括但不限于文字、图片、多媒体信息及外部链接）均基于善意原则提供参考信息。尽管我致力于确保内容的准确性，但不对信息的完整性、时效性及适用性作任何担保。<strong>使用者应自行判断相关内容可靠性，本站对因使用或无法使用博客信息导致的任何直接或间接损失不承担法律责任</strong>。</p>\n<h3 id=\"2、内容更新条款\"><a href=\"#2、内容更新条款\" class=\"headerlink\" title=\"2、内容更新条款\"></a>2、内容更新条款</h3><p>本站保留在不预先通知的情况下对博客内容进行修改、删除或更新的权利。建议您定期访问以获取最新资讯，所有变更自发布之日起自动生效，不另行追溯通知。</p>\n<h3 id=\"3、第三方内容声明\"><a href=\"#3、第三方内容声明\" class=\"headerlink\" title=\"3、第三方内容声明\"></a>3、第三方内容声明</h3><p>本站所涉第三方服务信息（包括但不限于商品、服务及链接）仅供信息参考之目的，相关呈现不构成任何形式的担保、推荐或合作承诺。第三方内容之真实性、合法性应由提供者承担全部责任。</p>\n<h3 id=\"4、使用须知\"><a href=\"#4、使用须知\" class=\"headerlink\" title=\"4、使用须知\"></a>4、使用须知</h3><p>访问者理解并同意，使用本博客内容即视为接受本声明全部条款。我们保留对本声明的最终解释权及修订权，建议定期查阅最新版本声明。</p>\n","excerpt":"","more":"<!-- <center><img src=\"img/icon1.png\" alt=\"logo\" style=\"zoom:70%;border:0px\"  /></center> -->\n\n\n\n\n<h2 id=\"关于我\"><a href=\"#关于我\" class=\"headerlink\" title=\"关于我\"></a>关于我</h2><p>大家好，我是子规。</p>\n<p>如果在这里能帮到你，那将是我最大的荣幸！</p>\n<h2 id=\"关于本站\"><a href=\"#关于本站\" class=\"headerlink\" title=\"关于本站\"></a>关于本站</h2><blockquote>\n<p>子规入梧桐，对杯惊暮钟。挥手笑别过，泪眼影三重。<br>                                                                                                                                         ——《相别》</p>\n</blockquote>\n<p>2014年高中毕业之际所作，之后一直就用 <strong>「子规入梧桐」</strong> 在为自己博客命名。在这里，你也可以叫我<strong>子规</strong>。建立这个网站的原因是我喜欢写作和思考，希望把我的思考和经验分享给需要帮助的人。</p>\n<p>您可以免费阅读本站所有内容，如果本站文章对你有帮助，欢迎留言赞赏！当然，最简单的方式是发送一封感谢信到我的 Email <a href=\"mailto:&#x6c;&#x65;&#x6f;&#110;&#54;&#108;&#x69;&#x6e;&#101;&#x40;&#x67;&#x6d;&#x61;&#105;&#x6c;&#46;&#x63;&#x6f;&#109;\">「leon6line@gmail.com」</a>。</p>\n<h3 id=\"功能内容\"><a href=\"#功能内容\" class=\"headerlink\" title=\"功能内容\"></a>功能内容</h3><ul>\n<li><input checked=\"\" disabled=\"\" type=\"checkbox\"> RSS 订阅（页脚右下角图标）</li>\n<li><input checked=\"\" disabled=\"\" type=\"checkbox\"> 分类、标签功能及搜索跳转</li>\n<li><input checked=\"\" disabled=\"\" type=\"checkbox\"> 文章目录，上下篇切换</li>\n<li><input checked=\"\" disabled=\"\" type=\"checkbox\"> 分类列表</li>\n<li><input checked=\"\" disabled=\"\" type=\"checkbox\"> 优化归档页面</li>\n<li><input checked=\"\" disabled=\"\" type=\"checkbox\"> 文章页面图片懒加载</li>\n<li><input checked=\"\" disabled=\"\" type=\"checkbox\"> 添加评论</li>\n<li><input disabled=\"\" type=\"checkbox\"> 全站内容搜索</li>\n</ul>\n<h3 id=\"支持-版权\"><a href=\"#支持-版权\" class=\"headerlink\" title=\"支持 &amp; 版权\"></a>支持 &amp; 版权</h3><p>本站使用 <a href=\"https://hexo.io/\">Hexo</a> 搭建，使用 <a href=\"https://github.com/z1gui/hexo-theme-ZenMind-Pro\">hexo-theme-ZenMind-Pro</a> 主题搭建。</p>\n<p><strong>hexo-theme-ZenMind-Pro</strong> 是本人在 <a href=\"https://github.com/zhoulianglen/hexo-theme-ZenMind\">hexo-theme-ZenMind</a> 主题上做了修改优化。如有问题，可以联系我或在 issues 中提出您的问题。<strong>在此感谢 <a href=\"https://github.com/zhoulianglen\">@周良粥凉</a> 的主题以及其博客样式参考</strong>。</p>\n<p>本站所有文章除了特别声明外，均采用 <a href=\"https://creativecommons.org/licenses/by-nc-sa/4.0/\">知识共享 署名-非商业性使用-相同方式共享 4.0 国际许可协议 CC BY-NC-SA 4.0</a> 进行授权。<strong>转载请在文中明显位置注明出处</strong>。</p>\n<h3 id=\"历史版本\"><a href=\"#历史版本\" class=\"headerlink\" title=\"历史版本\"></a>历史版本</h3><div class=\"timeline\">\n<div class=\"timeline-item\">\n    <div class=\"timeline-dot\"></div>\n    <div class=\"timeline-content\">\n      <div class=\"timeline-date\">2025年7月</div>\n      <div class=\"timeline-title\">Planet</div>\n      <div class=\"timeline-desc\"> 用Planet搭建IPFS版Web内容接入该网站，详情点击『碎碎念🔗』或者访问Web3域名  <a herf=\"https://uhufoundme.sol.build\">https://uhufoundme.sol.build</a>  </div>\n    </div>\n  </div>\n  <div class=\"timeline-item\">\n    <div class=\"timeline-dot\"></div>\n    <div class=\"timeline-content\">\n      <div class=\"timeline-date\">2024年 - 2025年</div>\n      <div class=\"timeline-title\">Hexo</div>\n      <div class=\"timeline-desc\">改用 Hexo 进行博客搭建，由于个人云服务器不容易管理，重新改用Github Pages托管。</div>\n    </div>\n  </div>\n\n  <div class=\"timeline-item\">\n    <div class=\"timeline-dot\"></div>\n    <div class=\"timeline-content\">\n      <div class=\"timeline-date\">2024年</div>\n      <div class=\"timeline-title\">绑定域名</div>\n      <div class=\"timeline-desc\">将博客网站绑定在 <a herf=\"www.lazydaily.cn\">www.lazydaily.cn</a> 域名上。</div>\n    </div>\n  </div>\n\n  <div class=\"timeline-item\">\n    <div class=\"timeline-dot\"></div>\n    <div class=\"timeline-content\">\n      <div class=\"timeline-date\">2023年 - 2024年</div>\n      <div class=\"timeline-title\">Docsify + 云服务器</div>\n      <div class=\"timeline-desc\">将博客网站迁移到个人云服务器上。</div>\n    </div>\n  </div>\n\n  <div class=\"timeline-item\">\n    <div class=\"timeline-dot\"></div>\n    <div class=\"timeline-content\">\n      <div class=\"timeline-date\">2022年 - 2023年</div>\n      <div class=\"timeline-title\">Docsify + Github</div>\n      <div class=\"timeline-desc\">改用 Docsify 搭建博客，迁移内容，并开始使用Github Pages进行博客托管。</div>\n    </div>\n  </div>\n  \n  <div class=\"timeline-item\">\n    <div class=\"timeline-dot\"></div>\n    <div class=\"timeline-content\">\n      <div class=\"timeline-date\">2018年 - 2022年</div>\n      <div class=\"timeline-title\">CSDN博客</div>\n      <div class=\"timeline-desc\">在CSDN上以<a href=\"https://blog.csdn.net/weixin_34570718?spm=1018.2226.3001.10640\">「子规入梧桐」</a>为名输出博客内容，目前已不更新。</div>\n    </div>\n  </div>\n</div>\n\n\n\n<h2 id=\"声明-条款-须知\"><a href=\"#声明-条款-须知\" class=\"headerlink\" title=\"声明 &amp; 条款 &amp; 须知\"></a>声明 &amp; 条款 &amp; 须知</h2><h3 id=\"1、信息免责条款\"><a href=\"#1、信息免责条款\" class=\"headerlink\" title=\"1、信息免责条款\"></a>1、信息免责条款</h3><p>本站所载全部内容（包括但不限于文字、图片、多媒体信息及外部链接）均基于善意原则提供参考信息。尽管我致力于确保内容的准确性，但不对信息的完整性、时效性及适用性作任何担保。<strong>使用者应自行判断相关内容可靠性，本站对因使用或无法使用博客信息导致的任何直接或间接损失不承担法律责任</strong>。</p>\n<h3 id=\"2、内容更新条款\"><a href=\"#2、内容更新条款\" class=\"headerlink\" title=\"2、内容更新条款\"></a>2、内容更新条款</h3><p>本站保留在不预先通知的情况下对博客内容进行修改、删除或更新的权利。建议您定期访问以获取最新资讯，所有变更自发布之日起自动生效，不另行追溯通知。</p>\n<h3 id=\"3、第三方内容声明\"><a href=\"#3、第三方内容声明\" class=\"headerlink\" title=\"3、第三方内容声明\"></a>3、第三方内容声明</h3><p>本站所涉第三方服务信息（包括但不限于商品、服务及链接）仅供信息参考之目的，相关呈现不构成任何形式的担保、推荐或合作承诺。第三方内容之真实性、合法性应由提供者承担全部责任。</p>\n<h3 id=\"4、使用须知\"><a href=\"#4、使用须知\" class=\"headerlink\" title=\"4、使用须知\"></a>4、使用须知</h3><p>访问者理解并同意，使用本博客内容即视为接受本声明全部条款。我们保留对本声明的最终解释权及修订权，建议定期查阅最新版本声明。</p>\n"},{"_content":"> 2024年7月中旬，明年这个时候自己就30岁了。刚毕业那会，总觉得程序员35岁危机不会发生在自己身上。回顾毕业到现在，站在30岁的路口，发现自己之后的路不知道何去何从，这篇连载小说也算是给自己之后留一条退路吧。\n\n\n\n* 《亦幻》\n \n 奇异世界，人人修炼，一花一世界，一叶一菩提。当踏出这片土地，秦月会发现什么？\n\n\n\n\n\n   * 2024-7-12 统一搬迁中...... [第一章 炼体](一、炼体 )\n\n   * 2024-7-12 统一搬迁中...... [第二章 清读笛、赋](/二、清读笛、赋 )\n\n   * 2024-7-12 统一搬迁中...... [第三章 笛碎](/三、笛碎 )\n\n   * 2024-7-15 统一搬迁中...... [第四章 通诀师和拓诀师](/四、通诀师和拓诀师 )\n\n   * 2024-7-15 统一搬迁中...... [第五章 秘密](/五、秘密 )\n","source":"novel/index.md","raw":"> 2024年7月中旬，明年这个时候自己就30岁了。刚毕业那会，总觉得程序员35岁危机不会发生在自己身上。回顾毕业到现在，站在30岁的路口，发现自己之后的路不知道何去何从，这篇连载小说也算是给自己之后留一条退路吧。\n\n\n\n* 《亦幻》\n \n 奇异世界，人人修炼，一花一世界，一叶一菩提。当踏出这片土地，秦月会发现什么？\n\n\n\n\n\n   * 2024-7-12 统一搬迁中...... [第一章 炼体](一、炼体 )\n\n   * 2024-7-12 统一搬迁中...... [第二章 清读笛、赋](/二、清读笛、赋 )\n\n   * 2024-7-12 统一搬迁中...... [第三章 笛碎](/三、笛碎 )\n\n   * 2024-7-15 统一搬迁中...... [第四章 通诀师和拓诀师](/四、通诀师和拓诀师 )\n\n   * 2024-7-15 统一搬迁中...... [第五章 秘密](/五、秘密 )\n","date":"2025-04-24T03:35:34.125Z","updated":"2025-04-24T01:46:46.170Z","path":"novel/index.html","title":"","comments":1,"layout":"page","_id":"cmhc3m3u90002xdp84u055z1q","content":"<blockquote>\n<p>2024年7月中旬，明年这个时候自己就30岁了。刚毕业那会，总觉得程序员35岁危机不会发生在自己身上。回顾毕业到现在，站在30岁的路口，发现自己之后的路不知道何去何从，这篇连载小说也算是给自己之后留一条退路吧。</p>\n</blockquote>\n<ul>\n<li>《亦幻》</li>\n</ul>\n<p> 奇异世界，人人修炼，一花一世界，一叶一菩提。当踏出这片土地，秦月会发现什么？</p>\n<ul>\n<li><p>2024-7-12 统一搬迁中…… <a href=\"%E4%B8%80%E3%80%81%E7%82%BC%E4%BD%93\">第一章 炼体</a></p>\n</li>\n<li><p>2024-7-12 统一搬迁中…… <a href=\"/%E4%BA%8C%E3%80%81%E6%B8%85%E8%AF%BB%E7%AC%9B%E3%80%81%E8%B5%8B\">第二章 清读笛、赋</a></p>\n</li>\n<li><p>2024-7-12 统一搬迁中…… <a href=\"/%E4%B8%89%E3%80%81%E7%AC%9B%E7%A2%8E\">第三章 笛碎</a></p>\n</li>\n<li><p>2024-7-15 统一搬迁中…… <a href=\"/%E5%9B%9B%E3%80%81%E9%80%9A%E8%AF%80%E5%B8%88%E5%92%8C%E6%8B%93%E8%AF%80%E5%B8%88\">第四章 通诀师和拓诀师</a></p>\n</li>\n<li><p>2024-7-15 统一搬迁中…… <a href=\"/%E4%BA%94%E3%80%81%E7%A7%98%E5%AF%86\">第五章 秘密</a></p>\n</li>\n</ul>\n","excerpt":"","more":"<blockquote>\n<p>2024年7月中旬，明年这个时候自己就30岁了。刚毕业那会，总觉得程序员35岁危机不会发生在自己身上。回顾毕业到现在，站在30岁的路口，发现自己之后的路不知道何去何从，这篇连载小说也算是给自己之后留一条退路吧。</p>\n</blockquote>\n<ul>\n<li>《亦幻》</li>\n</ul>\n<p> 奇异世界，人人修炼，一花一世界，一叶一菩提。当踏出这片土地，秦月会发现什么？</p>\n<ul>\n<li><p>2024-7-12 统一搬迁中…… <a href=\"%E4%B8%80%E3%80%81%E7%82%BC%E4%BD%93\">第一章 炼体</a></p>\n</li>\n<li><p>2024-7-12 统一搬迁中…… <a href=\"/%E4%BA%8C%E3%80%81%E6%B8%85%E8%AF%BB%E7%AC%9B%E3%80%81%E8%B5%8B\">第二章 清读笛、赋</a></p>\n</li>\n<li><p>2024-7-12 统一搬迁中…… <a href=\"/%E4%B8%89%E3%80%81%E7%AC%9B%E7%A2%8E\">第三章 笛碎</a></p>\n</li>\n<li><p>2024-7-15 统一搬迁中…… <a href=\"/%E5%9B%9B%E3%80%81%E9%80%9A%E8%AF%80%E5%B8%88%E5%92%8C%E6%8B%93%E8%AF%80%E5%B8%88\">第四章 通诀师和拓诀师</a></p>\n</li>\n<li><p>2024-7-15 统一搬迁中…… <a href=\"/%E4%BA%94%E3%80%81%E7%A7%98%E5%AF%86\">第五章 秘密</a></p>\n</li>\n</ul>\n"},{"_content":"### 第一章 炼体\n\n当紫黑色的焰气侵入身体的各个穴位时，秦月感到无比的畅快。\n\n虚白空间。\n\n“难道你这么渴望得到力量吗？”声音兀的从深处涌出，“为什么用这种方式？”\n\n“你懂什么？ 这些年来我所煎熬的，你又怎能明白？”\n\n“你的体质，这样做就是在找死。”深处的声音变得严厉起来。\n\n“够了，不这样做，难道还去做那些没用的吗？”\n\n“现在的你已经完全被邪念控制了，即使获得了力量，也无法解开那个东西。孩子，我答应过你的父亲，要好好照顾你。我不允许你这样做。”\n\n“父亲？”\n\n现实。\n\n紫黑色焰气包裹的人影颤抖了一下， 身上的紫黑色焰气渐渐的消散，最后化作一束火种。一张俊白的少年脸庞浮现。\n\n“为什么？为什么他们要离开？他们究竟去了哪里？为什么不带上我？”秦月虚弱跪在地上，不断的喃喃道。\n\n“他们会回来的，我不是告诉你了吗？”老人安慰道，“幸好刚才我用唤心术进入你的虚白空间，不然...总之不要再碰这炼体之气，这是战士修炼的物件。它与你的体质相克。”\n\n说完，老人将火种收入掌心，转身离去。\n\n“你的清读笛我已经帮你校好了音，你的《清读赋》这几天也快完成了。过几天\n\n照以往一样，后山检查。”    ","source":"novel/一、炼体.md","raw":"### 第一章 炼体\n\n当紫黑色的焰气侵入身体的各个穴位时，秦月感到无比的畅快。\n\n虚白空间。\n\n“难道你这么渴望得到力量吗？”声音兀的从深处涌出，“为什么用这种方式？”\n\n“你懂什么？ 这些年来我所煎熬的，你又怎能明白？”\n\n“你的体质，这样做就是在找死。”深处的声音变得严厉起来。\n\n“够了，不这样做，难道还去做那些没用的吗？”\n\n“现在的你已经完全被邪念控制了，即使获得了力量，也无法解开那个东西。孩子，我答应过你的父亲，要好好照顾你。我不允许你这样做。”\n\n“父亲？”\n\n现实。\n\n紫黑色焰气包裹的人影颤抖了一下， 身上的紫黑色焰气渐渐的消散，最后化作一束火种。一张俊白的少年脸庞浮现。\n\n“为什么？为什么他们要离开？他们究竟去了哪里？为什么不带上我？”秦月虚弱跪在地上，不断的喃喃道。\n\n“他们会回来的，我不是告诉你了吗？”老人安慰道，“幸好刚才我用唤心术进入你的虚白空间，不然...总之不要再碰这炼体之气，这是战士修炼的物件。它与你的体质相克。”\n\n说完，老人将火种收入掌心，转身离去。\n\n“你的清读笛我已经帮你校好了音，你的《清读赋》这几天也快完成了。过几天\n\n照以往一样，后山检查。”    ","date":"2025-07-28T01:30:12.914Z","updated":"2024-07-15T10:03:17.937Z","path":"novel/一、炼体.html","title":"","comments":1,"layout":"page","_id":"cmhc3m3ua0006xdp8gfacgock","content":"<h3 id=\"第一章-炼体\"><a href=\"#第一章-炼体\" class=\"headerlink\" title=\"第一章 炼体\"></a>第一章 炼体</h3><p>当紫黑色的焰气侵入身体的各个穴位时，秦月感到无比的畅快。</p>\n<p>虚白空间。</p>\n<p>“难道你这么渴望得到力量吗？”声音兀的从深处涌出，“为什么用这种方式？”</p>\n<p>“你懂什么？ 这些年来我所煎熬的，你又怎能明白？”</p>\n<p>“你的体质，这样做就是在找死。”深处的声音变得严厉起来。</p>\n<p>“够了，不这样做，难道还去做那些没用的吗？”</p>\n<p>“现在的你已经完全被邪念控制了，即使获得了力量，也无法解开那个东西。孩子，我答应过你的父亲，要好好照顾你。我不允许你这样做。”</p>\n<p>“父亲？”</p>\n<p>现实。</p>\n<p>紫黑色焰气包裹的人影颤抖了一下， 身上的紫黑色焰气渐渐的消散，最后化作一束火种。一张俊白的少年脸庞浮现。</p>\n<p>“为什么？为什么他们要离开？他们究竟去了哪里？为什么不带上我？”秦月虚弱跪在地上，不断的喃喃道。</p>\n<p>“他们会回来的，我不是告诉你了吗？”老人安慰道，“幸好刚才我用唤心术进入你的虚白空间，不然…总之不要再碰这炼体之气，这是战士修炼的物件。它与你的体质相克。”</p>\n<p>说完，老人将火种收入掌心，转身离去。</p>\n<p>“你的清读笛我已经帮你校好了音，你的《清读赋》这几天也快完成了。过几天</p>\n<p>照以往一样，后山检查。”    </p>\n","excerpt":"","more":"<h3 id=\"第一章-炼体\"><a href=\"#第一章-炼体\" class=\"headerlink\" title=\"第一章 炼体\"></a>第一章 炼体</h3><p>当紫黑色的焰气侵入身体的各个穴位时，秦月感到无比的畅快。</p>\n<p>虚白空间。</p>\n<p>“难道你这么渴望得到力量吗？”声音兀的从深处涌出，“为什么用这种方式？”</p>\n<p>“你懂什么？ 这些年来我所煎熬的，你又怎能明白？”</p>\n<p>“你的体质，这样做就是在找死。”深处的声音变得严厉起来。</p>\n<p>“够了，不这样做，难道还去做那些没用的吗？”</p>\n<p>“现在的你已经完全被邪念控制了，即使获得了力量，也无法解开那个东西。孩子，我答应过你的父亲，要好好照顾你。我不允许你这样做。”</p>\n<p>“父亲？”</p>\n<p>现实。</p>\n<p>紫黑色焰气包裹的人影颤抖了一下， 身上的紫黑色焰气渐渐的消散，最后化作一束火种。一张俊白的少年脸庞浮现。</p>\n<p>“为什么？为什么他们要离开？他们究竟去了哪里？为什么不带上我？”秦月虚弱跪在地上，不断的喃喃道。</p>\n<p>“他们会回来的，我不是告诉你了吗？”老人安慰道，“幸好刚才我用唤心术进入你的虚白空间，不然…总之不要再碰这炼体之气，这是战士修炼的物件。它与你的体质相克。”</p>\n<p>说完，老人将火种收入掌心，转身离去。</p>\n<p>“你的清读笛我已经帮你校好了音，你的《清读赋》这几天也快完成了。过几天</p>\n<p>照以往一样，后山检查。”    </p>\n"},{"_content":"\n第三章  笛碎\n\n“这是…”秦月望着这团青色之气，“诀源！！！”  诀源，想必在这片天地的人都应该知道这样的东西。在这片天地的人，每个人都具有修炼诀元的资质，只要有导师的引导，以致不会走火入魔，每个人都有机会修炼出属于自己的诀气之元。这样的人便脱离平凡人的行列，一举成为诀师。一个人能修唤出诀气之元，便是诀师的标志，而诀源则是诀元的另一种凝聚态。能够凝聚出诀源，便是在诀元修炼上小有成就了。\n\n简单地说，这片天地下人分为两类，一类是凡人，则另一类就是诀师。凡人和诀师的区别便是能否修唤出诀元。然而这样说也不尽然，在这片光怪陆离的天地，有许许多多奇怪的事发生。不修唤出诀气但异于凡人的却有存在，这类人便是战士。战士的狂横，足以算得上诀师，甚至可以说在某些方面超越诀师，比如意志力。\n\n沐儿能够凝聚出诀源，秦月并不惊讶，毕竟她的父亲是风老。尽管风老并没有在他面前展现过，但秦月仍觉得风老的实力高深莫测。又想到自己连最基本的诀元修唤不出，秦月无奈地叹了口气。  似乎觉察到秦月的悲伤，冰雪聪明的沐儿便明白了秦月内心的痛苦，当下嘟嘟囔着:“爹爹真是的。为什么不让秦月哥哥修炼诀元呢？”“好了，你个小古灵精怪，就别去折腾你爹了，风老他也是为我好。”见沐儿乖乖地点头，秦月笑了笑，“今天庆祝沐儿凝聚出诀源，我请客。”\n\n“好耶。”沐儿笑嘻嘻地欢呼，“秦月哥哥，去素萱馆吧，好久没见萱姨了。”秦月默许。\n\n素萱馆。\n\n“萱姨，好久不见了。”“你这小丫头，这些天没来，是不是把萱姨给忘了”站在沐儿面前的丽人就是素萱馆的主人，萱姨。这女人年龄倒也不大，看上来只有二十几岁，更像是秦月和沐儿的姐姐。\n\n“哪有，沐儿天天都在想着萱姨做的素面呢！是不是？秦月哥哥。”沐儿依旧笑嘻嘻的。秦月微微一笑，像是在回应沐儿。\n\n“好吧，我今天就下回厨，给两个小家伙做碗面。”萱姨挽起衣袖，向内堂走去。“那便先谢谢萱姨了。”尽管常来这里，秦月对萱姨还是十分恭敬的。“你这孩子，把萱姨当外人了。”说着，萱姨白了秦月一眼，自顾自的走进内堂。\n\n见萱姨离开，秦月自嘲笑刚刚自己说错了话。“秦月哥哥，我们先找个地方坐下吧。”沐儿问道。“嗯”秦月便拉起沐儿向靠窗的位子走去---那一直是他们的位子。\n\n“哟，这不是我们常山镇的大乐师秦月嘛，哎，哥儿几个，要不咱们请他给咱们奏几段乐，给咱助助兴？”刚走几步，秦月便被声音叫住。“严武，你太过分了。”沐儿自然听出了严武的话中意。严武是严家子祠，严家又是常山镇一大户人家，也是常山镇三大家族之一。其中镇上玄昶学院大部分的财力支持都要靠严家，可见严家的势力有多恐怖。有这样财大气粗的家族，足以让严武在常山镇上横行霸道。而严武挑衅的目标只有一个，那就是让秦月在沐儿面前出丑。\n\n“我们走，不用理他。”秦月低声道。\n\n“哟，倒挺狂的。你不是不修炼诀元吗？你不是吹那破笛子很厉害吗？那给我们几个表演表演啊？”严武跨过几步，闪到秦月面前，显然使用了某种步法。\n\n“滚。”秦月冷冷吐出一个字。尽管表面十分冷静，只有沐儿知道他是真生气了。秦月倒不是因为严武对自己的羞辱而动怒，这样的羞辱秦月忍过不一回，而是因为严武亵渎了父母留给他的清读笛。\n\n“你小子，就是找死。”严武狠狠地说道，突然挥起手劈向秦月。\n\n“你混蛋。”沐儿察觉到严武不对劲，全身散发出青色之气，一个侧身便护在秦月面前。严武的手劈在那青色之气上便被弹开，连带严武后退了几步。“好啊，沐儿妹妹也修练了诀元了。”一击末中，严武僵笑道，迅速向自己的兄弟们使了个眼色。\n\n“小心。”沐儿未反应过来，身后的人便冲了过来。秦月镇静地抬起右手护着攻向沐儿的攻击，任由另一侧的攻击落在身上。\n\n“砰”清碎的响声响起，似乎是什么东西碎了。","source":"novel/三、笛碎.md","raw":"\n第三章  笛碎\n\n“这是…”秦月望着这团青色之气，“诀源！！！”  诀源，想必在这片天地的人都应该知道这样的东西。在这片天地的人，每个人都具有修炼诀元的资质，只要有导师的引导，以致不会走火入魔，每个人都有机会修炼出属于自己的诀气之元。这样的人便脱离平凡人的行列，一举成为诀师。一个人能修唤出诀气之元，便是诀师的标志，而诀源则是诀元的另一种凝聚态。能够凝聚出诀源，便是在诀元修炼上小有成就了。\n\n简单地说，这片天地下人分为两类，一类是凡人，则另一类就是诀师。凡人和诀师的区别便是能否修唤出诀元。然而这样说也不尽然，在这片光怪陆离的天地，有许许多多奇怪的事发生。不修唤出诀气但异于凡人的却有存在，这类人便是战士。战士的狂横，足以算得上诀师，甚至可以说在某些方面超越诀师，比如意志力。\n\n沐儿能够凝聚出诀源，秦月并不惊讶，毕竟她的父亲是风老。尽管风老并没有在他面前展现过，但秦月仍觉得风老的实力高深莫测。又想到自己连最基本的诀元修唤不出，秦月无奈地叹了口气。  似乎觉察到秦月的悲伤，冰雪聪明的沐儿便明白了秦月内心的痛苦，当下嘟嘟囔着:“爹爹真是的。为什么不让秦月哥哥修炼诀元呢？”“好了，你个小古灵精怪，就别去折腾你爹了，风老他也是为我好。”见沐儿乖乖地点头，秦月笑了笑，“今天庆祝沐儿凝聚出诀源，我请客。”\n\n“好耶。”沐儿笑嘻嘻地欢呼，“秦月哥哥，去素萱馆吧，好久没见萱姨了。”秦月默许。\n\n素萱馆。\n\n“萱姨，好久不见了。”“你这小丫头，这些天没来，是不是把萱姨给忘了”站在沐儿面前的丽人就是素萱馆的主人，萱姨。这女人年龄倒也不大，看上来只有二十几岁，更像是秦月和沐儿的姐姐。\n\n“哪有，沐儿天天都在想着萱姨做的素面呢！是不是？秦月哥哥。”沐儿依旧笑嘻嘻的。秦月微微一笑，像是在回应沐儿。\n\n“好吧，我今天就下回厨，给两个小家伙做碗面。”萱姨挽起衣袖，向内堂走去。“那便先谢谢萱姨了。”尽管常来这里，秦月对萱姨还是十分恭敬的。“你这孩子，把萱姨当外人了。”说着，萱姨白了秦月一眼，自顾自的走进内堂。\n\n见萱姨离开，秦月自嘲笑刚刚自己说错了话。“秦月哥哥，我们先找个地方坐下吧。”沐儿问道。“嗯”秦月便拉起沐儿向靠窗的位子走去---那一直是他们的位子。\n\n“哟，这不是我们常山镇的大乐师秦月嘛，哎，哥儿几个，要不咱们请他给咱们奏几段乐，给咱助助兴？”刚走几步，秦月便被声音叫住。“严武，你太过分了。”沐儿自然听出了严武的话中意。严武是严家子祠，严家又是常山镇一大户人家，也是常山镇三大家族之一。其中镇上玄昶学院大部分的财力支持都要靠严家，可见严家的势力有多恐怖。有这样财大气粗的家族，足以让严武在常山镇上横行霸道。而严武挑衅的目标只有一个，那就是让秦月在沐儿面前出丑。\n\n“我们走，不用理他。”秦月低声道。\n\n“哟，倒挺狂的。你不是不修炼诀元吗？你不是吹那破笛子很厉害吗？那给我们几个表演表演啊？”严武跨过几步，闪到秦月面前，显然使用了某种步法。\n\n“滚。”秦月冷冷吐出一个字。尽管表面十分冷静，只有沐儿知道他是真生气了。秦月倒不是因为严武对自己的羞辱而动怒，这样的羞辱秦月忍过不一回，而是因为严武亵渎了父母留给他的清读笛。\n\n“你小子，就是找死。”严武狠狠地说道，突然挥起手劈向秦月。\n\n“你混蛋。”沐儿察觉到严武不对劲，全身散发出青色之气，一个侧身便护在秦月面前。严武的手劈在那青色之气上便被弹开，连带严武后退了几步。“好啊，沐儿妹妹也修练了诀元了。”一击末中，严武僵笑道，迅速向自己的兄弟们使了个眼色。\n\n“小心。”沐儿未反应过来，身后的人便冲了过来。秦月镇静地抬起右手护着攻向沐儿的攻击，任由另一侧的攻击落在身上。\n\n“砰”清碎的响声响起，似乎是什么东西碎了。","date":"2025-07-28T01:30:12.913Z","updated":"2024-07-12T10:00:46.178Z","path":"novel/三、笛碎.html","title":"","comments":1,"layout":"page","_id":"cmhc3m3uc0008xdp855b1dcw2","content":"<p>第三章  笛碎</p>\n<p>“这是…”秦月望着这团青色之气，“诀源！！！”  诀源，想必在这片天地的人都应该知道这样的东西。在这片天地的人，每个人都具有修炼诀元的资质，只要有导师的引导，以致不会走火入魔，每个人都有机会修炼出属于自己的诀气之元。这样的人便脱离平凡人的行列，一举成为诀师。一个人能修唤出诀气之元，便是诀师的标志，而诀源则是诀元的另一种凝聚态。能够凝聚出诀源，便是在诀元修炼上小有成就了。</p>\n<p>简单地说，这片天地下人分为两类，一类是凡人，则另一类就是诀师。凡人和诀师的区别便是能否修唤出诀元。然而这样说也不尽然，在这片光怪陆离的天地，有许许多多奇怪的事发生。不修唤出诀气但异于凡人的却有存在，这类人便是战士。战士的狂横，足以算得上诀师，甚至可以说在某些方面超越诀师，比如意志力。</p>\n<p>沐儿能够凝聚出诀源，秦月并不惊讶，毕竟她的父亲是风老。尽管风老并没有在他面前展现过，但秦月仍觉得风老的实力高深莫测。又想到自己连最基本的诀元修唤不出，秦月无奈地叹了口气。  似乎觉察到秦月的悲伤，冰雪聪明的沐儿便明白了秦月内心的痛苦，当下嘟嘟囔着:“爹爹真是的。为什么不让秦月哥哥修炼诀元呢？”“好了，你个小古灵精怪，就别去折腾你爹了，风老他也是为我好。”见沐儿乖乖地点头，秦月笑了笑，“今天庆祝沐儿凝聚出诀源，我请客。”</p>\n<p>“好耶。”沐儿笑嘻嘻地欢呼，“秦月哥哥，去素萱馆吧，好久没见萱姨了。”秦月默许。</p>\n<p>素萱馆。</p>\n<p>“萱姨，好久不见了。”“你这小丫头，这些天没来，是不是把萱姨给忘了”站在沐儿面前的丽人就是素萱馆的主人，萱姨。这女人年龄倒也不大，看上来只有二十几岁，更像是秦月和沐儿的姐姐。</p>\n<p>“哪有，沐儿天天都在想着萱姨做的素面呢！是不是？秦月哥哥。”沐儿依旧笑嘻嘻的。秦月微微一笑，像是在回应沐儿。</p>\n<p>“好吧，我今天就下回厨，给两个小家伙做碗面。”萱姨挽起衣袖，向内堂走去。“那便先谢谢萱姨了。”尽管常来这里，秦月对萱姨还是十分恭敬的。“你这孩子，把萱姨当外人了。”说着，萱姨白了秦月一眼，自顾自的走进内堂。</p>\n<p>见萱姨离开，秦月自嘲笑刚刚自己说错了话。“秦月哥哥，我们先找个地方坐下吧。”沐儿问道。“嗯”秦月便拉起沐儿向靠窗的位子走去—那一直是他们的位子。</p>\n<p>“哟，这不是我们常山镇的大乐师秦月嘛，哎，哥儿几个，要不咱们请他给咱们奏几段乐，给咱助助兴？”刚走几步，秦月便被声音叫住。“严武，你太过分了。”沐儿自然听出了严武的话中意。严武是严家子祠，严家又是常山镇一大户人家，也是常山镇三大家族之一。其中镇上玄昶学院大部分的财力支持都要靠严家，可见严家的势力有多恐怖。有这样财大气粗的家族，足以让严武在常山镇上横行霸道。而严武挑衅的目标只有一个，那就是让秦月在沐儿面前出丑。</p>\n<p>“我们走，不用理他。”秦月低声道。</p>\n<p>“哟，倒挺狂的。你不是不修炼诀元吗？你不是吹那破笛子很厉害吗？那给我们几个表演表演啊？”严武跨过几步，闪到秦月面前，显然使用了某种步法。</p>\n<p>“滚。”秦月冷冷吐出一个字。尽管表面十分冷静，只有沐儿知道他是真生气了。秦月倒不是因为严武对自己的羞辱而动怒，这样的羞辱秦月忍过不一回，而是因为严武亵渎了父母留给他的清读笛。</p>\n<p>“你小子，就是找死。”严武狠狠地说道，突然挥起手劈向秦月。</p>\n<p>“你混蛋。”沐儿察觉到严武不对劲，全身散发出青色之气，一个侧身便护在秦月面前。严武的手劈在那青色之气上便被弹开，连带严武后退了几步。“好啊，沐儿妹妹也修练了诀元了。”一击末中，严武僵笑道，迅速向自己的兄弟们使了个眼色。</p>\n<p>“小心。”沐儿未反应过来，身后的人便冲了过来。秦月镇静地抬起右手护着攻向沐儿的攻击，任由另一侧的攻击落在身上。</p>\n<p>“砰”清碎的响声响起，似乎是什么东西碎了。</p>\n","excerpt":"","more":"<p>第三章  笛碎</p>\n<p>“这是…”秦月望着这团青色之气，“诀源！！！”  诀源，想必在这片天地的人都应该知道这样的东西。在这片天地的人，每个人都具有修炼诀元的资质，只要有导师的引导，以致不会走火入魔，每个人都有机会修炼出属于自己的诀气之元。这样的人便脱离平凡人的行列，一举成为诀师。一个人能修唤出诀气之元，便是诀师的标志，而诀源则是诀元的另一种凝聚态。能够凝聚出诀源，便是在诀元修炼上小有成就了。</p>\n<p>简单地说，这片天地下人分为两类，一类是凡人，则另一类就是诀师。凡人和诀师的区别便是能否修唤出诀元。然而这样说也不尽然，在这片光怪陆离的天地，有许许多多奇怪的事发生。不修唤出诀气但异于凡人的却有存在，这类人便是战士。战士的狂横，足以算得上诀师，甚至可以说在某些方面超越诀师，比如意志力。</p>\n<p>沐儿能够凝聚出诀源，秦月并不惊讶，毕竟她的父亲是风老。尽管风老并没有在他面前展现过，但秦月仍觉得风老的实力高深莫测。又想到自己连最基本的诀元修唤不出，秦月无奈地叹了口气。  似乎觉察到秦月的悲伤，冰雪聪明的沐儿便明白了秦月内心的痛苦，当下嘟嘟囔着:“爹爹真是的。为什么不让秦月哥哥修炼诀元呢？”“好了，你个小古灵精怪，就别去折腾你爹了，风老他也是为我好。”见沐儿乖乖地点头，秦月笑了笑，“今天庆祝沐儿凝聚出诀源，我请客。”</p>\n<p>“好耶。”沐儿笑嘻嘻地欢呼，“秦月哥哥，去素萱馆吧，好久没见萱姨了。”秦月默许。</p>\n<p>素萱馆。</p>\n<p>“萱姨，好久不见了。”“你这小丫头，这些天没来，是不是把萱姨给忘了”站在沐儿面前的丽人就是素萱馆的主人，萱姨。这女人年龄倒也不大，看上来只有二十几岁，更像是秦月和沐儿的姐姐。</p>\n<p>“哪有，沐儿天天都在想着萱姨做的素面呢！是不是？秦月哥哥。”沐儿依旧笑嘻嘻的。秦月微微一笑，像是在回应沐儿。</p>\n<p>“好吧，我今天就下回厨，给两个小家伙做碗面。”萱姨挽起衣袖，向内堂走去。“那便先谢谢萱姨了。”尽管常来这里，秦月对萱姨还是十分恭敬的。“你这孩子，把萱姨当外人了。”说着，萱姨白了秦月一眼，自顾自的走进内堂。</p>\n<p>见萱姨离开，秦月自嘲笑刚刚自己说错了话。“秦月哥哥，我们先找个地方坐下吧。”沐儿问道。“嗯”秦月便拉起沐儿向靠窗的位子走去—那一直是他们的位子。</p>\n<p>“哟，这不是我们常山镇的大乐师秦月嘛，哎，哥儿几个，要不咱们请他给咱们奏几段乐，给咱助助兴？”刚走几步，秦月便被声音叫住。“严武，你太过分了。”沐儿自然听出了严武的话中意。严武是严家子祠，严家又是常山镇一大户人家，也是常山镇三大家族之一。其中镇上玄昶学院大部分的财力支持都要靠严家，可见严家的势力有多恐怖。有这样财大气粗的家族，足以让严武在常山镇上横行霸道。而严武挑衅的目标只有一个，那就是让秦月在沐儿面前出丑。</p>\n<p>“我们走，不用理他。”秦月低声道。</p>\n<p>“哟，倒挺狂的。你不是不修炼诀元吗？你不是吹那破笛子很厉害吗？那给我们几个表演表演啊？”严武跨过几步，闪到秦月面前，显然使用了某种步法。</p>\n<p>“滚。”秦月冷冷吐出一个字。尽管表面十分冷静，只有沐儿知道他是真生气了。秦月倒不是因为严武对自己的羞辱而动怒，这样的羞辱秦月忍过不一回，而是因为严武亵渎了父母留给他的清读笛。</p>\n<p>“你小子，就是找死。”严武狠狠地说道，突然挥起手劈向秦月。</p>\n<p>“你混蛋。”沐儿察觉到严武不对劲，全身散发出青色之气，一个侧身便护在秦月面前。严武的手劈在那青色之气上便被弹开，连带严武后退了几步。“好啊，沐儿妹妹也修练了诀元了。”一击末中，严武僵笑道，迅速向自己的兄弟们使了个眼色。</p>\n<p>“小心。”沐儿未反应过来，身后的人便冲了过来。秦月镇静地抬起右手护着攻向沐儿的攻击，任由另一侧的攻击落在身上。</p>\n<p>“砰”清碎的响声响起，似乎是什么东西碎了。</p>\n"},{"_content":"第二章 清读笛、赋\n\n阳光懒洋洋地洒在巨树上，树影交错，格外美丽。树林深处有两处身影，一处便是秦月，另一处则是那位老人。  “风老，我不明白，为什么要我十几年学这些没用的东西，为什么我不能像其他人一样进入玄昶学院，和他们一起修练诀元呢？”面前这位老人就是秦月口中所说的风老，风岩。望着秦月迷惘的眼神，风老摇了摇头。十一年来，这样的问题秦月问了上千遍了。  “这是你父亲留下来的，他希望你学会。”风老含糊地说出了这个一直没变的理由，“好了，《清读赋》的最后一节你可曾练好了？”  “嗯”说着，一道白影从袖间滑入秦月的手中，这便是清读笛。清读笛长约七寸，笛身毫无杂色纹路，通体乳白，晶莹剔透，阳光下能发现其中一丝丝的碧海之蓝，十分奇异。笛的一端用白绳系着一个菱状白色物件，里面装着莫名的青色液体，散发出清新的幽香。  清读笛、赋本为一体，是秦月父母留给他两件物品之一，所以秦月一直小心翼翼保护着，唯恐摔坏了笛子，摔破了父母这仅有的留物。将笛子凑到嘴边，熟悉的冰凉之意涌上心头，清新优美的旋律便回荡在这片天地，万籁俱寂，惟有笛声回旋在天空中…\n\n“好”迷漫在这笛声中，风老不由得失声叫好。忽感失态，便轻咳两声。\n\n秦月五岁被他收养，便开始学笛。经过一年的训练，六岁接触《清读赋》。时至今日，秦月终于能够完整出将这首曲子演奏出来。十一年了，而风老又一次听到了这首曲子。\n\n秦月这些年来的努力和坚持，风老是有目共睹的。《清读赋》，赋乐，以单乐器笛演奏，分为为上、下两部，每部分八篇，每篇分八节，共一百二十八节。如此繁重的赋乐，足以让大多数的少年望而却步，而秦月凭着自己的毅力，竟将其完整的习会了。\n\n秦月并没有被身边的叫好声干扰，一心将曲子吹完。\n\n一曲终罢，风老满脸激动，“这《清读赋》你终于成功了，也不枉我这些年来的教导。好了，今天你够累的，下山休息吧。”\n\n纵使秦月性情冷静沉着，喜悦之情也不免流露在脸上。秦月将笛子收入袖间，疑惑地问:“风老，那我明天训练什么？”\n\n风老笑了笑，“明天的事明天再说吧。”\n\n风老的性格秦月很清楚，便不再问了。“那我先…”\n\n“秦月哥哥，就知道你在这呢！”山路那头站着一位小姑娘，水蓝色的眼睛正盯着秦月。\n\n“这两天这丫头一直在找你，问了我好几回了，”风老摇摇头，苦笑道，“怕妨碍你练习，我没有告诉她，只是说这两天你要来这。”\n\n女孩笑了笑，快步走了上来，“你不要怪爹爹了，是我任性，让他告诉我的。”\n\n女孩身着紫衫，青色的长发随风飘散。当她走近了，秦月才注意女孩脸上汗珠。\n\n“沐儿，你来干什么呢？”秦月微笑。\n\n“走啦。”被称为沐儿的女孩向前走了一步，抓住秦月的手，向山下跑去。\n\n面对风沐儿，秦月也很无奈，毕竟是风老的女儿，秦月一直把她当作是自己的亲妹妹。\n\n“沐儿，你带我去哪呢？”秦月苦笑道。\n\n“我们的私密基地啊，让秦月哥哥看个东西。”沐儿终于停下了。熟悉的环境映入秦月眼帘，周围尽是竹林，竹叶飞舞，一片翠绿，这就是沐儿所说的基地了。“来，看看这个。”\n\n沐儿伸出玉手，一丝青色之气便在手中凝聚，渐渐地，青色之气便凝结成形，不断幻化，虽然很轻薄，但仍能看出凝聚之形似树，又幻化成小兽。\n\n“这是…”秦月望着这团青色之气。","source":"novel/二、清读笛、赋.md","raw":"第二章 清读笛、赋\n\n阳光懒洋洋地洒在巨树上，树影交错，格外美丽。树林深处有两处身影，一处便是秦月，另一处则是那位老人。  “风老，我不明白，为什么要我十几年学这些没用的东西，为什么我不能像其他人一样进入玄昶学院，和他们一起修练诀元呢？”面前这位老人就是秦月口中所说的风老，风岩。望着秦月迷惘的眼神，风老摇了摇头。十一年来，这样的问题秦月问了上千遍了。  “这是你父亲留下来的，他希望你学会。”风老含糊地说出了这个一直没变的理由，“好了，《清读赋》的最后一节你可曾练好了？”  “嗯”说着，一道白影从袖间滑入秦月的手中，这便是清读笛。清读笛长约七寸，笛身毫无杂色纹路，通体乳白，晶莹剔透，阳光下能发现其中一丝丝的碧海之蓝，十分奇异。笛的一端用白绳系着一个菱状白色物件，里面装着莫名的青色液体，散发出清新的幽香。  清读笛、赋本为一体，是秦月父母留给他两件物品之一，所以秦月一直小心翼翼保护着，唯恐摔坏了笛子，摔破了父母这仅有的留物。将笛子凑到嘴边，熟悉的冰凉之意涌上心头，清新优美的旋律便回荡在这片天地，万籁俱寂，惟有笛声回旋在天空中…\n\n“好”迷漫在这笛声中，风老不由得失声叫好。忽感失态，便轻咳两声。\n\n秦月五岁被他收养，便开始学笛。经过一年的训练，六岁接触《清读赋》。时至今日，秦月终于能够完整出将这首曲子演奏出来。十一年了，而风老又一次听到了这首曲子。\n\n秦月这些年来的努力和坚持，风老是有目共睹的。《清读赋》，赋乐，以单乐器笛演奏，分为为上、下两部，每部分八篇，每篇分八节，共一百二十八节。如此繁重的赋乐，足以让大多数的少年望而却步，而秦月凭着自己的毅力，竟将其完整的习会了。\n\n秦月并没有被身边的叫好声干扰，一心将曲子吹完。\n\n一曲终罢，风老满脸激动，“这《清读赋》你终于成功了，也不枉我这些年来的教导。好了，今天你够累的，下山休息吧。”\n\n纵使秦月性情冷静沉着，喜悦之情也不免流露在脸上。秦月将笛子收入袖间，疑惑地问:“风老，那我明天训练什么？”\n\n风老笑了笑，“明天的事明天再说吧。”\n\n风老的性格秦月很清楚，便不再问了。“那我先…”\n\n“秦月哥哥，就知道你在这呢！”山路那头站着一位小姑娘，水蓝色的眼睛正盯着秦月。\n\n“这两天这丫头一直在找你，问了我好几回了，”风老摇摇头，苦笑道，“怕妨碍你练习，我没有告诉她，只是说这两天你要来这。”\n\n女孩笑了笑，快步走了上来，“你不要怪爹爹了，是我任性，让他告诉我的。”\n\n女孩身着紫衫，青色的长发随风飘散。当她走近了，秦月才注意女孩脸上汗珠。\n\n“沐儿，你来干什么呢？”秦月微笑。\n\n“走啦。”被称为沐儿的女孩向前走了一步，抓住秦月的手，向山下跑去。\n\n面对风沐儿，秦月也很无奈，毕竟是风老的女儿，秦月一直把她当作是自己的亲妹妹。\n\n“沐儿，你带我去哪呢？”秦月苦笑道。\n\n“我们的私密基地啊，让秦月哥哥看个东西。”沐儿终于停下了。熟悉的环境映入秦月眼帘，周围尽是竹林，竹叶飞舞，一片翠绿，这就是沐儿所说的基地了。“来，看看这个。”\n\n沐儿伸出玉手，一丝青色之气便在手中凝聚，渐渐地，青色之气便凝结成形，不断幻化，虽然很轻薄，但仍能看出凝聚之形似树，又幻化成小兽。\n\n“这是…”秦月望着这团青色之气。","date":"2025-07-28T01:30:12.914Z","updated":"2024-07-12T07:21:44.011Z","path":"novel/二、清读笛、赋.html","title":"","comments":1,"layout":"page","_id":"cmhc3m3uc000axdp8aclz66r9","content":"<p>第二章 清读笛、赋</p>\n<p>阳光懒洋洋地洒在巨树上，树影交错，格外美丽。树林深处有两处身影，一处便是秦月，另一处则是那位老人。  “风老，我不明白，为什么要我十几年学这些没用的东西，为什么我不能像其他人一样进入玄昶学院，和他们一起修练诀元呢？”面前这位老人就是秦月口中所说的风老，风岩。望着秦月迷惘的眼神，风老摇了摇头。十一年来，这样的问题秦月问了上千遍了。  “这是你父亲留下来的，他希望你学会。”风老含糊地说出了这个一直没变的理由，“好了，《清读赋》的最后一节你可曾练好了？”  “嗯”说着，一道白影从袖间滑入秦月的手中，这便是清读笛。清读笛长约七寸，笛身毫无杂色纹路，通体乳白，晶莹剔透，阳光下能发现其中一丝丝的碧海之蓝，十分奇异。笛的一端用白绳系着一个菱状白色物件，里面装着莫名的青色液体，散发出清新的幽香。  清读笛、赋本为一体，是秦月父母留给他两件物品之一，所以秦月一直小心翼翼保护着，唯恐摔坏了笛子，摔破了父母这仅有的留物。将笛子凑到嘴边，熟悉的冰凉之意涌上心头，清新优美的旋律便回荡在这片天地，万籁俱寂，惟有笛声回旋在天空中…</p>\n<p>“好”迷漫在这笛声中，风老不由得失声叫好。忽感失态，便轻咳两声。</p>\n<p>秦月五岁被他收养，便开始学笛。经过一年的训练，六岁接触《清读赋》。时至今日，秦月终于能够完整出将这首曲子演奏出来。十一年了，而风老又一次听到了这首曲子。</p>\n<p>秦月这些年来的努力和坚持，风老是有目共睹的。《清读赋》，赋乐，以单乐器笛演奏，分为为上、下两部，每部分八篇，每篇分八节，共一百二十八节。如此繁重的赋乐，足以让大多数的少年望而却步，而秦月凭着自己的毅力，竟将其完整的习会了。</p>\n<p>秦月并没有被身边的叫好声干扰，一心将曲子吹完。</p>\n<p>一曲终罢，风老满脸激动，“这《清读赋》你终于成功了，也不枉我这些年来的教导。好了，今天你够累的，下山休息吧。”</p>\n<p>纵使秦月性情冷静沉着，喜悦之情也不免流露在脸上。秦月将笛子收入袖间，疑惑地问:“风老，那我明天训练什么？”</p>\n<p>风老笑了笑，“明天的事明天再说吧。”</p>\n<p>风老的性格秦月很清楚，便不再问了。“那我先…”</p>\n<p>“秦月哥哥，就知道你在这呢！”山路那头站着一位小姑娘，水蓝色的眼睛正盯着秦月。</p>\n<p>“这两天这丫头一直在找你，问了我好几回了，”风老摇摇头，苦笑道，“怕妨碍你练习，我没有告诉她，只是说这两天你要来这。”</p>\n<p>女孩笑了笑，快步走了上来，“你不要怪爹爹了，是我任性，让他告诉我的。”</p>\n<p>女孩身着紫衫，青色的长发随风飘散。当她走近了，秦月才注意女孩脸上汗珠。</p>\n<p>“沐儿，你来干什么呢？”秦月微笑。</p>\n<p>“走啦。”被称为沐儿的女孩向前走了一步，抓住秦月的手，向山下跑去。</p>\n<p>面对风沐儿，秦月也很无奈，毕竟是风老的女儿，秦月一直把她当作是自己的亲妹妹。</p>\n<p>“沐儿，你带我去哪呢？”秦月苦笑道。</p>\n<p>“我们的私密基地啊，让秦月哥哥看个东西。”沐儿终于停下了。熟悉的环境映入秦月眼帘，周围尽是竹林，竹叶飞舞，一片翠绿，这就是沐儿所说的基地了。“来，看看这个。”</p>\n<p>沐儿伸出玉手，一丝青色之气便在手中凝聚，渐渐地，青色之气便凝结成形，不断幻化，虽然很轻薄，但仍能看出凝聚之形似树，又幻化成小兽。</p>\n<p>“这是…”秦月望着这团青色之气。</p>\n","excerpt":"","more":"<p>第二章 清读笛、赋</p>\n<p>阳光懒洋洋地洒在巨树上，树影交错，格外美丽。树林深处有两处身影，一处便是秦月，另一处则是那位老人。  “风老，我不明白，为什么要我十几年学这些没用的东西，为什么我不能像其他人一样进入玄昶学院，和他们一起修练诀元呢？”面前这位老人就是秦月口中所说的风老，风岩。望着秦月迷惘的眼神，风老摇了摇头。十一年来，这样的问题秦月问了上千遍了。  “这是你父亲留下来的，他希望你学会。”风老含糊地说出了这个一直没变的理由，“好了，《清读赋》的最后一节你可曾练好了？”  “嗯”说着，一道白影从袖间滑入秦月的手中，这便是清读笛。清读笛长约七寸，笛身毫无杂色纹路，通体乳白，晶莹剔透，阳光下能发现其中一丝丝的碧海之蓝，十分奇异。笛的一端用白绳系着一个菱状白色物件，里面装着莫名的青色液体，散发出清新的幽香。  清读笛、赋本为一体，是秦月父母留给他两件物品之一，所以秦月一直小心翼翼保护着，唯恐摔坏了笛子，摔破了父母这仅有的留物。将笛子凑到嘴边，熟悉的冰凉之意涌上心头，清新优美的旋律便回荡在这片天地，万籁俱寂，惟有笛声回旋在天空中…</p>\n<p>“好”迷漫在这笛声中，风老不由得失声叫好。忽感失态，便轻咳两声。</p>\n<p>秦月五岁被他收养，便开始学笛。经过一年的训练，六岁接触《清读赋》。时至今日，秦月终于能够完整出将这首曲子演奏出来。十一年了，而风老又一次听到了这首曲子。</p>\n<p>秦月这些年来的努力和坚持，风老是有目共睹的。《清读赋》，赋乐，以单乐器笛演奏，分为为上、下两部，每部分八篇，每篇分八节，共一百二十八节。如此繁重的赋乐，足以让大多数的少年望而却步，而秦月凭着自己的毅力，竟将其完整的习会了。</p>\n<p>秦月并没有被身边的叫好声干扰，一心将曲子吹完。</p>\n<p>一曲终罢，风老满脸激动，“这《清读赋》你终于成功了，也不枉我这些年来的教导。好了，今天你够累的，下山休息吧。”</p>\n<p>纵使秦月性情冷静沉着，喜悦之情也不免流露在脸上。秦月将笛子收入袖间，疑惑地问:“风老，那我明天训练什么？”</p>\n<p>风老笑了笑，“明天的事明天再说吧。”</p>\n<p>风老的性格秦月很清楚，便不再问了。“那我先…”</p>\n<p>“秦月哥哥，就知道你在这呢！”山路那头站着一位小姑娘，水蓝色的眼睛正盯着秦月。</p>\n<p>“这两天这丫头一直在找你，问了我好几回了，”风老摇摇头，苦笑道，“怕妨碍你练习，我没有告诉她，只是说这两天你要来这。”</p>\n<p>女孩笑了笑，快步走了上来，“你不要怪爹爹了，是我任性，让他告诉我的。”</p>\n<p>女孩身着紫衫，青色的长发随风飘散。当她走近了，秦月才注意女孩脸上汗珠。</p>\n<p>“沐儿，你来干什么呢？”秦月微笑。</p>\n<p>“走啦。”被称为沐儿的女孩向前走了一步，抓住秦月的手，向山下跑去。</p>\n<p>面对风沐儿，秦月也很无奈，毕竟是风老的女儿，秦月一直把她当作是自己的亲妹妹。</p>\n<p>“沐儿，你带我去哪呢？”秦月苦笑道。</p>\n<p>“我们的私密基地啊，让秦月哥哥看个东西。”沐儿终于停下了。熟悉的环境映入秦月眼帘，周围尽是竹林，竹叶飞舞，一片翠绿，这就是沐儿所说的基地了。“来，看看这个。”</p>\n<p>沐儿伸出玉手，一丝青色之气便在手中凝聚，渐渐地，青色之气便凝结成形，不断幻化，虽然很轻薄，但仍能看出凝聚之形似树，又幻化成小兽。</p>\n<p>“这是…”秦月望着这团青色之气。</p>\n"},{"_content":"\n第五章  秘密\n\n“通、拓诀师？”\n\n风老以前从没和秦月说过这些。\n\n“通诀师和拓诀师都是要修炼诀元，唯一不同的是拓诀师催动诀元的手法更为繁琐，隐晦，修炼起来更加地艰辛，许许多多的通诀师想要在拓诀上一展手脚，面对如些繁重的修炼不得不知难而退，所以即使在远古，拓诀师数量也不多，现在就更少了。”\n\n“更少了？”秦月不解，按理说，拓诀师修炼困难，但也不至于越来越少了。”\n\n“你不知道这些也不奇怪，能知道这些的只有那些至今一直保留的远古宗派或远古家族。相传数百年前在这片天地下，出现了一位通诀天才，十岁他便凝出诀元，后来痴迷通诀，一心一意成为通诀师，在他认为诀师之间的战斗就应该是攻击与防守，而那些迷惑敌人，布阵，召唤等都是无用的。最终在不懈努力下，他问诀破天，成为问天师---这片天地的强者。也许是因为拓诀太难修炼，当时的人们不约而同地在他的领导下勤学通诀，这样，拓诀师就逐渐的变少。直到今天，消失在世人的脑海中。想想看，当今天下除了一些大势力能够重视拓诀的发展，其他的再没有任何人知道诀师了。”\n\n秦月十分欣赏风老所说的那位天才，但他坚信自己有一天会到达那个人的地步。“可是这和父亲有什么关系，难道父亲是…”\n\n“不错，你的父亲就是拓诀师，并且是一名优秀的幻术师。”风老依旧严肃。\n\n“幻术师？！”秦月有些兴奋，毕竟在他的记忆里只有父亲离开时的背影，却不知道父亲如此地了不起。\n\n“嗯，这个是你父亲留给你的锦囊，我想是时候该给你了。”风老从怀中取出一个灰色锦囊，递给秦月。\n\n秦月缓缓伸出手，接下这锦囊，轻轻地撕开。一束流光便窜到自己的脑海里。\n\n虚白空间。\n\n一位高大的身影站在那里，缓缓地转过身，“孩子，好久不见。”\n\n“父亲！”见到这个熟悉的面孔，这些年来的辛酸，思念一下子涌上心头，秦月禁不住泪流，一下子扑向秦天，不料落空。“怎么回事？”\n\n“傻孩子，你现在看到的不过是父亲的一道残像罢了。”\n\n秦天苦笑，有些心痛地说。“那父亲，你在哪里？”秦月问。“很远很远的地方，现在的你还不能到达那个地方。”\n\n秦天想摸摸孩子的头，愣了一下，叹了口气，“我知道你有很多的问题想问我，但现在我还不能告诉你，因为现在的你太弱小，这些答案对你百害无一利。如果想要知道这些答案，你就要好好修炼，成为强者，这样，一切的问题都会迎刃而解。”“嗯！”秦月抹去眼角的眼泪，努力说服自己不要再流泪。“好孩子，我想你已经知道了我的身份，那清读笛便是我能留给你的最后留物。好了，时间也差不多了，我也该走了。”说着，秦天的身体渐渐的透明起来，慢慢地化作颗粒般细小的荧光，“记着，你是我秦天的儿子，我一直相信你能成为比我还要强的人。还有，不要再流泪，你已经长大了，去努力撑起自己的一片天。我和你的母亲在远方等着你。”\n\n“父亲，父亲…”看着父亲消失在自己眼前，秦月很无助。\n\n现实。\n\n“风老，清读笛这些年来为什么不起作用？”秦天边擦眼泪边问。“现在可以了，你试试吹一下。”风老递过清读笛，说。秦月半信半疑，将笛子凑到嘴边，一曲清新脱俗的曲子响起…\n\n“啊？！痛…痛。”巨痛传入秦月的脑海里，秦月赶快停了下来。“怎么会这样？”\n\n“你已经把你父亲设的封印初步解开了。清读笛不再只是乐器，而是幻器。我说过，幻术师是拓诀师中的一种，他们通过对诀元的运用，注入幻器，产生影响敌人视觉，听觉，嗅觉，触觉，感觉等特殊效果，让敌人置身于幻境之中，从而使他们在现实中失去战斗能力。而你的身体内并没有诀元，所以你才会因为受自己的笛声影响。”风老将他要说的都说了出来，心中松了口气。“那我现在是不是可以修炼诀元了？”见风老轻嗯一声，秦月眼中闪烁着火热。\n\n两天后。\n\n“仪象归道，自相于生，唤。”\n\n\n\n（有些情节写的太仓促，见谅了。）","source":"novel/五、秘密.md","raw":"\n第五章  秘密\n\n“通、拓诀师？”\n\n风老以前从没和秦月说过这些。\n\n“通诀师和拓诀师都是要修炼诀元，唯一不同的是拓诀师催动诀元的手法更为繁琐，隐晦，修炼起来更加地艰辛，许许多多的通诀师想要在拓诀上一展手脚，面对如些繁重的修炼不得不知难而退，所以即使在远古，拓诀师数量也不多，现在就更少了。”\n\n“更少了？”秦月不解，按理说，拓诀师修炼困难，但也不至于越来越少了。”\n\n“你不知道这些也不奇怪，能知道这些的只有那些至今一直保留的远古宗派或远古家族。相传数百年前在这片天地下，出现了一位通诀天才，十岁他便凝出诀元，后来痴迷通诀，一心一意成为通诀师，在他认为诀师之间的战斗就应该是攻击与防守，而那些迷惑敌人，布阵，召唤等都是无用的。最终在不懈努力下，他问诀破天，成为问天师---这片天地的强者。也许是因为拓诀太难修炼，当时的人们不约而同地在他的领导下勤学通诀，这样，拓诀师就逐渐的变少。直到今天，消失在世人的脑海中。想想看，当今天下除了一些大势力能够重视拓诀的发展，其他的再没有任何人知道诀师了。”\n\n秦月十分欣赏风老所说的那位天才，但他坚信自己有一天会到达那个人的地步。“可是这和父亲有什么关系，难道父亲是…”\n\n“不错，你的父亲就是拓诀师，并且是一名优秀的幻术师。”风老依旧严肃。\n\n“幻术师？！”秦月有些兴奋，毕竟在他的记忆里只有父亲离开时的背影，却不知道父亲如此地了不起。\n\n“嗯，这个是你父亲留给你的锦囊，我想是时候该给你了。”风老从怀中取出一个灰色锦囊，递给秦月。\n\n秦月缓缓伸出手，接下这锦囊，轻轻地撕开。一束流光便窜到自己的脑海里。\n\n虚白空间。\n\n一位高大的身影站在那里，缓缓地转过身，“孩子，好久不见。”\n\n“父亲！”见到这个熟悉的面孔，这些年来的辛酸，思念一下子涌上心头，秦月禁不住泪流，一下子扑向秦天，不料落空。“怎么回事？”\n\n“傻孩子，你现在看到的不过是父亲的一道残像罢了。”\n\n秦天苦笑，有些心痛地说。“那父亲，你在哪里？”秦月问。“很远很远的地方，现在的你还不能到达那个地方。”\n\n秦天想摸摸孩子的头，愣了一下，叹了口气，“我知道你有很多的问题想问我，但现在我还不能告诉你，因为现在的你太弱小，这些答案对你百害无一利。如果想要知道这些答案，你就要好好修炼，成为强者，这样，一切的问题都会迎刃而解。”“嗯！”秦月抹去眼角的眼泪，努力说服自己不要再流泪。“好孩子，我想你已经知道了我的身份，那清读笛便是我能留给你的最后留物。好了，时间也差不多了，我也该走了。”说着，秦天的身体渐渐的透明起来，慢慢地化作颗粒般细小的荧光，“记着，你是我秦天的儿子，我一直相信你能成为比我还要强的人。还有，不要再流泪，你已经长大了，去努力撑起自己的一片天。我和你的母亲在远方等着你。”\n\n“父亲，父亲…”看着父亲消失在自己眼前，秦月很无助。\n\n现实。\n\n“风老，清读笛这些年来为什么不起作用？”秦天边擦眼泪边问。“现在可以了，你试试吹一下。”风老递过清读笛，说。秦月半信半疑，将笛子凑到嘴边，一曲清新脱俗的曲子响起…\n\n“啊？！痛…痛。”巨痛传入秦月的脑海里，秦月赶快停了下来。“怎么会这样？”\n\n“你已经把你父亲设的封印初步解开了。清读笛不再只是乐器，而是幻器。我说过，幻术师是拓诀师中的一种，他们通过对诀元的运用，注入幻器，产生影响敌人视觉，听觉，嗅觉，触觉，感觉等特殊效果，让敌人置身于幻境之中，从而使他们在现实中失去战斗能力。而你的身体内并没有诀元，所以你才会因为受自己的笛声影响。”风老将他要说的都说了出来，心中松了口气。“那我现在是不是可以修炼诀元了？”见风老轻嗯一声，秦月眼中闪烁着火热。\n\n两天后。\n\n“仪象归道，自相于生，唤。”\n\n\n\n（有些情节写的太仓促，见谅了。）","date":"2025-07-28T01:30:12.913Z","updated":"2024-07-15T09:48:41.544Z","path":"novel/五、秘密.html","title":"","comments":1,"layout":"page","_id":"cmhc3m3ud000fxdp829xv3gix","content":"<p>第五章  秘密</p>\n<p>“通、拓诀师？”</p>\n<p>风老以前从没和秦月说过这些。</p>\n<p>“通诀师和拓诀师都是要修炼诀元，唯一不同的是拓诀师催动诀元的手法更为繁琐，隐晦，修炼起来更加地艰辛，许许多多的通诀师想要在拓诀上一展手脚，面对如些繁重的修炼不得不知难而退，所以即使在远古，拓诀师数量也不多，现在就更少了。”</p>\n<p>“更少了？”秦月不解，按理说，拓诀师修炼困难，但也不至于越来越少了。”</p>\n<p>“你不知道这些也不奇怪，能知道这些的只有那些至今一直保留的远古宗派或远古家族。相传数百年前在这片天地下，出现了一位通诀天才，十岁他便凝出诀元，后来痴迷通诀，一心一意成为通诀师，在他认为诀师之间的战斗就应该是攻击与防守，而那些迷惑敌人，布阵，召唤等都是无用的。最终在不懈努力下，他问诀破天，成为问天师—这片天地的强者。也许是因为拓诀太难修炼，当时的人们不约而同地在他的领导下勤学通诀，这样，拓诀师就逐渐的变少。直到今天，消失在世人的脑海中。想想看，当今天下除了一些大势力能够重视拓诀的发展，其他的再没有任何人知道诀师了。”</p>\n<p>秦月十分欣赏风老所说的那位天才，但他坚信自己有一天会到达那个人的地步。“可是这和父亲有什么关系，难道父亲是…”</p>\n<p>“不错，你的父亲就是拓诀师，并且是一名优秀的幻术师。”风老依旧严肃。</p>\n<p>“幻术师？！”秦月有些兴奋，毕竟在他的记忆里只有父亲离开时的背影，却不知道父亲如此地了不起。</p>\n<p>“嗯，这个是你父亲留给你的锦囊，我想是时候该给你了。”风老从怀中取出一个灰色锦囊，递给秦月。</p>\n<p>秦月缓缓伸出手，接下这锦囊，轻轻地撕开。一束流光便窜到自己的脑海里。</p>\n<p>虚白空间。</p>\n<p>一位高大的身影站在那里，缓缓地转过身，“孩子，好久不见。”</p>\n<p>“父亲！”见到这个熟悉的面孔，这些年来的辛酸，思念一下子涌上心头，秦月禁不住泪流，一下子扑向秦天，不料落空。“怎么回事？”</p>\n<p>“傻孩子，你现在看到的不过是父亲的一道残像罢了。”</p>\n<p>秦天苦笑，有些心痛地说。“那父亲，你在哪里？”秦月问。“很远很远的地方，现在的你还不能到达那个地方。”</p>\n<p>秦天想摸摸孩子的头，愣了一下，叹了口气，“我知道你有很多的问题想问我，但现在我还不能告诉你，因为现在的你太弱小，这些答案对你百害无一利。如果想要知道这些答案，你就要好好修炼，成为强者，这样，一切的问题都会迎刃而解。”“嗯！”秦月抹去眼角的眼泪，努力说服自己不要再流泪。“好孩子，我想你已经知道了我的身份，那清读笛便是我能留给你的最后留物。好了，时间也差不多了，我也该走了。”说着，秦天的身体渐渐的透明起来，慢慢地化作颗粒般细小的荧光，“记着，你是我秦天的儿子，我一直相信你能成为比我还要强的人。还有，不要再流泪，你已经长大了，去努力撑起自己的一片天。我和你的母亲在远方等着你。”</p>\n<p>“父亲，父亲…”看着父亲消失在自己眼前，秦月很无助。</p>\n<p>现实。</p>\n<p>“风老，清读笛这些年来为什么不起作用？”秦天边擦眼泪边问。“现在可以了，你试试吹一下。”风老递过清读笛，说。秦月半信半疑，将笛子凑到嘴边，一曲清新脱俗的曲子响起…</p>\n<p>“啊？！痛…痛。”巨痛传入秦月的脑海里，秦月赶快停了下来。“怎么会这样？”</p>\n<p>“你已经把你父亲设的封印初步解开了。清读笛不再只是乐器，而是幻器。我说过，幻术师是拓诀师中的一种，他们通过对诀元的运用，注入幻器，产生影响敌人视觉，听觉，嗅觉，触觉，感觉等特殊效果，让敌人置身于幻境之中，从而使他们在现实中失去战斗能力。而你的身体内并没有诀元，所以你才会因为受自己的笛声影响。”风老将他要说的都说了出来，心中松了口气。“那我现在是不是可以修炼诀元了？”见风老轻嗯一声，秦月眼中闪烁着火热。</p>\n<p>两天后。</p>\n<p>“仪象归道，自相于生，唤。”</p>\n<p>（有些情节写的太仓促，见谅了。）</p>\n","excerpt":"","more":"<p>第五章  秘密</p>\n<p>“通、拓诀师？”</p>\n<p>风老以前从没和秦月说过这些。</p>\n<p>“通诀师和拓诀师都是要修炼诀元，唯一不同的是拓诀师催动诀元的手法更为繁琐，隐晦，修炼起来更加地艰辛，许许多多的通诀师想要在拓诀上一展手脚，面对如些繁重的修炼不得不知难而退，所以即使在远古，拓诀师数量也不多，现在就更少了。”</p>\n<p>“更少了？”秦月不解，按理说，拓诀师修炼困难，但也不至于越来越少了。”</p>\n<p>“你不知道这些也不奇怪，能知道这些的只有那些至今一直保留的远古宗派或远古家族。相传数百年前在这片天地下，出现了一位通诀天才，十岁他便凝出诀元，后来痴迷通诀，一心一意成为通诀师，在他认为诀师之间的战斗就应该是攻击与防守，而那些迷惑敌人，布阵，召唤等都是无用的。最终在不懈努力下，他问诀破天，成为问天师—这片天地的强者。也许是因为拓诀太难修炼，当时的人们不约而同地在他的领导下勤学通诀，这样，拓诀师就逐渐的变少。直到今天，消失在世人的脑海中。想想看，当今天下除了一些大势力能够重视拓诀的发展，其他的再没有任何人知道诀师了。”</p>\n<p>秦月十分欣赏风老所说的那位天才，但他坚信自己有一天会到达那个人的地步。“可是这和父亲有什么关系，难道父亲是…”</p>\n<p>“不错，你的父亲就是拓诀师，并且是一名优秀的幻术师。”风老依旧严肃。</p>\n<p>“幻术师？！”秦月有些兴奋，毕竟在他的记忆里只有父亲离开时的背影，却不知道父亲如此地了不起。</p>\n<p>“嗯，这个是你父亲留给你的锦囊，我想是时候该给你了。”风老从怀中取出一个灰色锦囊，递给秦月。</p>\n<p>秦月缓缓伸出手，接下这锦囊，轻轻地撕开。一束流光便窜到自己的脑海里。</p>\n<p>虚白空间。</p>\n<p>一位高大的身影站在那里，缓缓地转过身，“孩子，好久不见。”</p>\n<p>“父亲！”见到这个熟悉的面孔，这些年来的辛酸，思念一下子涌上心头，秦月禁不住泪流，一下子扑向秦天，不料落空。“怎么回事？”</p>\n<p>“傻孩子，你现在看到的不过是父亲的一道残像罢了。”</p>\n<p>秦天苦笑，有些心痛地说。“那父亲，你在哪里？”秦月问。“很远很远的地方，现在的你还不能到达那个地方。”</p>\n<p>秦天想摸摸孩子的头，愣了一下，叹了口气，“我知道你有很多的问题想问我，但现在我还不能告诉你，因为现在的你太弱小，这些答案对你百害无一利。如果想要知道这些答案，你就要好好修炼，成为强者，这样，一切的问题都会迎刃而解。”“嗯！”秦月抹去眼角的眼泪，努力说服自己不要再流泪。“好孩子，我想你已经知道了我的身份，那清读笛便是我能留给你的最后留物。好了，时间也差不多了，我也该走了。”说着，秦天的身体渐渐的透明起来，慢慢地化作颗粒般细小的荧光，“记着，你是我秦天的儿子，我一直相信你能成为比我还要强的人。还有，不要再流泪，你已经长大了，去努力撑起自己的一片天。我和你的母亲在远方等着你。”</p>\n<p>“父亲，父亲…”看着父亲消失在自己眼前，秦月很无助。</p>\n<p>现实。</p>\n<p>“风老，清读笛这些年来为什么不起作用？”秦天边擦眼泪边问。“现在可以了，你试试吹一下。”风老递过清读笛，说。秦月半信半疑，将笛子凑到嘴边，一曲清新脱俗的曲子响起…</p>\n<p>“啊？！痛…痛。”巨痛传入秦月的脑海里，秦月赶快停了下来。“怎么会这样？”</p>\n<p>“你已经把你父亲设的封印初步解开了。清读笛不再只是乐器，而是幻器。我说过，幻术师是拓诀师中的一种，他们通过对诀元的运用，注入幻器，产生影响敌人视觉，听觉，嗅觉，触觉，感觉等特殊效果，让敌人置身于幻境之中，从而使他们在现实中失去战斗能力。而你的身体内并没有诀元，所以你才会因为受自己的笛声影响。”风老将他要说的都说了出来，心中松了口气。“那我现在是不是可以修炼诀元了？”见风老轻嗯一声，秦月眼中闪烁着火热。</p>\n<p>两天后。</p>\n<p>“仪象归道，自相于生，唤。”</p>\n<p>（有些情节写的太仓促，见谅了。）</p>\n"},{"_content":"\n第四章 通诀师和拓诀师\n\n后山。\n\n“秦月这孩子也长大了，是时候告诉他一些事了。”风老面对正北方，似乎在和远方的某个人说话。\n\n素萱馆。\n\n突如其来的攻击在电光火石间结束，攻击的人便迅速倒退。\n\n“秦月哥哥，你没事吧。”沐儿急忙搀扶着秦月。受到那样的重击，沐儿心里十分清楚秦月哥哥伤得不轻，毕竟他的身体里半点诀元都没有，这意味着是肉体和诀元的碰撞。要知道如果刚才的攻击落在自己的身上，即使已经凝聚出诀源的自己也消受不了。或许秦月哥哥也知道这些，才挡住刚才攻向自己的攻击。 秦月大口喘着气，艰难地站了起来。望着几步之外两个人身上诀元的雄浑程度，这两个人的实力至少和沐儿是同一级别，刚才的那一击着实猛然，可是自己感觉分明并没有受到想象中的重创。难道是因为……之前的炼体之气？听风老说过，这炼体之气是战士修炼的物件，具有淬炼筋骨之效，没想到自己只是使用过三次，功效就如此神奇。\n\n不过，风老已经禁令他使用炼体之气。\n\n“血…秦月哥哥，你流血了。”看到血沿着秦月手滑落，沐儿有些失色，身上的青色之气更加浓郁。 “沐儿，别…你打不过…他们。”尽管秦月硬扛过这一击，但说话仍有些吃力。 “秦月哥哥，你感觉怎么样？”沐儿关切地问。“没什么大不碍。”秦月惨白地笑了笑。 “没想到你这小子挺能扛的，那…这样呢？”严武又一次闪到秦月的侧面，一个提膝攻向秦月的要害。 “严武，素萱馆还容不得你撒野。”听到外面的动静的萱姨刚出内堂，便看见严武偷袭秦月。\n\n的确，素萱馆在常山镇虽然规模不大，但也算是有着过硬的招牌的地方。倒不因为别的，只是因为这家店店主姓谢。也就是说萱姨本名谢萱，是常山镇三大家族谢家人。谢家在常山镇做事比较低调，但低调不意味着实力弱。谢家具有优良的修养和严厉的家规。在这样的环境中，谢家人勤于修炼，争相进步。所以从谢家出来的人个个身怀绝技，武技高强，绝不是严家那种用金钱砸出来的能手相比的，这也是为什么谢家能立足常山镇。因此一般的人不敢在谢家的地盘滋事。 听到谢萱的喝斥，严武的动作缓了下来，毕竟这里是谢家人的地方，而父亲严霸经常提醒自己不到万不得已，不要轻易招惹谢家人。\n\n“哟，萱姨都出来了。”严武也是个识相的人，当下笑道，“那哥儿几个，今天就算了吧。没办法，秦大乐师不太乐意为我们助兴了。”继而他将转向沐儿，脸上依然堆满笑容:“沐儿姑娘来这里吃饭，今天算我请客吧。”\n\n“谁稀罕你的臭钱，滚。”经过刚才一战，沐儿对严武厌恶极了。\n\n“好，好，好。我走。”严武抬脚向门口走去，经过秦月，低声道，“不服七日后竞技场一决生死。”\n\n看着严武一行人离开，秦月松了口气，瘫坐在椅子上，豆大的汗珠一直往下滴，即使淬炼过的筋骨也难保自己毫发无伤。\n\n“秦月哥哥，你的胳膊在流血。”沐儿小心地说。目光落在右手上，秦月注意到的并不是手臂上的血，而是一股青色的液体，散发出阵阵幽香。\n\n“清读笛！！！”秦月惊了一下，刚才一心注意严武的攻击，并没有在意清读笛。小心翼翼撩起衣袖，清读笛出现，白色的笛身沾满了血已不再是白色，并且已经出现几处裂痕，白绳所系他菱状物体也破碎了，青色的液体测满了衣袖。 “严武你个混蛋，我与你不共戴天。”秦月眼里闪现出一丝凶光。“秦月哥哥，你快看。”秦月又望向清读笛:“这是？” 笛上的血液正缓慢地向裂痕处聚集，消失，似乎已经渗入了笛子内，然后只见裂痕处凭空聚集了十分深邃的碧海之蓝，紧接着笛子上的裂痕竟以可见的速度收缩。等到裂痕完全消失，碧海之蓝也十分黯淡虚薄。仅剩有的碧海之蓝便向四周扩散，将清读笛染成淡蓝色。\n\n“这到底是怎么回事？”秦月喃喃道。“秦月哥哥，我也不知道啊。要不我们去问问我爹。”沐儿也有些诧异。“嗯。”秦月若有所思道。在素萱馆简单地包扎了一下，秦月便奔向后山。由于今天经历的事过于惊险，秦月便让沐儿先回去了。 后山。 当秦月将清读笛取出递给风老的时候，风老脸上并没有什么波动。\n\n“风老，这…”秦月还没说完话，便被风老示意停住。\n\n“孩子，这些年来有些事一直没和你说，只是想让你安心地将《清读赋》练习好。”\n\n“风老，是什么事？”秦月谨慎地问。“孩子，你知道你父亲的身份吗？”风老严肃起来。\n\n“父亲的身份？不是诀师吗？”\n\n“的确是诀师，但诀师只是一个总称，它是相对于凡人而言的。所谓诀师，简而言之，就是通过印诀将体内的诀气之元催动出来，并达到最大效用的一类人。然而催动诀元的手法不尽相同，大到可以分为两类。一是通过催动诀元进行直接地攻击，防御，躲闪等，人们称这样的诀师为通诀师，另一是通过对诀元的运用实行一些特殊的功效，如迷惑，布阵等，这便是拓诀师。”\n\n\n\n\n\n（喜欢亦幻的朋友们希望多给些评论，你们的评论是我最大的动力，谢谢）","source":"novel/四、通诀师和拓诀师.md","raw":"\n第四章 通诀师和拓诀师\n\n后山。\n\n“秦月这孩子也长大了，是时候告诉他一些事了。”风老面对正北方，似乎在和远方的某个人说话。\n\n素萱馆。\n\n突如其来的攻击在电光火石间结束，攻击的人便迅速倒退。\n\n“秦月哥哥，你没事吧。”沐儿急忙搀扶着秦月。受到那样的重击，沐儿心里十分清楚秦月哥哥伤得不轻，毕竟他的身体里半点诀元都没有，这意味着是肉体和诀元的碰撞。要知道如果刚才的攻击落在自己的身上，即使已经凝聚出诀源的自己也消受不了。或许秦月哥哥也知道这些，才挡住刚才攻向自己的攻击。 秦月大口喘着气，艰难地站了起来。望着几步之外两个人身上诀元的雄浑程度，这两个人的实力至少和沐儿是同一级别，刚才的那一击着实猛然，可是自己感觉分明并没有受到想象中的重创。难道是因为……之前的炼体之气？听风老说过，这炼体之气是战士修炼的物件，具有淬炼筋骨之效，没想到自己只是使用过三次，功效就如此神奇。\n\n不过，风老已经禁令他使用炼体之气。\n\n“血…秦月哥哥，你流血了。”看到血沿着秦月手滑落，沐儿有些失色，身上的青色之气更加浓郁。 “沐儿，别…你打不过…他们。”尽管秦月硬扛过这一击，但说话仍有些吃力。 “秦月哥哥，你感觉怎么样？”沐儿关切地问。“没什么大不碍。”秦月惨白地笑了笑。 “没想到你这小子挺能扛的，那…这样呢？”严武又一次闪到秦月的侧面，一个提膝攻向秦月的要害。 “严武，素萱馆还容不得你撒野。”听到外面的动静的萱姨刚出内堂，便看见严武偷袭秦月。\n\n的确，素萱馆在常山镇虽然规模不大，但也算是有着过硬的招牌的地方。倒不因为别的，只是因为这家店店主姓谢。也就是说萱姨本名谢萱，是常山镇三大家族谢家人。谢家在常山镇做事比较低调，但低调不意味着实力弱。谢家具有优良的修养和严厉的家规。在这样的环境中，谢家人勤于修炼，争相进步。所以从谢家出来的人个个身怀绝技，武技高强，绝不是严家那种用金钱砸出来的能手相比的，这也是为什么谢家能立足常山镇。因此一般的人不敢在谢家的地盘滋事。 听到谢萱的喝斥，严武的动作缓了下来，毕竟这里是谢家人的地方，而父亲严霸经常提醒自己不到万不得已，不要轻易招惹谢家人。\n\n“哟，萱姨都出来了。”严武也是个识相的人，当下笑道，“那哥儿几个，今天就算了吧。没办法，秦大乐师不太乐意为我们助兴了。”继而他将转向沐儿，脸上依然堆满笑容:“沐儿姑娘来这里吃饭，今天算我请客吧。”\n\n“谁稀罕你的臭钱，滚。”经过刚才一战，沐儿对严武厌恶极了。\n\n“好，好，好。我走。”严武抬脚向门口走去，经过秦月，低声道，“不服七日后竞技场一决生死。”\n\n看着严武一行人离开，秦月松了口气，瘫坐在椅子上，豆大的汗珠一直往下滴，即使淬炼过的筋骨也难保自己毫发无伤。\n\n“秦月哥哥，你的胳膊在流血。”沐儿小心地说。目光落在右手上，秦月注意到的并不是手臂上的血，而是一股青色的液体，散发出阵阵幽香。\n\n“清读笛！！！”秦月惊了一下，刚才一心注意严武的攻击，并没有在意清读笛。小心翼翼撩起衣袖，清读笛出现，白色的笛身沾满了血已不再是白色，并且已经出现几处裂痕，白绳所系他菱状物体也破碎了，青色的液体测满了衣袖。 “严武你个混蛋，我与你不共戴天。”秦月眼里闪现出一丝凶光。“秦月哥哥，你快看。”秦月又望向清读笛:“这是？” 笛上的血液正缓慢地向裂痕处聚集，消失，似乎已经渗入了笛子内，然后只见裂痕处凭空聚集了十分深邃的碧海之蓝，紧接着笛子上的裂痕竟以可见的速度收缩。等到裂痕完全消失，碧海之蓝也十分黯淡虚薄。仅剩有的碧海之蓝便向四周扩散，将清读笛染成淡蓝色。\n\n“这到底是怎么回事？”秦月喃喃道。“秦月哥哥，我也不知道啊。要不我们去问问我爹。”沐儿也有些诧异。“嗯。”秦月若有所思道。在素萱馆简单地包扎了一下，秦月便奔向后山。由于今天经历的事过于惊险，秦月便让沐儿先回去了。 后山。 当秦月将清读笛取出递给风老的时候，风老脸上并没有什么波动。\n\n“风老，这…”秦月还没说完话，便被风老示意停住。\n\n“孩子，这些年来有些事一直没和你说，只是想让你安心地将《清读赋》练习好。”\n\n“风老，是什么事？”秦月谨慎地问。“孩子，你知道你父亲的身份吗？”风老严肃起来。\n\n“父亲的身份？不是诀师吗？”\n\n“的确是诀师，但诀师只是一个总称，它是相对于凡人而言的。所谓诀师，简而言之，就是通过印诀将体内的诀气之元催动出来，并达到最大效用的一类人。然而催动诀元的手法不尽相同，大到可以分为两类。一是通过催动诀元进行直接地攻击，防御，躲闪等，人们称这样的诀师为通诀师，另一是通过对诀元的运用实行一些特殊的功效，如迷惑，布阵等，这便是拓诀师。”\n\n\n\n\n\n（喜欢亦幻的朋友们希望多给些评论，你们的评论是我最大的动力，谢谢）","date":"2025-07-28T01:30:12.913Z","updated":"2024-07-15T07:40:55.640Z","path":"novel/四、通诀师和拓诀师.html","title":"","comments":1,"layout":"page","_id":"cmhc3m3ud000hxdp8gff532xz","content":"<p>第四章 通诀师和拓诀师</p>\n<p>后山。</p>\n<p>“秦月这孩子也长大了，是时候告诉他一些事了。”风老面对正北方，似乎在和远方的某个人说话。</p>\n<p>素萱馆。</p>\n<p>突如其来的攻击在电光火石间结束，攻击的人便迅速倒退。</p>\n<p>“秦月哥哥，你没事吧。”沐儿急忙搀扶着秦月。受到那样的重击，沐儿心里十分清楚秦月哥哥伤得不轻，毕竟他的身体里半点诀元都没有，这意味着是肉体和诀元的碰撞。要知道如果刚才的攻击落在自己的身上，即使已经凝聚出诀源的自己也消受不了。或许秦月哥哥也知道这些，才挡住刚才攻向自己的攻击。 秦月大口喘着气，艰难地站了起来。望着几步之外两个人身上诀元的雄浑程度，这两个人的实力至少和沐儿是同一级别，刚才的那一击着实猛然，可是自己感觉分明并没有受到想象中的重创。难道是因为……之前的炼体之气？听风老说过，这炼体之气是战士修炼的物件，具有淬炼筋骨之效，没想到自己只是使用过三次，功效就如此神奇。</p>\n<p>不过，风老已经禁令他使用炼体之气。</p>\n<p>“血…秦月哥哥，你流血了。”看到血沿着秦月手滑落，沐儿有些失色，身上的青色之气更加浓郁。 “沐儿，别…你打不过…他们。”尽管秦月硬扛过这一击，但说话仍有些吃力。 “秦月哥哥，你感觉怎么样？”沐儿关切地问。“没什么大不碍。”秦月惨白地笑了笑。 “没想到你这小子挺能扛的，那…这样呢？”严武又一次闪到秦月的侧面，一个提膝攻向秦月的要害。 “严武，素萱馆还容不得你撒野。”听到外面的动静的萱姨刚出内堂，便看见严武偷袭秦月。</p>\n<p>的确，素萱馆在常山镇虽然规模不大，但也算是有着过硬的招牌的地方。倒不因为别的，只是因为这家店店主姓谢。也就是说萱姨本名谢萱，是常山镇三大家族谢家人。谢家在常山镇做事比较低调，但低调不意味着实力弱。谢家具有优良的修养和严厉的家规。在这样的环境中，谢家人勤于修炼，争相进步。所以从谢家出来的人个个身怀绝技，武技高强，绝不是严家那种用金钱砸出来的能手相比的，这也是为什么谢家能立足常山镇。因此一般的人不敢在谢家的地盘滋事。 听到谢萱的喝斥，严武的动作缓了下来，毕竟这里是谢家人的地方，而父亲严霸经常提醒自己不到万不得已，不要轻易招惹谢家人。</p>\n<p>“哟，萱姨都出来了。”严武也是个识相的人，当下笑道，“那哥儿几个，今天就算了吧。没办法，秦大乐师不太乐意为我们助兴了。”继而他将转向沐儿，脸上依然堆满笑容:“沐儿姑娘来这里吃饭，今天算我请客吧。”</p>\n<p>“谁稀罕你的臭钱，滚。”经过刚才一战，沐儿对严武厌恶极了。</p>\n<p>“好，好，好。我走。”严武抬脚向门口走去，经过秦月，低声道，“不服七日后竞技场一决生死。”</p>\n<p>看着严武一行人离开，秦月松了口气，瘫坐在椅子上，豆大的汗珠一直往下滴，即使淬炼过的筋骨也难保自己毫发无伤。</p>\n<p>“秦月哥哥，你的胳膊在流血。”沐儿小心地说。目光落在右手上，秦月注意到的并不是手臂上的血，而是一股青色的液体，散发出阵阵幽香。</p>\n<p>“清读笛！！！”秦月惊了一下，刚才一心注意严武的攻击，并没有在意清读笛。小心翼翼撩起衣袖，清读笛出现，白色的笛身沾满了血已不再是白色，并且已经出现几处裂痕，白绳所系他菱状物体也破碎了，青色的液体测满了衣袖。 “严武你个混蛋，我与你不共戴天。”秦月眼里闪现出一丝凶光。“秦月哥哥，你快看。”秦月又望向清读笛:“这是？” 笛上的血液正缓慢地向裂痕处聚集，消失，似乎已经渗入了笛子内，然后只见裂痕处凭空聚集了十分深邃的碧海之蓝，紧接着笛子上的裂痕竟以可见的速度收缩。等到裂痕完全消失，碧海之蓝也十分黯淡虚薄。仅剩有的碧海之蓝便向四周扩散，将清读笛染成淡蓝色。</p>\n<p>“这到底是怎么回事？”秦月喃喃道。“秦月哥哥，我也不知道啊。要不我们去问问我爹。”沐儿也有些诧异。“嗯。”秦月若有所思道。在素萱馆简单地包扎了一下，秦月便奔向后山。由于今天经历的事过于惊险，秦月便让沐儿先回去了。 后山。 当秦月将清读笛取出递给风老的时候，风老脸上并没有什么波动。</p>\n<p>“风老，这…”秦月还没说完话，便被风老示意停住。</p>\n<p>“孩子，这些年来有些事一直没和你说，只是想让你安心地将《清读赋》练习好。”</p>\n<p>“风老，是什么事？”秦月谨慎地问。“孩子，你知道你父亲的身份吗？”风老严肃起来。</p>\n<p>“父亲的身份？不是诀师吗？”</p>\n<p>“的确是诀师，但诀师只是一个总称，它是相对于凡人而言的。所谓诀师，简而言之，就是通过印诀将体内的诀气之元催动出来，并达到最大效用的一类人。然而催动诀元的手法不尽相同，大到可以分为两类。一是通过催动诀元进行直接地攻击，防御，躲闪等，人们称这样的诀师为通诀师，另一是通过对诀元的运用实行一些特殊的功效，如迷惑，布阵等，这便是拓诀师。”</p>\n<p>（喜欢亦幻的朋友们希望多给些评论，你们的评论是我最大的动力，谢谢）</p>\n","excerpt":"","more":"<p>第四章 通诀师和拓诀师</p>\n<p>后山。</p>\n<p>“秦月这孩子也长大了，是时候告诉他一些事了。”风老面对正北方，似乎在和远方的某个人说话。</p>\n<p>素萱馆。</p>\n<p>突如其来的攻击在电光火石间结束，攻击的人便迅速倒退。</p>\n<p>“秦月哥哥，你没事吧。”沐儿急忙搀扶着秦月。受到那样的重击，沐儿心里十分清楚秦月哥哥伤得不轻，毕竟他的身体里半点诀元都没有，这意味着是肉体和诀元的碰撞。要知道如果刚才的攻击落在自己的身上，即使已经凝聚出诀源的自己也消受不了。或许秦月哥哥也知道这些，才挡住刚才攻向自己的攻击。 秦月大口喘着气，艰难地站了起来。望着几步之外两个人身上诀元的雄浑程度，这两个人的实力至少和沐儿是同一级别，刚才的那一击着实猛然，可是自己感觉分明并没有受到想象中的重创。难道是因为……之前的炼体之气？听风老说过，这炼体之气是战士修炼的物件，具有淬炼筋骨之效，没想到自己只是使用过三次，功效就如此神奇。</p>\n<p>不过，风老已经禁令他使用炼体之气。</p>\n<p>“血…秦月哥哥，你流血了。”看到血沿着秦月手滑落，沐儿有些失色，身上的青色之气更加浓郁。 “沐儿，别…你打不过…他们。”尽管秦月硬扛过这一击，但说话仍有些吃力。 “秦月哥哥，你感觉怎么样？”沐儿关切地问。“没什么大不碍。”秦月惨白地笑了笑。 “没想到你这小子挺能扛的，那…这样呢？”严武又一次闪到秦月的侧面，一个提膝攻向秦月的要害。 “严武，素萱馆还容不得你撒野。”听到外面的动静的萱姨刚出内堂，便看见严武偷袭秦月。</p>\n<p>的确，素萱馆在常山镇虽然规模不大，但也算是有着过硬的招牌的地方。倒不因为别的，只是因为这家店店主姓谢。也就是说萱姨本名谢萱，是常山镇三大家族谢家人。谢家在常山镇做事比较低调，但低调不意味着实力弱。谢家具有优良的修养和严厉的家规。在这样的环境中，谢家人勤于修炼，争相进步。所以从谢家出来的人个个身怀绝技，武技高强，绝不是严家那种用金钱砸出来的能手相比的，这也是为什么谢家能立足常山镇。因此一般的人不敢在谢家的地盘滋事。 听到谢萱的喝斥，严武的动作缓了下来，毕竟这里是谢家人的地方，而父亲严霸经常提醒自己不到万不得已，不要轻易招惹谢家人。</p>\n<p>“哟，萱姨都出来了。”严武也是个识相的人，当下笑道，“那哥儿几个，今天就算了吧。没办法，秦大乐师不太乐意为我们助兴了。”继而他将转向沐儿，脸上依然堆满笑容:“沐儿姑娘来这里吃饭，今天算我请客吧。”</p>\n<p>“谁稀罕你的臭钱，滚。”经过刚才一战，沐儿对严武厌恶极了。</p>\n<p>“好，好，好。我走。”严武抬脚向门口走去，经过秦月，低声道，“不服七日后竞技场一决生死。”</p>\n<p>看着严武一行人离开，秦月松了口气，瘫坐在椅子上，豆大的汗珠一直往下滴，即使淬炼过的筋骨也难保自己毫发无伤。</p>\n<p>“秦月哥哥，你的胳膊在流血。”沐儿小心地说。目光落在右手上，秦月注意到的并不是手臂上的血，而是一股青色的液体，散发出阵阵幽香。</p>\n<p>“清读笛！！！”秦月惊了一下，刚才一心注意严武的攻击，并没有在意清读笛。小心翼翼撩起衣袖，清读笛出现，白色的笛身沾满了血已不再是白色，并且已经出现几处裂痕，白绳所系他菱状物体也破碎了，青色的液体测满了衣袖。 “严武你个混蛋，我与你不共戴天。”秦月眼里闪现出一丝凶光。“秦月哥哥，你快看。”秦月又望向清读笛:“这是？” 笛上的血液正缓慢地向裂痕处聚集，消失，似乎已经渗入了笛子内，然后只见裂痕处凭空聚集了十分深邃的碧海之蓝，紧接着笛子上的裂痕竟以可见的速度收缩。等到裂痕完全消失，碧海之蓝也十分黯淡虚薄。仅剩有的碧海之蓝便向四周扩散，将清读笛染成淡蓝色。</p>\n<p>“这到底是怎么回事？”秦月喃喃道。“秦月哥哥，我也不知道啊。要不我们去问问我爹。”沐儿也有些诧异。“嗯。”秦月若有所思道。在素萱馆简单地包扎了一下，秦月便奔向后山。由于今天经历的事过于惊险，秦月便让沐儿先回去了。 后山。 当秦月将清读笛取出递给风老的时候，风老脸上并没有什么波动。</p>\n<p>“风老，这…”秦月还没说完话，便被风老示意停住。</p>\n<p>“孩子，这些年来有些事一直没和你说，只是想让你安心地将《清读赋》练习好。”</p>\n<p>“风老，是什么事？”秦月谨慎地问。“孩子，你知道你父亲的身份吗？”风老严肃起来。</p>\n<p>“父亲的身份？不是诀师吗？”</p>\n<p>“的确是诀师，但诀师只是一个总称，它是相对于凡人而言的。所谓诀师，简而言之，就是通过印诀将体内的诀气之元催动出来，并达到最大效用的一类人。然而催动诀元的手法不尽相同，大到可以分为两类。一是通过催动诀元进行直接地攻击，防御，躲闪等，人们称这样的诀师为通诀师，另一是通过对诀元的运用实行一些特殊的功效，如迷惑，布阵等，这便是拓诀师。”</p>\n<p>（喜欢亦幻的朋友们希望多给些评论，你们的评论是我最大的动力，谢谢）</p>\n"},{"_content":"\n\n\n\n## Devices  · 正在使用的设备\n\n<div class=\"device-card\">\n    <img src=\"img/macbookpro.jpg\" alt=\"Apple Macbook pro 14 2024 M2\">\n    <div class=\"device-info\">\n        <head3>Apple Macbook pro 14 2024 M2</head3>\n        <p>2023 年初购入，目前主要生产力</p>\n    </div>\n</div>\n\n<div class=\"device-card\">\n    <img src=\"img/iphone13pro.jpg\" alt=\"Apple iPhone 13 Pro\">\n    <div class=\"device-info\">\n        <head3>Apple iPhone 13 Pro</head3>\n        <p>2020 年双 11 购入，除了电池不耐用，其他依旧能打</p>\n    </div>\n</div>\n\n<div class=\"device-card\">\n    <img src=\"img/sonyzv1.jpg\" alt=\"Sony ZV-1\">\n    <div class=\"device-info\">\n        <head3>Sony ZV-1</head3>\n        <p>Vlog 相机，当年 \"Vlog 第一机\"，目前能打，旅游，日常采风给 Amelia 拍照</p>\n    </div>\n</div>\n\n<div class=\"device-card\">\n    <img src=\"img/bosemini2.png\" alt=\"Bose SoundLink Mini 2\">\n    <div class=\"device-info\">\n        <head3>Bose SoundLink Mini 2</head3>\n        <p>声音效果强，日常影音，打游戏挺适合的，用于家里台式机</p>\n    </div>\n</div>\n\n<div class=\"device-card\">\n    <img src=\"img/ktch27v22s.jpg\" alt=\"KTC H27V22s\">\n    <div class=\"device-info\">\n        <head3>KTC H27V22s</head3>\n        <p>购入 2022 年 9 月，27 寸 2K 170Hz，用于家里台式机，娱乐使用</p>\n    </div>\n</div>\n\n<div class=\"device-card\">\n    <img src=\"img/dellp2419h.png\" alt=\"Dell P2419H\">\n    <div class=\"device-info\">\n        <head3>Dell P2419H</head3>\n        <p>购入 2019 年，24 寸 2K 60Hz。Dell 校色没的说，目前办公够用</p>\n    </div>\n</div>\n\n<div class=\"device-card\">\n    <img src=\"img/kindlepaperwhite5.jpg\" alt=\"Kindle paperwhite 5\">\n    <div class=\"device-info\">\n        <head3>Kindle paperwhite 5</head3>\n        <p>公司积分换的，读书伴侣，相较于 kindle 4 多了屏幕灯，提升巨大</p>\n    </div>\n</div>\n\n<div class=\"device-card discontinued\">\n    <img src=\"img/kindle4.jpeg\" alt=\"Kindle 4\">\n    <div class=\"device-info\">\n        <head3>Kindle 4</head3>\n        <p>之前主力阅读器，后来换 Kindle paperwhite 5 后送个弟弟用了</p>\n    </div>\n</div>\n\n<div class=\"device-card discontinued\">\n    <img src=\"img/vgn98pro.jpeg\" alt=\"VGN 98pro\">\n    <div class=\"device-info\">\n        <head3>VGN 98pro</head3>\n        <p>蒸汽波轴，原来是海盐蓝，配了苹果 ins 风白色键帽，颜值无敌，手感也好，换 MX keys 前主力办公键盘，稍微有点吵，目前已二手出了。VGN 的键盘啥都好，就是脚垫做不好</p>\n    </div>\n</div>\n\n<div class=\"device-card\">\n    <img src=\"img/mxkeys.jpg\" alt=\"Logitech MX keys\">\n    <div class=\"device-info\">\n        <head3>Logitech MX keys for Bussiness</head3>\n        <p>改变了对传统薄膜键盘的偏见，续航长，布局合理，多设备连接，适配 Macbook，适合办公使用</p>\n    </div>\n</div>\n\n<div class=\"device-card\">\n    <img src=\"img/gpw.jpg\" alt=\"Logitech GPW\">\n    <div class=\"device-info\">\n        <head3>Logitech GPW 1代</head3>\n        <p>购入 2019 年，适合小手，目前在役游戏使用</p>\n    </div>\n</div>\n\n<div class=\"device-card\">\n    <img src=\"img/mxmaster3.jpg\" alt=\"Logitech MX Master 3\">\n    <div class=\"device-info\">\n        <head3>Logitech MX Master 3</head3>\n        <p>配套 MX keys 办公室使用，主要用 Logitech Flow 技术在多平台切换</p>\n    </div>\n</div>\n\n<div class=\"device-card discontinued\">\n    <img src=\"img/g102.webp\" alt=\"Logitech G102\">\n    <div class=\"device-info\">\n        <head3>Logitech G102</head3>\n        <p>在役 6 年，太能打了，后连击问题换了</p>\n    </div>\n</div>\n\n<div class=\"device-card\">\n    <img src=\"img/boseqc352.jpg\" alt=\"BOSE QuietComfort QC35 II\">\n    <div class=\"device-info\">\n        <head3>BOSE QuietComfort QC35 II</head3>\n        <p>2020 年购入，降噪效果明显，大耳适合在冬天通勤当耳暖用，夏天几乎不戴</p>\n    </div>\n</div>\n\n<div class=\"device-card discontinued\">\n    <img src=\"img/airpodspro.jpg\" alt=\"Apple AirPods Pro 1代\">\n    <div class=\"device-info\">\n        <head3>Apple AirPods Pro 1代</head3>\n        <p>2019 年购入，Amelia 不习惯佩戴，送给我用，因为首批有降噪模块问题，目前已闲置</p>\n    </div>\n</div>\n\n<div class=\"device-card\">\n    <img src=\"img/airpods3.jpg\" alt=\"Apple AirPods 3\">\n    <div class=\"device-info\">\n        <head3>Airpods 3</head3>\n        <p>Airpods pro 闲置之后购入，夏季通勤，办公室开会使用</p>\n    </div>\n</div>\n\n<div class=\"device-card\">\n    <img src=\"img/athim70.jpg\" alt=\"铁三角ATH-IM70\">\n    <div class=\"device-info\">\n        <head3>铁三角ATH-IM70</head3>\n        <p>大学主力有线耳机，ACG，人声通透，目前退居二线，主要连吉他效果器音响练琴用</p>\n    </div>\n</div>\n\n<div class=\"device-card\">\n    <img src=\"img/fg830.webp\" alt=\"Yamaha FG830\">\n    <div class=\"device-info\">\n        <head3>Yamaha FG830</head3>\n        <p>41 寸，咸鱼购入，已改效果器，偶尔摸摸练练歌</p>\n    </div>\n</div>\n\n\n","source":"use/index.md","raw":"\n\n\n\n## Devices  · 正在使用的设备\n\n<div class=\"device-card\">\n    <img src=\"img/macbookpro.jpg\" alt=\"Apple Macbook pro 14 2024 M2\">\n    <div class=\"device-info\">\n        <head3>Apple Macbook pro 14 2024 M2</head3>\n        <p>2023 年初购入，目前主要生产力</p>\n    </div>\n</div>\n\n<div class=\"device-card\">\n    <img src=\"img/iphone13pro.jpg\" alt=\"Apple iPhone 13 Pro\">\n    <div class=\"device-info\">\n        <head3>Apple iPhone 13 Pro</head3>\n        <p>2020 年双 11 购入，除了电池不耐用，其他依旧能打</p>\n    </div>\n</div>\n\n<div class=\"device-card\">\n    <img src=\"img/sonyzv1.jpg\" alt=\"Sony ZV-1\">\n    <div class=\"device-info\">\n        <head3>Sony ZV-1</head3>\n        <p>Vlog 相机，当年 \"Vlog 第一机\"，目前能打，旅游，日常采风给 Amelia 拍照</p>\n    </div>\n</div>\n\n<div class=\"device-card\">\n    <img src=\"img/bosemini2.png\" alt=\"Bose SoundLink Mini 2\">\n    <div class=\"device-info\">\n        <head3>Bose SoundLink Mini 2</head3>\n        <p>声音效果强，日常影音，打游戏挺适合的，用于家里台式机</p>\n    </div>\n</div>\n\n<div class=\"device-card\">\n    <img src=\"img/ktch27v22s.jpg\" alt=\"KTC H27V22s\">\n    <div class=\"device-info\">\n        <head3>KTC H27V22s</head3>\n        <p>购入 2022 年 9 月，27 寸 2K 170Hz，用于家里台式机，娱乐使用</p>\n    </div>\n</div>\n\n<div class=\"device-card\">\n    <img src=\"img/dellp2419h.png\" alt=\"Dell P2419H\">\n    <div class=\"device-info\">\n        <head3>Dell P2419H</head3>\n        <p>购入 2019 年，24 寸 2K 60Hz。Dell 校色没的说，目前办公够用</p>\n    </div>\n</div>\n\n<div class=\"device-card\">\n    <img src=\"img/kindlepaperwhite5.jpg\" alt=\"Kindle paperwhite 5\">\n    <div class=\"device-info\">\n        <head3>Kindle paperwhite 5</head3>\n        <p>公司积分换的，读书伴侣，相较于 kindle 4 多了屏幕灯，提升巨大</p>\n    </div>\n</div>\n\n<div class=\"device-card discontinued\">\n    <img src=\"img/kindle4.jpeg\" alt=\"Kindle 4\">\n    <div class=\"device-info\">\n        <head3>Kindle 4</head3>\n        <p>之前主力阅读器，后来换 Kindle paperwhite 5 后送个弟弟用了</p>\n    </div>\n</div>\n\n<div class=\"device-card discontinued\">\n    <img src=\"img/vgn98pro.jpeg\" alt=\"VGN 98pro\">\n    <div class=\"device-info\">\n        <head3>VGN 98pro</head3>\n        <p>蒸汽波轴，原来是海盐蓝，配了苹果 ins 风白色键帽，颜值无敌，手感也好，换 MX keys 前主力办公键盘，稍微有点吵，目前已二手出了。VGN 的键盘啥都好，就是脚垫做不好</p>\n    </div>\n</div>\n\n<div class=\"device-card\">\n    <img src=\"img/mxkeys.jpg\" alt=\"Logitech MX keys\">\n    <div class=\"device-info\">\n        <head3>Logitech MX keys for Bussiness</head3>\n        <p>改变了对传统薄膜键盘的偏见，续航长，布局合理，多设备连接，适配 Macbook，适合办公使用</p>\n    </div>\n</div>\n\n<div class=\"device-card\">\n    <img src=\"img/gpw.jpg\" alt=\"Logitech GPW\">\n    <div class=\"device-info\">\n        <head3>Logitech GPW 1代</head3>\n        <p>购入 2019 年，适合小手，目前在役游戏使用</p>\n    </div>\n</div>\n\n<div class=\"device-card\">\n    <img src=\"img/mxmaster3.jpg\" alt=\"Logitech MX Master 3\">\n    <div class=\"device-info\">\n        <head3>Logitech MX Master 3</head3>\n        <p>配套 MX keys 办公室使用，主要用 Logitech Flow 技术在多平台切换</p>\n    </div>\n</div>\n\n<div class=\"device-card discontinued\">\n    <img src=\"img/g102.webp\" alt=\"Logitech G102\">\n    <div class=\"device-info\">\n        <head3>Logitech G102</head3>\n        <p>在役 6 年，太能打了，后连击问题换了</p>\n    </div>\n</div>\n\n<div class=\"device-card\">\n    <img src=\"img/boseqc352.jpg\" alt=\"BOSE QuietComfort QC35 II\">\n    <div class=\"device-info\">\n        <head3>BOSE QuietComfort QC35 II</head3>\n        <p>2020 年购入，降噪效果明显，大耳适合在冬天通勤当耳暖用，夏天几乎不戴</p>\n    </div>\n</div>\n\n<div class=\"device-card discontinued\">\n    <img src=\"img/airpodspro.jpg\" alt=\"Apple AirPods Pro 1代\">\n    <div class=\"device-info\">\n        <head3>Apple AirPods Pro 1代</head3>\n        <p>2019 年购入，Amelia 不习惯佩戴，送给我用，因为首批有降噪模块问题，目前已闲置</p>\n    </div>\n</div>\n\n<div class=\"device-card\">\n    <img src=\"img/airpods3.jpg\" alt=\"Apple AirPods 3\">\n    <div class=\"device-info\">\n        <head3>Airpods 3</head3>\n        <p>Airpods pro 闲置之后购入，夏季通勤，办公室开会使用</p>\n    </div>\n</div>\n\n<div class=\"device-card\">\n    <img src=\"img/athim70.jpg\" alt=\"铁三角ATH-IM70\">\n    <div class=\"device-info\">\n        <head3>铁三角ATH-IM70</head3>\n        <p>大学主力有线耳机，ACG，人声通透，目前退居二线，主要连吉他效果器音响练琴用</p>\n    </div>\n</div>\n\n<div class=\"device-card\">\n    <img src=\"img/fg830.webp\" alt=\"Yamaha FG830\">\n    <div class=\"device-info\">\n        <head3>Yamaha FG830</head3>\n        <p>41 寸，咸鱼购入，已改效果器，偶尔摸摸练练歌</p>\n    </div>\n</div>\n\n\n","date":"2025-08-15T02:56:00.519Z","updated":"2025-08-15T02:56:00.519Z","path":"use/index.html","title":"","comments":1,"layout":"page","_id":"cmhc3m3ud000mxdp879vi2sue","content":"<h2 id=\"Devices-·-正在使用的设备\"><a href=\"#Devices-·-正在使用的设备\" class=\"headerlink\" title=\"Devices  · 正在使用的设备\"></a>Devices  · 正在使用的设备</h2><div class=\"device-card\">\n    <img src=\"img/macbookpro.jpg\" alt=\"Apple Macbook pro 14 2024 M2\">\n    <div class=\"device-info\">\n        <head3>Apple Macbook pro 14 2024 M2</head3>\n        <p>2023 年初购入，目前主要生产力</p>\n    </div>\n</div>\n\n<div class=\"device-card\">\n    <img src=\"img/iphone13pro.jpg\" alt=\"Apple iPhone 13 Pro\">\n    <div class=\"device-info\">\n        <head3>Apple iPhone 13 Pro</head3>\n        <p>2020 年双 11 购入，除了电池不耐用，其他依旧能打</p>\n    </div>\n</div>\n\n<div class=\"device-card\">\n    <img src=\"img/sonyzv1.jpg\" alt=\"Sony ZV-1\">\n    <div class=\"device-info\">\n        <head3>Sony ZV-1</head3>\n        <p>Vlog 相机，当年 \"Vlog 第一机\"，目前能打，旅游，日常采风给 Amelia 拍照</p>\n    </div>\n</div>\n\n<div class=\"device-card\">\n    <img src=\"img/bosemini2.png\" alt=\"Bose SoundLink Mini 2\">\n    <div class=\"device-info\">\n        <head3>Bose SoundLink Mini 2</head3>\n        <p>声音效果强，日常影音，打游戏挺适合的，用于家里台式机</p>\n    </div>\n</div>\n\n<div class=\"device-card\">\n    <img src=\"img/ktch27v22s.jpg\" alt=\"KTC H27V22s\">\n    <div class=\"device-info\">\n        <head3>KTC H27V22s</head3>\n        <p>购入 2022 年 9 月，27 寸 2K 170Hz，用于家里台式机，娱乐使用</p>\n    </div>\n</div>\n\n<div class=\"device-card\">\n    <img src=\"img/dellp2419h.png\" alt=\"Dell P2419H\">\n    <div class=\"device-info\">\n        <head3>Dell P2419H</head3>\n        <p>购入 2019 年，24 寸 2K 60Hz。Dell 校色没的说，目前办公够用</p>\n    </div>\n</div>\n\n<div class=\"device-card\">\n    <img src=\"img/kindlepaperwhite5.jpg\" alt=\"Kindle paperwhite 5\">\n    <div class=\"device-info\">\n        <head3>Kindle paperwhite 5</head3>\n        <p>公司积分换的，读书伴侣，相较于 kindle 4 多了屏幕灯，提升巨大</p>\n    </div>\n</div>\n\n<div class=\"device-card discontinued\">\n    <img src=\"img/kindle4.jpeg\" alt=\"Kindle 4\">\n    <div class=\"device-info\">\n        <head3>Kindle 4</head3>\n        <p>之前主力阅读器，后来换 Kindle paperwhite 5 后送个弟弟用了</p>\n    </div>\n</div>\n\n<div class=\"device-card discontinued\">\n    <img src=\"img/vgn98pro.jpeg\" alt=\"VGN 98pro\">\n    <div class=\"device-info\">\n        <head3>VGN 98pro</head3>\n        <p>蒸汽波轴，原来是海盐蓝，配了苹果 ins 风白色键帽，颜值无敌，手感也好，换 MX keys 前主力办公键盘，稍微有点吵，目前已二手出了。VGN 的键盘啥都好，就是脚垫做不好</p>\n    </div>\n</div>\n\n<div class=\"device-card\">\n    <img src=\"img/mxkeys.jpg\" alt=\"Logitech MX keys\">\n    <div class=\"device-info\">\n        <head3>Logitech MX keys for Bussiness</head3>\n        <p>改变了对传统薄膜键盘的偏见，续航长，布局合理，多设备连接，适配 Macbook，适合办公使用</p>\n    </div>\n</div>\n\n<div class=\"device-card\">\n    <img src=\"img/gpw.jpg\" alt=\"Logitech GPW\">\n    <div class=\"device-info\">\n        <head3>Logitech GPW 1代</head3>\n        <p>购入 2019 年，适合小手，目前在役游戏使用</p>\n    </div>\n</div>\n\n<div class=\"device-card\">\n    <img src=\"img/mxmaster3.jpg\" alt=\"Logitech MX Master 3\">\n    <div class=\"device-info\">\n        <head3>Logitech MX Master 3</head3>\n        <p>配套 MX keys 办公室使用，主要用 Logitech Flow 技术在多平台切换</p>\n    </div>\n</div>\n\n<div class=\"device-card discontinued\">\n    <img src=\"img/g102.webp\" alt=\"Logitech G102\">\n    <div class=\"device-info\">\n        <head3>Logitech G102</head3>\n        <p>在役 6 年，太能打了，后连击问题换了</p>\n    </div>\n</div>\n\n<div class=\"device-card\">\n    <img src=\"img/boseqc352.jpg\" alt=\"BOSE QuietComfort QC35 II\">\n    <div class=\"device-info\">\n        <head3>BOSE QuietComfort QC35 II</head3>\n        <p>2020 年购入，降噪效果明显，大耳适合在冬天通勤当耳暖用，夏天几乎不戴</p>\n    </div>\n</div>\n\n<div class=\"device-card discontinued\">\n    <img src=\"img/airpodspro.jpg\" alt=\"Apple AirPods Pro 1代\">\n    <div class=\"device-info\">\n        <head3>Apple AirPods Pro 1代</head3>\n        <p>2019 年购入，Amelia 不习惯佩戴，送给我用，因为首批有降噪模块问题，目前已闲置</p>\n    </div>\n</div>\n\n<div class=\"device-card\">\n    <img src=\"img/airpods3.jpg\" alt=\"Apple AirPods 3\">\n    <div class=\"device-info\">\n        <head3>Airpods 3</head3>\n        <p>Airpods pro 闲置之后购入，夏季通勤，办公室开会使用</p>\n    </div>\n</div>\n\n<div class=\"device-card\">\n    <img src=\"img/athim70.jpg\" alt=\"铁三角ATH-IM70\">\n    <div class=\"device-info\">\n        <head3>铁三角ATH-IM70</head3>\n        <p>大学主力有线耳机，ACG，人声通透，目前退居二线，主要连吉他效果器音响练琴用</p>\n    </div>\n</div>\n\n<div class=\"device-card\">\n    <img src=\"img/fg830.webp\" alt=\"Yamaha FG830\">\n    <div class=\"device-info\">\n        <head3>Yamaha FG830</head3>\n        <p>41 寸，咸鱼购入，已改效果器，偶尔摸摸练练歌</p>\n    </div>\n</div>\n\n\n","excerpt":"","more":"<h2 id=\"Devices-·-正在使用的设备\"><a href=\"#Devices-·-正在使用的设备\" class=\"headerlink\" title=\"Devices  · 正在使用的设备\"></a>Devices  · 正在使用的设备</h2><div class=\"device-card\">\n    <img src=\"img/macbookpro.jpg\" alt=\"Apple Macbook pro 14 2024 M2\">\n    <div class=\"device-info\">\n        <head3>Apple Macbook pro 14 2024 M2</head3>\n        <p>2023 年初购入，目前主要生产力</p>\n    </div>\n</div>\n\n<div class=\"device-card\">\n    <img src=\"img/iphone13pro.jpg\" alt=\"Apple iPhone 13 Pro\">\n    <div class=\"device-info\">\n        <head3>Apple iPhone 13 Pro</head3>\n        <p>2020 年双 11 购入，除了电池不耐用，其他依旧能打</p>\n    </div>\n</div>\n\n<div class=\"device-card\">\n    <img src=\"img/sonyzv1.jpg\" alt=\"Sony ZV-1\">\n    <div class=\"device-info\">\n        <head3>Sony ZV-1</head3>\n        <p>Vlog 相机，当年 \"Vlog 第一机\"，目前能打，旅游，日常采风给 Amelia 拍照</p>\n    </div>\n</div>\n\n<div class=\"device-card\">\n    <img src=\"img/bosemini2.png\" alt=\"Bose SoundLink Mini 2\">\n    <div class=\"device-info\">\n        <head3>Bose SoundLink Mini 2</head3>\n        <p>声音效果强，日常影音，打游戏挺适合的，用于家里台式机</p>\n    </div>\n</div>\n\n<div class=\"device-card\">\n    <img src=\"img/ktch27v22s.jpg\" alt=\"KTC H27V22s\">\n    <div class=\"device-info\">\n        <head3>KTC H27V22s</head3>\n        <p>购入 2022 年 9 月，27 寸 2K 170Hz，用于家里台式机，娱乐使用</p>\n    </div>\n</div>\n\n<div class=\"device-card\">\n    <img src=\"img/dellp2419h.png\" alt=\"Dell P2419H\">\n    <div class=\"device-info\">\n        <head3>Dell P2419H</head3>\n        <p>购入 2019 年，24 寸 2K 60Hz。Dell 校色没的说，目前办公够用</p>\n    </div>\n</div>\n\n<div class=\"device-card\">\n    <img src=\"img/kindlepaperwhite5.jpg\" alt=\"Kindle paperwhite 5\">\n    <div class=\"device-info\">\n        <head3>Kindle paperwhite 5</head3>\n        <p>公司积分换的，读书伴侣，相较于 kindle 4 多了屏幕灯，提升巨大</p>\n    </div>\n</div>\n\n<div class=\"device-card discontinued\">\n    <img src=\"img/kindle4.jpeg\" alt=\"Kindle 4\">\n    <div class=\"device-info\">\n        <head3>Kindle 4</head3>\n        <p>之前主力阅读器，后来换 Kindle paperwhite 5 后送个弟弟用了</p>\n    </div>\n</div>\n\n<div class=\"device-card discontinued\">\n    <img src=\"img/vgn98pro.jpeg\" alt=\"VGN 98pro\">\n    <div class=\"device-info\">\n        <head3>VGN 98pro</head3>\n        <p>蒸汽波轴，原来是海盐蓝，配了苹果 ins 风白色键帽，颜值无敌，手感也好，换 MX keys 前主力办公键盘，稍微有点吵，目前已二手出了。VGN 的键盘啥都好，就是脚垫做不好</p>\n    </div>\n</div>\n\n<div class=\"device-card\">\n    <img src=\"img/mxkeys.jpg\" alt=\"Logitech MX keys\">\n    <div class=\"device-info\">\n        <head3>Logitech MX keys for Bussiness</head3>\n        <p>改变了对传统薄膜键盘的偏见，续航长，布局合理，多设备连接，适配 Macbook，适合办公使用</p>\n    </div>\n</div>\n\n<div class=\"device-card\">\n    <img src=\"img/gpw.jpg\" alt=\"Logitech GPW\">\n    <div class=\"device-info\">\n        <head3>Logitech GPW 1代</head3>\n        <p>购入 2019 年，适合小手，目前在役游戏使用</p>\n    </div>\n</div>\n\n<div class=\"device-card\">\n    <img src=\"img/mxmaster3.jpg\" alt=\"Logitech MX Master 3\">\n    <div class=\"device-info\">\n        <head3>Logitech MX Master 3</head3>\n        <p>配套 MX keys 办公室使用，主要用 Logitech Flow 技术在多平台切换</p>\n    </div>\n</div>\n\n<div class=\"device-card discontinued\">\n    <img src=\"img/g102.webp\" alt=\"Logitech G102\">\n    <div class=\"device-info\">\n        <head3>Logitech G102</head3>\n        <p>在役 6 年，太能打了，后连击问题换了</p>\n    </div>\n</div>\n\n<div class=\"device-card\">\n    <img src=\"img/boseqc352.jpg\" alt=\"BOSE QuietComfort QC35 II\">\n    <div class=\"device-info\">\n        <head3>BOSE QuietComfort QC35 II</head3>\n        <p>2020 年购入，降噪效果明显，大耳适合在冬天通勤当耳暖用，夏天几乎不戴</p>\n    </div>\n</div>\n\n<div class=\"device-card discontinued\">\n    <img src=\"img/airpodspro.jpg\" alt=\"Apple AirPods Pro 1代\">\n    <div class=\"device-info\">\n        <head3>Apple AirPods Pro 1代</head3>\n        <p>2019 年购入，Amelia 不习惯佩戴，送给我用，因为首批有降噪模块问题，目前已闲置</p>\n    </div>\n</div>\n\n<div class=\"device-card\">\n    <img src=\"img/airpods3.jpg\" alt=\"Apple AirPods 3\">\n    <div class=\"device-info\">\n        <head3>Airpods 3</head3>\n        <p>Airpods pro 闲置之后购入，夏季通勤，办公室开会使用</p>\n    </div>\n</div>\n\n<div class=\"device-card\">\n    <img src=\"img/athim70.jpg\" alt=\"铁三角ATH-IM70\">\n    <div class=\"device-info\">\n        <head3>铁三角ATH-IM70</head3>\n        <p>大学主力有线耳机，ACG，人声通透，目前退居二线，主要连吉他效果器音响练琴用</p>\n    </div>\n</div>\n\n<div class=\"device-card\">\n    <img src=\"img/fg830.webp\" alt=\"Yamaha FG830\">\n    <div class=\"device-info\">\n        <head3>Yamaha FG830</head3>\n        <p>41 寸，咸鱼购入，已改效果器，偶尔摸摸练练歌</p>\n    </div>\n</div>\n\n\n"}],"Post":[{"title":"Planet配置Web3域名","id":"6885322357796359","date":"2025-08-07T16:00:00.000Z","_content":"\nPlanet 项目是 V 站站长 Livid 很早之前启动的项目。最近 V 站也出了 $V2EX 币， Livid 也一直在推动区块链和 Web3 在 V 站的快速应用。跟着这个趋势，我也学习了很多这方面的知识。\n\n\n\n>  Planet 是一款免费的开源 macOS 应用程序，用于发布和关注 Web 内容。它不依赖于中央服务器或服务，而是使用 IPFS 进行点对点内容分发。您可以将您的内容链接到以太坊名称（例如，planetable.eth），以便其他人可以使用您的 .eth 名称在 Planet 上关注您，或通过 eth.limo 或 eth.sucks 等网关访问您的 ENS 网站。由于 IPFS 和 ENS 都是去中心化的，因此 Planet 可以帮助您以去中心化的方式构建和关注网站。\n\n\n了解到 Planet 的特性以及原理后，我发现 Planet 很适合做日志，随记，心情，备忘录的 Posts。正好我当前 Web2 的博客网站上没有类似的功能，索性把 Planet 的 Web 集成到博客网站上。我火速给自己搭建了 Web，并在此 Web 上链接了 Web3 的域名。你可以点击导航栏上的 『碎碎念🔗』或者直接访问我的 Web3 域名『 https://uhufoundme.sol.build/ 』，跳转到我的日常更新 Posts。\n\n\n言归正题，Planet 应用能够轻松将 Web 内容发布在链上，并通过 IPFS 生成的 IPNS 访问链上内容。但是这个 IPNS 是随机的哈希值，难记，不易传播，所以就需要链接一个 Web3 域名。这里有两种方案，一种是直接买一个 Web3 的域名，类似 .eth 或者 .sol 的。另一种是 Web2 域名开启 IPNS，支持链上内容的绑定。因为我本来就有个 Web2 域名，所以一开始我想开通 IPNS 就不用再折腾了。这里吐槽一下，阿里云域名开通 IPNS 要￥120，而 .eth 域名每月几美刀，.sol 冷门域名 1 刀就可以永久拥有，那就用 .sol 吧。\n\n\n## 购买域名\n\n\n> Solana域名服务（SNS）的目标是提供一种去中心化且可负担的方式，将域名（.sol）和链上数据连接起来。这些链上数据可以是SOL地址、 IPFS CID、图片、文本、或者任何其它的东西。\n\n\n![Solana域名主页](img/image-202588319698.png)\n\n\n\n在 [Solana](https://www.sns.id/zh-Hans) 上购买域名需要通过 Web3钱包登录，该网站支持多种钱包，我使用的是 phantom 钱包。登录之后就可以直接在页面上搜索想要的域名，其中大部分的域名都在 20 USDC（大概 $20），一些冷门的域名可以 1 USDC 捡到，可以多试试。\n\n\n\n![image-202588559199.png](img/image-202588559199.png)\n\n\n\n支付时候也有多种方式，可以用 SOL，USDC，USDT 或者其他虚拟货币，甚至可以用信用卡。在这里，不讨论如何充值虚拟货币，如果有疑问可以 google。需要注意的是，**所有链上操作都需要有手续费，在充币或者兑换时候要考虑多买多充**。\n\n\n\n![image-202588839176.png](img/image-202588839176.png)\n\n\n\n## 绑定 IPNS\n\n\n\n![image-2025882636315.png](img/image-2025882636315.png)\n\n![image-2025884737529.png](img/image-2025884737529.png)\n\n\n\n在购买之后，就可以去我的域名里面配置，将 Planet 上复制的 IPNS 复制配置好即可。这里我出现了下图的问题，一开始也不清楚什么情况。请教了一下 Livid 之后，才知道是因为绑定操作也是需要消耗 gas 的，我钱包里面 SOL 不够。然后 Livid 给我空投 0.1 SOL 之后就绑定成功。\n\n\n\n![telegram-cloud-photo-size-5-6098227393199198658-y.jpg](img/telegram-cloud-photo-size-5-6098227393199198658-y.jpg)\n\n\n\n这样就可以通过 https://uhufoundme.sol.build/ 访问了。在这个过程中，感谢 Livid 大佬的答疑以及空投。\n\n\n\n得益于 IPFS 这种 P2P 的方式，在 Planet 中 Send 之后就发布在 Web 上，不需要额外的去服务器上发布内容。这种便捷的方式对我来说更适合去记录即时的灵感和感受。所以我决定在 https://uhufoundme.sol.build/ 更新些更随意，更生活的内容，在 https://www.lazydaily.cn/ 更新些更严谨，更有质量的内容。你也可以通过不同的地址来关注感兴趣的内容。\n","source":"_posts/md/Planet配置Web3域名.md","raw":"---\n\ntitle: Planet配置Web3域名\ntag:\n- Planet\ncategory:\n- Web3\nid:  6885322357796359\ndate:  2025-08-08\n\n---\n\nPlanet 项目是 V 站站长 Livid 很早之前启动的项目。最近 V 站也出了 $V2EX 币， Livid 也一直在推动区块链和 Web3 在 V 站的快速应用。跟着这个趋势，我也学习了很多这方面的知识。\n\n\n\n>  Planet 是一款免费的开源 macOS 应用程序，用于发布和关注 Web 内容。它不依赖于中央服务器或服务，而是使用 IPFS 进行点对点内容分发。您可以将您的内容链接到以太坊名称（例如，planetable.eth），以便其他人可以使用您的 .eth 名称在 Planet 上关注您，或通过 eth.limo 或 eth.sucks 等网关访问您的 ENS 网站。由于 IPFS 和 ENS 都是去中心化的，因此 Planet 可以帮助您以去中心化的方式构建和关注网站。\n\n\n了解到 Planet 的特性以及原理后，我发现 Planet 很适合做日志，随记，心情，备忘录的 Posts。正好我当前 Web2 的博客网站上没有类似的功能，索性把 Planet 的 Web 集成到博客网站上。我火速给自己搭建了 Web，并在此 Web 上链接了 Web3 的域名。你可以点击导航栏上的 『碎碎念🔗』或者直接访问我的 Web3 域名『 https://uhufoundme.sol.build/ 』，跳转到我的日常更新 Posts。\n\n\n言归正题，Planet 应用能够轻松将 Web 内容发布在链上，并通过 IPFS 生成的 IPNS 访问链上内容。但是这个 IPNS 是随机的哈希值，难记，不易传播，所以就需要链接一个 Web3 域名。这里有两种方案，一种是直接买一个 Web3 的域名，类似 .eth 或者 .sol 的。另一种是 Web2 域名开启 IPNS，支持链上内容的绑定。因为我本来就有个 Web2 域名，所以一开始我想开通 IPNS 就不用再折腾了。这里吐槽一下，阿里云域名开通 IPNS 要￥120，而 .eth 域名每月几美刀，.sol 冷门域名 1 刀就可以永久拥有，那就用 .sol 吧。\n\n\n## 购买域名\n\n\n> Solana域名服务（SNS）的目标是提供一种去中心化且可负担的方式，将域名（.sol）和链上数据连接起来。这些链上数据可以是SOL地址、 IPFS CID、图片、文本、或者任何其它的东西。\n\n\n![Solana域名主页](img/image-202588319698.png)\n\n\n\n在 [Solana](https://www.sns.id/zh-Hans) 上购买域名需要通过 Web3钱包登录，该网站支持多种钱包，我使用的是 phantom 钱包。登录之后就可以直接在页面上搜索想要的域名，其中大部分的域名都在 20 USDC（大概 $20），一些冷门的域名可以 1 USDC 捡到，可以多试试。\n\n\n\n![image-202588559199.png](img/image-202588559199.png)\n\n\n\n支付时候也有多种方式，可以用 SOL，USDC，USDT 或者其他虚拟货币，甚至可以用信用卡。在这里，不讨论如何充值虚拟货币，如果有疑问可以 google。需要注意的是，**所有链上操作都需要有手续费，在充币或者兑换时候要考虑多买多充**。\n\n\n\n![image-202588839176.png](img/image-202588839176.png)\n\n\n\n## 绑定 IPNS\n\n\n\n![image-2025882636315.png](img/image-2025882636315.png)\n\n![image-2025884737529.png](img/image-2025884737529.png)\n\n\n\n在购买之后，就可以去我的域名里面配置，将 Planet 上复制的 IPNS 复制配置好即可。这里我出现了下图的问题，一开始也不清楚什么情况。请教了一下 Livid 之后，才知道是因为绑定操作也是需要消耗 gas 的，我钱包里面 SOL 不够。然后 Livid 给我空投 0.1 SOL 之后就绑定成功。\n\n\n\n![telegram-cloud-photo-size-5-6098227393199198658-y.jpg](img/telegram-cloud-photo-size-5-6098227393199198658-y.jpg)\n\n\n\n这样就可以通过 https://uhufoundme.sol.build/ 访问了。在这个过程中，感谢 Livid 大佬的答疑以及空投。\n\n\n\n得益于 IPFS 这种 P2P 的方式，在 Planet 中 Send 之后就发布在 Web 上，不需要额外的去服务器上发布内容。这种便捷的方式对我来说更适合去记录即时的灵感和感受。所以我决定在 https://uhufoundme.sol.build/ 更新些更随意，更生活的内容，在 https://www.lazydaily.cn/ 更新些更严谨，更有质量的内容。你也可以通过不同的地址来关注感兴趣的内容。\n","slug":"md/Planet配置Web3域名","published":1,"updated":"2025-08-21T09:29:25.589Z","comments":1,"layout":"post","photos":[],"_id":"cmhc3m3u80001xdp8591sb4mm","content":"<p>Planet 项目是 V 站站长 Livid 很早之前启动的项目。最近 V 站也出了 $V2EX 币， Livid 也一直在推动区块链和 Web3 在 V 站的快速应用。跟着这个趋势，我也学习了很多这方面的知识。</p>\n<blockquote>\n<p> Planet 是一款免费的开源 macOS 应用程序，用于发布和关注 Web 内容。它不依赖于中央服务器或服务，而是使用 IPFS 进行点对点内容分发。您可以将您的内容链接到以太坊名称（例如，planetable.eth），以便其他人可以使用您的 .eth 名称在 Planet 上关注您，或通过 eth.limo 或 eth.sucks 等网关访问您的 ENS 网站。由于 IPFS 和 ENS 都是去中心化的，因此 Planet 可以帮助您以去中心化的方式构建和关注网站。</p>\n</blockquote>\n<p>了解到 Planet 的特性以及原理后，我发现 Planet 很适合做日志，随记，心情，备忘录的 Posts。正好我当前 Web2 的博客网站上没有类似的功能，索性把 Planet 的 Web 集成到博客网站上。我火速给自己搭建了 Web，并在此 Web 上链接了 Web3 的域名。你可以点击导航栏上的 『碎碎念🔗』或者直接访问我的 Web3 域名『 <a href=\"https://uhufoundme.sol.build/\">https://uhufoundme.sol.build/</a> 』，跳转到我的日常更新 Posts。</p>\n<p>言归正题，Planet 应用能够轻松将 Web 内容发布在链上，并通过 IPFS 生成的 IPNS 访问链上内容。但是这个 IPNS 是随机的哈希值，难记，不易传播，所以就需要链接一个 Web3 域名。这里有两种方案，一种是直接买一个 Web3 的域名，类似 .eth 或者 .sol 的。另一种是 Web2 域名开启 IPNS，支持链上内容的绑定。因为我本来就有个 Web2 域名，所以一开始我想开通 IPNS 就不用再折腾了。这里吐槽一下，阿里云域名开通 IPNS 要￥120，而 .eth 域名每月几美刀，.sol 冷门域名 1 刀就可以永久拥有，那就用 .sol 吧。</p>\n<h2 id=\"购买域名\"><a href=\"#购买域名\" class=\"headerlink\" title=\"购买域名\"></a>购买域名</h2><blockquote>\n<p>Solana域名服务（SNS）的目标是提供一种去中心化且可负担的方式，将域名（.sol）和链上数据连接起来。这些链上数据可以是SOL地址、 IPFS CID、图片、文本、或者任何其它的东西。</p>\n</blockquote>\n<p><img src=\"/img/image-202588319698.png\" alt=\"Solana域名主页\"></p>\n<p>在 <a href=\"https://www.sns.id/zh-Hans\">Solana</a> 上购买域名需要通过 Web3钱包登录，该网站支持多种钱包，我使用的是 phantom 钱包。登录之后就可以直接在页面上搜索想要的域名，其中大部分的域名都在 20 USDC（大概 $20），一些冷门的域名可以 1 USDC 捡到，可以多试试。</p>\n<p><img src=\"/img/image-202588559199.png\" alt=\"image-202588559199.png\"></p>\n<p>支付时候也有多种方式，可以用 SOL，USDC，USDT 或者其他虚拟货币，甚至可以用信用卡。在这里，不讨论如何充值虚拟货币，如果有疑问可以 google。需要注意的是，<strong>所有链上操作都需要有手续费，在充币或者兑换时候要考虑多买多充</strong>。</p>\n<p><img src=\"/img/image-202588839176.png\" alt=\"image-202588839176.png\"></p>\n<h2 id=\"绑定-IPNS\"><a href=\"#绑定-IPNS\" class=\"headerlink\" title=\"绑定 IPNS\"></a>绑定 IPNS</h2><p><img src=\"/img/image-2025882636315.png\" alt=\"image-2025882636315.png\"></p>\n<p><img src=\"/img/image-2025884737529.png\" alt=\"image-2025884737529.png\"></p>\n<p>在购买之后，就可以去我的域名里面配置，将 Planet 上复制的 IPNS 复制配置好即可。这里我出现了下图的问题，一开始也不清楚什么情况。请教了一下 Livid 之后，才知道是因为绑定操作也是需要消耗 gas 的，我钱包里面 SOL 不够。然后 Livid 给我空投 0.1 SOL 之后就绑定成功。</p>\n<p><img src=\"/img/telegram-cloud-photo-size-5-6098227393199198658-y.jpg\" alt=\"telegram-cloud-photo-size-5-6098227393199198658-y.jpg\"></p>\n<p>这样就可以通过 <a href=\"https://uhufoundme.sol.build/\">https://uhufoundme.sol.build/</a> 访问了。在这个过程中，感谢 Livid 大佬的答疑以及空投。</p>\n<p>得益于 IPFS 这种 P2P 的方式，在 Planet 中 Send 之后就发布在 Web 上，不需要额外的去服务器上发布内容。这种便捷的方式对我来说更适合去记录即时的灵感和感受。所以我决定在 <a href=\"https://uhufoundme.sol.build/\">https://uhufoundme.sol.build/</a> 更新些更随意，更生活的内容，在 <a href=\"https://www.lazydaily.cn/\">https://www.lazydaily.cn/</a> 更新些更严谨，更有质量的内容。你也可以通过不同的地址来关注感兴趣的内容。</p>\n","excerpt":"","more":"<p>Planet 项目是 V 站站长 Livid 很早之前启动的项目。最近 V 站也出了 $V2EX 币， Livid 也一直在推动区块链和 Web3 在 V 站的快速应用。跟着这个趋势，我也学习了很多这方面的知识。</p>\n<blockquote>\n<p> Planet 是一款免费的开源 macOS 应用程序，用于发布和关注 Web 内容。它不依赖于中央服务器或服务，而是使用 IPFS 进行点对点内容分发。您可以将您的内容链接到以太坊名称（例如，planetable.eth），以便其他人可以使用您的 .eth 名称在 Planet 上关注您，或通过 eth.limo 或 eth.sucks 等网关访问您的 ENS 网站。由于 IPFS 和 ENS 都是去中心化的，因此 Planet 可以帮助您以去中心化的方式构建和关注网站。</p>\n</blockquote>\n<p>了解到 Planet 的特性以及原理后，我发现 Planet 很适合做日志，随记，心情，备忘录的 Posts。正好我当前 Web2 的博客网站上没有类似的功能，索性把 Planet 的 Web 集成到博客网站上。我火速给自己搭建了 Web，并在此 Web 上链接了 Web3 的域名。你可以点击导航栏上的 『碎碎念🔗』或者直接访问我的 Web3 域名『 <a href=\"https://uhufoundme.sol.build/\">https://uhufoundme.sol.build/</a> 』，跳转到我的日常更新 Posts。</p>\n<p>言归正题，Planet 应用能够轻松将 Web 内容发布在链上，并通过 IPFS 生成的 IPNS 访问链上内容。但是这个 IPNS 是随机的哈希值，难记，不易传播，所以就需要链接一个 Web3 域名。这里有两种方案，一种是直接买一个 Web3 的域名，类似 .eth 或者 .sol 的。另一种是 Web2 域名开启 IPNS，支持链上内容的绑定。因为我本来就有个 Web2 域名，所以一开始我想开通 IPNS 就不用再折腾了。这里吐槽一下，阿里云域名开通 IPNS 要￥120，而 .eth 域名每月几美刀，.sol 冷门域名 1 刀就可以永久拥有，那就用 .sol 吧。</p>\n<h2 id=\"购买域名\"><a href=\"#购买域名\" class=\"headerlink\" title=\"购买域名\"></a>购买域名</h2><blockquote>\n<p>Solana域名服务（SNS）的目标是提供一种去中心化且可负担的方式，将域名（.sol）和链上数据连接起来。这些链上数据可以是SOL地址、 IPFS CID、图片、文本、或者任何其它的东西。</p>\n</blockquote>\n<p><img src=\"/img/image-202588319698.png\" alt=\"Solana域名主页\"></p>\n<p>在 <a href=\"https://www.sns.id/zh-Hans\">Solana</a> 上购买域名需要通过 Web3钱包登录，该网站支持多种钱包，我使用的是 phantom 钱包。登录之后就可以直接在页面上搜索想要的域名，其中大部分的域名都在 20 USDC（大概 $20），一些冷门的域名可以 1 USDC 捡到，可以多试试。</p>\n<p><img src=\"/img/image-202588559199.png\" alt=\"image-202588559199.png\"></p>\n<p>支付时候也有多种方式，可以用 SOL，USDC，USDT 或者其他虚拟货币，甚至可以用信用卡。在这里，不讨论如何充值虚拟货币，如果有疑问可以 google。需要注意的是，<strong>所有链上操作都需要有手续费，在充币或者兑换时候要考虑多买多充</strong>。</p>\n<p><img src=\"/img/image-202588839176.png\" alt=\"image-202588839176.png\"></p>\n<h2 id=\"绑定-IPNS\"><a href=\"#绑定-IPNS\" class=\"headerlink\" title=\"绑定 IPNS\"></a>绑定 IPNS</h2><p><img src=\"/img/image-2025882636315.png\" alt=\"image-2025882636315.png\"></p>\n<p><img src=\"/img/image-2025884737529.png\" alt=\"image-2025884737529.png\"></p>\n<p>在购买之后，就可以去我的域名里面配置，将 Planet 上复制的 IPNS 复制配置好即可。这里我出现了下图的问题，一开始也不清楚什么情况。请教了一下 Livid 之后，才知道是因为绑定操作也是需要消耗 gas 的，我钱包里面 SOL 不够。然后 Livid 给我空投 0.1 SOL 之后就绑定成功。</p>\n<p><img src=\"/img/telegram-cloud-photo-size-5-6098227393199198658-y.jpg\" alt=\"telegram-cloud-photo-size-5-6098227393199198658-y.jpg\"></p>\n<p>这样就可以通过 <a href=\"https://uhufoundme.sol.build/\">https://uhufoundme.sol.build/</a> 访问了。在这个过程中，感谢 Livid 大佬的答疑以及空投。</p>\n<p>得益于 IPFS 这种 P2P 的方式，在 Planet 中 Send 之后就发布在 Web 上，不需要额外的去服务器上发布内容。这种便捷的方式对我来说更适合去记录即时的灵感和感受。所以我决定在 <a href=\"https://uhufoundme.sol.build/\">https://uhufoundme.sol.build/</a> 更新些更随意，更生活的内容，在 <a href=\"https://www.lazydaily.cn/\">https://www.lazydaily.cn/</a> 更新些更严谨，更有质量的内容。你也可以通过不同的地址来关注感兴趣的内容。</p>\n"},{"title":"「持续更新」AI辅助编程使用心得","date":"2025-05-12T16:00:00.000Z","id":"761386768996888","_content":"\n\n\n## 前言\n\n2025 年初，Deepseek 爆火。随之而来，就是各种 AI 相关的技术如同雨后春笋般涌现。其中关于 AI 编程方向，各家大厂各显神通。\n\n早在 2024 年初，我就开始接触 AI 编程，一开始就使用了 Cursor。当我熟悉了它的操作之后，惊叹于它输出代码的质量。随后，我向身边朋友，同事极力推荐 Cursor。\n\n本质上，Cursor 是一个集成 AI 能力的 VS Code 编辑器。尽管后来尝试各个大厂的不同的 AI 编程工具，例如：通义灵码，Windsurf，Trae 等，甚至自己搭建平台调用 Deepseek Api 完成编程辅助工作，但坦言来讲，体验都不如 Cursor。\n\n## Cursor 收费模式\n\n当然，Cursor 并不是免费的。它的收费方式是订阅制，订阅价格在 $20 / 月。其中包含 500 次快请求，以及不限次数的慢请求。说实话，每月 140 块钱确实让人望而却步。\n\n![Cursor收费模式](img/Pastedimage20250514161308.png)\n\nCursor 相对新用户还是有很好的政策。新用户首月 14 天 150 次快请求，次月及以后每月 50 次快请求，用完就不能再使用了。理论上有足够多的账号，也可以白嫖。在没有教育优惠前，我就是用两个账号的试用和免费请求体验了 cursor 的绝大数功能。\n\n> 个人使用来说，我一般使用 cursor 调整前端样式，或者解决前端报错问题。或者直接需求文档丢给 cursor 让他给我生成前端文件。50 次请求大概能完成 2~3 个复杂功能页面的开发。\n\n## Cursor 教育优惠\n\n2025 年 5 月 8 号上午，cursor 开放教育优惠。凭借学生身份可以申请为期 1 年的 pro 会员。但是因为中国用户申请过多，在当天下午取消 CN 节点。目前可以用国外 edu 邮箱+学生信息验证，推荐咸鱼，一般来说 ￥100~200 不等可以搞定成品号。\n\n目前，我使用的就是 Cursor 教育优惠。在咸鱼上搜 Cursor 教育优惠，用￥120 购买一个 [SAN JOSÉ STATE UNIVERSITY](http://www.sjsu.edu/) 的 edu 邮箱和绑定信息。操作相对简单，只需要绑定登录邮箱，申请 Cursor 教育优惠认证即可（过程中可能需要绑定支付宝 0 元订阅，订阅成功之后可直接取消订阅，不影响当前订阅）。如果后续还有学生认证，可以转发 edu 邮箱到自己常用邮箱，这样就不会错过认证邮件。\n\n> 2025-5-20：订阅时间从 2025 年 5 月 12 号到 2026 年 5 月 12 号，当前使用无问题，后续有问题补充\n\n![Pro会员状态](img/Pastedimage20250520090726.png)\n\n目前来说，500 次快请求基本满足个人高强度使用的要求。","source":"_posts/md/「持续更新」AI辅助编程使用心得.md","raw":"---\n\ntitle: 「持续更新」AI辅助编程使用心得\ntag:\n- Cursor\ncategory:\n- AI\ndate:  2025-05-13\nid: 761386768996888\n---\n\n\n\n## 前言\n\n2025 年初，Deepseek 爆火。随之而来，就是各种 AI 相关的技术如同雨后春笋般涌现。其中关于 AI 编程方向，各家大厂各显神通。\n\n早在 2024 年初，我就开始接触 AI 编程，一开始就使用了 Cursor。当我熟悉了它的操作之后，惊叹于它输出代码的质量。随后，我向身边朋友，同事极力推荐 Cursor。\n\n本质上，Cursor 是一个集成 AI 能力的 VS Code 编辑器。尽管后来尝试各个大厂的不同的 AI 编程工具，例如：通义灵码，Windsurf，Trae 等，甚至自己搭建平台调用 Deepseek Api 完成编程辅助工作，但坦言来讲，体验都不如 Cursor。\n\n## Cursor 收费模式\n\n当然，Cursor 并不是免费的。它的收费方式是订阅制，订阅价格在 $20 / 月。其中包含 500 次快请求，以及不限次数的慢请求。说实话，每月 140 块钱确实让人望而却步。\n\n![Cursor收费模式](img/Pastedimage20250514161308.png)\n\nCursor 相对新用户还是有很好的政策。新用户首月 14 天 150 次快请求，次月及以后每月 50 次快请求，用完就不能再使用了。理论上有足够多的账号，也可以白嫖。在没有教育优惠前，我就是用两个账号的试用和免费请求体验了 cursor 的绝大数功能。\n\n> 个人使用来说，我一般使用 cursor 调整前端样式，或者解决前端报错问题。或者直接需求文档丢给 cursor 让他给我生成前端文件。50 次请求大概能完成 2~3 个复杂功能页面的开发。\n\n## Cursor 教育优惠\n\n2025 年 5 月 8 号上午，cursor 开放教育优惠。凭借学生身份可以申请为期 1 年的 pro 会员。但是因为中国用户申请过多，在当天下午取消 CN 节点。目前可以用国外 edu 邮箱+学生信息验证，推荐咸鱼，一般来说 ￥100~200 不等可以搞定成品号。\n\n目前，我使用的就是 Cursor 教育优惠。在咸鱼上搜 Cursor 教育优惠，用￥120 购买一个 [SAN JOSÉ STATE UNIVERSITY](http://www.sjsu.edu/) 的 edu 邮箱和绑定信息。操作相对简单，只需要绑定登录邮箱，申请 Cursor 教育优惠认证即可（过程中可能需要绑定支付宝 0 元订阅，订阅成功之后可直接取消订阅，不影响当前订阅）。如果后续还有学生认证，可以转发 edu 邮箱到自己常用邮箱，这样就不会错过认证邮件。\n\n> 2025-5-20：订阅时间从 2025 年 5 月 12 号到 2026 年 5 月 12 号，当前使用无问题，后续有问题补充\n\n![Pro会员状态](img/Pastedimage20250520090726.png)\n\n目前来说，500 次快请求基本满足个人高强度使用的要求。","slug":"md/「持续更新」AI辅助编程使用心得","published":1,"updated":"2025-05-20T07:21:06.990Z","comments":1,"layout":"post","photos":[],"_id":"cmhc3m3u90003xdp8fv4k2eqc","content":"<h2 id=\"前言\"><a href=\"#前言\" class=\"headerlink\" title=\"前言\"></a>前言</h2><p>2025 年初，Deepseek 爆火。随之而来，就是各种 AI 相关的技术如同雨后春笋般涌现。其中关于 AI 编程方向，各家大厂各显神通。</p>\n<p>早在 2024 年初，我就开始接触 AI 编程，一开始就使用了 Cursor。当我熟悉了它的操作之后，惊叹于它输出代码的质量。随后，我向身边朋友，同事极力推荐 Cursor。</p>\n<p>本质上，Cursor 是一个集成 AI 能力的 VS Code 编辑器。尽管后来尝试各个大厂的不同的 AI 编程工具，例如：通义灵码，Windsurf，Trae 等，甚至自己搭建平台调用 Deepseek Api 完成编程辅助工作，但坦言来讲，体验都不如 Cursor。</p>\n<h2 id=\"Cursor-收费模式\"><a href=\"#Cursor-收费模式\" class=\"headerlink\" title=\"Cursor 收费模式\"></a>Cursor 收费模式</h2><p>当然，Cursor 并不是免费的。它的收费方式是订阅制，订阅价格在 $20 &#x2F; 月。其中包含 500 次快请求，以及不限次数的慢请求。说实话，每月 140 块钱确实让人望而却步。</p>\n<p><img src=\"/img/Pastedimage20250514161308.png\" alt=\"Cursor收费模式\"></p>\n<p>Cursor 相对新用户还是有很好的政策。新用户首月 14 天 150 次快请求，次月及以后每月 50 次快请求，用完就不能再使用了。理论上有足够多的账号，也可以白嫖。在没有教育优惠前，我就是用两个账号的试用和免费请求体验了 cursor 的绝大数功能。</p>\n<blockquote>\n<p>个人使用来说，我一般使用 cursor 调整前端样式，或者解决前端报错问题。或者直接需求文档丢给 cursor 让他给我生成前端文件。50 次请求大概能完成 2~3 个复杂功能页面的开发。</p>\n</blockquote>\n<h2 id=\"Cursor-教育优惠\"><a href=\"#Cursor-教育优惠\" class=\"headerlink\" title=\"Cursor 教育优惠\"></a>Cursor 教育优惠</h2><p>2025 年 5 月 8 号上午，cursor 开放教育优惠。凭借学生身份可以申请为期 1 年的 pro 会员。但是因为中国用户申请过多，在当天下午取消 CN 节点。目前可以用国外 edu 邮箱+学生信息验证，推荐咸鱼，一般来说 ￥100~200 不等可以搞定成品号。</p>\n<p>目前，我使用的就是 Cursor 教育优惠。在咸鱼上搜 Cursor 教育优惠，用￥120 购买一个 <a href=\"http://www.sjsu.edu/\">SAN JOSÉ STATE UNIVERSITY</a> 的 edu 邮箱和绑定信息。操作相对简单，只需要绑定登录邮箱，申请 Cursor 教育优惠认证即可（过程中可能需要绑定支付宝 0 元订阅，订阅成功之后可直接取消订阅，不影响当前订阅）。如果后续还有学生认证，可以转发 edu 邮箱到自己常用邮箱，这样就不会错过认证邮件。</p>\n<blockquote>\n<p>2025-5-20：订阅时间从 2025 年 5 月 12 号到 2026 年 5 月 12 号，当前使用无问题，后续有问题补充</p>\n</blockquote>\n<p><img src=\"/img/Pastedimage20250520090726.png\" alt=\"Pro会员状态\"></p>\n<p>目前来说，500 次快请求基本满足个人高强度使用的要求。</p>\n","excerpt":"","more":"<h2 id=\"前言\"><a href=\"#前言\" class=\"headerlink\" title=\"前言\"></a>前言</h2><p>2025 年初，Deepseek 爆火。随之而来，就是各种 AI 相关的技术如同雨后春笋般涌现。其中关于 AI 编程方向，各家大厂各显神通。</p>\n<p>早在 2024 年初，我就开始接触 AI 编程，一开始就使用了 Cursor。当我熟悉了它的操作之后，惊叹于它输出代码的质量。随后，我向身边朋友，同事极力推荐 Cursor。</p>\n<p>本质上，Cursor 是一个集成 AI 能力的 VS Code 编辑器。尽管后来尝试各个大厂的不同的 AI 编程工具，例如：通义灵码，Windsurf，Trae 等，甚至自己搭建平台调用 Deepseek Api 完成编程辅助工作，但坦言来讲，体验都不如 Cursor。</p>\n<h2 id=\"Cursor-收费模式\"><a href=\"#Cursor-收费模式\" class=\"headerlink\" title=\"Cursor 收费模式\"></a>Cursor 收费模式</h2><p>当然，Cursor 并不是免费的。它的收费方式是订阅制，订阅价格在 $20 &#x2F; 月。其中包含 500 次快请求，以及不限次数的慢请求。说实话，每月 140 块钱确实让人望而却步。</p>\n<p><img src=\"/img/Pastedimage20250514161308.png\" alt=\"Cursor收费模式\"></p>\n<p>Cursor 相对新用户还是有很好的政策。新用户首月 14 天 150 次快请求，次月及以后每月 50 次快请求，用完就不能再使用了。理论上有足够多的账号，也可以白嫖。在没有教育优惠前，我就是用两个账号的试用和免费请求体验了 cursor 的绝大数功能。</p>\n<blockquote>\n<p>个人使用来说，我一般使用 cursor 调整前端样式，或者解决前端报错问题。或者直接需求文档丢给 cursor 让他给我生成前端文件。50 次请求大概能完成 2~3 个复杂功能页面的开发。</p>\n</blockquote>\n<h2 id=\"Cursor-教育优惠\"><a href=\"#Cursor-教育优惠\" class=\"headerlink\" title=\"Cursor 教育优惠\"></a>Cursor 教育优惠</h2><p>2025 年 5 月 8 号上午，cursor 开放教育优惠。凭借学生身份可以申请为期 1 年的 pro 会员。但是因为中国用户申请过多，在当天下午取消 CN 节点。目前可以用国外 edu 邮箱+学生信息验证，推荐咸鱼，一般来说 ￥100~200 不等可以搞定成品号。</p>\n<p>目前，我使用的就是 Cursor 教育优惠。在咸鱼上搜 Cursor 教育优惠，用￥120 购买一个 <a href=\"http://www.sjsu.edu/\">SAN JOSÉ STATE UNIVERSITY</a> 的 edu 邮箱和绑定信息。操作相对简单，只需要绑定登录邮箱，申请 Cursor 教育优惠认证即可（过程中可能需要绑定支付宝 0 元订阅，订阅成功之后可直接取消订阅，不影响当前订阅）。如果后续还有学生认证，可以转发 edu 邮箱到自己常用邮箱，这样就不会错过认证邮件。</p>\n<blockquote>\n<p>2025-5-20：订阅时间从 2025 年 5 月 12 号到 2026 年 5 月 12 号，当前使用无问题，后续有问题补充</p>\n</blockquote>\n<p><img src=\"/img/Pastedimage20250520090726.png\" alt=\"Pro会员状态\"></p>\n<p>目前来说，500 次快请求基本满足个人高强度使用的要求。</p>\n"},{"title":"为什么一定要有一个个人网站？","date":"2025-04-23T16:00:00.000Z","id":"761386768996832","_content":"\n  \n\n## 前言\n\n\n大家好，我是子规，很高兴能够在这里和大家相遇。本篇文章记录该站建立的初衷、建站过程以及在过程中的思考。\n \n## 为什么建立这个网站\n\n\n在此网站建立之前，我通常在CSDN上写作。\n\n但随着时间推移，我开始发现，CSDN上的文章， Although it is very good, but it is not very good for SEO。尽管我在CSDN上没有很多有质量的输出，但是繁杂的信息流却充斥在我面前。关注，点赞，私信，评论，活动等等都是我要面对的。这些信息流无时无刻不在分散我的注意力，使我感到非常痛苦。\n\n因此，我开始探索更有效的方式。前几年微信公众号爆火，我本人也关注不少微信公众号。其中，有非常多关于编程的公众号对我帮助极大，我非常喜欢。时常幻想自己能够在公众号上写好文章，这样我就可以分享自己的知识了，或者说更纯粹的分享自己的知识了。\n\n我也的确这么做了，「整点儿代码」就是尝试。「整点儿代码」最初的规划是，每天产出一篇文章，设置定时晚上10点左右发布，这也 call back 了“整点”这个 concept。可惜，我并没有成功。一方面微信公众号的审核不通过导致不能整点发布，让我十分困扰。另一方面，就是个人没有坚持下来。最重要的一点是，我仍然没有从关注，点赞，私信，评论中脱离出来。是的，公众号也有这样的问题需要我面对。显然，这不是我想要的、理想的博客记录方式。\n\n最终，我决定做一个自己的博客网站。\n\n## 建站过程\n\n\n2022 年，我了解到，GitHub Pages 是一个非常优秀的博客托管平台。基于 Git 方式的 post 和自动化发布节省了我不少的时间，也使我更专注于内容的编写。确定了服务托管方式，剩下的工作就是考虑网站搭建技术方向了。互联网上关于博客类网站建设的技术已经非常成熟了，Wordpress，Vuepress，Docsify，Hexo，Next.js 等等。\n\n### Docsify\n\n最开始时候，我比较欣赏 Docsify 这种静态简单的风格。Docsify 本身支持的插件丰富，包括评论系统，访问次数，字数统计，页面搜索等，可以大大节省自己开发的时间。此外，将项目部署到 Github 上，使用 Github Page 托管之后，不用维护本地文档。编写文章发布也不需要编译，只要提交文件，等待自动部署即可。\n\n\n你可以访问 [ https://z1gui.github.io/chips/#/ ](https://z1gui.github.io/chips/#/) 来查看页面。该项目搭建具体参考了[小傅哥](https://bugstack.cn/)的这篇博客 [《# 在GitHub/Gitee上，搭建一个简单的所见即所得博客》](https://blog.csdn.net/generalfu/article/details/123268118?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522815fa9b0be7b0090fc06b78edb862108%2522%252C%2522scm%2522%253A%252220140713.130102334.pc%255Fblog.%2522%257D&request_id=815fa9b0be7b0090fc06b78edb862108&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~blog~first_rank_ecpm_v1~rank_v31_ecpm-2-123268118-null-null.nonecase&utm_term=docsify&spm=1018.2226.3001.4450)。如果你觉得这个样式符合自己的审美，也可以参考我仓库里面的这个项目 [ https://github.com/z1gui/chips ](https://github.com/z1gui/chips) 配置。\n\n期间，我还尝试将 Docsify 部署到云服务器上，后来发现不如在 Github 上好管理，遂放弃。\n\n\n### Hexo\n\n再后来，我发现 docsify 很好，但是不够好。在文章展示，以及必要插件上，docsify 能满足一个博客的基础功能。但是，docsify 没有标签，分类，归档等功能。虽然我不追求极致的动效和交互效果，但 Docsify 过于简单的交互效果，让我感觉在阅读一个在线的 markdown 阅读器。与此同时，在 V2ex 的 VXNA 模块看过太多优秀博主的博客，让我又一次萌生了改博客样式的念头。\n\n我开始尝试使用 Hexo 博客框架。Hexo 是一个快速、简单、功能强大的博客框架。你使用 [Markdown](http://daringfireball.net/projects/markdown/)（或其他标记语言）撰写帖子，Hexo 会在几秒钟内生成具有漂亮主题的静态文件。\n\n本站当前使用 [Hexo](https://hexo.io/) 搭建，使用 [hexo-theme-ZenMind-Pro](https://github.com/z1gui/hexo-theme-ZenMind-Pro) 主题搭建。**hexo-theme-ZenMind-Pro** 是本人在 [hexo-theme-ZenMind](https://github.com/zhoulianglen/hexo-theme-ZenMind) 主题上做了修改优化。如有问题，可以联系我或在 issues 中提出您的问题。**在此感谢 [@周良粥凉](https://github.com/zhoulianglen) 的主题以及其博客样式参考**。\n\n在改造 hexo-theme-ZenMind 过程中，我大量使用了 Cursor 进行编程开发。一般来说，简单的样式调整，以及想要达成的效果 Cursor 都能够轻松完成。如果你对 Cursor 编程感兴趣，请参考这篇文章 [[「持续更新」AI辅助编程使用心得]]。其实，Hexo 丰富的生态，即使不二次开发，我相信你也能找到自己心仪的样式框架。\n\n\n\n\n\n## 如何写好自己的博客\n\n  \n从一开始下定决心写博客，我也是迷茫的。什么写，什么不写，这些很难形成一个标准。\n\n究其原因，大部分在写博客的时候，我都在想如何让读者读明白，又如何让读者快速理解。参考我早期的博客就能看出来，有些概念太想解释清楚，以至于长篇大论，尽管它可能很简单。 后来，我意识到博客其实是给自己的知识做沉淀，目的是让自己 \"知其所以然\"。以这个思想来写博客，会发现写好博客并不难。\n\n这是关于《如何写好自己的博客》我想说的其一，**「以自己为中心，让自己 \"知其所以然\"」。** 大多数人写博客是为了提升自己的知识水平，提升自己的专业技能，形成一个自己的知识体系。**「如何通过博客建立自己的知识体系」** ，便是我想要说的其二。\n\n后来有幸拜读 pdai 佬引用的[《知识体系：如何构建自己的知识体系》](https://pdai.tech/md/team/team-z-tixi.html)，醍醐灌顶，感受颇多。这里引用一下文章中的话：\n\n> 我们的学习分为四阶段：输入、内化、沉淀、输出。碎片化在输入的时候用，因为信息本身是碎片化的，时间也是碎片化的，所以输入信息的时候，要碎片化。但有需要体系化的沉淀。因此碎片化的输入，加上体系化的沉淀，你就可以实现利用碎片化的时间，做体系化的学习。\n\n\n整篇文章中，强调了“碎片化学习”形成“体系化技能”。并总结出相应的三个步骤：定目标、搭建知识体系、填内容。其实建立自己的博客，写好自己的博客，也遵从着三个步骤。\n\n这里就扣合了之前提的第一点。在我看来，建立博客的目标应是让自己“知其所以然”。在这个目标下，再去定义体系，填写内容。当然，再后来我发现博客也可以是一个思想沉淀的地方，久而久之我也会将自己的一些体验，感悟放在这里，这是后话，容我们日后再谈。\n\n对我来说，建立博客更像是形成自己知识体系，总结人生感悟的具象化的体现。","source":"_posts/md/为什么一定要有一个个人网站？.md","raw":"---\ntitle: 为什么一定要有一个个人网站？\ntag:\n- 随笔\ncategory:\n- 生活\ndate: 2025-04-24\nid: 761386768996832\n---\n\n  \n\n## 前言\n\n\n大家好，我是子规，很高兴能够在这里和大家相遇。本篇文章记录该站建立的初衷、建站过程以及在过程中的思考。\n \n## 为什么建立这个网站\n\n\n在此网站建立之前，我通常在CSDN上写作。\n\n但随着时间推移，我开始发现，CSDN上的文章， Although it is very good, but it is not very good for SEO。尽管我在CSDN上没有很多有质量的输出，但是繁杂的信息流却充斥在我面前。关注，点赞，私信，评论，活动等等都是我要面对的。这些信息流无时无刻不在分散我的注意力，使我感到非常痛苦。\n\n因此，我开始探索更有效的方式。前几年微信公众号爆火，我本人也关注不少微信公众号。其中，有非常多关于编程的公众号对我帮助极大，我非常喜欢。时常幻想自己能够在公众号上写好文章，这样我就可以分享自己的知识了，或者说更纯粹的分享自己的知识了。\n\n我也的确这么做了，「整点儿代码」就是尝试。「整点儿代码」最初的规划是，每天产出一篇文章，设置定时晚上10点左右发布，这也 call back 了“整点”这个 concept。可惜，我并没有成功。一方面微信公众号的审核不通过导致不能整点发布，让我十分困扰。另一方面，就是个人没有坚持下来。最重要的一点是，我仍然没有从关注，点赞，私信，评论中脱离出来。是的，公众号也有这样的问题需要我面对。显然，这不是我想要的、理想的博客记录方式。\n\n最终，我决定做一个自己的博客网站。\n\n## 建站过程\n\n\n2022 年，我了解到，GitHub Pages 是一个非常优秀的博客托管平台。基于 Git 方式的 post 和自动化发布节省了我不少的时间，也使我更专注于内容的编写。确定了服务托管方式，剩下的工作就是考虑网站搭建技术方向了。互联网上关于博客类网站建设的技术已经非常成熟了，Wordpress，Vuepress，Docsify，Hexo，Next.js 等等。\n\n### Docsify\n\n最开始时候，我比较欣赏 Docsify 这种静态简单的风格。Docsify 本身支持的插件丰富，包括评论系统，访问次数，字数统计，页面搜索等，可以大大节省自己开发的时间。此外，将项目部署到 Github 上，使用 Github Page 托管之后，不用维护本地文档。编写文章发布也不需要编译，只要提交文件，等待自动部署即可。\n\n\n你可以访问 [ https://z1gui.github.io/chips/#/ ](https://z1gui.github.io/chips/#/) 来查看页面。该项目搭建具体参考了[小傅哥](https://bugstack.cn/)的这篇博客 [《# 在GitHub/Gitee上，搭建一个简单的所见即所得博客》](https://blog.csdn.net/generalfu/article/details/123268118?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522815fa9b0be7b0090fc06b78edb862108%2522%252C%2522scm%2522%253A%252220140713.130102334.pc%255Fblog.%2522%257D&request_id=815fa9b0be7b0090fc06b78edb862108&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~blog~first_rank_ecpm_v1~rank_v31_ecpm-2-123268118-null-null.nonecase&utm_term=docsify&spm=1018.2226.3001.4450)。如果你觉得这个样式符合自己的审美，也可以参考我仓库里面的这个项目 [ https://github.com/z1gui/chips ](https://github.com/z1gui/chips) 配置。\n\n期间，我还尝试将 Docsify 部署到云服务器上，后来发现不如在 Github 上好管理，遂放弃。\n\n\n### Hexo\n\n再后来，我发现 docsify 很好，但是不够好。在文章展示，以及必要插件上，docsify 能满足一个博客的基础功能。但是，docsify 没有标签，分类，归档等功能。虽然我不追求极致的动效和交互效果，但 Docsify 过于简单的交互效果，让我感觉在阅读一个在线的 markdown 阅读器。与此同时，在 V2ex 的 VXNA 模块看过太多优秀博主的博客，让我又一次萌生了改博客样式的念头。\n\n我开始尝试使用 Hexo 博客框架。Hexo 是一个快速、简单、功能强大的博客框架。你使用 [Markdown](http://daringfireball.net/projects/markdown/)（或其他标记语言）撰写帖子，Hexo 会在几秒钟内生成具有漂亮主题的静态文件。\n\n本站当前使用 [Hexo](https://hexo.io/) 搭建，使用 [hexo-theme-ZenMind-Pro](https://github.com/z1gui/hexo-theme-ZenMind-Pro) 主题搭建。**hexo-theme-ZenMind-Pro** 是本人在 [hexo-theme-ZenMind](https://github.com/zhoulianglen/hexo-theme-ZenMind) 主题上做了修改优化。如有问题，可以联系我或在 issues 中提出您的问题。**在此感谢 [@周良粥凉](https://github.com/zhoulianglen) 的主题以及其博客样式参考**。\n\n在改造 hexo-theme-ZenMind 过程中，我大量使用了 Cursor 进行编程开发。一般来说，简单的样式调整，以及想要达成的效果 Cursor 都能够轻松完成。如果你对 Cursor 编程感兴趣，请参考这篇文章 [[「持续更新」AI辅助编程使用心得]]。其实，Hexo 丰富的生态，即使不二次开发，我相信你也能找到自己心仪的样式框架。\n\n\n\n\n\n## 如何写好自己的博客\n\n  \n从一开始下定决心写博客，我也是迷茫的。什么写，什么不写，这些很难形成一个标准。\n\n究其原因，大部分在写博客的时候，我都在想如何让读者读明白，又如何让读者快速理解。参考我早期的博客就能看出来，有些概念太想解释清楚，以至于长篇大论，尽管它可能很简单。 后来，我意识到博客其实是给自己的知识做沉淀，目的是让自己 \"知其所以然\"。以这个思想来写博客，会发现写好博客并不难。\n\n这是关于《如何写好自己的博客》我想说的其一，**「以自己为中心，让自己 \"知其所以然\"」。** 大多数人写博客是为了提升自己的知识水平，提升自己的专业技能，形成一个自己的知识体系。**「如何通过博客建立自己的知识体系」** ，便是我想要说的其二。\n\n后来有幸拜读 pdai 佬引用的[《知识体系：如何构建自己的知识体系》](https://pdai.tech/md/team/team-z-tixi.html)，醍醐灌顶，感受颇多。这里引用一下文章中的话：\n\n> 我们的学习分为四阶段：输入、内化、沉淀、输出。碎片化在输入的时候用，因为信息本身是碎片化的，时间也是碎片化的，所以输入信息的时候，要碎片化。但有需要体系化的沉淀。因此碎片化的输入，加上体系化的沉淀，你就可以实现利用碎片化的时间，做体系化的学习。\n\n\n整篇文章中，强调了“碎片化学习”形成“体系化技能”。并总结出相应的三个步骤：定目标、搭建知识体系、填内容。其实建立自己的博客，写好自己的博客，也遵从着三个步骤。\n\n这里就扣合了之前提的第一点。在我看来，建立博客的目标应是让自己“知其所以然”。在这个目标下，再去定义体系，填写内容。当然，再后来我发现博客也可以是一个思想沉淀的地方，久而久之我也会将自己的一些体验，感悟放在这里，这是后话，容我们日后再谈。\n\n对我来说，建立博客更像是形成自己知识体系，总结人生感悟的具象化的体现。","slug":"md/为什么一定要有一个个人网站？","published":1,"updated":"2025-07-23T01:43:49.781Z","comments":1,"layout":"post","photos":[],"_id":"cmhc3m3ub0007xdp8fiz2f97n","content":"<h2 id=\"前言\"><a href=\"#前言\" class=\"headerlink\" title=\"前言\"></a>前言</h2><p>大家好，我是子规，很高兴能够在这里和大家相遇。本篇文章记录该站建立的初衷、建站过程以及在过程中的思考。</p>\n<h2 id=\"为什么建立这个网站\"><a href=\"#为什么建立这个网站\" class=\"headerlink\" title=\"为什么建立这个网站\"></a>为什么建立这个网站</h2><p>在此网站建立之前，我通常在CSDN上写作。</p>\n<p>但随着时间推移，我开始发现，CSDN上的文章， Although it is very good, but it is not very good for SEO。尽管我在CSDN上没有很多有质量的输出，但是繁杂的信息流却充斥在我面前。关注，点赞，私信，评论，活动等等都是我要面对的。这些信息流无时无刻不在分散我的注意力，使我感到非常痛苦。</p>\n<p>因此，我开始探索更有效的方式。前几年微信公众号爆火，我本人也关注不少微信公众号。其中，有非常多关于编程的公众号对我帮助极大，我非常喜欢。时常幻想自己能够在公众号上写好文章，这样我就可以分享自己的知识了，或者说更纯粹的分享自己的知识了。</p>\n<p>我也的确这么做了，「整点儿代码」就是尝试。「整点儿代码」最初的规划是，每天产出一篇文章，设置定时晚上10点左右发布，这也 call back 了“整点”这个 concept。可惜，我并没有成功。一方面微信公众号的审核不通过导致不能整点发布，让我十分困扰。另一方面，就是个人没有坚持下来。最重要的一点是，我仍然没有从关注，点赞，私信，评论中脱离出来。是的，公众号也有这样的问题需要我面对。显然，这不是我想要的、理想的博客记录方式。</p>\n<p>最终，我决定做一个自己的博客网站。</p>\n<h2 id=\"建站过程\"><a href=\"#建站过程\" class=\"headerlink\" title=\"建站过程\"></a>建站过程</h2><p>2022 年，我了解到，GitHub Pages 是一个非常优秀的博客托管平台。基于 Git 方式的 post 和自动化发布节省了我不少的时间，也使我更专注于内容的编写。确定了服务托管方式，剩下的工作就是考虑网站搭建技术方向了。互联网上关于博客类网站建设的技术已经非常成熟了，Wordpress，Vuepress，Docsify，Hexo，Next.js 等等。</p>\n<h3 id=\"Docsify\"><a href=\"#Docsify\" class=\"headerlink\" title=\"Docsify\"></a>Docsify</h3><p>最开始时候，我比较欣赏 Docsify 这种静态简单的风格。Docsify 本身支持的插件丰富，包括评论系统，访问次数，字数统计，页面搜索等，可以大大节省自己开发的时间。此外，将项目部署到 Github 上，使用 Github Page 托管之后，不用维护本地文档。编写文章发布也不需要编译，只要提交文件，等待自动部署即可。</p>\n<p>你可以访问 <a href=\"https://z1gui.github.io/chips/#/\"> https://z1gui.github.io/chips/#/ </a> 来查看页面。该项目搭建具体参考了<a href=\"https://bugstack.cn/\">小傅哥</a>的这篇博客 <a href=\"https://blog.csdn.net/generalfu/article/details/123268118?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522815fa9b0be7b0090fc06b78edb862108%2522%252C%2522scm%2522%253A%252220140713.130102334.pc%255Fblog.%2522%257D&request_id=815fa9b0be7b0090fc06b78edb862108&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~blog~first_rank_ecpm_v1~rank_v31_ecpm-2-123268118-null-null.nonecase&utm_term=docsify&spm=1018.2226.3001.4450\">《# 在GitHub&#x2F;Gitee上，搭建一个简单的所见即所得博客》</a>。如果你觉得这个样式符合自己的审美，也可以参考我仓库里面的这个项目 <a href=\"https://github.com/z1gui/chips\"> https://github.com/z1gui/chips </a> 配置。</p>\n<p>期间，我还尝试将 Docsify 部署到云服务器上，后来发现不如在 Github 上好管理，遂放弃。</p>\n<h3 id=\"Hexo\"><a href=\"#Hexo\" class=\"headerlink\" title=\"Hexo\"></a>Hexo</h3><p>再后来，我发现 docsify 很好，但是不够好。在文章展示，以及必要插件上，docsify 能满足一个博客的基础功能。但是，docsify 没有标签，分类，归档等功能。虽然我不追求极致的动效和交互效果，但 Docsify 过于简单的交互效果，让我感觉在阅读一个在线的 markdown 阅读器。与此同时，在 V2ex 的 VXNA 模块看过太多优秀博主的博客，让我又一次萌生了改博客样式的念头。</p>\n<p>我开始尝试使用 Hexo 博客框架。Hexo 是一个快速、简单、功能强大的博客框架。你使用 <a href=\"http://daringfireball.net/projects/markdown/\">Markdown</a>（或其他标记语言）撰写帖子，Hexo 会在几秒钟内生成具有漂亮主题的静态文件。</p>\n<p>本站当前使用 <a href=\"https://hexo.io/\">Hexo</a> 搭建，使用 <a href=\"https://github.com/z1gui/hexo-theme-ZenMind-Pro\">hexo-theme-ZenMind-Pro</a> 主题搭建。<strong>hexo-theme-ZenMind-Pro</strong> 是本人在 <a href=\"https://github.com/zhoulianglen/hexo-theme-ZenMind\">hexo-theme-ZenMind</a> 主题上做了修改优化。如有问题，可以联系我或在 issues 中提出您的问题。<strong>在此感谢 <a href=\"https://github.com/zhoulianglen\">@周良粥凉</a> 的主题以及其博客样式参考</strong>。</p>\n<p>在改造 hexo-theme-ZenMind 过程中，我大量使用了 Cursor 进行编程开发。一般来说，简单的样式调整，以及想要达成的效果 Cursor 都能够轻松完成。如果你对 Cursor 编程感兴趣，请参考这篇文章 [[「持续更新」AI辅助编程使用心得]]。其实，Hexo 丰富的生态，即使不二次开发，我相信你也能找到自己心仪的样式框架。</p>\n<h2 id=\"如何写好自己的博客\"><a href=\"#如何写好自己的博客\" class=\"headerlink\" title=\"如何写好自己的博客\"></a>如何写好自己的博客</h2><p>从一开始下定决心写博客，我也是迷茫的。什么写，什么不写，这些很难形成一个标准。</p>\n<p>究其原因，大部分在写博客的时候，我都在想如何让读者读明白，又如何让读者快速理解。参考我早期的博客就能看出来，有些概念太想解释清楚，以至于长篇大论，尽管它可能很简单。 后来，我意识到博客其实是给自己的知识做沉淀，目的是让自己 “知其所以然”。以这个思想来写博客，会发现写好博客并不难。</p>\n<p>这是关于《如何写好自己的博客》我想说的其一，<strong>「以自己为中心，让自己 “知其所以然”」。</strong> 大多数人写博客是为了提升自己的知识水平，提升自己的专业技能，形成一个自己的知识体系。<strong>「如何通过博客建立自己的知识体系」</strong> ，便是我想要说的其二。</p>\n<p>后来有幸拜读 pdai 佬引用的<a href=\"https://pdai.tech/md/team/team-z-tixi.html\">《知识体系：如何构建自己的知识体系》</a>，醍醐灌顶，感受颇多。这里引用一下文章中的话：</p>\n<blockquote>\n<p>我们的学习分为四阶段：输入、内化、沉淀、输出。碎片化在输入的时候用，因为信息本身是碎片化的，时间也是碎片化的，所以输入信息的时候，要碎片化。但有需要体系化的沉淀。因此碎片化的输入，加上体系化的沉淀，你就可以实现利用碎片化的时间，做体系化的学习。</p>\n</blockquote>\n<p>整篇文章中，强调了“碎片化学习”形成“体系化技能”。并总结出相应的三个步骤：定目标、搭建知识体系、填内容。其实建立自己的博客，写好自己的博客，也遵从着三个步骤。</p>\n<p>这里就扣合了之前提的第一点。在我看来，建立博客的目标应是让自己“知其所以然”。在这个目标下，再去定义体系，填写内容。当然，再后来我发现博客也可以是一个思想沉淀的地方，久而久之我也会将自己的一些体验，感悟放在这里，这是后话，容我们日后再谈。</p>\n<p>对我来说，建立博客更像是形成自己知识体系，总结人生感悟的具象化的体现。</p>\n","excerpt":"","more":"<h2 id=\"前言\"><a href=\"#前言\" class=\"headerlink\" title=\"前言\"></a>前言</h2><p>大家好，我是子规，很高兴能够在这里和大家相遇。本篇文章记录该站建立的初衷、建站过程以及在过程中的思考。</p>\n<h2 id=\"为什么建立这个网站\"><a href=\"#为什么建立这个网站\" class=\"headerlink\" title=\"为什么建立这个网站\"></a>为什么建立这个网站</h2><p>在此网站建立之前，我通常在CSDN上写作。</p>\n<p>但随着时间推移，我开始发现，CSDN上的文章， Although it is very good, but it is not very good for SEO。尽管我在CSDN上没有很多有质量的输出，但是繁杂的信息流却充斥在我面前。关注，点赞，私信，评论，活动等等都是我要面对的。这些信息流无时无刻不在分散我的注意力，使我感到非常痛苦。</p>\n<p>因此，我开始探索更有效的方式。前几年微信公众号爆火，我本人也关注不少微信公众号。其中，有非常多关于编程的公众号对我帮助极大，我非常喜欢。时常幻想自己能够在公众号上写好文章，这样我就可以分享自己的知识了，或者说更纯粹的分享自己的知识了。</p>\n<p>我也的确这么做了，「整点儿代码」就是尝试。「整点儿代码」最初的规划是，每天产出一篇文章，设置定时晚上10点左右发布，这也 call back 了“整点”这个 concept。可惜，我并没有成功。一方面微信公众号的审核不通过导致不能整点发布，让我十分困扰。另一方面，就是个人没有坚持下来。最重要的一点是，我仍然没有从关注，点赞，私信，评论中脱离出来。是的，公众号也有这样的问题需要我面对。显然，这不是我想要的、理想的博客记录方式。</p>\n<p>最终，我决定做一个自己的博客网站。</p>\n<h2 id=\"建站过程\"><a href=\"#建站过程\" class=\"headerlink\" title=\"建站过程\"></a>建站过程</h2><p>2022 年，我了解到，GitHub Pages 是一个非常优秀的博客托管平台。基于 Git 方式的 post 和自动化发布节省了我不少的时间，也使我更专注于内容的编写。确定了服务托管方式，剩下的工作就是考虑网站搭建技术方向了。互联网上关于博客类网站建设的技术已经非常成熟了，Wordpress，Vuepress，Docsify，Hexo，Next.js 等等。</p>\n<h3 id=\"Docsify\"><a href=\"#Docsify\" class=\"headerlink\" title=\"Docsify\"></a>Docsify</h3><p>最开始时候，我比较欣赏 Docsify 这种静态简单的风格。Docsify 本身支持的插件丰富，包括评论系统，访问次数，字数统计，页面搜索等，可以大大节省自己开发的时间。此外，将项目部署到 Github 上，使用 Github Page 托管之后，不用维护本地文档。编写文章发布也不需要编译，只要提交文件，等待自动部署即可。</p>\n<p>你可以访问 <a href=\"https://z1gui.github.io/chips/#/\"> https://z1gui.github.io/chips/#/ </a> 来查看页面。该项目搭建具体参考了<a href=\"https://bugstack.cn/\">小傅哥</a>的这篇博客 <a href=\"https://blog.csdn.net/generalfu/article/details/123268118?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522815fa9b0be7b0090fc06b78edb862108%2522%252C%2522scm%2522%253A%252220140713.130102334.pc%255Fblog.%2522%257D&request_id=815fa9b0be7b0090fc06b78edb862108&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~blog~first_rank_ecpm_v1~rank_v31_ecpm-2-123268118-null-null.nonecase&utm_term=docsify&spm=1018.2226.3001.4450\">《# 在GitHub&#x2F;Gitee上，搭建一个简单的所见即所得博客》</a>。如果你觉得这个样式符合自己的审美，也可以参考我仓库里面的这个项目 <a href=\"https://github.com/z1gui/chips\"> https://github.com/z1gui/chips </a> 配置。</p>\n<p>期间，我还尝试将 Docsify 部署到云服务器上，后来发现不如在 Github 上好管理，遂放弃。</p>\n<h3 id=\"Hexo\"><a href=\"#Hexo\" class=\"headerlink\" title=\"Hexo\"></a>Hexo</h3><p>再后来，我发现 docsify 很好，但是不够好。在文章展示，以及必要插件上，docsify 能满足一个博客的基础功能。但是，docsify 没有标签，分类，归档等功能。虽然我不追求极致的动效和交互效果，但 Docsify 过于简单的交互效果，让我感觉在阅读一个在线的 markdown 阅读器。与此同时，在 V2ex 的 VXNA 模块看过太多优秀博主的博客，让我又一次萌生了改博客样式的念头。</p>\n<p>我开始尝试使用 Hexo 博客框架。Hexo 是一个快速、简单、功能强大的博客框架。你使用 <a href=\"http://daringfireball.net/projects/markdown/\">Markdown</a>（或其他标记语言）撰写帖子，Hexo 会在几秒钟内生成具有漂亮主题的静态文件。</p>\n<p>本站当前使用 <a href=\"https://hexo.io/\">Hexo</a> 搭建，使用 <a href=\"https://github.com/z1gui/hexo-theme-ZenMind-Pro\">hexo-theme-ZenMind-Pro</a> 主题搭建。<strong>hexo-theme-ZenMind-Pro</strong> 是本人在 <a href=\"https://github.com/zhoulianglen/hexo-theme-ZenMind\">hexo-theme-ZenMind</a> 主题上做了修改优化。如有问题，可以联系我或在 issues 中提出您的问题。<strong>在此感谢 <a href=\"https://github.com/zhoulianglen\">@周良粥凉</a> 的主题以及其博客样式参考</strong>。</p>\n<p>在改造 hexo-theme-ZenMind 过程中，我大量使用了 Cursor 进行编程开发。一般来说，简单的样式调整，以及想要达成的效果 Cursor 都能够轻松完成。如果你对 Cursor 编程感兴趣，请参考这篇文章 [[「持续更新」AI辅助编程使用心得]]。其实，Hexo 丰富的生态，即使不二次开发，我相信你也能找到自己心仪的样式框架。</p>\n<h2 id=\"如何写好自己的博客\"><a href=\"#如何写好自己的博客\" class=\"headerlink\" title=\"如何写好自己的博客\"></a>如何写好自己的博客</h2><p>从一开始下定决心写博客，我也是迷茫的。什么写，什么不写，这些很难形成一个标准。</p>\n<p>究其原因，大部分在写博客的时候，我都在想如何让读者读明白，又如何让读者快速理解。参考我早期的博客就能看出来，有些概念太想解释清楚，以至于长篇大论，尽管它可能很简单。 后来，我意识到博客其实是给自己的知识做沉淀，目的是让自己 “知其所以然”。以这个思想来写博客，会发现写好博客并不难。</p>\n<p>这是关于《如何写好自己的博客》我想说的其一，<strong>「以自己为中心，让自己 “知其所以然”」。</strong> 大多数人写博客是为了提升自己的知识水平，提升自己的专业技能，形成一个自己的知识体系。<strong>「如何通过博客建立自己的知识体系」</strong> ，便是我想要说的其二。</p>\n<p>后来有幸拜读 pdai 佬引用的<a href=\"https://pdai.tech/md/team/team-z-tixi.html\">《知识体系：如何构建自己的知识体系》</a>，醍醐灌顶，感受颇多。这里引用一下文章中的话：</p>\n<blockquote>\n<p>我们的学习分为四阶段：输入、内化、沉淀、输出。碎片化在输入的时候用，因为信息本身是碎片化的，时间也是碎片化的，所以输入信息的时候，要碎片化。但有需要体系化的沉淀。因此碎片化的输入，加上体系化的沉淀，你就可以实现利用碎片化的时间，做体系化的学习。</p>\n</blockquote>\n<p>整篇文章中，强调了“碎片化学习”形成“体系化技能”。并总结出相应的三个步骤：定目标、搭建知识体系、填内容。其实建立自己的博客，写好自己的博客，也遵从着三个步骤。</p>\n<p>这里就扣合了之前提的第一点。在我看来，建立博客的目标应是让自己“知其所以然”。在这个目标下，再去定义体系，填写内容。当然，再后来我发现博客也可以是一个思想沉淀的地方，久而久之我也会将自己的一些体验，感悟放在这里，这是后话，容我们日后再谈。</p>\n<p>对我来说，建立博客更像是形成自己知识体系，总结人生感悟的具象化的体现。</p>\n"},{"title":"Kafka深入浅出","date":"2024-12-10T16:00:00.000Z","id":"761386768996831","_content":"\n\nKafka 服务器端的代码是由 Scala 代码编写，支持面向对象编程和函数式数据，编译过后也是普通的 .class 文件。其的作用：提供统一的、高吞吐量、低延迟的平台来处理实时数据\n\n# 一、基本概念\n\n## 「Kafka 是什么？主要应用场景什么？」\n\nKafka 是一个分布式流式处理平台。\n\n![Kafka结构示意图](img/6aaf06740442599b6c52bb586545dfb8_MD5.png)\n\n\n\n**1 . 主题**：发布订阅的对象是主题（Topic），可以为每个业务、每个应用甚至每类数据都创建专属的主题\n\n\n\n**2 . 生产者和消费者**：向主题发布消息的客户端应用程序成为生产者，生产者程序通常持续不断地向一个或者多个主题发送消息\n\n\n\n**3 . Broker**：集群由多个 Broker 组成，Broker 负责接收和处理客户端发送过来的请求，以及对消息进行持久化。\n\n\t虽然多个 Broker 能够运行在同一台机器上，但是常见的做法是将不同的 Broker 分散运行在不同的机器上，这样如果某一台机器宕机，即使在它上面运行的所有 Broker 进程都挂掉了，其他机器上的 Broker 也一眼能够对外提供服务。\n\n\n\n **4 . 备份机制**：备份的思想很简单，就是把相同的数据拷贝到多台机器上，而这些相同的数据拷贝被称为副本。\n\n\tKafka 定义了两类副本：领导者副本和追随者副本。\n\n\t前者对外提供服务，即与客户端程序进行交互；后者只是被动地追随领导者副本而已，不对外进行交互。\n\n\n\n**5 . 分区**：分区机制指的是将每个主题分成多个分区，每个分区是一组有序的消息日志\n\n\t生产者生产的每条消息总会被发送到一个分区中，也就是说如果向一个双分区的主题发送一条消息，该条消息要不在分区 0 中，要不在分区 1 中。\n\n\t生产者向分区中写入消息，每条消息在分区中的位置信息叫做位移。\n\n\n\n**6 . 消费者组**：多个消费者实例共同组成一个组来消费一组主题\n\n\t这组主题中的每个分区只会被组内的一个消费者实例消费，其他消费者实例不能消费它\n\n\t消息引擎的两大模型：\n\n\t\t如果所有实例都属于同一个 Group，那么它实现的就是消息队列模型\n\n\t\t如果所有实例属于不同的 Group，那么它实现的就是发布/订阅模型\n\n> **RocketMQ 的消息模型和 Kafka 基本是完全一样的。唯一的区别是 Kafka 中没有队列这个概念，与之对应的是 Partition（分区）。**\n\n\n\n**7 . Coordinator：协调者**：负责为 Group 执行 Rebalance 以及提供唯一管理和组成员管理等。\n\n\n\n**8 . 消费者位移：Consumer offset**：消费者消费进度，每个消费者都有自己的消费者位移\n\n\n\n**9 . 重平衡：Rebalance**：消费者组内某个消费者实例挂掉后，其他消费者实例自动重新分配订阅主题分区的过程。\n\nRebalance 是 Kafka 消费者端实现高可用的重要手段\n\n\n\n**10 . AR（Assigned Replicas）**：分区中的所有副本统称为 AR。\n\n所有消息都会先发送到领导者副本，然后追随者副本才能从领导者中拉去信息进行同步\n\n但是同步期间，追随者副本相对于领导者副本而言有一定程度的滞后，这时候追随者副本和领导者副本并非完全同步状态\n\n\n\n**11 . OSR（Out Sync Replicas）**：AR 的一个子集，其中都是追随者副本和领导者副本没有完全同步或者之后的副本集合\n\n\n\n**12 . ISR（In Sync Replicas）**：AR 的一个子集，ISR 中的副本都是和领导者副本是保持完全同步的副本。\n\n如果某一个在 ISR 中的 follower 副本落后于 leader 副本太多，就会从 ISR 中移除，否则如果完全同步，会从 OSR 中移到 ISR 集合中\n\n\n\n**13 . HW（High Watermark）**：高水位，标识一个特定的消息偏移量（offset），消费者只能来取这个水位 offset 之前的消息\n\n下图表示一个日志文件，这个日志文件中只有9条消息，第一条消息的offset（LogStartOffset）为0，最有一条消息的offset为8，offset为9的消息使用虚线表示的，代表下一条待写入的消息。\n\n日志文件的 HW 为6，表示消费者只能拉取offset在 0 到 5 之间的消息，offset为6的消息对消费者而言是不可见的。\n\n![消息偏移量展示](img/ce77dd7ccc11dc7642aad16560000cb9_MD5.png)\n\n\n\n**14 . LEO（Log End Offset）**：标识当前日志文件中下一条待写入的消息的offset\n\n# 二、系统架构\n\nKafka 基础框架：一个生产者发送一个消息到 Kafka 的一个 Topic，该 Topic 的消息存放在 Broker 中，消费者订阅这个 Topic，然后从 Broker 中消费消息。\n\n\n\n1.**消息状态**：在 Kafka 中，消息是否被消费的状态保存在消费者中，Broker 不会关系消息是否消费，或者被谁消费，消费者会记录一个 offset 值（指向分区中下一条被消费的消息位置），如果 offset 被错误设置可能会导致同一条消息多次消费或者丢失。\n\n2.**消息持久化**：Kafka 会把消息持久化到本地文件系统中，并且具有极高的性能。\n\n3.**批量发送**：Kafka 支持以消息集合为单位进行批量发送，以提高效率。\n\n4.**Push-and-Pull**：Kafka 中的生产者和消费者采用的是 Push-and-Pull 模式，即生产者向 Broker Push 消息，消费者从 Broker Pull 消息。\n\n5.**分区机制**：Kafka 的 Broker 是支持分区的，Producer 可以决定将消息放在哪个 Partition，在一个 Partition 中的消息顺序就是 Producer 发送消息的顺序，一个 Topic 中的 Partition 是可以配置的，Partition 是保证 Kafka 高吞吐量的重要保证。\n\n![系统架构](img/68d9aaa9dd34dbc9d516201de1f2ab55_MD5.png)\n\n通常情况下，一个 Kafka 体系是包含多个 Producer，多个 Broker，多个 Consumer，以及一个 Zookeeper 集群\n\n# 三、生产者分区\n\n一条 Kafka 消息的的组织架构是三层：主题（Topic）- 分区（Partition）- 消息（Message）\n\n分区其实是一种负载均衡的做法。因为同一个 Topic 下的不同分区可以在不同 Broker 节点上，并且，数据读写是以分区为粒度，这样的话，每个节点都可以执行自己分区的消息的读写。除此之外，还能通过增加节点来提高吞吐量。\n\n## 「分区策略」\n\n所谓的分区策略其实就是决定生产者将消息发送到哪个分区的算法。\n\n### 自定义分区策略\n\n如果需要自己定义分区策略，在编写生产者程序的时候，可以编写一个具体的实现类`org.apache.kafka.clients.producer.Partitioner` 接口。这接口也非常简单，只定义了两个方法：partition() 和 close() 方法。通常情况我们只需要实现 partition() 方法即可。\n\n```java\nint partition(String topic, Object key, byte[] keyBytes, Object value, byte[] valueBytes, Cluster cluster);\n```\n\n这里的 topic、key、keyBytes、value 和 valueBytes 都属于消息数据，cluster 则是集群信息（比如当前 Kafka 集群共有多少主题、多少 Broker 等）。\n\n### 轮询策略\n\n也称 Round-robin 策略，即顺序分配。轮询策略是 Kafka 生产者 API 默认提供的分区策略。\n\n轮询策略有非常优秀的负载均衡表现，它总是保证消息最大限度的平均分配到所有的分区上，所以默认下它是最合理的分区策略，也是最常用的分区策略。\n\n### 随机策略\n\n也称 Randomness 策略。想要实现随机策略的 partition 方法，其实很简单，只需要两行代码即可：\n\n```java\n List partitions = cluster.partitionsForTopic(topic);\n return ThreadLocalRandom.current().nextInt(partitions.size());\n\n```\n\n先计算出该主题的总分区数，然后随机返回一个小于它的正整数。\n\n随机策略在负载均衡上面略逊于轮询策略。在老的版本里面常用随机策略，再后来的版本更新中被轮询策略所替代。\n\n### 按消息键保序策略\n\nKafka 允许为每条消息定义消息键，简称 Key。\n\nKey 可以为具体的业务代码，也可以用来表征消息元数据。在 Kafka 中如果消息定义了 Key，那么就可以保证同一个 Key 的消息进入相同的分区，有序分区下的消息处理是有顺序的，所以这个策略被称为安消息键保存策略。\n\n实现这个策略的 partition 方法同样简单，只需要下面两行代码即可：\n\n```java\n List partitions = cluster.partitionsForTopic(topic);\n return Math.abs(key.hashCode()) % partitions.size();\n```\n\n其实，Kafka 默认的分区策略是两种：\n\t如果指定了 Key ，默认实现按消息键保序策略；\n\t如果未指定 Key，则使用轮询策略。\n\n### 「其他分区策略」\n\n另外还有一种比较常见的，所谓的基于地理位置的分区策略。当然这种策略只针对大规模的 Kafka 集群，特别是跨城市、跨国家甚至是跨大洲的集群。我们可以根据 Broker 所在的 IP 地址实现定制化的分区策略。比如下段代码：\n\n```java\nList partitions = cluster.partitionsForTopic(topic);\nreturn partitions.stream().filter(p -> isSouth(p.leader().host())).map(PartitionInfo::partition).findAny().get();\n```\n\n我们可以从所有分区中找出那些 Leader 副本在南方的所有分区，然后随机挑选一个进行消息发送。\n\n# 四、生产者压缩算法\n\n为什么要压缩消息？压缩消息是为了更好的节省网络传输贷款以及 Kafka Broker 端的磁盘占用。\n\n### 「Kafka 是如何压缩消息的呢？」\n\nKafka 的消息层次分为两层：消息集合和消息。\n\n??？\n\n### 「何时压缩？」\n\n在 Kafka 中，压缩可能发生在两个地方：生产者端和 Broker 端。\n\n在生产者程序中配置 compression.type 参数即表示弃用指定类型的压缩算法。\n\n比如这段代码中展示了如何构建一个开启 GZIP 的 Producer 对象：\n\n```java\nProperties props = new Properties();\nprops.put(\"bootstrap.servers\", \"localhost:9092\");\nprops.put(\"acks\", \"all\");\nprops.put(\"key.serializer\", \"org.apache.kafka.common.serialization.StringSerializer\"); props.put(\"value.serializer\", \"org.apache.kafka.common.serialization.StringSerializer\"); // 开启GZIP压缩\nprops.put(\"compression.type\", \"gzip\"); //Producer的压缩算法是GZIP\nProducer producer = new KafkaProducer<>(props);\n```\n\n这样 Producer 启动之后生产的每个消息集合都是经 GZIP 压缩过的，故而能很好的节省网络传输贷款以及 Kafka Broker 端的磁盘占用。\n\n有两种情况可能导致 Broker 重新压缩消息：\n\n- 情况一：Broker 端指定了和 Producer 端不同的压缩算法。\n\n一旦 Broker 端设置了不同的 compression.type 值，就一定要小心了，因为可能会发生预料之外的压缩、解压缩操作，通常表现为 Broker 端 CPU 使用率飙升。\n\n- 情况二：Broker 端发生了消息格式转换。\n\n所谓的消息格式转换主要是为了兼容老版本的消费者程序。在一个生产环境中，Kafka 集群中同时保存多个版本的消息格式非常常见。为了兼容老版本的格式，Broker 端会对新版本消息指向向老版本的转换。这个过程会涉及到消息的解压缩和重新压缩。一般情况下这种消息格式转换成对性能是有很大影响的，除了这里的压缩之外，他还让 Kafka 丧失了 Zero Copy 特性。\n\n### 「何时解压缩？」\n\n有压缩必有解压缩！通常来说解压缩发生在消费者程序中。\n\n**基本过程：Producer 端压缩，Broker 端保持，Consumer 端解压缩。**\n\n注意：除了在 Consumer 端解压缩外，Broker 端也会进行解压缩。\n\n每个压缩过的消息集合在 Broker 端写入时都要发生解压缩操作，目的就是为了对消息执行各种验证。我们必须承认这种解压缩对 Broker 端性能有一定的影响，特别是对 CPU 的使用率而言。\n\n### 「各种压缩算法对比」\n\nKafka 支持 4 种压缩算法：GZIP、Snappy 、LZ4 和 zstd(Zstandard 算法)。在实际使用中，各个算法各有千秋。\n\n吞吐量：LZ4 > Snappy > zst 和 GZIP；\n\n压缩比：zstd > LZ4 > GZIP > Snappy；\n\n占用宽带：zstd < LZ4 和 GZIP < Snappy；\n\n在CPU使用率方面，各个算法表现得差不多，只是在压缩时Snappy算法使用的CPU较多一些，而在解压缩时GZIP算法则可能使用更多的CPU。\n\n# 五、消费者组\n\nConsumer Group 是 Kafka 提供可拓展且具有容错性的消费机制。\n\n既然是一个组，那么组内必然是可以有多个消费者或者消费者实例，它们共享一个公共的 ID，这个 ID 被称为 Group ID。组内所有的消费者协调在一起来消费订阅主题的所有分区。每个分区只能有同一个消费组内的一个 Consumer 实例来消费。\n\n### Consumer Group 三个特性\n\n1.Consumer Group 下可以有一个或者多个 Consumer 实例，这里的实例可以是一个单独的进程，也可以是同一个进程下的线程。\n\n2.Group ID 是一个字符串，在一个 Kafka 集群中，它表示唯一的一个 Consumer Group。\n\n3.Consumer Group 下所有实例订阅的主题的单独分区，只能分配给组内的某个 Consumer 实例消费，这个分区当然也可以被其他的 Group 消费。\n\nKafka 仅仅使用 Consumer Group 这一种机制，却同时实现了传统消息引擎系统的两大模型：\n\n- 如果所有实例都是属于同一个 Group，那么它实现的是消息队列模型；\n\n- 如果所有实例分别属于不同的 Group，那么它实现的就是发布/订阅模型。\n\n### 一个 Group 下应该有多少个 Consumer 实例呢？\n\n理想情况下，Consumer 实例的数量应该等于 Group 订阅主题的分区总数。\n\n> 假设一个 Comsumer Group 订阅了 3 个主题，分别是 A、B、C，它们的分区数分别是 1，2，3，那么通常情况下，为改 Group 设置 6 个 Consumer 实例是比较理想的情形，因为它能最大限度的视线高伸缩性。\n\n\n\n### 针对 Consumer Group，Kafka 是怎么管理位移呢？\n\n老版本 Consumer Group 把位移保存在 ZooKeeper 中。Apache ZooKeeper 是一个分布式的协调服务框架，Kafka 重度依赖它实现的各种各样的协调管理。将唯一保存到 ZooKeeper 外部系统的做法，最显而易见的好处就是减少了 Kafka Broker 端的状态保存开销。\n\n但是，慢慢的发现一个问题，即 ZooKeeper 这类元框架其实并不适合进行频繁的写更新，而 Consumer Group 的位移更新是一个非常频繁的操作。这种大吞吐量的写操作会极大拖慢 ZooKeeper 集群的性能。于是，新版本的 Consumer Group 中，Kafka 社区重新设计了 Consumer Group 的位移管理方式，采用将位移保存在 Kafka 内部主题的方法。\n\n这个内部主题就是\\_counsumer_offset.\n\n# 六、消费者策略\n\n消费者消费同一主题的哪个分区，是通过消费者策略决定的。\n\n#### 轮询 Round\n\nKakfa 默认的消费者策略——轮询，通过轮询方式，决定消费者消费的分区。\n\n![轮询策略](img/2ca562d1dc3a2d8d06c7c2bfe2c394c8_MD5.png)\n\n#### 范围计算 Range\n\n对一个消费者组来说，决定消费方式是以分区总数除以消费者总数来决定，一般如果不能整除，往往是从头开始将剩余的分区分配开\n\n![范围计算](img/c3276b5f713b8b0641463b496c196ce2_MD5.png)\n\n#### 范围计算升华版 Sticky\n\n是在0.11.x，新增的，它和前面两个不是很一样，它是在Range上的一种升华，且前面两个当同组内有新的消费者加入或者旧的消费者退出的时候，会从新开始决定消费者消费方式，但是Sticky，在同组中有新的新的消费者加入或者旧的消费者退出时，不会直接开始新的Range分配，而是保留现有消费者原来的消费策略，将退出的消费者所消费的分区平均分配给现有消费者，新增消费者同理，同其他现存消费者的消费策略中分离。\n\n# 七、位移提交\n\n假设一个分区中有 10 条消息，唯一分别是 0 到 9.\n\n某个 Consumer 应用已经消费了 5 条消息，这就说明该 Consumer 消费了位移为 0 到 4 的 5 条消息，此时 Consumer 的位移是 5，指向了下一条消息的位移。因为 Consumer 能够同时消费多个分区的数据，所以位移的提交实际上是在分区粒度上进行的，即 **Consumer 需要为分配给它的每一个分区提交各自的位移数据。**\n\n位移提交分为自动提交和手动提交；从 Consumer 端的角度来说，位移提交分为同步提交和异步提交。\n\n开启自动提交位移的方法：Consumer 端有一个参数 `enable.auto.commint`，把它设置为 true 或者不设置它即可。\n\n如果开启了自动提交，Consumer 端还有个参数：`auto.commit.interval.ms`。默认为 5 秒，表明 Kafka 每 5 秒会自动提交一次位移。\n\n```java\nProperties props = new Properties();\nprops.put(\"bootstrap.servers\", \"localhost:9092\");\nprops.put(\"group.id\", \"test\");\n//开启自动提交\nprops.put(\"enable.auto.commit\", \"true\");\n//自动提交时间间隔\nprops.put(\"auto.commit.interval.ms\", \"2000\");\nprops.put(\"key.deserializer\", \"org.apache.kafka.common.serialization.StringDeserializer\");\nprops.put(\"value.deserializer\", \"org.apache.kafka.common.serialization.StringDeserializer\");\nKafkaConsumer consumer = new KafkaConsumer<>(props);\nconsumer.subscribe(Arrays.asList(\"foo\", \"bar\"));\nwhile (true) {\n    ConsumerRecords records = consumer.poll(100);\n    for (ConsumerRecord record : records)\n        System.out.printf(\"offset = %d, key = %s, value = %s%n\", record.offset(), record.key(), record.value());\n}\n```\n\n如果要开启手动提交，只需要将 `enable.auto.commit` 设置为 `false` 即可。\n\n手动提交需要调用相应的 API 手动提交位移。最简单的 API 就是 `KafkaConsumer#commitSync()` 。该方法会提交 `KafkaConsumer#poll()` 返回的最新位移。从名字上来看，这是一个同步方法，即该方法会一直等待，直到位移成功提交之后才会返回。如果提交过程中出现异常，该方法会将异常信息抛出。\n\n下面这段代码展示了 commitSync() 的使用方法：\n\n```java\nwhile (true) {\n        ConsumerRecords records =consumer.poll(Duration.ofSeconds(1));\n        process(records); // 处理消息\n        try {\n            consumer.commitSync();\n        } catch (CommitFailedException e) {\n            handle(e); // 处理提交失败异常\n        }\n}\n```\n\n自动提交时，Kafka 会保证再开始调用 poll 方法时候，提交上次 poll 方法返回的所有消息。从顺序上来说，poll 方法的逻辑是先提交上一批消息的位移，然后在处理下一批消息，因此，自动提交能保证不会出消费丢失的情况。但是自动提交位移的问题在于，**可能出现重复消费。**\n\n手动提交的好处在于更加灵活，可以完全把控位移提交的时机和频率。但是他也有一个缺陷，就是在调用 `commitSync()` 时候会处于阻塞状态，直到远端 Broker 返回提交结果，这个状态才能结束。\n\n这时候，手动提交的另一个方法就出现了 `KafkaConsumer#commitAsync()`。从名字上看，这是个异步操作。调用 `commitAsync()` 方法之后，它会立即返回，不会阻塞，因此不影响 Consumer 应用的 TPS（吞吐量）。由于它是异步的，Kafka 提供了一个回调函数（callback），供开发者实现提交之后的逻辑，比如记录日志或处理异常。\n\n下面这段代码展示了调用 commintAsync() 方法：\n\n```java\nwhile (true) {\n            ConsumerRecords records = consumer.poll(Duration.ofSeconds(1));\n            process(records); // 处理消息\n            consumer.commitAsync((offsets, exception) -> {\n\t\t\t\t if (exception != null)\n\t\t\t\t\t handle(exception);\n\t\t\t});\n}\n```\n\ncommitAsync 的问题在于，出了问题时它不会重试。\n\n显然，如果手动提交，我们需要将 commitSync 和 commitAsync 组合使用才能达到最理想的效果：\n\t1.我们可以利用 commitSync 的自动动重试来规避那些瞬时错误，比如网络的瞬时都懂，Broker 端的 GC 问题，因为这些问题是短暂的，自动重试通常都会成功。\n\t2.我们不希望程序总是处于阻塞状态，影响 TPS。\n\n我们来看一下下面这段代码，它展示的是如何将两个 API 方法结合使用进行手动提交。\n\n```java\ntry {\n    while(true) {\n        ConsumerRecords records = consumer.poll(Duration.ofSeconds(1));\n        process(records); // 处理消息\n        commitAysnc(); // 使用异步提交规避阻塞\n    }\n} catch(Exception e) {\n        handle(e); // 处理异常\n} finally {\n      try {\n        consumer.commitSync(); // 最后一次提交使用同步阻塞式提交\n} finally {\n \t\tconsumer.close();\n}\n}\n```\n\n试想这样一个场景：poll 方法返回的不是 500 条消息，而是 5000 条。\n\n那么，你肯定不想把这 5000 条消息处理完之后再提交位移，因为一旦中间出差错，之前处理的全部都要重来一遍。那么我们可以每处理完 100 条消息就提交一次位移，这样避免大批量的消息重新消费。\n\nKafka Consumer API 为手动提交提供了这样的方法：`commitSync(Map)` 和 `commitAsync(Map)`。它们的参数是一个 Map 对象，键就是 TopicPartition，即消费的分区，而值是一个 OffsetAndMetadata 对象，保存主要是位移数据。\n\n以 commitAsync 为例，展示一段代码。实际上，commitSync 的调用方法和它一模一样的。\n\n```java\nprivate Map offsets = new HashMap<>();\nint count = 0;\n……\nwhile (true) {\n    ConsumerRecords records = consumer.poll(Duration.ofSeconds(1));\n        for (ConsumerRecord record: records) {\n            process(record);  // 处理消息\n            offsets.put(new TopicPartition(record.topic(), record.partition()),new OffsetAndMetadata(record.offset() + 1)；\n            if（count % 100 == 0）\n                consumer.commitAsync(offsets, null); // 回调处理逻辑是null\n                count++;\n }\n}\n```\n\n与调用无参的 commitAsync 不同，这里调用了带 Map 对象参数的 commitAsync 进行细粒度的位移提交。\n\n# 八、重平衡\n\n重平衡 Rebalance 本质上是一种协议，规定了一个 Consumer Group 如何分配订阅 Topic 的每一个分区。Kafka 在为 Consumer Group 内的 Consumer 分配分区的过程，就是 Rebalance。\n\nRebalance 触发条件有三个：\n\n- 组内成员发生变化，即有新的 Consumer 实例加入组或者离开祖，或者因崩溃而退出组。\n\n- 订阅主题数发生变化，Consumer Group 可以通过正则表达式方式订阅主题，比如 `consumer.subscribe(Pattern.compile(\"t.*c\"))` 就表明 Group 订阅所有以字母 t 开头、字母 c 结尾的主题，所以在 Consumer Group 运行过程中，如果创建了满足要求的主题，就会发生 Rebalance。\n\n- 订阅主题的分区发生变化，Kafka 当前只能允许增加一个主题的分区数，当主题的分区数发生变化，就会触发该主题下所有 Group 的 Rebalance。\n\n### 「分配策略」\n\n当前Kafka默认提供了3种分配策略，每种策略都有一定的优势和劣势，社区会不断地完善这些策略，保证提供最公平的分配策略，即每个Consumer实例都能够得到较为平均的分区数。\n\n\n\n### 「Coordinator 会在什么情况下确认 Consumer 实例挂掉了从而要退组？」\n\n在 Consumer Group 完成 Rebalance 之后，每个 Consumer 实例都会定期的想 Coordinator 发送心跳请求，表明它还活着。如果某个 Consumer 不能及时的发送心跳请求，娜美 Coordinator 就会认为它已经死了，从而将其从 Group 中移除，然后开启新一轮的 Rebalance。\n\nConsumer 端设置参数里面有个：`session.timeout.ms`。默认为 10 秒，即如果 Coordinator 在 10 秒内没有收到 Group 的某个 Consumer 的心跳请求，则认为它已经挂了。除了这个参数，还有个允许开发者控制发送心跳的频率的参数，就是 `heartbeat.interval.ms`。这个参数设置越小，Consumer 发送心跳请求的频率越高。当然，请求频率越高，消耗的带宽资源也就越高。\n\n除此之外，Consumer 端还有个参数，用于控制 Consumer 实际消费能力对对 Rebalance 的影响，即：`max.pool.interval.ms` 参数。它限定了 Consumer 端应用程序两次调用 poll 方法的最大时间间隔。默认值为 5 分钟，表示如果 Consumer 在 5 分钟内没有消费完 poll 方法返回的消息，那么 Consumer 会主动发起离开 Group 的请求，Coordinator 则会开启新的 Rebalance。\n\n### 「如何设置避免 Rebalance」\n\n1. 如果是因为未能及时发送心跳请求，导致 Consumer 被踢出 Group ，引发的 Rebalance。则可以设置 `session.timeout.ms` 和 `heartbeat.interval.ms` 的值。\n\n\t- 设置 `session.timeout.ms` = 6s。\n\n\t- 设置 `heartbeat.interval.ms` = 2s。\n\n\t- 要保证 Consumer 实例在被判定为 dead 之前，能够发送 3 条心跳请求，即 `session.timeout.ms >= 3 * heartbeat.interval.ms`。\n\n将 `session.timeout.ms` 设置为 6s 主要是为了让 Coordinator 能更快定位已经挂掉的 Consumer。\n\n2. 如果是因为 Consumer 消费时间过长导致的 Rebalance。在开发过程中，为业务逻辑处理留足充足的时间，这样 Consumer 就不会因为处理这些消息太长而引起 Rebalance 了。\n\n# 九、ConsumerOffsets\n\n`_consumer_offsets` 是一个 Kafka 的普通主题，它主要是保存 Kafka Consumer 的位移信息。当 Kafka 中的第一个 Consumer 启动时候，就会创建该主题。其默认分区数是 50，副本数是 3。`_consumer_offsets` 主题是一个普通的 Kafka 主题，开发者可以手动的创建、修改甚至删除它。但是它的消息格式是 Kafka 自己定义的，不能修改。开发者只能按照规定传入消息，否则内部不能成功解析，就会导致 Broker 崩溃。\n\n`_consumer_offsets` 有 3 中消息格式：\n\n- 用于保存 Consumer Group 信息的消息。\n\n- 用于删除 Group 过期位移甚至删除 Group 的消息。\n\n- 保存了位移值。\n\n前面已经提到过，Kafka 的提交方式有两种：自动提交和手动提交。\n\n手动提交：比较灵活可控，通过调用 `commitSync()` 或者 `commitAsync()` 等 Kafka Consumer 的 API，Kafka 会向 `_consumer_offsets` 主题中写入相应的消息。\n\n自动提交：显著优点就是省事，不用操心位移提交的事情，就能保证消息不会丢失。但是自动提交位移的有个问题，只要 Consumer 一直启动着，它就会无限期的向位移主题写入消息。\n\n> 假设Consumer当前消费到了某个主题的最新一条消息，位移是100，之后该主题没有任何新消息产生，故Consumer无消息可消费了，所以位移永远保持在100。由于是自动提交位移，位移主题中会不停地写入位移=100 的消息。显然 Kafka 只需要保留这类消息中的最新一条就可以了，之前的消息都是可以删除的。\n\n\n\n显然，Kafka 必须要有针对位移主题消息特点的消息删除策略，否则这种消息越多，最重撑爆整个磁盘\n\n### 「Compact 策略」\n\nKafka 通过 Compact 策略来删除 `_consumer_offsets` 主题中的过期消息，避免该主题无限膨胀。Compact 的过程就是扫描日志的所有消息，剔除过期消息，把剩下消息整理在一起。\n\nKafka 提供了专门的后台线程定期的巡检待 Compact 的主题，看看是否存在猫族条件的可删除数据。这个后台线程叫做 **Log cleaner**。如果生产环境中出现了位移主题无限膨胀占用过多磁盘空间问题，请检查一下 Log cleaner 线程是否挂掉了。\n\n# 十、副本机制\n\n根据 Kafka 副本机制定义，同一个分区下面的所有副本保存有相同的消息队列，这些副本是分布在不同 Broker 中，以确保某个 Broker 宕机后其他副本可以正常使用。\n\n在 Kafka 中，副本分为领导者副本和追随者副本。其中追随者副本不参与什么读写请求操作。追随者副本只异步拉去领导者副本，在领导者副本所在的 Broker 宕机的时候，重新从追随者副本中推选出一个领导者副本。\n\n追随者副本唯一的工作就是，不断的从领导者副本中拉取消息，然后写入自己的提交日志中。\n\n![副本机制](img/ff0fd5af97f5f5ad3a954f3ffa4076d0_MD5.png)\n\n# 十一、ISR 机制\n\nin-sync Replicas，也就是所谓的 ISR 副本集合。这个集合是动态的，而非静态不变。\n\nISR 中的副本一定是好 Leader 副本同步的，相反不在 ISR 中的副本一定是和 Leader 副本不同步的。\n\nLeader 副本一定在 ISR 中，Follower 副本不一定在 ISR 中。在 Broker 端有个配置参数 `replica.lag.time.max.ms`，这个参数的含义是 Follower 副本落后 Leader 副本的时间不连续超过 10 秒，那么 Kafka 认为 Follower 副本和 Leader 是同步的，即使此时 Follower 副本中保存的消息明显少于 Leader 副本中的消息。\n\n# 十二、Unclean 领导者选举\n\nKafka 将所有不在 ISR 中的副本都认为是非同步副本。在领导者选举的时候，如果选举这种副本的过程称为 Unclean 领导者选举。在 Broker 端中参数 `unclean.leader.election.enable` 控制是否开启 Unclean 领导者选举。\n\nUnclean 领导者选举有利有弊。优点在于：因为一个分区中 Leader 副本负责读写请求，如果 Leader 副本挂了，整个分区就改了。开启 Unclean 领导者选取，会使 Leader 副本一直存在，不至于对外停止服务，提高了高可用；缺点在于：因为从 ISR 中选举 Leader 副本，就会出现数据不同步情况，就会导致数据丢失。\n\n# 十三、副本选举\n\nKafka 在选取 Leader 副本时候，考虑到负载均衡的平衡性，会将不同的分区的 Leader 副本分配到不同的 Broker 中，这样既能避免 Broker 宕机导致多个分区不可用，也能平衡 Broker 的负载。\n\nKafka 引入了优先副本的概念，优先副本的意思是，在分区的所有 AR 集合列表中的第一个副本，理想状态下就是该分区的 Leader 副本。\n\n例如kafka集群由3台broker组成，创建了一个名为 `topic-partitions` 的topic，设置partition为3，副本数为3，partition0中AR列表为 `[1,2,0]`，那么分区0的优先副本为1\n\n![副本选举](img/882565aff441558b043b911c7c240f29_MD5.png)\n\n当分区leader节点发生故障时，其中的一个follower节点就会选举为新的leader节点。当原来leader的节点恢复之后，它只能成为一个follower节点，此时就导致了集群负载不均衡。比如分区1的leader节点broker2崩溃了，此时选举了在broker1上的分区1follower节点作为新的leader节点。当broker2重新恢复时，此时的kafka集群状态如下：\n\n![副本选举](img/d9e50eff06b436f7621152f2739a05c5_MD5.png)\n\n可以看到，此时broker1上负载更大，而broker2上没有负载。\n\n**「为了解决上述负载不均衡的情况，kafka支持了优先副本选举，优先副本指的是一个分区所在的AR集合的第一个副本」**。\n\n比如上面的分区1，它的AR集合是`[2,0,1]`，表示分区1的优先副本就是在broker2上。\n\n理想情况下，优先副本应该就是leader副本，kafka保证了优先副本的均衡分布，而这与broker节点宕机与否没有关系。\n\n**「优先副本选举就是对分区leader副本进行选举的时候，尽可能让优先副本成为leader副本」**，针对上述的情况，只要再触发一次优先副本选举就能保证分区负载均衡。\n\nkafka支持自动优先副本选举功能，默认每5分钟触发一次优先副本选举操作。\n\n# 十四、网络通信模型\n\n![网络通信模型](img/93681a72e52523561d8f052cb74d6da0_MD5.png)\n\nBroker 中有个`Acceptor(mainReactor)`监听新连接的到来，与新连接建连之后轮询选择一个`Processor(subReactor)`管理这个连接。\n\n而`Processor`会监听其管理的连接，当事件到达之后，读取封装成`Request`，并将`Request`放入共享请求队列中。\n\n然后IO线程池不断的从该队列中取出请求，执行真正的处理。处理完之后将响应发送到对应的`Processor`的响应队列中，然后由`Processor`将`Response`返还给客户端。\n\n每个`listener`只有一个`Acceptor线程`，因为它只是作为新连接建连再分发，没有过多的逻辑，很轻量。\n\n`Processor` 在Kafka中称之为网络线程，默认网络线程池有3个线程，对应的参数是`num.network.threads`，并且可以根据实际的业务动态增减。\n\n还有个 IO 线程池，即`KafkaRequestHandlerPool`，执行真正的处理，对应的参数是`num.io.threads`，默认值是 8。\n\nIO线程处理完之后会将`Response`放入对应的`Processor`中，由`Processor`将响应返还给客户端。\n\n可以看到网络线程和IO线程之间利用的经典的生产者 - 消费者模式，不论是用于处理Request的共享请求队列，还是IO处理完返回的Response。\n\n# 十五、幂等性\n\n## **「幂等性Producer」**\n\n在 Kafka 中，Producer 默认不是幂等性的，但是我们可以创建幂等性 Producer。`enable.idempotence` 设置为 True，即可保证 Producer 自动升级成幂等性 Producer，其他所有的代码逻辑都不需要更改。配置后，Kafka 自动做消息的去重操作。\n\n其实，底层原理非常简单，就是经典的以空间换时间的做法，Broker 多保存一些字段，当 Producer 发送消息请求的时候，Broker 能够判断消息是否重复，进而再丢弃掉重复消息。\n\n## 「幂等性 Producer 的作用范围」\n\n- 幂等性只能保证单个分区上的幂等性，无法实现多分区幂等性。\n\n- 幂等性针对单个会话的幂等性，不会实现跨会话的幂等性。\n\n\n\n> 这里的会话，可以理解成 Producer 进程的一次运行，当重启了 Producer 进程之后，这种幂等性就丧失了。\n\n# 十六、事务\n\nKafka 自从 0.11 版本就开始支持事务，目前主要是在 read committed 隔离级别上做事务。它能保证多条消息原子性地写入到目标分区，同时也能保证Consumer 只能看到事务成功提交的消息。\n\n## 「事务型 Producer」\n\n事物型 Producer 能够保证将消息原子性的写入到多个分区中。这批消息要么全部成功，要么全部失败，另外，事务型 Producer 也不怕进程的重启。当 Producer 重启之后，Kafka 仍能保证它们发送消息的精确一次处理。\n\n设置事务型 Producer 的方式也比较简单，满足两个设置即可：\n\n- 和幂等性 Producer 一样，开启 `enable.idempotence = true`。\n\n- 设置 Producer 端参数 `transactional.id`，最好设置一个有意义的名字。\n\n此外，还需要在 Producer 代码中做一些调整，如这段代码所示：\n\n```java\nproducer.initTransactions();  \ntry {  \n            producer.beginTransaction();  \n            producer.send(record1);  \n            producer.send(record2);  \n            producer.commitTransaction();  \n} catch (KafkaException e) {  \n            producer.abortTransaction();  \n}\n```\n\n和普通Producer代码相比，事务型Producer的显著特点是调用了一些事务API，如initTransaction、beginTransaction、commitTransaction和abortTransaction，它们分别对应事务的初始化、事务开始、事务提交以及事务终止。\n\n实际上即使写入失败，Kafka也会把它们写入到底层的日志中，也就是说Consumer还是会看到这些消息。\n\n有一个 `isolation.level` 参数，这个参数有两个取值：\n\n1. `read_uncommitted`：这是默认值，表明Consumer能够读取到Kafka写入的任何消息，不论事务型Producer提交事务还是终止事务，其写入的消息都可以读取，如果你用了事务型Producer，那么对应的Consumer就不要使用这个值。\n\n    \n\n2. `read_committed`：表明Consumer只会读取事务型Producer成功提交事务写入的消息，它也能看到非事务型Producer写入的所有消息\n\n# 十七、拦截器\n\n**Kafka 拦截器分为生产者拦截器和消费者拦截器。** 生产者拦截器允许你在发送消息前以及消息提交成功之后植入拦截器逻辑。而消费者拦截器支持消费消息前以及提交位移后编写特定逻辑。可以将一组懒啊节气串联成一个大的拦截器，Kafka 会按照顺序依次执行拦截器逻辑。\n\n当前 Kafka 拦截器是通过参数配置完成，生产者和消费者两端都有个相同的参数 `interceptor.classes`，它指定的是一组类的列表，每个类就是特定逻辑的拦截器实现类。\n\n```java\nProperties props = new Properties();   \nList interceptors = new ArrayList<>();   \ninterceptors.add(\"com.yourcompany.kafkaproject.interceptors.AddTimestampInterceptor\"); // 拦截器1   \ninterceptors.add(\"com.yourcompany.kafkaproject.interceptors.UpdateCounterInterceptor\"); // 拦截器2   \nprops.put(ProducerConfig.INTERCEPTOR_CLASSES_CONFIG, interceptors);\n```\n\n怎么编写 AddTimeStampInterceptor 和 UpdateCounterInterceptor 类呢？\n\n这两个类以及所有 Producer 端拦截器实现类都要继承 `org.apache.kafka.clients.producer.ProducerInterceptor` 接口。\n\n该接口是 Kafka 提供的，里面有两个核心方法：\n\n1. onSend：该方法在消息发送前被调用。\n\n2. onAcknowledgement：该方法在消息成功提交或者提交失败之后被调用。onAcknowledgement 的调用要早于 callback 的调用。值得注意的是，这个方法和 onSend 方法不在同一个线程中调用，因此如果在这两个方法中调用了共享可变变量，一定要注意线程安全问题。\n\n同理，消费者拦截器也是同样的方法，都要继承 `org.apache.kafka.clients.consumer.ConsumerInterceptor` 接口，这里也有两个核心方法。\n\n1. onConsuume：该方法在消息返回给 Consumer 程序之前调用。\n\n2. onCommit：Consumer 在提交位移之后调用该方法。通常做法是在该方法中做一些记账的动作，例如打印日志等。\n\n# 十八、控制器（Controller）\n\n**控制器组件（controller），主要是用于在 Apache Zookeeper 的帮助下管理和协调整个 Kafka 集群。**\n\n集群中任意一台 Broker 都可以成为控制器角色。在 Kafka 集群启动的时候，第一个在 Zookeeper 中创建/controller 节点的 Broker 会被指定为控制器。\n\n控制器主要的功能如下：\n\n1. **主题管理（创建，删除，增加分区）**\n\n控制器帮我们完成对 Kafka 主题的创建，删除以及分区增加的操作。\n\n2. **分区重分配**\n\n3. **Preferred 领导者选举**\n\nPreferred 领导者选举主要是 Kafka 为了避免部分 Broker 负载过重而提供的一种换 Leader 的方案。\n\n4. **集群成员管理（新增 Broker、Broker 主动关闭、Broker 宕机）**\n\n在 Zookeeper 对 Kafka 协助管理工程中，**「Watch 机制」** 和 **「临时节点」** 是两个重要的机制。 \n\nBroker 的创建时候，Zookeeper 会在 Zookeeper 的 /broker/ids 下创建专属的 znode 节点，这个节点就是临时节点。一旦节点创建完成，ZooKeeper 就会通过 Watch 机制将消息通知推送给控制器，只要，控制器就能自动感知这个变化，进而开启后续的新增 Broker 作业。\n\n当Broker宕机或主动关闭后，该Broker与ZooKeeper的会话结束，这个znode会被自动删除。\n\n同理，ZooKeeper的Watch机制将这一变更推送给控制器，这样控制器就能知道有Broker关闭或宕机了，从而进行善后。\n\n5. **数据服务**\n\n控制器上保存了最全的集群元数据信息，其他所有Broker会定期接收控制器发来的元数据更新请求，从而更新其内存中的缓存数据。\n\n## 「控制器故障转移（Failover）」\n\n**「故障转移指的是，当运行中的控制器突然宕机或意外终止时，Kafka能够快速地感知到，并立即启用备用控制器来代替之前失败的控制器」**。这个过程就被称为Failover，该过程是自动完成的，无需你手动干预。\n\n![控制器故障转移](img/5711d6da84f2000a181c356e080deec4_MD5.png)\n\n最开始时，Broker 0是控制器。当Broker 0宕机后，ZooKeeper通过Watch机制感知到并删除了`/controller`临时节点。\n\n之后，所有存活的Broker开始竞选新的控制器身份。Broker 3最终赢得了选举，成功地在ZooKeeper上重建了 `/controller` 节点。之后，Broker 3会从ZooKeeper中读取集群元数据信息，并初始化到自己的缓存中。\n\n至此，控制器的Failover完成，可以行使正常的工作职责了。\n\n# 二十、日志存储\n\nKafka中的消息是以主题为基本单位进行归类的，每个主题在逻辑上相互独立。\n\n每个主题又可以分为一个或多个分区，在不考虑副本的情况下，一个分区会对应一个日志。\n\n但设计者考虑到随着时间推移，日志文件会不断扩大，因此为了防止Log过大，设计者引入了日志分段（LogSegment）的概念，将Log切分为多个LogSegment，便于后续的消息维护和清理工作。\n\n下图描绘了主题、分区、副本、Log、LogSegment五者之间的关系。\n\n![关系图解](img/4cc119f98ed02df15c264d1cf428d32b_MD5.png)\n\n**「LogSegment」**\n\n在Kafka中，每个Log对象又可以划分为多个LogSegment文件，每个LogSegment文件包括一个日志数据文件和两个索引文件（偏移量索引文件和消息时间戳索引文件）。\n\n其中，每个LogSegment中的日志数据文件大小均相等（该日志数据文件的大小可以通过在Kafka Broker的 `config/server.properties` 配置文件的中的**「log.segment.bytes」**进行设置，默认为1G大小（1073741824字节），在顺序写入消息时如果超出该设定的阈值，将会创建一组新的日志数据和索引文件）。\n\n![日志内部结构](img/5c376d6d6186292ebc461285ce0ac879_MD5.png)\n\n# 常用参数\n\n**「broker端配置」**\n\n- `broker.id`\n\n每个 kafka broker 都有一个唯一的标识来表示，这个唯一的标识符即是 `broker.id`，它的默认值是 0。\n\n这个值在 kafka 集群中必须是唯一的，这个值可以任意设定，\n\n- `port`\n\n如果使用配置样本来启动 kafka，它会监听 9092 端口，修改 port 配置参数可以把它设置成任意的端口。\n\n要注意，如果使用 1024 以下的端口，需要使用 root 权限启动 kakfa。\n\n- `zookeeper.connect`\n\n用于保存 broker 元数据的 Zookeeper 地址是通过 `zookeeper.connect` 来指定的。\n\n比如可以这么指定 `localhost:2181` 表示这个 Zookeeper 是运行在本地 2181 端口上的。\n\n我们也可以通过 比如我们可以通过 `zk1:2181,zk2:2181,zk3:2181` 来指定 `zookeeper.connect` 的多个参数值。\n\n该配置参数是用冒号分割的一组 `hostname:port/path` 列表，其含义如下\n\n- hostname 是 Zookeeper 服务器的机器名或者 ip 地址。\n\n- port 是 Zookeeper 客户端的端口号\n\n- /path 是可选择的 Zookeeper 路径，Kafka 路径是使用了 `chroot` 环境，如果不指定默认使用跟路径。\n\n> ❝\n> 如果你有两套 Kafka 集群，假设分别叫它们 kafka1 和 kafka2，那么两套集群的`zookeeper.connect`参数可以这样指定：`zk1:2181,zk2:2181,zk3:2181/kafka1`和`zk1:2181,zk2:2181,zk3:2181/kafka2`\n> ❞\n\n- `log.dirs`\n\nKafka 把所有的消息都保存到磁盘上，存放这些日志片段的目录是通过 `log.dirs` 来制定的，它是用一组逗号来分割的本地系统路径，`log.dirs` 是没有默认值的，**「你必须手动指定他的默认值」**。\n\n其实还有一个参数是 `log.dir`，这个配置是没有 `s` 的，默认情况下只用配置 `log.dirs` 就好了，比如你可以通过 `/home/kafka1,/home/kafka2,/home/kafka3` 这样来配置这个参数的值。\n\n- `auto.create.topics.enable`\n\n默认情况下，kafka 会自动创建主题\n\n`auto.create.topics.enable`参数建议最好设置成 false，即不允许自动创建 Topic。\n\n**「主题相关配置」**\n\n- `num.partitions`\n\nnum.partitions 参数指定了新创建的主题需要包含多少个分区，该参数的默认值是 1。\n\n- `default.replication.factor`\n\n这个参数比较简单，它表示 kafka保存消息的副本数。\n\n- `log.retention.ms`\n\nKafka 常根据时间来决定数据可以保留多久。\n\n默认使用`log.retention.hours`参数来配置时间，默认是 168 个小时，也就是一周。\n\n除此之外，还有两个参数`log.retention.minutes` 和`log.retentiion.ms` 。\n\n这三个参数作用是一样的，都是决定消息多久以后被删除，推荐使用`log.retention.ms`。\n\n- `message.max.bytes`\n\nbroker 通过设置 `message.max.bytes` 参数来限制单个消息的大小，默认是 1000 000， 也就是 1MB，如果生产者尝试发送的消息超过这个大小，不仅消息不会被接收，还会收到 broker 返回的错误消息。\n\n- `retention.ms`\n\n规定了该主题消息被保存的时常，默认是7天，即该主题只能保存7天的消息，一旦设置了这个值，它会覆盖掉 Broker 端的全局参数值。\n\n#  消息丢失问题\n\n## **「生产者程序丢失数据」**\n\n目前Kafka Producer是异步发送消息的，也就是说如果你调用的是`producer.send(msg)`这个API，那么它通常会立即返回，但此时你不能认为消息发送已成功完成。\n\n**如果用这个方式，可能会有哪些因素导致消息没有发送成功呢？**\n\n其实原因有很多：\n\n1. 例如网络抖动，导致消息压根就没有发送到Broker端；\n\n如果是网络抖动导致的失败，可以通过 Producer 中的参数 `retries` (重试次数)设置比较合理的值来解决，一般来说为 3。同时，建议还要设置重试间隔 `retry.backoff.ms` 来避免 3 次重试间隔太短导致多次失败。\n\n2. 或者消息本身不合格导致Broker拒绝接收（比如消息太大了，超过了Broker的承受能力）等。\n\n实际上，解决此问题的方法非常简单：Producer永远要使用带有回调通知的发送API，也就是说不要使用 `producer.send(msg)`，而要使用 `producer.send(msg, callback)`。在 SpringBoot 中可以用类似的方式来处理：\n\n```java\nListenableFuture<SendResult<String, Object>> future = kafkaTemplate.send(smsBusiPrediction, msg);  \nfuture.addCallback(new ListenableFutureCallback<SendResult<String, Object>>() {  \n   @Override  \n   public void onSuccess(SendResult<String, Object> result) {  \n      log.info(\"=====向kafka推送信息成功=====\");  \n   }  \n   @Override  \n   public void onFailure(Throwable ex) {  \n      log.info(\"=====向kafka推送信息失败！！=====\",ex);  \n   }   \n});\n```\n\n它能准确地告诉你消息是否真的提交成功了。一旦出现消息提交失败的情况，你就可以有针对性地进行处理。\n\n## **「消费者程序丢失数据」**\n\nConsumer端丢失数据主要体现在Consumer端要消费的消息不见了。\n\n下面这张图它清晰地展示了Consumer端的位移数据。\n\n![Consumer端的位移数据](img/adc9951c2edb1fba60deea2d87fb2d44_MD5.png)\n\n比如对于Consumer A而言，它当前的位移值就是9；Consumer B的位移值是11。Consumer程序从Kafka获取到消息后开启了多个线程异步处理消息，而Consumer程序自动地向前更新位移。\n\n假如其中某个线程运行失败了，它负责的消息没有被成功处理，但位移已经被更新了，因此这条消息对于Consumer而言实际上是丢失了。这里的关键在于Consumer自动提交位移。这个问题的解决方案也很简单：**「如果是多线程异步处理消费消息，Consumer程序不要开启自动提交位移，而是要应用程序手动提交位移」**。\n\n## **「Kafka 内部出现消息丢失」**\n\n试想一种情况：假如 leader 副本所在的 broker 突然挂掉，那么就要从 follower 副本重新选出一个 leader ，但是 leader 的数据还有一些没有被 follower 副本的同步的话，就会造成消息丢失。\n\n**设置 `acks = all`**\n\n解决办法就是我们设置 `acks = all`。`acks` 是 Kafka 生产者(Producer) 很重要的一个参数。\n\nacks 的默认值即为 1，代表我们的消息被 leader 副本接收之后就算被成功发送。当我们配置 **acks = all** 表示只有所有 ISR 列表的副本全部收到消息时，生产者才会接收到来自服务器的响应. 这种模式是最高级别的，也是最安全的，可以确保不止一个 Broker 接收到了消息. 该模式的延迟会很高.\n\n**设置 `replication.factor >= 3`**\n\n为了保证 leader 副本能有 follower 副本能同步消息，我们一般会为 topic 设置 `replication.factor >= 3`。这样就可以保证每个 分区(partition) 至少有 3 个副本。虽然造成了数据冗余，但是带来了数据的安全性。\n\n**设置 `min.insync.replicas > 1`**\n\n一般情况下我们还需要设置 **`min.insync.replicas> 1`** ，这样配置代表消息至少要被写入到 2 个副本才算是被成功发送。**min.insync.replicas** 的默认值为 1 ，在实际生产中应尽量避免默认值 1。\n\n但是，为了保证整个 Kafka 服务的高可用性，你需要确保 **`replication.factor > min.insync.replicas`** 。为什么呢？设想一下假如两者相等的话，只要是有一个副本挂掉，整个分区就无法正常工作了。这明显违反高可用性！一般推荐设置成 **`replication.factor = min.insync.replicas + 1`**。\n\n**设置 `unclean.leader.election.enable = false`**\n\n\n\n> **Kafka 0.11.0.0 版本开始 unclean.leader.election.enable 参数的默认值由原来的 true 改为 false**\n\n\n\n我们最开始也说了我们发送的消息会被发送到 leader 副本，然后 follower 副本才能从 leader 副本中拉取消息进行同步。多个 follower 副本之间的消息同步情况不一样，当我们配置了 **`unclean.leader.election.enable = false`** 的话，当 leader 副本发生故障时就不会从 follower 副本中和 leader 同步程度达不到要求的副本中选择出 leader ，这样降低了消息丢失的可能性。\n\n## 「最佳实践」\n\n总结Kafka 避免消息丢失的配置：\n\n1. 在 Producer 端：\n\n\t- 不要使用 `producer.send(msg)`，而要使用 `producer.send(msg, callback)`，一定要使用带有回调通知的 send 方法。\n\n\t- 设置 `retries`  为一个较大的值。这里的`retries`同样是Producer的参数，对应前面提到的Producer自动重试，当出现网络的瞬时抖动时，消息发送可能会失败，此时配置了 `retries > 0` 的 Producer 能够自动重试消息发送，避免消息丢失。\n\n\t- 设置 `acks = all`，acks 是 Producer 的一个参数，代表了你对已提交消息的定义，如果设置成 all，则表明所有副本 Broker 都要接收到消息，该消息才算是已提交。\n\n2. 在 Consumer 端：\n\n\t - 确保消息消费完成再提交，Consumer端有个参数 `enable.auto.commit`，最好把它设置成 false，并采用手动提交位移的方式。\n\n3. 在 Kafka 内部：\n\n\t- 设置 `unclean.leader.election.enable = false`，这是 Broker 端的参数，它控制的是哪些 Broker 有资格竞选分区的 Leader，如果一个 Broker 落后原先的 Leader 太多，那么它一旦成为新的 Leader，必然会造成消息的丢失，故一般都要将该参数设置成 false，即不允许这种情况的发生。\n\n\t- 设置 `replication.factor >= 3`，这也是 Broker 端的参数，将消息多保存几份，目前防止消息丢失的主要机制就是冗余。\n\n\t- 设置 `min.insync.replicas > 1`，这依然是 Broker 端参数，控制的是消息至少要被写入到多少个副本才算是已提交，设置成大于 1 可以提升消息持久性，在实际环境中千万不要使用默认值 1。\n\n\t- 确保 `replication.factor > min.insync.replicas`，如果两者相等，那么只要有一个副本挂机，整个分区就无法正常工作了，我们不仅要改善消息的持久性，防止数据丢失，还要在不降低可用性的基础上完成，推荐设置成 `replication.factor = min.insync.replicas + 1`。\n\n\n\n# 重复消费问题\n\n**「消费重复的场景」**\n\n在 `enable.auto.commit` 默认值true情况下，出现重复消费的场景有以下几种：\n\n\n\n> ❝\n> consumer 在消费过程中，应用进程被强制kill掉或发生异常退出。\n> ❞\n\n\n\n例如在一次poll 500条消息后，消费到200条时，进程被强制kill消费到offset未提交，或出现异常退出导致消费到offset未提交。\n\n下次重启时，依然会重新拉取500消息，造成之前消费到200条消息重复消费了两次。\n\n解决方案：在发生异常时正确处理未提交的offset\n\n**「消费者消费时间过长」**\n\n`max.poll.interval.ms`参数定义了两次poll的最大间隔，它的默认值是 5 分钟，表示你的 Consumer 程序如果在 5 分钟之内无法消费完 poll 方法返回的消息，那么 Consumer 会主动发起离开组的请求，Coordinator 也会开启新一轮 Rebalance。\n\n举例：单次拉取11条消息，每条消息耗时30s，11条消息耗时5分钟30秒，由于`max.poll.interval.ms`  默认值5分钟，所以消费者无法在5分钟内消费完，consumer会离开组，导致rebalance。\n\n在消费完11条消息后，consumer会重新连接broker，再次rebalance，因为上次消费的offset未提交，再次拉取的消息是之前消费过的消息，造成重复消费。\n\n**「解决方案：」**\n\n1、提高消费能力，提高单条消息的处理速度；根据实际场景可讲`max.poll.interval.ms`值设置大一点，避免不必要的rebalance；可适当减小`max.poll.records`的值，默认值是500，可根据实际消息速率适当调小。\n\n2、生成消息时，可加入唯一标识符如消息id，在消费端，保存最近的1000条消息id存入到redis或mysql中，消费的消息时通过前置去重。\n\n# 消息顺序问题\n\n我们都知道 `kafka` 的 `topic` 是无序的，但是一个 `topic` 包含多个 `partition`，每个 `partition` 内部是有序的（分区内采用尾插法）\n\n![消息消费顺序](img/466a6f44f4b183a6bae184c90378b300_MD5.png)\n\n**「乱序场景1」**\n\n因为一个topic可以有多个partition，kafka只能保证partition内部有序\n\n**「解决方案」**\n\n1、可以设置topic，有且只有一个partition，**不推荐，这样就违背了 Kafka 的设计初衷，即多分区，多副本的概念。**\n\n2、**（推荐）** 根据业务需要，需要顺序的指定为同一个partition，在 Broker 提交的时候，规定 topic，partition，key，data 四个参数统一。\n\n**「乱序场景2」**\n\n对于同一业务进入了同一个消费者组之后，用了多线程来处理消息，会导致消息的乱序\n\n**「解决方案」**\n\n消费者内部根据线程数量创建等量的内存队列，对于需要顺序的一系列业务数据，根据key或者业务数据，放到同一个内存队列中，然后线程从对应的内存队列中取出并操作\n\n![解决方案](img/bb94c4025a04733be2eb858d968eaffd_MD5.png)\n\n**「通过设置相同key来保证消息有序性，会有一点缺陷：」**\n\n例如消息发送设置了重试机制，并且异步发送，消息A和B设置相同的key，业务上A先发，B后发，由于网络或者其他原因A发送失败，B发送成功；A由于发送失败就会重试且重试成功，这时候消息顺序B在前A在后，与业务发送顺序不一致，如果需要解决这个问题，需要设置参数 `max.in.flight.requests.per.connection=1`，其含义是限制客户端在单个连接上能够发送的未响应请求的个数，设置此值是1表示kafka broker在响应请求之前client不能再向同一个broker发送请求，这个参数默认值是5\n\n# 高性能原因\n\n## **「顺序读写」**\n\nkafka的消息是不断追加到文件中的，这个特性使`kafka`可以充分利用磁盘的顺序读写性能\n\n顺序读写不需要硬盘磁头的寻道时间，只需很少的扇区旋转时间，所以速度远快于随机读写\n\nKafka 可以配置异步刷盘，不开启同步刷盘，异步刷盘不需要等写入磁盘后返回消息投递的 ACK，所以它提高了消息发送的吞吐量，降低了请求的延时\n\n## **「零拷贝」**\n\n传统的 IO 流程，需要先把数据拷贝到内核缓冲区，再从内核缓冲拷贝到用户空间，应用程序处理完成以后，再拷贝回内核缓冲区\n\n这个过程中发生了多次数据拷贝\n\n为了减少不必要的拷贝，`Kafka` 依赖 Linux 内核提供的 `Sendfile` 系统调用\n\n在 Sendfile 方法中，数据在内核缓冲区完成输入和输出，不需要拷贝到用户空间处理，这也就避免了重复的数据拷贝\n\n在具体的操作中，Kafka 把所有的消息都存放在单独的文件里，在消息投递时直接通过 `Sendfile` 方法发送文件，减少了上下文切换，因此大大提高了性能\n\n## **「MMAP技术」**\n\n除了 `Sendfile` 之外，还有一种零拷贝的实现技术，即 Memory Mapped Files\n\nKafka 使用 `Memory Mapped Files` 完成内存映射，`Memory Mapped Files` 对文件的操作不是 `write/read`，而是直接对内存地址的操作，如果是调用文件的 `read` 操作，则把数据先读取到内核空间中，然后再复制到用户空间，但 `MMAP`可以将文件直接映射到用户态的内存空间，省去了用户空间到内核空间复制的开销\n\nProducer生产的数据持久化到broker，采用mmap文件映射，实现顺序的快速写入\n\nCustomer从broker读取数据，采用sendfile，将磁盘文件读到OS内核缓冲区后，直接转到socket buffer进行网络发送。\n\n## **「批量发送读取」**\n\nKafka 的批量包括批量写入、批量发布等。它在消息投递时会将消息缓存起来，然后批量发送\n\n同样，消费端在消费消息时，也不是一条一条处理的，而是批量进行拉取，提高了消息的处理速度\n\n## **「数据压缩」**\n\nKafka还支持对消息集合进行压缩，`Producer`可以通过`GZIP`或`Snappy`格式对消息集合进行压缩\n\n压缩的好处就是减少传输的数据量，减轻对网络传输的压力\n\nProducer压缩之后，在`Consumer`需进行解压，虽然增加了CPU的工作，但在对大数据处理上，瓶颈在网络上而不是CPU，所以这个成本很值得\n\n## **「分区机制」**\n\nkafka中的topic中的内容可以被分为多partition存在，每个partition又分为多个段segment，所以每次操作都是针对一小部分做操作，很轻便，并且增加 `并行操作` 的能力\n\n# 常见面试题\n\n## **「Kafka是Push还是Pull模式？」**\n\nKafka最初考虑的问题是，customer应该从brokes拉取消息还是brokers将消息推送到consumer。\n\n在这方面，Kafka遵循了一种大部分消息系统共同的传统的设计：producer将消息推送到broker，consumer从broker拉取消息。\n\npush模式由broker决定消息推送的速率，对于不同消费速率的consumer就不太好处理了。\n\n消息系统都致力于让consumer以最大的速率最快速的消费消息，push模式下，当broker推送的速率远大于consumer消费的速率时，consumer恐怕就要崩溃了。\n\n\n\n> ❝\n> Kafka中的Producer和Consumer采用的是Push-and-Pull模式，即Producer向Broker Push消息，Consumer从Broker Pull消息。\n> ❞\n\n\n\nPull模式的一个好处是consumer可以自主决定是否批量的从broker拉取数据。\n\nPull有个缺点是，如果broker没有可供消费的消息，将导致consumer不断在循环中轮询，直到新消息到达。\n\n## **「Kafka如何保证高可用?」**\n\n[面试题：Kafka如何保证高可用？有图有真相](https://mp.weixin.qq.com/s?__biz=MzUyOTg1OTkyMA==&mid=2247484980&idx=1&sn=6e0c7112dd72d0edc284009e7503b2ac&scene=21#wechat_redirect)\n\n## **「Kafk的使用场景」**\n\n业界Kafka实际应用场景\n\n> ❝\n> 异步通信\n> ❞\n\n\n\n消息中间件在异步通信中用的最多，很多业务流程中，如果所有步骤都同步进行可能会导致核心流程耗时非常长，更重要的是所有步骤都同步进行一旦非核心步骤失败会导致核心流程整体失败，因此在很多业务流程中Kafka就充当了异步通信角色。\n\n\n\n> ❝\n> 日志同步\n> ❞\n\n\n\n大规模分布式系统中的机器非常多而且分散在不同机房中，分布式系统带来的一个明显问题就是业务日志的查看、追踪和分析等行为变得十分困难，对于集群规模在百台以上的系统，查询线上日志很恐怖。\n\n为了应对这种场景统一日志系统应运而生，日志数据都是海量数据，通常为了不给系统带来额外负担一般会采用异步上报，这里Kafka以其高吞吐量在日志处理中得到了很好的应用。\n\n\n\n> ❝\n> 实时计算\n> ❞\n\n\n\n随着据量的增加，离线的计算会越来越慢，难以满足用户在某些场景下的实时性要求，因此很多解决方案中引入了实时计算。\n\n很多时候，即使是海量数据，我们也希望即时去查看一些数据指标，实时流计算应运而生。\n\n实时流计算有两个特点，一个是实时，随时可以看数据；另一个是流。\n\n\n\n## **「Kafka 的多分区（Partition）以及多副本（Replica）机制有什么好处呢？」**\n\n1. Kafka 通过给特定 Topic 指定多个 Partition, 而各个 Partition 可以分布在不同的 Broker 上, 这样便能提供比较好的并发能力（负载均衡）。\n\n2. Partition 可以指定对应的 Replica 数, 这也极大地提高了消息存储的安全性, 提高了容灾能力，不过也相应的增加了所需要的存储空间。\n\n\n\n\n\n参考资料：\n\n>  [Kafka常见问题总结](https://javaguide.cn/high-performance/message-queue/kafka-questions-01.html)\n> \n>  [Kafka核心知识总结！](https://mp.weixin.qq.com/s/zfHoSsuSpXWOaxQrm7uvkA)\n\n","source":"_posts/md/万字详解，Kafka这一篇就够了！.md","raw":"---\ntitle: Kafka深入浅出\ntag: \n- Kafka\ncategory: \n- 中间件\ndate: 2024-12-11\nid: 761386768996831\n---\n\n\nKafka 服务器端的代码是由 Scala 代码编写，支持面向对象编程和函数式数据，编译过后也是普通的 .class 文件。其的作用：提供统一的、高吞吐量、低延迟的平台来处理实时数据\n\n# 一、基本概念\n\n## 「Kafka 是什么？主要应用场景什么？」\n\nKafka 是一个分布式流式处理平台。\n\n![Kafka结构示意图](img/6aaf06740442599b6c52bb586545dfb8_MD5.png)\n\n\n\n**1 . 主题**：发布订阅的对象是主题（Topic），可以为每个业务、每个应用甚至每类数据都创建专属的主题\n\n\n\n**2 . 生产者和消费者**：向主题发布消息的客户端应用程序成为生产者，生产者程序通常持续不断地向一个或者多个主题发送消息\n\n\n\n**3 . Broker**：集群由多个 Broker 组成，Broker 负责接收和处理客户端发送过来的请求，以及对消息进行持久化。\n\n\t虽然多个 Broker 能够运行在同一台机器上，但是常见的做法是将不同的 Broker 分散运行在不同的机器上，这样如果某一台机器宕机，即使在它上面运行的所有 Broker 进程都挂掉了，其他机器上的 Broker 也一眼能够对外提供服务。\n\n\n\n **4 . 备份机制**：备份的思想很简单，就是把相同的数据拷贝到多台机器上，而这些相同的数据拷贝被称为副本。\n\n\tKafka 定义了两类副本：领导者副本和追随者副本。\n\n\t前者对外提供服务，即与客户端程序进行交互；后者只是被动地追随领导者副本而已，不对外进行交互。\n\n\n\n**5 . 分区**：分区机制指的是将每个主题分成多个分区，每个分区是一组有序的消息日志\n\n\t生产者生产的每条消息总会被发送到一个分区中，也就是说如果向一个双分区的主题发送一条消息，该条消息要不在分区 0 中，要不在分区 1 中。\n\n\t生产者向分区中写入消息，每条消息在分区中的位置信息叫做位移。\n\n\n\n**6 . 消费者组**：多个消费者实例共同组成一个组来消费一组主题\n\n\t这组主题中的每个分区只会被组内的一个消费者实例消费，其他消费者实例不能消费它\n\n\t消息引擎的两大模型：\n\n\t\t如果所有实例都属于同一个 Group，那么它实现的就是消息队列模型\n\n\t\t如果所有实例属于不同的 Group，那么它实现的就是发布/订阅模型\n\n> **RocketMQ 的消息模型和 Kafka 基本是完全一样的。唯一的区别是 Kafka 中没有队列这个概念，与之对应的是 Partition（分区）。**\n\n\n\n**7 . Coordinator：协调者**：负责为 Group 执行 Rebalance 以及提供唯一管理和组成员管理等。\n\n\n\n**8 . 消费者位移：Consumer offset**：消费者消费进度，每个消费者都有自己的消费者位移\n\n\n\n**9 . 重平衡：Rebalance**：消费者组内某个消费者实例挂掉后，其他消费者实例自动重新分配订阅主题分区的过程。\n\nRebalance 是 Kafka 消费者端实现高可用的重要手段\n\n\n\n**10 . AR（Assigned Replicas）**：分区中的所有副本统称为 AR。\n\n所有消息都会先发送到领导者副本，然后追随者副本才能从领导者中拉去信息进行同步\n\n但是同步期间，追随者副本相对于领导者副本而言有一定程度的滞后，这时候追随者副本和领导者副本并非完全同步状态\n\n\n\n**11 . OSR（Out Sync Replicas）**：AR 的一个子集，其中都是追随者副本和领导者副本没有完全同步或者之后的副本集合\n\n\n\n**12 . ISR（In Sync Replicas）**：AR 的一个子集，ISR 中的副本都是和领导者副本是保持完全同步的副本。\n\n如果某一个在 ISR 中的 follower 副本落后于 leader 副本太多，就会从 ISR 中移除，否则如果完全同步，会从 OSR 中移到 ISR 集合中\n\n\n\n**13 . HW（High Watermark）**：高水位，标识一个特定的消息偏移量（offset），消费者只能来取这个水位 offset 之前的消息\n\n下图表示一个日志文件，这个日志文件中只有9条消息，第一条消息的offset（LogStartOffset）为0，最有一条消息的offset为8，offset为9的消息使用虚线表示的，代表下一条待写入的消息。\n\n日志文件的 HW 为6，表示消费者只能拉取offset在 0 到 5 之间的消息，offset为6的消息对消费者而言是不可见的。\n\n![消息偏移量展示](img/ce77dd7ccc11dc7642aad16560000cb9_MD5.png)\n\n\n\n**14 . LEO（Log End Offset）**：标识当前日志文件中下一条待写入的消息的offset\n\n# 二、系统架构\n\nKafka 基础框架：一个生产者发送一个消息到 Kafka 的一个 Topic，该 Topic 的消息存放在 Broker 中，消费者订阅这个 Topic，然后从 Broker 中消费消息。\n\n\n\n1.**消息状态**：在 Kafka 中，消息是否被消费的状态保存在消费者中，Broker 不会关系消息是否消费，或者被谁消费，消费者会记录一个 offset 值（指向分区中下一条被消费的消息位置），如果 offset 被错误设置可能会导致同一条消息多次消费或者丢失。\n\n2.**消息持久化**：Kafka 会把消息持久化到本地文件系统中，并且具有极高的性能。\n\n3.**批量发送**：Kafka 支持以消息集合为单位进行批量发送，以提高效率。\n\n4.**Push-and-Pull**：Kafka 中的生产者和消费者采用的是 Push-and-Pull 模式，即生产者向 Broker Push 消息，消费者从 Broker Pull 消息。\n\n5.**分区机制**：Kafka 的 Broker 是支持分区的，Producer 可以决定将消息放在哪个 Partition，在一个 Partition 中的消息顺序就是 Producer 发送消息的顺序，一个 Topic 中的 Partition 是可以配置的，Partition 是保证 Kafka 高吞吐量的重要保证。\n\n![系统架构](img/68d9aaa9dd34dbc9d516201de1f2ab55_MD5.png)\n\n通常情况下，一个 Kafka 体系是包含多个 Producer，多个 Broker，多个 Consumer，以及一个 Zookeeper 集群\n\n# 三、生产者分区\n\n一条 Kafka 消息的的组织架构是三层：主题（Topic）- 分区（Partition）- 消息（Message）\n\n分区其实是一种负载均衡的做法。因为同一个 Topic 下的不同分区可以在不同 Broker 节点上，并且，数据读写是以分区为粒度，这样的话，每个节点都可以执行自己分区的消息的读写。除此之外，还能通过增加节点来提高吞吐量。\n\n## 「分区策略」\n\n所谓的分区策略其实就是决定生产者将消息发送到哪个分区的算法。\n\n### 自定义分区策略\n\n如果需要自己定义分区策略，在编写生产者程序的时候，可以编写一个具体的实现类`org.apache.kafka.clients.producer.Partitioner` 接口。这接口也非常简单，只定义了两个方法：partition() 和 close() 方法。通常情况我们只需要实现 partition() 方法即可。\n\n```java\nint partition(String topic, Object key, byte[] keyBytes, Object value, byte[] valueBytes, Cluster cluster);\n```\n\n这里的 topic、key、keyBytes、value 和 valueBytes 都属于消息数据，cluster 则是集群信息（比如当前 Kafka 集群共有多少主题、多少 Broker 等）。\n\n### 轮询策略\n\n也称 Round-robin 策略，即顺序分配。轮询策略是 Kafka 生产者 API 默认提供的分区策略。\n\n轮询策略有非常优秀的负载均衡表现，它总是保证消息最大限度的平均分配到所有的分区上，所以默认下它是最合理的分区策略，也是最常用的分区策略。\n\n### 随机策略\n\n也称 Randomness 策略。想要实现随机策略的 partition 方法，其实很简单，只需要两行代码即可：\n\n```java\n List partitions = cluster.partitionsForTopic(topic);\n return ThreadLocalRandom.current().nextInt(partitions.size());\n\n```\n\n先计算出该主题的总分区数，然后随机返回一个小于它的正整数。\n\n随机策略在负载均衡上面略逊于轮询策略。在老的版本里面常用随机策略，再后来的版本更新中被轮询策略所替代。\n\n### 按消息键保序策略\n\nKafka 允许为每条消息定义消息键，简称 Key。\n\nKey 可以为具体的业务代码，也可以用来表征消息元数据。在 Kafka 中如果消息定义了 Key，那么就可以保证同一个 Key 的消息进入相同的分区，有序分区下的消息处理是有顺序的，所以这个策略被称为安消息键保存策略。\n\n实现这个策略的 partition 方法同样简单，只需要下面两行代码即可：\n\n```java\n List partitions = cluster.partitionsForTopic(topic);\n return Math.abs(key.hashCode()) % partitions.size();\n```\n\n其实，Kafka 默认的分区策略是两种：\n\t如果指定了 Key ，默认实现按消息键保序策略；\n\t如果未指定 Key，则使用轮询策略。\n\n### 「其他分区策略」\n\n另外还有一种比较常见的，所谓的基于地理位置的分区策略。当然这种策略只针对大规模的 Kafka 集群，特别是跨城市、跨国家甚至是跨大洲的集群。我们可以根据 Broker 所在的 IP 地址实现定制化的分区策略。比如下段代码：\n\n```java\nList partitions = cluster.partitionsForTopic(topic);\nreturn partitions.stream().filter(p -> isSouth(p.leader().host())).map(PartitionInfo::partition).findAny().get();\n```\n\n我们可以从所有分区中找出那些 Leader 副本在南方的所有分区，然后随机挑选一个进行消息发送。\n\n# 四、生产者压缩算法\n\n为什么要压缩消息？压缩消息是为了更好的节省网络传输贷款以及 Kafka Broker 端的磁盘占用。\n\n### 「Kafka 是如何压缩消息的呢？」\n\nKafka 的消息层次分为两层：消息集合和消息。\n\n??？\n\n### 「何时压缩？」\n\n在 Kafka 中，压缩可能发生在两个地方：生产者端和 Broker 端。\n\n在生产者程序中配置 compression.type 参数即表示弃用指定类型的压缩算法。\n\n比如这段代码中展示了如何构建一个开启 GZIP 的 Producer 对象：\n\n```java\nProperties props = new Properties();\nprops.put(\"bootstrap.servers\", \"localhost:9092\");\nprops.put(\"acks\", \"all\");\nprops.put(\"key.serializer\", \"org.apache.kafka.common.serialization.StringSerializer\"); props.put(\"value.serializer\", \"org.apache.kafka.common.serialization.StringSerializer\"); // 开启GZIP压缩\nprops.put(\"compression.type\", \"gzip\"); //Producer的压缩算法是GZIP\nProducer producer = new KafkaProducer<>(props);\n```\n\n这样 Producer 启动之后生产的每个消息集合都是经 GZIP 压缩过的，故而能很好的节省网络传输贷款以及 Kafka Broker 端的磁盘占用。\n\n有两种情况可能导致 Broker 重新压缩消息：\n\n- 情况一：Broker 端指定了和 Producer 端不同的压缩算法。\n\n一旦 Broker 端设置了不同的 compression.type 值，就一定要小心了，因为可能会发生预料之外的压缩、解压缩操作，通常表现为 Broker 端 CPU 使用率飙升。\n\n- 情况二：Broker 端发生了消息格式转换。\n\n所谓的消息格式转换主要是为了兼容老版本的消费者程序。在一个生产环境中，Kafka 集群中同时保存多个版本的消息格式非常常见。为了兼容老版本的格式，Broker 端会对新版本消息指向向老版本的转换。这个过程会涉及到消息的解压缩和重新压缩。一般情况下这种消息格式转换成对性能是有很大影响的，除了这里的压缩之外，他还让 Kafka 丧失了 Zero Copy 特性。\n\n### 「何时解压缩？」\n\n有压缩必有解压缩！通常来说解压缩发生在消费者程序中。\n\n**基本过程：Producer 端压缩，Broker 端保持，Consumer 端解压缩。**\n\n注意：除了在 Consumer 端解压缩外，Broker 端也会进行解压缩。\n\n每个压缩过的消息集合在 Broker 端写入时都要发生解压缩操作，目的就是为了对消息执行各种验证。我们必须承认这种解压缩对 Broker 端性能有一定的影响，特别是对 CPU 的使用率而言。\n\n### 「各种压缩算法对比」\n\nKafka 支持 4 种压缩算法：GZIP、Snappy 、LZ4 和 zstd(Zstandard 算法)。在实际使用中，各个算法各有千秋。\n\n吞吐量：LZ4 > Snappy > zst 和 GZIP；\n\n压缩比：zstd > LZ4 > GZIP > Snappy；\n\n占用宽带：zstd < LZ4 和 GZIP < Snappy；\n\n在CPU使用率方面，各个算法表现得差不多，只是在压缩时Snappy算法使用的CPU较多一些，而在解压缩时GZIP算法则可能使用更多的CPU。\n\n# 五、消费者组\n\nConsumer Group 是 Kafka 提供可拓展且具有容错性的消费机制。\n\n既然是一个组，那么组内必然是可以有多个消费者或者消费者实例，它们共享一个公共的 ID，这个 ID 被称为 Group ID。组内所有的消费者协调在一起来消费订阅主题的所有分区。每个分区只能有同一个消费组内的一个 Consumer 实例来消费。\n\n### Consumer Group 三个特性\n\n1.Consumer Group 下可以有一个或者多个 Consumer 实例，这里的实例可以是一个单独的进程，也可以是同一个进程下的线程。\n\n2.Group ID 是一个字符串，在一个 Kafka 集群中，它表示唯一的一个 Consumer Group。\n\n3.Consumer Group 下所有实例订阅的主题的单独分区，只能分配给组内的某个 Consumer 实例消费，这个分区当然也可以被其他的 Group 消费。\n\nKafka 仅仅使用 Consumer Group 这一种机制，却同时实现了传统消息引擎系统的两大模型：\n\n- 如果所有实例都是属于同一个 Group，那么它实现的是消息队列模型；\n\n- 如果所有实例分别属于不同的 Group，那么它实现的就是发布/订阅模型。\n\n### 一个 Group 下应该有多少个 Consumer 实例呢？\n\n理想情况下，Consumer 实例的数量应该等于 Group 订阅主题的分区总数。\n\n> 假设一个 Comsumer Group 订阅了 3 个主题，分别是 A、B、C，它们的分区数分别是 1，2，3，那么通常情况下，为改 Group 设置 6 个 Consumer 实例是比较理想的情形，因为它能最大限度的视线高伸缩性。\n\n\n\n### 针对 Consumer Group，Kafka 是怎么管理位移呢？\n\n老版本 Consumer Group 把位移保存在 ZooKeeper 中。Apache ZooKeeper 是一个分布式的协调服务框架，Kafka 重度依赖它实现的各种各样的协调管理。将唯一保存到 ZooKeeper 外部系统的做法，最显而易见的好处就是减少了 Kafka Broker 端的状态保存开销。\n\n但是，慢慢的发现一个问题，即 ZooKeeper 这类元框架其实并不适合进行频繁的写更新，而 Consumer Group 的位移更新是一个非常频繁的操作。这种大吞吐量的写操作会极大拖慢 ZooKeeper 集群的性能。于是，新版本的 Consumer Group 中，Kafka 社区重新设计了 Consumer Group 的位移管理方式，采用将位移保存在 Kafka 内部主题的方法。\n\n这个内部主题就是\\_counsumer_offset.\n\n# 六、消费者策略\n\n消费者消费同一主题的哪个分区，是通过消费者策略决定的。\n\n#### 轮询 Round\n\nKakfa 默认的消费者策略——轮询，通过轮询方式，决定消费者消费的分区。\n\n![轮询策略](img/2ca562d1dc3a2d8d06c7c2bfe2c394c8_MD5.png)\n\n#### 范围计算 Range\n\n对一个消费者组来说，决定消费方式是以分区总数除以消费者总数来决定，一般如果不能整除，往往是从头开始将剩余的分区分配开\n\n![范围计算](img/c3276b5f713b8b0641463b496c196ce2_MD5.png)\n\n#### 范围计算升华版 Sticky\n\n是在0.11.x，新增的，它和前面两个不是很一样，它是在Range上的一种升华，且前面两个当同组内有新的消费者加入或者旧的消费者退出的时候，会从新开始决定消费者消费方式，但是Sticky，在同组中有新的新的消费者加入或者旧的消费者退出时，不会直接开始新的Range分配，而是保留现有消费者原来的消费策略，将退出的消费者所消费的分区平均分配给现有消费者，新增消费者同理，同其他现存消费者的消费策略中分离。\n\n# 七、位移提交\n\n假设一个分区中有 10 条消息，唯一分别是 0 到 9.\n\n某个 Consumer 应用已经消费了 5 条消息，这就说明该 Consumer 消费了位移为 0 到 4 的 5 条消息，此时 Consumer 的位移是 5，指向了下一条消息的位移。因为 Consumer 能够同时消费多个分区的数据，所以位移的提交实际上是在分区粒度上进行的，即 **Consumer 需要为分配给它的每一个分区提交各自的位移数据。**\n\n位移提交分为自动提交和手动提交；从 Consumer 端的角度来说，位移提交分为同步提交和异步提交。\n\n开启自动提交位移的方法：Consumer 端有一个参数 `enable.auto.commint`，把它设置为 true 或者不设置它即可。\n\n如果开启了自动提交，Consumer 端还有个参数：`auto.commit.interval.ms`。默认为 5 秒，表明 Kafka 每 5 秒会自动提交一次位移。\n\n```java\nProperties props = new Properties();\nprops.put(\"bootstrap.servers\", \"localhost:9092\");\nprops.put(\"group.id\", \"test\");\n//开启自动提交\nprops.put(\"enable.auto.commit\", \"true\");\n//自动提交时间间隔\nprops.put(\"auto.commit.interval.ms\", \"2000\");\nprops.put(\"key.deserializer\", \"org.apache.kafka.common.serialization.StringDeserializer\");\nprops.put(\"value.deserializer\", \"org.apache.kafka.common.serialization.StringDeserializer\");\nKafkaConsumer consumer = new KafkaConsumer<>(props);\nconsumer.subscribe(Arrays.asList(\"foo\", \"bar\"));\nwhile (true) {\n    ConsumerRecords records = consumer.poll(100);\n    for (ConsumerRecord record : records)\n        System.out.printf(\"offset = %d, key = %s, value = %s%n\", record.offset(), record.key(), record.value());\n}\n```\n\n如果要开启手动提交，只需要将 `enable.auto.commit` 设置为 `false` 即可。\n\n手动提交需要调用相应的 API 手动提交位移。最简单的 API 就是 `KafkaConsumer#commitSync()` 。该方法会提交 `KafkaConsumer#poll()` 返回的最新位移。从名字上来看，这是一个同步方法，即该方法会一直等待，直到位移成功提交之后才会返回。如果提交过程中出现异常，该方法会将异常信息抛出。\n\n下面这段代码展示了 commitSync() 的使用方法：\n\n```java\nwhile (true) {\n        ConsumerRecords records =consumer.poll(Duration.ofSeconds(1));\n        process(records); // 处理消息\n        try {\n            consumer.commitSync();\n        } catch (CommitFailedException e) {\n            handle(e); // 处理提交失败异常\n        }\n}\n```\n\n自动提交时，Kafka 会保证再开始调用 poll 方法时候，提交上次 poll 方法返回的所有消息。从顺序上来说，poll 方法的逻辑是先提交上一批消息的位移，然后在处理下一批消息，因此，自动提交能保证不会出消费丢失的情况。但是自动提交位移的问题在于，**可能出现重复消费。**\n\n手动提交的好处在于更加灵活，可以完全把控位移提交的时机和频率。但是他也有一个缺陷，就是在调用 `commitSync()` 时候会处于阻塞状态，直到远端 Broker 返回提交结果，这个状态才能结束。\n\n这时候，手动提交的另一个方法就出现了 `KafkaConsumer#commitAsync()`。从名字上看，这是个异步操作。调用 `commitAsync()` 方法之后，它会立即返回，不会阻塞，因此不影响 Consumer 应用的 TPS（吞吐量）。由于它是异步的，Kafka 提供了一个回调函数（callback），供开发者实现提交之后的逻辑，比如记录日志或处理异常。\n\n下面这段代码展示了调用 commintAsync() 方法：\n\n```java\nwhile (true) {\n            ConsumerRecords records = consumer.poll(Duration.ofSeconds(1));\n            process(records); // 处理消息\n            consumer.commitAsync((offsets, exception) -> {\n\t\t\t\t if (exception != null)\n\t\t\t\t\t handle(exception);\n\t\t\t});\n}\n```\n\ncommitAsync 的问题在于，出了问题时它不会重试。\n\n显然，如果手动提交，我们需要将 commitSync 和 commitAsync 组合使用才能达到最理想的效果：\n\t1.我们可以利用 commitSync 的自动动重试来规避那些瞬时错误，比如网络的瞬时都懂，Broker 端的 GC 问题，因为这些问题是短暂的，自动重试通常都会成功。\n\t2.我们不希望程序总是处于阻塞状态，影响 TPS。\n\n我们来看一下下面这段代码，它展示的是如何将两个 API 方法结合使用进行手动提交。\n\n```java\ntry {\n    while(true) {\n        ConsumerRecords records = consumer.poll(Duration.ofSeconds(1));\n        process(records); // 处理消息\n        commitAysnc(); // 使用异步提交规避阻塞\n    }\n} catch(Exception e) {\n        handle(e); // 处理异常\n} finally {\n      try {\n        consumer.commitSync(); // 最后一次提交使用同步阻塞式提交\n} finally {\n \t\tconsumer.close();\n}\n}\n```\n\n试想这样一个场景：poll 方法返回的不是 500 条消息，而是 5000 条。\n\n那么，你肯定不想把这 5000 条消息处理完之后再提交位移，因为一旦中间出差错，之前处理的全部都要重来一遍。那么我们可以每处理完 100 条消息就提交一次位移，这样避免大批量的消息重新消费。\n\nKafka Consumer API 为手动提交提供了这样的方法：`commitSync(Map)` 和 `commitAsync(Map)`。它们的参数是一个 Map 对象，键就是 TopicPartition，即消费的分区，而值是一个 OffsetAndMetadata 对象，保存主要是位移数据。\n\n以 commitAsync 为例，展示一段代码。实际上，commitSync 的调用方法和它一模一样的。\n\n```java\nprivate Map offsets = new HashMap<>();\nint count = 0;\n……\nwhile (true) {\n    ConsumerRecords records = consumer.poll(Duration.ofSeconds(1));\n        for (ConsumerRecord record: records) {\n            process(record);  // 处理消息\n            offsets.put(new TopicPartition(record.topic(), record.partition()),new OffsetAndMetadata(record.offset() + 1)；\n            if（count % 100 == 0）\n                consumer.commitAsync(offsets, null); // 回调处理逻辑是null\n                count++;\n }\n}\n```\n\n与调用无参的 commitAsync 不同，这里调用了带 Map 对象参数的 commitAsync 进行细粒度的位移提交。\n\n# 八、重平衡\n\n重平衡 Rebalance 本质上是一种协议，规定了一个 Consumer Group 如何分配订阅 Topic 的每一个分区。Kafka 在为 Consumer Group 内的 Consumer 分配分区的过程，就是 Rebalance。\n\nRebalance 触发条件有三个：\n\n- 组内成员发生变化，即有新的 Consumer 实例加入组或者离开祖，或者因崩溃而退出组。\n\n- 订阅主题数发生变化，Consumer Group 可以通过正则表达式方式订阅主题，比如 `consumer.subscribe(Pattern.compile(\"t.*c\"))` 就表明 Group 订阅所有以字母 t 开头、字母 c 结尾的主题，所以在 Consumer Group 运行过程中，如果创建了满足要求的主题，就会发生 Rebalance。\n\n- 订阅主题的分区发生变化，Kafka 当前只能允许增加一个主题的分区数，当主题的分区数发生变化，就会触发该主题下所有 Group 的 Rebalance。\n\n### 「分配策略」\n\n当前Kafka默认提供了3种分配策略，每种策略都有一定的优势和劣势，社区会不断地完善这些策略，保证提供最公平的分配策略，即每个Consumer实例都能够得到较为平均的分区数。\n\n\n\n### 「Coordinator 会在什么情况下确认 Consumer 实例挂掉了从而要退组？」\n\n在 Consumer Group 完成 Rebalance 之后，每个 Consumer 实例都会定期的想 Coordinator 发送心跳请求，表明它还活着。如果某个 Consumer 不能及时的发送心跳请求，娜美 Coordinator 就会认为它已经死了，从而将其从 Group 中移除，然后开启新一轮的 Rebalance。\n\nConsumer 端设置参数里面有个：`session.timeout.ms`。默认为 10 秒，即如果 Coordinator 在 10 秒内没有收到 Group 的某个 Consumer 的心跳请求，则认为它已经挂了。除了这个参数，还有个允许开发者控制发送心跳的频率的参数，就是 `heartbeat.interval.ms`。这个参数设置越小，Consumer 发送心跳请求的频率越高。当然，请求频率越高，消耗的带宽资源也就越高。\n\n除此之外，Consumer 端还有个参数，用于控制 Consumer 实际消费能力对对 Rebalance 的影响，即：`max.pool.interval.ms` 参数。它限定了 Consumer 端应用程序两次调用 poll 方法的最大时间间隔。默认值为 5 分钟，表示如果 Consumer 在 5 分钟内没有消费完 poll 方法返回的消息，那么 Consumer 会主动发起离开 Group 的请求，Coordinator 则会开启新的 Rebalance。\n\n### 「如何设置避免 Rebalance」\n\n1. 如果是因为未能及时发送心跳请求，导致 Consumer 被踢出 Group ，引发的 Rebalance。则可以设置 `session.timeout.ms` 和 `heartbeat.interval.ms` 的值。\n\n\t- 设置 `session.timeout.ms` = 6s。\n\n\t- 设置 `heartbeat.interval.ms` = 2s。\n\n\t- 要保证 Consumer 实例在被判定为 dead 之前，能够发送 3 条心跳请求，即 `session.timeout.ms >= 3 * heartbeat.interval.ms`。\n\n将 `session.timeout.ms` 设置为 6s 主要是为了让 Coordinator 能更快定位已经挂掉的 Consumer。\n\n2. 如果是因为 Consumer 消费时间过长导致的 Rebalance。在开发过程中，为业务逻辑处理留足充足的时间，这样 Consumer 就不会因为处理这些消息太长而引起 Rebalance 了。\n\n# 九、ConsumerOffsets\n\n`_consumer_offsets` 是一个 Kafka 的普通主题，它主要是保存 Kafka Consumer 的位移信息。当 Kafka 中的第一个 Consumer 启动时候，就会创建该主题。其默认分区数是 50，副本数是 3。`_consumer_offsets` 主题是一个普通的 Kafka 主题，开发者可以手动的创建、修改甚至删除它。但是它的消息格式是 Kafka 自己定义的，不能修改。开发者只能按照规定传入消息，否则内部不能成功解析，就会导致 Broker 崩溃。\n\n`_consumer_offsets` 有 3 中消息格式：\n\n- 用于保存 Consumer Group 信息的消息。\n\n- 用于删除 Group 过期位移甚至删除 Group 的消息。\n\n- 保存了位移值。\n\n前面已经提到过，Kafka 的提交方式有两种：自动提交和手动提交。\n\n手动提交：比较灵活可控，通过调用 `commitSync()` 或者 `commitAsync()` 等 Kafka Consumer 的 API，Kafka 会向 `_consumer_offsets` 主题中写入相应的消息。\n\n自动提交：显著优点就是省事，不用操心位移提交的事情，就能保证消息不会丢失。但是自动提交位移的有个问题，只要 Consumer 一直启动着，它就会无限期的向位移主题写入消息。\n\n> 假设Consumer当前消费到了某个主题的最新一条消息，位移是100，之后该主题没有任何新消息产生，故Consumer无消息可消费了，所以位移永远保持在100。由于是自动提交位移，位移主题中会不停地写入位移=100 的消息。显然 Kafka 只需要保留这类消息中的最新一条就可以了，之前的消息都是可以删除的。\n\n\n\n显然，Kafka 必须要有针对位移主题消息特点的消息删除策略，否则这种消息越多，最重撑爆整个磁盘\n\n### 「Compact 策略」\n\nKafka 通过 Compact 策略来删除 `_consumer_offsets` 主题中的过期消息，避免该主题无限膨胀。Compact 的过程就是扫描日志的所有消息，剔除过期消息，把剩下消息整理在一起。\n\nKafka 提供了专门的后台线程定期的巡检待 Compact 的主题，看看是否存在猫族条件的可删除数据。这个后台线程叫做 **Log cleaner**。如果生产环境中出现了位移主题无限膨胀占用过多磁盘空间问题，请检查一下 Log cleaner 线程是否挂掉了。\n\n# 十、副本机制\n\n根据 Kafka 副本机制定义，同一个分区下面的所有副本保存有相同的消息队列，这些副本是分布在不同 Broker 中，以确保某个 Broker 宕机后其他副本可以正常使用。\n\n在 Kafka 中，副本分为领导者副本和追随者副本。其中追随者副本不参与什么读写请求操作。追随者副本只异步拉去领导者副本，在领导者副本所在的 Broker 宕机的时候，重新从追随者副本中推选出一个领导者副本。\n\n追随者副本唯一的工作就是，不断的从领导者副本中拉取消息，然后写入自己的提交日志中。\n\n![副本机制](img/ff0fd5af97f5f5ad3a954f3ffa4076d0_MD5.png)\n\n# 十一、ISR 机制\n\nin-sync Replicas，也就是所谓的 ISR 副本集合。这个集合是动态的，而非静态不变。\n\nISR 中的副本一定是好 Leader 副本同步的，相反不在 ISR 中的副本一定是和 Leader 副本不同步的。\n\nLeader 副本一定在 ISR 中，Follower 副本不一定在 ISR 中。在 Broker 端有个配置参数 `replica.lag.time.max.ms`，这个参数的含义是 Follower 副本落后 Leader 副本的时间不连续超过 10 秒，那么 Kafka 认为 Follower 副本和 Leader 是同步的，即使此时 Follower 副本中保存的消息明显少于 Leader 副本中的消息。\n\n# 十二、Unclean 领导者选举\n\nKafka 将所有不在 ISR 中的副本都认为是非同步副本。在领导者选举的时候，如果选举这种副本的过程称为 Unclean 领导者选举。在 Broker 端中参数 `unclean.leader.election.enable` 控制是否开启 Unclean 领导者选举。\n\nUnclean 领导者选举有利有弊。优点在于：因为一个分区中 Leader 副本负责读写请求，如果 Leader 副本挂了，整个分区就改了。开启 Unclean 领导者选取，会使 Leader 副本一直存在，不至于对外停止服务，提高了高可用；缺点在于：因为从 ISR 中选举 Leader 副本，就会出现数据不同步情况，就会导致数据丢失。\n\n# 十三、副本选举\n\nKafka 在选取 Leader 副本时候，考虑到负载均衡的平衡性，会将不同的分区的 Leader 副本分配到不同的 Broker 中，这样既能避免 Broker 宕机导致多个分区不可用，也能平衡 Broker 的负载。\n\nKafka 引入了优先副本的概念，优先副本的意思是，在分区的所有 AR 集合列表中的第一个副本，理想状态下就是该分区的 Leader 副本。\n\n例如kafka集群由3台broker组成，创建了一个名为 `topic-partitions` 的topic，设置partition为3，副本数为3，partition0中AR列表为 `[1,2,0]`，那么分区0的优先副本为1\n\n![副本选举](img/882565aff441558b043b911c7c240f29_MD5.png)\n\n当分区leader节点发生故障时，其中的一个follower节点就会选举为新的leader节点。当原来leader的节点恢复之后，它只能成为一个follower节点，此时就导致了集群负载不均衡。比如分区1的leader节点broker2崩溃了，此时选举了在broker1上的分区1follower节点作为新的leader节点。当broker2重新恢复时，此时的kafka集群状态如下：\n\n![副本选举](img/d9e50eff06b436f7621152f2739a05c5_MD5.png)\n\n可以看到，此时broker1上负载更大，而broker2上没有负载。\n\n**「为了解决上述负载不均衡的情况，kafka支持了优先副本选举，优先副本指的是一个分区所在的AR集合的第一个副本」**。\n\n比如上面的分区1，它的AR集合是`[2,0,1]`，表示分区1的优先副本就是在broker2上。\n\n理想情况下，优先副本应该就是leader副本，kafka保证了优先副本的均衡分布，而这与broker节点宕机与否没有关系。\n\n**「优先副本选举就是对分区leader副本进行选举的时候，尽可能让优先副本成为leader副本」**，针对上述的情况，只要再触发一次优先副本选举就能保证分区负载均衡。\n\nkafka支持自动优先副本选举功能，默认每5分钟触发一次优先副本选举操作。\n\n# 十四、网络通信模型\n\n![网络通信模型](img/93681a72e52523561d8f052cb74d6da0_MD5.png)\n\nBroker 中有个`Acceptor(mainReactor)`监听新连接的到来，与新连接建连之后轮询选择一个`Processor(subReactor)`管理这个连接。\n\n而`Processor`会监听其管理的连接，当事件到达之后，读取封装成`Request`，并将`Request`放入共享请求队列中。\n\n然后IO线程池不断的从该队列中取出请求，执行真正的处理。处理完之后将响应发送到对应的`Processor`的响应队列中，然后由`Processor`将`Response`返还给客户端。\n\n每个`listener`只有一个`Acceptor线程`，因为它只是作为新连接建连再分发，没有过多的逻辑，很轻量。\n\n`Processor` 在Kafka中称之为网络线程，默认网络线程池有3个线程，对应的参数是`num.network.threads`，并且可以根据实际的业务动态增减。\n\n还有个 IO 线程池，即`KafkaRequestHandlerPool`，执行真正的处理，对应的参数是`num.io.threads`，默认值是 8。\n\nIO线程处理完之后会将`Response`放入对应的`Processor`中，由`Processor`将响应返还给客户端。\n\n可以看到网络线程和IO线程之间利用的经典的生产者 - 消费者模式，不论是用于处理Request的共享请求队列，还是IO处理完返回的Response。\n\n# 十五、幂等性\n\n## **「幂等性Producer」**\n\n在 Kafka 中，Producer 默认不是幂等性的，但是我们可以创建幂等性 Producer。`enable.idempotence` 设置为 True，即可保证 Producer 自动升级成幂等性 Producer，其他所有的代码逻辑都不需要更改。配置后，Kafka 自动做消息的去重操作。\n\n其实，底层原理非常简单，就是经典的以空间换时间的做法，Broker 多保存一些字段，当 Producer 发送消息请求的时候，Broker 能够判断消息是否重复，进而再丢弃掉重复消息。\n\n## 「幂等性 Producer 的作用范围」\n\n- 幂等性只能保证单个分区上的幂等性，无法实现多分区幂等性。\n\n- 幂等性针对单个会话的幂等性，不会实现跨会话的幂等性。\n\n\n\n> 这里的会话，可以理解成 Producer 进程的一次运行，当重启了 Producer 进程之后，这种幂等性就丧失了。\n\n# 十六、事务\n\nKafka 自从 0.11 版本就开始支持事务，目前主要是在 read committed 隔离级别上做事务。它能保证多条消息原子性地写入到目标分区，同时也能保证Consumer 只能看到事务成功提交的消息。\n\n## 「事务型 Producer」\n\n事物型 Producer 能够保证将消息原子性的写入到多个分区中。这批消息要么全部成功，要么全部失败，另外，事务型 Producer 也不怕进程的重启。当 Producer 重启之后，Kafka 仍能保证它们发送消息的精确一次处理。\n\n设置事务型 Producer 的方式也比较简单，满足两个设置即可：\n\n- 和幂等性 Producer 一样，开启 `enable.idempotence = true`。\n\n- 设置 Producer 端参数 `transactional.id`，最好设置一个有意义的名字。\n\n此外，还需要在 Producer 代码中做一些调整，如这段代码所示：\n\n```java\nproducer.initTransactions();  \ntry {  \n            producer.beginTransaction();  \n            producer.send(record1);  \n            producer.send(record2);  \n            producer.commitTransaction();  \n} catch (KafkaException e) {  \n            producer.abortTransaction();  \n}\n```\n\n和普通Producer代码相比，事务型Producer的显著特点是调用了一些事务API，如initTransaction、beginTransaction、commitTransaction和abortTransaction，它们分别对应事务的初始化、事务开始、事务提交以及事务终止。\n\n实际上即使写入失败，Kafka也会把它们写入到底层的日志中，也就是说Consumer还是会看到这些消息。\n\n有一个 `isolation.level` 参数，这个参数有两个取值：\n\n1. `read_uncommitted`：这是默认值，表明Consumer能够读取到Kafka写入的任何消息，不论事务型Producer提交事务还是终止事务，其写入的消息都可以读取，如果你用了事务型Producer，那么对应的Consumer就不要使用这个值。\n\n    \n\n2. `read_committed`：表明Consumer只会读取事务型Producer成功提交事务写入的消息，它也能看到非事务型Producer写入的所有消息\n\n# 十七、拦截器\n\n**Kafka 拦截器分为生产者拦截器和消费者拦截器。** 生产者拦截器允许你在发送消息前以及消息提交成功之后植入拦截器逻辑。而消费者拦截器支持消费消息前以及提交位移后编写特定逻辑。可以将一组懒啊节气串联成一个大的拦截器，Kafka 会按照顺序依次执行拦截器逻辑。\n\n当前 Kafka 拦截器是通过参数配置完成，生产者和消费者两端都有个相同的参数 `interceptor.classes`，它指定的是一组类的列表，每个类就是特定逻辑的拦截器实现类。\n\n```java\nProperties props = new Properties();   \nList interceptors = new ArrayList<>();   \ninterceptors.add(\"com.yourcompany.kafkaproject.interceptors.AddTimestampInterceptor\"); // 拦截器1   \ninterceptors.add(\"com.yourcompany.kafkaproject.interceptors.UpdateCounterInterceptor\"); // 拦截器2   \nprops.put(ProducerConfig.INTERCEPTOR_CLASSES_CONFIG, interceptors);\n```\n\n怎么编写 AddTimeStampInterceptor 和 UpdateCounterInterceptor 类呢？\n\n这两个类以及所有 Producer 端拦截器实现类都要继承 `org.apache.kafka.clients.producer.ProducerInterceptor` 接口。\n\n该接口是 Kafka 提供的，里面有两个核心方法：\n\n1. onSend：该方法在消息发送前被调用。\n\n2. onAcknowledgement：该方法在消息成功提交或者提交失败之后被调用。onAcknowledgement 的调用要早于 callback 的调用。值得注意的是，这个方法和 onSend 方法不在同一个线程中调用，因此如果在这两个方法中调用了共享可变变量，一定要注意线程安全问题。\n\n同理，消费者拦截器也是同样的方法，都要继承 `org.apache.kafka.clients.consumer.ConsumerInterceptor` 接口，这里也有两个核心方法。\n\n1. onConsuume：该方法在消息返回给 Consumer 程序之前调用。\n\n2. onCommit：Consumer 在提交位移之后调用该方法。通常做法是在该方法中做一些记账的动作，例如打印日志等。\n\n# 十八、控制器（Controller）\n\n**控制器组件（controller），主要是用于在 Apache Zookeeper 的帮助下管理和协调整个 Kafka 集群。**\n\n集群中任意一台 Broker 都可以成为控制器角色。在 Kafka 集群启动的时候，第一个在 Zookeeper 中创建/controller 节点的 Broker 会被指定为控制器。\n\n控制器主要的功能如下：\n\n1. **主题管理（创建，删除，增加分区）**\n\n控制器帮我们完成对 Kafka 主题的创建，删除以及分区增加的操作。\n\n2. **分区重分配**\n\n3. **Preferred 领导者选举**\n\nPreferred 领导者选举主要是 Kafka 为了避免部分 Broker 负载过重而提供的一种换 Leader 的方案。\n\n4. **集群成员管理（新增 Broker、Broker 主动关闭、Broker 宕机）**\n\n在 Zookeeper 对 Kafka 协助管理工程中，**「Watch 机制」** 和 **「临时节点」** 是两个重要的机制。 \n\nBroker 的创建时候，Zookeeper 会在 Zookeeper 的 /broker/ids 下创建专属的 znode 节点，这个节点就是临时节点。一旦节点创建完成，ZooKeeper 就会通过 Watch 机制将消息通知推送给控制器，只要，控制器就能自动感知这个变化，进而开启后续的新增 Broker 作业。\n\n当Broker宕机或主动关闭后，该Broker与ZooKeeper的会话结束，这个znode会被自动删除。\n\n同理，ZooKeeper的Watch机制将这一变更推送给控制器，这样控制器就能知道有Broker关闭或宕机了，从而进行善后。\n\n5. **数据服务**\n\n控制器上保存了最全的集群元数据信息，其他所有Broker会定期接收控制器发来的元数据更新请求，从而更新其内存中的缓存数据。\n\n## 「控制器故障转移（Failover）」\n\n**「故障转移指的是，当运行中的控制器突然宕机或意外终止时，Kafka能够快速地感知到，并立即启用备用控制器来代替之前失败的控制器」**。这个过程就被称为Failover，该过程是自动完成的，无需你手动干预。\n\n![控制器故障转移](img/5711d6da84f2000a181c356e080deec4_MD5.png)\n\n最开始时，Broker 0是控制器。当Broker 0宕机后，ZooKeeper通过Watch机制感知到并删除了`/controller`临时节点。\n\n之后，所有存活的Broker开始竞选新的控制器身份。Broker 3最终赢得了选举，成功地在ZooKeeper上重建了 `/controller` 节点。之后，Broker 3会从ZooKeeper中读取集群元数据信息，并初始化到自己的缓存中。\n\n至此，控制器的Failover完成，可以行使正常的工作职责了。\n\n# 二十、日志存储\n\nKafka中的消息是以主题为基本单位进行归类的，每个主题在逻辑上相互独立。\n\n每个主题又可以分为一个或多个分区，在不考虑副本的情况下，一个分区会对应一个日志。\n\n但设计者考虑到随着时间推移，日志文件会不断扩大，因此为了防止Log过大，设计者引入了日志分段（LogSegment）的概念，将Log切分为多个LogSegment，便于后续的消息维护和清理工作。\n\n下图描绘了主题、分区、副本、Log、LogSegment五者之间的关系。\n\n![关系图解](img/4cc119f98ed02df15c264d1cf428d32b_MD5.png)\n\n**「LogSegment」**\n\n在Kafka中，每个Log对象又可以划分为多个LogSegment文件，每个LogSegment文件包括一个日志数据文件和两个索引文件（偏移量索引文件和消息时间戳索引文件）。\n\n其中，每个LogSegment中的日志数据文件大小均相等（该日志数据文件的大小可以通过在Kafka Broker的 `config/server.properties` 配置文件的中的**「log.segment.bytes」**进行设置，默认为1G大小（1073741824字节），在顺序写入消息时如果超出该设定的阈值，将会创建一组新的日志数据和索引文件）。\n\n![日志内部结构](img/5c376d6d6186292ebc461285ce0ac879_MD5.png)\n\n# 常用参数\n\n**「broker端配置」**\n\n- `broker.id`\n\n每个 kafka broker 都有一个唯一的标识来表示，这个唯一的标识符即是 `broker.id`，它的默认值是 0。\n\n这个值在 kafka 集群中必须是唯一的，这个值可以任意设定，\n\n- `port`\n\n如果使用配置样本来启动 kafka，它会监听 9092 端口，修改 port 配置参数可以把它设置成任意的端口。\n\n要注意，如果使用 1024 以下的端口，需要使用 root 权限启动 kakfa。\n\n- `zookeeper.connect`\n\n用于保存 broker 元数据的 Zookeeper 地址是通过 `zookeeper.connect` 来指定的。\n\n比如可以这么指定 `localhost:2181` 表示这个 Zookeeper 是运行在本地 2181 端口上的。\n\n我们也可以通过 比如我们可以通过 `zk1:2181,zk2:2181,zk3:2181` 来指定 `zookeeper.connect` 的多个参数值。\n\n该配置参数是用冒号分割的一组 `hostname:port/path` 列表，其含义如下\n\n- hostname 是 Zookeeper 服务器的机器名或者 ip 地址。\n\n- port 是 Zookeeper 客户端的端口号\n\n- /path 是可选择的 Zookeeper 路径，Kafka 路径是使用了 `chroot` 环境，如果不指定默认使用跟路径。\n\n> ❝\n> 如果你有两套 Kafka 集群，假设分别叫它们 kafka1 和 kafka2，那么两套集群的`zookeeper.connect`参数可以这样指定：`zk1:2181,zk2:2181,zk3:2181/kafka1`和`zk1:2181,zk2:2181,zk3:2181/kafka2`\n> ❞\n\n- `log.dirs`\n\nKafka 把所有的消息都保存到磁盘上，存放这些日志片段的目录是通过 `log.dirs` 来制定的，它是用一组逗号来分割的本地系统路径，`log.dirs` 是没有默认值的，**「你必须手动指定他的默认值」**。\n\n其实还有一个参数是 `log.dir`，这个配置是没有 `s` 的，默认情况下只用配置 `log.dirs` 就好了，比如你可以通过 `/home/kafka1,/home/kafka2,/home/kafka3` 这样来配置这个参数的值。\n\n- `auto.create.topics.enable`\n\n默认情况下，kafka 会自动创建主题\n\n`auto.create.topics.enable`参数建议最好设置成 false，即不允许自动创建 Topic。\n\n**「主题相关配置」**\n\n- `num.partitions`\n\nnum.partitions 参数指定了新创建的主题需要包含多少个分区，该参数的默认值是 1。\n\n- `default.replication.factor`\n\n这个参数比较简单，它表示 kafka保存消息的副本数。\n\n- `log.retention.ms`\n\nKafka 常根据时间来决定数据可以保留多久。\n\n默认使用`log.retention.hours`参数来配置时间，默认是 168 个小时，也就是一周。\n\n除此之外，还有两个参数`log.retention.minutes` 和`log.retentiion.ms` 。\n\n这三个参数作用是一样的，都是决定消息多久以后被删除，推荐使用`log.retention.ms`。\n\n- `message.max.bytes`\n\nbroker 通过设置 `message.max.bytes` 参数来限制单个消息的大小，默认是 1000 000， 也就是 1MB，如果生产者尝试发送的消息超过这个大小，不仅消息不会被接收，还会收到 broker 返回的错误消息。\n\n- `retention.ms`\n\n规定了该主题消息被保存的时常，默认是7天，即该主题只能保存7天的消息，一旦设置了这个值，它会覆盖掉 Broker 端的全局参数值。\n\n#  消息丢失问题\n\n## **「生产者程序丢失数据」**\n\n目前Kafka Producer是异步发送消息的，也就是说如果你调用的是`producer.send(msg)`这个API，那么它通常会立即返回，但此时你不能认为消息发送已成功完成。\n\n**如果用这个方式，可能会有哪些因素导致消息没有发送成功呢？**\n\n其实原因有很多：\n\n1. 例如网络抖动，导致消息压根就没有发送到Broker端；\n\n如果是网络抖动导致的失败，可以通过 Producer 中的参数 `retries` (重试次数)设置比较合理的值来解决，一般来说为 3。同时，建议还要设置重试间隔 `retry.backoff.ms` 来避免 3 次重试间隔太短导致多次失败。\n\n2. 或者消息本身不合格导致Broker拒绝接收（比如消息太大了，超过了Broker的承受能力）等。\n\n实际上，解决此问题的方法非常简单：Producer永远要使用带有回调通知的发送API，也就是说不要使用 `producer.send(msg)`，而要使用 `producer.send(msg, callback)`。在 SpringBoot 中可以用类似的方式来处理：\n\n```java\nListenableFuture<SendResult<String, Object>> future = kafkaTemplate.send(smsBusiPrediction, msg);  \nfuture.addCallback(new ListenableFutureCallback<SendResult<String, Object>>() {  \n   @Override  \n   public void onSuccess(SendResult<String, Object> result) {  \n      log.info(\"=====向kafka推送信息成功=====\");  \n   }  \n   @Override  \n   public void onFailure(Throwable ex) {  \n      log.info(\"=====向kafka推送信息失败！！=====\",ex);  \n   }   \n});\n```\n\n它能准确地告诉你消息是否真的提交成功了。一旦出现消息提交失败的情况，你就可以有针对性地进行处理。\n\n## **「消费者程序丢失数据」**\n\nConsumer端丢失数据主要体现在Consumer端要消费的消息不见了。\n\n下面这张图它清晰地展示了Consumer端的位移数据。\n\n![Consumer端的位移数据](img/adc9951c2edb1fba60deea2d87fb2d44_MD5.png)\n\n比如对于Consumer A而言，它当前的位移值就是9；Consumer B的位移值是11。Consumer程序从Kafka获取到消息后开启了多个线程异步处理消息，而Consumer程序自动地向前更新位移。\n\n假如其中某个线程运行失败了，它负责的消息没有被成功处理，但位移已经被更新了，因此这条消息对于Consumer而言实际上是丢失了。这里的关键在于Consumer自动提交位移。这个问题的解决方案也很简单：**「如果是多线程异步处理消费消息，Consumer程序不要开启自动提交位移，而是要应用程序手动提交位移」**。\n\n## **「Kafka 内部出现消息丢失」**\n\n试想一种情况：假如 leader 副本所在的 broker 突然挂掉，那么就要从 follower 副本重新选出一个 leader ，但是 leader 的数据还有一些没有被 follower 副本的同步的话，就会造成消息丢失。\n\n**设置 `acks = all`**\n\n解决办法就是我们设置 `acks = all`。`acks` 是 Kafka 生产者(Producer) 很重要的一个参数。\n\nacks 的默认值即为 1，代表我们的消息被 leader 副本接收之后就算被成功发送。当我们配置 **acks = all** 表示只有所有 ISR 列表的副本全部收到消息时，生产者才会接收到来自服务器的响应. 这种模式是最高级别的，也是最安全的，可以确保不止一个 Broker 接收到了消息. 该模式的延迟会很高.\n\n**设置 `replication.factor >= 3`**\n\n为了保证 leader 副本能有 follower 副本能同步消息，我们一般会为 topic 设置 `replication.factor >= 3`。这样就可以保证每个 分区(partition) 至少有 3 个副本。虽然造成了数据冗余，但是带来了数据的安全性。\n\n**设置 `min.insync.replicas > 1`**\n\n一般情况下我们还需要设置 **`min.insync.replicas> 1`** ，这样配置代表消息至少要被写入到 2 个副本才算是被成功发送。**min.insync.replicas** 的默认值为 1 ，在实际生产中应尽量避免默认值 1。\n\n但是，为了保证整个 Kafka 服务的高可用性，你需要确保 **`replication.factor > min.insync.replicas`** 。为什么呢？设想一下假如两者相等的话，只要是有一个副本挂掉，整个分区就无法正常工作了。这明显违反高可用性！一般推荐设置成 **`replication.factor = min.insync.replicas + 1`**。\n\n**设置 `unclean.leader.election.enable = false`**\n\n\n\n> **Kafka 0.11.0.0 版本开始 unclean.leader.election.enable 参数的默认值由原来的 true 改为 false**\n\n\n\n我们最开始也说了我们发送的消息会被发送到 leader 副本，然后 follower 副本才能从 leader 副本中拉取消息进行同步。多个 follower 副本之间的消息同步情况不一样，当我们配置了 **`unclean.leader.election.enable = false`** 的话，当 leader 副本发生故障时就不会从 follower 副本中和 leader 同步程度达不到要求的副本中选择出 leader ，这样降低了消息丢失的可能性。\n\n## 「最佳实践」\n\n总结Kafka 避免消息丢失的配置：\n\n1. 在 Producer 端：\n\n\t- 不要使用 `producer.send(msg)`，而要使用 `producer.send(msg, callback)`，一定要使用带有回调通知的 send 方法。\n\n\t- 设置 `retries`  为一个较大的值。这里的`retries`同样是Producer的参数，对应前面提到的Producer自动重试，当出现网络的瞬时抖动时，消息发送可能会失败，此时配置了 `retries > 0` 的 Producer 能够自动重试消息发送，避免消息丢失。\n\n\t- 设置 `acks = all`，acks 是 Producer 的一个参数，代表了你对已提交消息的定义，如果设置成 all，则表明所有副本 Broker 都要接收到消息，该消息才算是已提交。\n\n2. 在 Consumer 端：\n\n\t - 确保消息消费完成再提交，Consumer端有个参数 `enable.auto.commit`，最好把它设置成 false，并采用手动提交位移的方式。\n\n3. 在 Kafka 内部：\n\n\t- 设置 `unclean.leader.election.enable = false`，这是 Broker 端的参数，它控制的是哪些 Broker 有资格竞选分区的 Leader，如果一个 Broker 落后原先的 Leader 太多，那么它一旦成为新的 Leader，必然会造成消息的丢失，故一般都要将该参数设置成 false，即不允许这种情况的发生。\n\n\t- 设置 `replication.factor >= 3`，这也是 Broker 端的参数，将消息多保存几份，目前防止消息丢失的主要机制就是冗余。\n\n\t- 设置 `min.insync.replicas > 1`，这依然是 Broker 端参数，控制的是消息至少要被写入到多少个副本才算是已提交，设置成大于 1 可以提升消息持久性，在实际环境中千万不要使用默认值 1。\n\n\t- 确保 `replication.factor > min.insync.replicas`，如果两者相等，那么只要有一个副本挂机，整个分区就无法正常工作了，我们不仅要改善消息的持久性，防止数据丢失，还要在不降低可用性的基础上完成，推荐设置成 `replication.factor = min.insync.replicas + 1`。\n\n\n\n# 重复消费问题\n\n**「消费重复的场景」**\n\n在 `enable.auto.commit` 默认值true情况下，出现重复消费的场景有以下几种：\n\n\n\n> ❝\n> consumer 在消费过程中，应用进程被强制kill掉或发生异常退出。\n> ❞\n\n\n\n例如在一次poll 500条消息后，消费到200条时，进程被强制kill消费到offset未提交，或出现异常退出导致消费到offset未提交。\n\n下次重启时，依然会重新拉取500消息，造成之前消费到200条消息重复消费了两次。\n\n解决方案：在发生异常时正确处理未提交的offset\n\n**「消费者消费时间过长」**\n\n`max.poll.interval.ms`参数定义了两次poll的最大间隔，它的默认值是 5 分钟，表示你的 Consumer 程序如果在 5 分钟之内无法消费完 poll 方法返回的消息，那么 Consumer 会主动发起离开组的请求，Coordinator 也会开启新一轮 Rebalance。\n\n举例：单次拉取11条消息，每条消息耗时30s，11条消息耗时5分钟30秒，由于`max.poll.interval.ms`  默认值5分钟，所以消费者无法在5分钟内消费完，consumer会离开组，导致rebalance。\n\n在消费完11条消息后，consumer会重新连接broker，再次rebalance，因为上次消费的offset未提交，再次拉取的消息是之前消费过的消息，造成重复消费。\n\n**「解决方案：」**\n\n1、提高消费能力，提高单条消息的处理速度；根据实际场景可讲`max.poll.interval.ms`值设置大一点，避免不必要的rebalance；可适当减小`max.poll.records`的值，默认值是500，可根据实际消息速率适当调小。\n\n2、生成消息时，可加入唯一标识符如消息id，在消费端，保存最近的1000条消息id存入到redis或mysql中，消费的消息时通过前置去重。\n\n# 消息顺序问题\n\n我们都知道 `kafka` 的 `topic` 是无序的，但是一个 `topic` 包含多个 `partition`，每个 `partition` 内部是有序的（分区内采用尾插法）\n\n![消息消费顺序](img/466a6f44f4b183a6bae184c90378b300_MD5.png)\n\n**「乱序场景1」**\n\n因为一个topic可以有多个partition，kafka只能保证partition内部有序\n\n**「解决方案」**\n\n1、可以设置topic，有且只有一个partition，**不推荐，这样就违背了 Kafka 的设计初衷，即多分区，多副本的概念。**\n\n2、**（推荐）** 根据业务需要，需要顺序的指定为同一个partition，在 Broker 提交的时候，规定 topic，partition，key，data 四个参数统一。\n\n**「乱序场景2」**\n\n对于同一业务进入了同一个消费者组之后，用了多线程来处理消息，会导致消息的乱序\n\n**「解决方案」**\n\n消费者内部根据线程数量创建等量的内存队列，对于需要顺序的一系列业务数据，根据key或者业务数据，放到同一个内存队列中，然后线程从对应的内存队列中取出并操作\n\n![解决方案](img/bb94c4025a04733be2eb858d968eaffd_MD5.png)\n\n**「通过设置相同key来保证消息有序性，会有一点缺陷：」**\n\n例如消息发送设置了重试机制，并且异步发送，消息A和B设置相同的key，业务上A先发，B后发，由于网络或者其他原因A发送失败，B发送成功；A由于发送失败就会重试且重试成功，这时候消息顺序B在前A在后，与业务发送顺序不一致，如果需要解决这个问题，需要设置参数 `max.in.flight.requests.per.connection=1`，其含义是限制客户端在单个连接上能够发送的未响应请求的个数，设置此值是1表示kafka broker在响应请求之前client不能再向同一个broker发送请求，这个参数默认值是5\n\n# 高性能原因\n\n## **「顺序读写」**\n\nkafka的消息是不断追加到文件中的，这个特性使`kafka`可以充分利用磁盘的顺序读写性能\n\n顺序读写不需要硬盘磁头的寻道时间，只需很少的扇区旋转时间，所以速度远快于随机读写\n\nKafka 可以配置异步刷盘，不开启同步刷盘，异步刷盘不需要等写入磁盘后返回消息投递的 ACK，所以它提高了消息发送的吞吐量，降低了请求的延时\n\n## **「零拷贝」**\n\n传统的 IO 流程，需要先把数据拷贝到内核缓冲区，再从内核缓冲拷贝到用户空间，应用程序处理完成以后，再拷贝回内核缓冲区\n\n这个过程中发生了多次数据拷贝\n\n为了减少不必要的拷贝，`Kafka` 依赖 Linux 内核提供的 `Sendfile` 系统调用\n\n在 Sendfile 方法中，数据在内核缓冲区完成输入和输出，不需要拷贝到用户空间处理，这也就避免了重复的数据拷贝\n\n在具体的操作中，Kafka 把所有的消息都存放在单独的文件里，在消息投递时直接通过 `Sendfile` 方法发送文件，减少了上下文切换，因此大大提高了性能\n\n## **「MMAP技术」**\n\n除了 `Sendfile` 之外，还有一种零拷贝的实现技术，即 Memory Mapped Files\n\nKafka 使用 `Memory Mapped Files` 完成内存映射，`Memory Mapped Files` 对文件的操作不是 `write/read`，而是直接对内存地址的操作，如果是调用文件的 `read` 操作，则把数据先读取到内核空间中，然后再复制到用户空间，但 `MMAP`可以将文件直接映射到用户态的内存空间，省去了用户空间到内核空间复制的开销\n\nProducer生产的数据持久化到broker，采用mmap文件映射，实现顺序的快速写入\n\nCustomer从broker读取数据，采用sendfile，将磁盘文件读到OS内核缓冲区后，直接转到socket buffer进行网络发送。\n\n## **「批量发送读取」**\n\nKafka 的批量包括批量写入、批量发布等。它在消息投递时会将消息缓存起来，然后批量发送\n\n同样，消费端在消费消息时，也不是一条一条处理的，而是批量进行拉取，提高了消息的处理速度\n\n## **「数据压缩」**\n\nKafka还支持对消息集合进行压缩，`Producer`可以通过`GZIP`或`Snappy`格式对消息集合进行压缩\n\n压缩的好处就是减少传输的数据量，减轻对网络传输的压力\n\nProducer压缩之后，在`Consumer`需进行解压，虽然增加了CPU的工作，但在对大数据处理上，瓶颈在网络上而不是CPU，所以这个成本很值得\n\n## **「分区机制」**\n\nkafka中的topic中的内容可以被分为多partition存在，每个partition又分为多个段segment，所以每次操作都是针对一小部分做操作，很轻便，并且增加 `并行操作` 的能力\n\n# 常见面试题\n\n## **「Kafka是Push还是Pull模式？」**\n\nKafka最初考虑的问题是，customer应该从brokes拉取消息还是brokers将消息推送到consumer。\n\n在这方面，Kafka遵循了一种大部分消息系统共同的传统的设计：producer将消息推送到broker，consumer从broker拉取消息。\n\npush模式由broker决定消息推送的速率，对于不同消费速率的consumer就不太好处理了。\n\n消息系统都致力于让consumer以最大的速率最快速的消费消息，push模式下，当broker推送的速率远大于consumer消费的速率时，consumer恐怕就要崩溃了。\n\n\n\n> ❝\n> Kafka中的Producer和Consumer采用的是Push-and-Pull模式，即Producer向Broker Push消息，Consumer从Broker Pull消息。\n> ❞\n\n\n\nPull模式的一个好处是consumer可以自主决定是否批量的从broker拉取数据。\n\nPull有个缺点是，如果broker没有可供消费的消息，将导致consumer不断在循环中轮询，直到新消息到达。\n\n## **「Kafka如何保证高可用?」**\n\n[面试题：Kafka如何保证高可用？有图有真相](https://mp.weixin.qq.com/s?__biz=MzUyOTg1OTkyMA==&mid=2247484980&idx=1&sn=6e0c7112dd72d0edc284009e7503b2ac&scene=21#wechat_redirect)\n\n## **「Kafk的使用场景」**\n\n业界Kafka实际应用场景\n\n> ❝\n> 异步通信\n> ❞\n\n\n\n消息中间件在异步通信中用的最多，很多业务流程中，如果所有步骤都同步进行可能会导致核心流程耗时非常长，更重要的是所有步骤都同步进行一旦非核心步骤失败会导致核心流程整体失败，因此在很多业务流程中Kafka就充当了异步通信角色。\n\n\n\n> ❝\n> 日志同步\n> ❞\n\n\n\n大规模分布式系统中的机器非常多而且分散在不同机房中，分布式系统带来的一个明显问题就是业务日志的查看、追踪和分析等行为变得十分困难，对于集群规模在百台以上的系统，查询线上日志很恐怖。\n\n为了应对这种场景统一日志系统应运而生，日志数据都是海量数据，通常为了不给系统带来额外负担一般会采用异步上报，这里Kafka以其高吞吐量在日志处理中得到了很好的应用。\n\n\n\n> ❝\n> 实时计算\n> ❞\n\n\n\n随着据量的增加，离线的计算会越来越慢，难以满足用户在某些场景下的实时性要求，因此很多解决方案中引入了实时计算。\n\n很多时候，即使是海量数据，我们也希望即时去查看一些数据指标，实时流计算应运而生。\n\n实时流计算有两个特点，一个是实时，随时可以看数据；另一个是流。\n\n\n\n## **「Kafka 的多分区（Partition）以及多副本（Replica）机制有什么好处呢？」**\n\n1. Kafka 通过给特定 Topic 指定多个 Partition, 而各个 Partition 可以分布在不同的 Broker 上, 这样便能提供比较好的并发能力（负载均衡）。\n\n2. Partition 可以指定对应的 Replica 数, 这也极大地提高了消息存储的安全性, 提高了容灾能力，不过也相应的增加了所需要的存储空间。\n\n\n\n\n\n参考资料：\n\n>  [Kafka常见问题总结](https://javaguide.cn/high-performance/message-queue/kafka-questions-01.html)\n> \n>  [Kafka核心知识总结！](https://mp.weixin.qq.com/s/zfHoSsuSpXWOaxQrm7uvkA)\n\n","slug":"md/万字详解，Kafka这一篇就够了！","published":1,"updated":"2025-08-21T09:27:47.433Z","comments":1,"layout":"post","photos":[],"_id":"cmhc3m3uc0009xdp800z7e3tt","content":"<p>Kafka 服务器端的代码是由 Scala 代码编写，支持面向对象编程和函数式数据，编译过后也是普通的 .class 文件。其的作用：提供统一的、高吞吐量、低延迟的平台来处理实时数据</p>\n<h1 id=\"一、基本概念\"><a href=\"#一、基本概念\" class=\"headerlink\" title=\"一、基本概念\"></a>一、基本概念</h1><h2 id=\"「Kafka-是什么？主要应用场景什么？」\"><a href=\"#「Kafka-是什么？主要应用场景什么？」\" class=\"headerlink\" title=\"「Kafka 是什么？主要应用场景什么？」\"></a>「Kafka 是什么？主要应用场景什么？」</h2><p>Kafka 是一个分布式流式处理平台。</p>\n<p><img src=\"/img/6aaf06740442599b6c52bb586545dfb8_MD5.png\" alt=\"Kafka结构示意图\"></p>\n<p><strong>1 . 主题</strong>：发布订阅的对象是主题（Topic），可以为每个业务、每个应用甚至每类数据都创建专属的主题</p>\n<p><strong>2 . 生产者和消费者</strong>：向主题发布消息的客户端应用程序成为生产者，生产者程序通常持续不断地向一个或者多个主题发送消息</p>\n<p><strong>3 . Broker</strong>：集群由多个 Broker 组成，Broker 负责接收和处理客户端发送过来的请求，以及对消息进行持久化。</p>\n<pre><code>虽然多个 Broker 能够运行在同一台机器上，但是常见的做法是将不同的 Broker 分散运行在不同的机器上，这样如果某一台机器宕机，即使在它上面运行的所有 Broker 进程都挂掉了，其他机器上的 Broker 也一眼能够对外提供服务。\n</code></pre>\n<p> <strong>4 . 备份机制</strong>：备份的思想很简单，就是把相同的数据拷贝到多台机器上，而这些相同的数据拷贝被称为副本。</p>\n<pre><code>Kafka 定义了两类副本：领导者副本和追随者副本。\n\n前者对外提供服务，即与客户端程序进行交互；后者只是被动地追随领导者副本而已，不对外进行交互。\n</code></pre>\n<p><strong>5 . 分区</strong>：分区机制指的是将每个主题分成多个分区，每个分区是一组有序的消息日志</p>\n<pre><code>生产者生产的每条消息总会被发送到一个分区中，也就是说如果向一个双分区的主题发送一条消息，该条消息要不在分区 0 中，要不在分区 1 中。\n\n生产者向分区中写入消息，每条消息在分区中的位置信息叫做位移。\n</code></pre>\n<p><strong>6 . 消费者组</strong>：多个消费者实例共同组成一个组来消费一组主题</p>\n<pre><code>这组主题中的每个分区只会被组内的一个消费者实例消费，其他消费者实例不能消费它\n\n消息引擎的两大模型：\n\n\t如果所有实例都属于同一个 Group，那么它实现的就是消息队列模型\n\n\t如果所有实例属于不同的 Group，那么它实现的就是发布/订阅模型\n</code></pre>\n<blockquote>\n<p><strong>RocketMQ 的消息模型和 Kafka 基本是完全一样的。唯一的区别是 Kafka 中没有队列这个概念，与之对应的是 Partition（分区）。</strong></p>\n</blockquote>\n<p><strong>7 . Coordinator：协调者</strong>：负责为 Group 执行 Rebalance 以及提供唯一管理和组成员管理等。</p>\n<p><strong>8 . 消费者位移：Consumer offset</strong>：消费者消费进度，每个消费者都有自己的消费者位移</p>\n<p><strong>9 . 重平衡：Rebalance</strong>：消费者组内某个消费者实例挂掉后，其他消费者实例自动重新分配订阅主题分区的过程。</p>\n<p>Rebalance 是 Kafka 消费者端实现高可用的重要手段</p>\n<p><strong>10 . AR（Assigned Replicas）</strong>：分区中的所有副本统称为 AR。</p>\n<p>所有消息都会先发送到领导者副本，然后追随者副本才能从领导者中拉去信息进行同步</p>\n<p>但是同步期间，追随者副本相对于领导者副本而言有一定程度的滞后，这时候追随者副本和领导者副本并非完全同步状态</p>\n<p><strong>11 . OSR（Out Sync Replicas）</strong>：AR 的一个子集，其中都是追随者副本和领导者副本没有完全同步或者之后的副本集合</p>\n<p><strong>12 . ISR（In Sync Replicas）</strong>：AR 的一个子集，ISR 中的副本都是和领导者副本是保持完全同步的副本。</p>\n<p>如果某一个在 ISR 中的 follower 副本落后于 leader 副本太多，就会从 ISR 中移除，否则如果完全同步，会从 OSR 中移到 ISR 集合中</p>\n<p><strong>13 . HW（High Watermark）</strong>：高水位，标识一个特定的消息偏移量（offset），消费者只能来取这个水位 offset 之前的消息</p>\n<p>下图表示一个日志文件，这个日志文件中只有9条消息，第一条消息的offset（LogStartOffset）为0，最有一条消息的offset为8，offset为9的消息使用虚线表示的，代表下一条待写入的消息。</p>\n<p>日志文件的 HW 为6，表示消费者只能拉取offset在 0 到 5 之间的消息，offset为6的消息对消费者而言是不可见的。</p>\n<p><img src=\"/img/ce77dd7ccc11dc7642aad16560000cb9_MD5.png\" alt=\"消息偏移量展示\"></p>\n<p><strong>14 . LEO（Log End Offset）</strong>：标识当前日志文件中下一条待写入的消息的offset</p>\n<h1 id=\"二、系统架构\"><a href=\"#二、系统架构\" class=\"headerlink\" title=\"二、系统架构\"></a>二、系统架构</h1><p>Kafka 基础框架：一个生产者发送一个消息到 Kafka 的一个 Topic，该 Topic 的消息存放在 Broker 中，消费者订阅这个 Topic，然后从 Broker 中消费消息。</p>\n<p>1.<strong>消息状态</strong>：在 Kafka 中，消息是否被消费的状态保存在消费者中，Broker 不会关系消息是否消费，或者被谁消费，消费者会记录一个 offset 值（指向分区中下一条被消费的消息位置），如果 offset 被错误设置可能会导致同一条消息多次消费或者丢失。</p>\n<p>2.<strong>消息持久化</strong>：Kafka 会把消息持久化到本地文件系统中，并且具有极高的性能。</p>\n<p>3.<strong>批量发送</strong>：Kafka 支持以消息集合为单位进行批量发送，以提高效率。</p>\n<p>4.<strong>Push-and-Pull</strong>：Kafka 中的生产者和消费者采用的是 Push-and-Pull 模式，即生产者向 Broker Push 消息，消费者从 Broker Pull 消息。</p>\n<p>5.<strong>分区机制</strong>：Kafka 的 Broker 是支持分区的，Producer 可以决定将消息放在哪个 Partition，在一个 Partition 中的消息顺序就是 Producer 发送消息的顺序，一个 Topic 中的 Partition 是可以配置的，Partition 是保证 Kafka 高吞吐量的重要保证。</p>\n<p><img src=\"/img/68d9aaa9dd34dbc9d516201de1f2ab55_MD5.png\" alt=\"系统架构\"></p>\n<p>通常情况下，一个 Kafka 体系是包含多个 Producer，多个 Broker，多个 Consumer，以及一个 Zookeeper 集群</p>\n<h1 id=\"三、生产者分区\"><a href=\"#三、生产者分区\" class=\"headerlink\" title=\"三、生产者分区\"></a>三、生产者分区</h1><p>一条 Kafka 消息的的组织架构是三层：主题（Topic）- 分区（Partition）- 消息（Message）</p>\n<p>分区其实是一种负载均衡的做法。因为同一个 Topic 下的不同分区可以在不同 Broker 节点上，并且，数据读写是以分区为粒度，这样的话，每个节点都可以执行自己分区的消息的读写。除此之外，还能通过增加节点来提高吞吐量。</p>\n<h2 id=\"「分区策略」\"><a href=\"#「分区策略」\" class=\"headerlink\" title=\"「分区策略」\"></a>「分区策略」</h2><p>所谓的分区策略其实就是决定生产者将消息发送到哪个分区的算法。</p>\n<h3 id=\"自定义分区策略\"><a href=\"#自定义分区策略\" class=\"headerlink\" title=\"自定义分区策略\"></a>自定义分区策略</h3><p>如果需要自己定义分区策略，在编写生产者程序的时候，可以编写一个具体的实现类<code>org.apache.kafka.clients.producer.Partitioner</code> 接口。这接口也非常简单，只定义了两个方法：partition() 和 close() 方法。通常情况我们只需要实现 partition() 方法即可。</p>\n<pre><code class=\"language-java\">int partition(String topic, Object key, byte[] keyBytes, Object value, byte[] valueBytes, Cluster cluster);\n</code></pre>\n<p>这里的 topic、key、keyBytes、value 和 valueBytes 都属于消息数据，cluster 则是集群信息（比如当前 Kafka 集群共有多少主题、多少 Broker 等）。</p>\n<h3 id=\"轮询策略\"><a href=\"#轮询策略\" class=\"headerlink\" title=\"轮询策略\"></a>轮询策略</h3><p>也称 Round-robin 策略，即顺序分配。轮询策略是 Kafka 生产者 API 默认提供的分区策略。</p>\n<p>轮询策略有非常优秀的负载均衡表现，它总是保证消息最大限度的平均分配到所有的分区上，所以默认下它是最合理的分区策略，也是最常用的分区策略。</p>\n<h3 id=\"随机策略\"><a href=\"#随机策略\" class=\"headerlink\" title=\"随机策略\"></a>随机策略</h3><p>也称 Randomness 策略。想要实现随机策略的 partition 方法，其实很简单，只需要两行代码即可：</p>\n<pre><code class=\"language-java\"> List partitions = cluster.partitionsForTopic(topic);\n return ThreadLocalRandom.current().nextInt(partitions.size());\n</code></pre>\n<p>先计算出该主题的总分区数，然后随机返回一个小于它的正整数。</p>\n<p>随机策略在负载均衡上面略逊于轮询策略。在老的版本里面常用随机策略，再后来的版本更新中被轮询策略所替代。</p>\n<h3 id=\"按消息键保序策略\"><a href=\"#按消息键保序策略\" class=\"headerlink\" title=\"按消息键保序策略\"></a>按消息键保序策略</h3><p>Kafka 允许为每条消息定义消息键，简称 Key。</p>\n<p>Key 可以为具体的业务代码，也可以用来表征消息元数据。在 Kafka 中如果消息定义了 Key，那么就可以保证同一个 Key 的消息进入相同的分区，有序分区下的消息处理是有顺序的，所以这个策略被称为安消息键保存策略。</p>\n<p>实现这个策略的 partition 方法同样简单，只需要下面两行代码即可：</p>\n<pre><code class=\"language-java\"> List partitions = cluster.partitionsForTopic(topic);\n return Math.abs(key.hashCode()) % partitions.size();\n</code></pre>\n<p>其实，Kafka 默认的分区策略是两种：<br>\t如果指定了 Key ，默认实现按消息键保序策略；<br>\t如果未指定 Key，则使用轮询策略。</p>\n<h3 id=\"「其他分区策略」\"><a href=\"#「其他分区策略」\" class=\"headerlink\" title=\"「其他分区策略」\"></a>「其他分区策略」</h3><p>另外还有一种比较常见的，所谓的基于地理位置的分区策略。当然这种策略只针对大规模的 Kafka 集群，特别是跨城市、跨国家甚至是跨大洲的集群。我们可以根据 Broker 所在的 IP 地址实现定制化的分区策略。比如下段代码：</p>\n<pre><code class=\"language-java\">List partitions = cluster.partitionsForTopic(topic);\nreturn partitions.stream().filter(p -&gt; isSouth(p.leader().host())).map(PartitionInfo::partition).findAny().get();\n</code></pre>\n<p>我们可以从所有分区中找出那些 Leader 副本在南方的所有分区，然后随机挑选一个进行消息发送。</p>\n<h1 id=\"四、生产者压缩算法\"><a href=\"#四、生产者压缩算法\" class=\"headerlink\" title=\"四、生产者压缩算法\"></a>四、生产者压缩算法</h1><p>为什么要压缩消息？压缩消息是为了更好的节省网络传输贷款以及 Kafka Broker 端的磁盘占用。</p>\n<h3 id=\"「Kafka-是如何压缩消息的呢？」\"><a href=\"#「Kafka-是如何压缩消息的呢？」\" class=\"headerlink\" title=\"「Kafka 是如何压缩消息的呢？」\"></a>「Kafka 是如何压缩消息的呢？」</h3><p>Kafka 的消息层次分为两层：消息集合和消息。</p>\n<p>??？</p>\n<h3 id=\"「何时压缩？」\"><a href=\"#「何时压缩？」\" class=\"headerlink\" title=\"「何时压缩？」\"></a>「何时压缩？」</h3><p>在 Kafka 中，压缩可能发生在两个地方：生产者端和 Broker 端。</p>\n<p>在生产者程序中配置 compression.type 参数即表示弃用指定类型的压缩算法。</p>\n<p>比如这段代码中展示了如何构建一个开启 GZIP 的 Producer 对象：</p>\n<pre><code class=\"language-java\">Properties props = new Properties();\nprops.put(&quot;bootstrap.servers&quot;, &quot;localhost:9092&quot;);\nprops.put(&quot;acks&quot;, &quot;all&quot;);\nprops.put(&quot;key.serializer&quot;, &quot;org.apache.kafka.common.serialization.StringSerializer&quot;); props.put(&quot;value.serializer&quot;, &quot;org.apache.kafka.common.serialization.StringSerializer&quot;); // 开启GZIP压缩\nprops.put(&quot;compression.type&quot;, &quot;gzip&quot;); //Producer的压缩算法是GZIP\nProducer producer = new KafkaProducer&lt;&gt;(props);\n</code></pre>\n<p>这样 Producer 启动之后生产的每个消息集合都是经 GZIP 压缩过的，故而能很好的节省网络传输贷款以及 Kafka Broker 端的磁盘占用。</p>\n<p>有两种情况可能导致 Broker 重新压缩消息：</p>\n<ul>\n<li>情况一：Broker 端指定了和 Producer 端不同的压缩算法。</li>\n</ul>\n<p>一旦 Broker 端设置了不同的 compression.type 值，就一定要小心了，因为可能会发生预料之外的压缩、解压缩操作，通常表现为 Broker 端 CPU 使用率飙升。</p>\n<ul>\n<li>情况二：Broker 端发生了消息格式转换。</li>\n</ul>\n<p>所谓的消息格式转换主要是为了兼容老版本的消费者程序。在一个生产环境中，Kafka 集群中同时保存多个版本的消息格式非常常见。为了兼容老版本的格式，Broker 端会对新版本消息指向向老版本的转换。这个过程会涉及到消息的解压缩和重新压缩。一般情况下这种消息格式转换成对性能是有很大影响的，除了这里的压缩之外，他还让 Kafka 丧失了 Zero Copy 特性。</p>\n<h3 id=\"「何时解压缩？」\"><a href=\"#「何时解压缩？」\" class=\"headerlink\" title=\"「何时解压缩？」\"></a>「何时解压缩？」</h3><p>有压缩必有解压缩！通常来说解压缩发生在消费者程序中。</p>\n<p><strong>基本过程：Producer 端压缩，Broker 端保持，Consumer 端解压缩。</strong></p>\n<p>注意：除了在 Consumer 端解压缩外，Broker 端也会进行解压缩。</p>\n<p>每个压缩过的消息集合在 Broker 端写入时都要发生解压缩操作，目的就是为了对消息执行各种验证。我们必须承认这种解压缩对 Broker 端性能有一定的影响，特别是对 CPU 的使用率而言。</p>\n<h3 id=\"「各种压缩算法对比」\"><a href=\"#「各种压缩算法对比」\" class=\"headerlink\" title=\"「各种压缩算法对比」\"></a>「各种压缩算法对比」</h3><p>Kafka 支持 4 种压缩算法：GZIP、Snappy 、LZ4 和 zstd(Zstandard 算法)。在实际使用中，各个算法各有千秋。</p>\n<p>吞吐量：LZ4 &gt; Snappy &gt; zst 和 GZIP；</p>\n<p>压缩比：zstd &gt; LZ4 &gt; GZIP &gt; Snappy；</p>\n<p>占用宽带：zstd &lt; LZ4 和 GZIP &lt; Snappy；</p>\n<p>在CPU使用率方面，各个算法表现得差不多，只是在压缩时Snappy算法使用的CPU较多一些，而在解压缩时GZIP算法则可能使用更多的CPU。</p>\n<h1 id=\"五、消费者组\"><a href=\"#五、消费者组\" class=\"headerlink\" title=\"五、消费者组\"></a>五、消费者组</h1><p>Consumer Group 是 Kafka 提供可拓展且具有容错性的消费机制。</p>\n<p>既然是一个组，那么组内必然是可以有多个消费者或者消费者实例，它们共享一个公共的 ID，这个 ID 被称为 Group ID。组内所有的消费者协调在一起来消费订阅主题的所有分区。每个分区只能有同一个消费组内的一个 Consumer 实例来消费。</p>\n<h3 id=\"Consumer-Group-三个特性\"><a href=\"#Consumer-Group-三个特性\" class=\"headerlink\" title=\"Consumer Group 三个特性\"></a>Consumer Group 三个特性</h3><p>1.Consumer Group 下可以有一个或者多个 Consumer 实例，这里的实例可以是一个单独的进程，也可以是同一个进程下的线程。</p>\n<p>2.Group ID 是一个字符串，在一个 Kafka 集群中，它表示唯一的一个 Consumer Group。</p>\n<p>3.Consumer Group 下所有实例订阅的主题的单独分区，只能分配给组内的某个 Consumer 实例消费，这个分区当然也可以被其他的 Group 消费。</p>\n<p>Kafka 仅仅使用 Consumer Group 这一种机制，却同时实现了传统消息引擎系统的两大模型：</p>\n<ul>\n<li><p>如果所有实例都是属于同一个 Group，那么它实现的是消息队列模型；</p>\n</li>\n<li><p>如果所有实例分别属于不同的 Group，那么它实现的就是发布&#x2F;订阅模型。</p>\n</li>\n</ul>\n<h3 id=\"一个-Group-下应该有多少个-Consumer-实例呢？\"><a href=\"#一个-Group-下应该有多少个-Consumer-实例呢？\" class=\"headerlink\" title=\"一个 Group 下应该有多少个 Consumer 实例呢？\"></a>一个 Group 下应该有多少个 Consumer 实例呢？</h3><p>理想情况下，Consumer 实例的数量应该等于 Group 订阅主题的分区总数。</p>\n<blockquote>\n<p>假设一个 Comsumer Group 订阅了 3 个主题，分别是 A、B、C，它们的分区数分别是 1，2，3，那么通常情况下，为改 Group 设置 6 个 Consumer 实例是比较理想的情形，因为它能最大限度的视线高伸缩性。</p>\n</blockquote>\n<h3 id=\"针对-Consumer-Group，Kafka-是怎么管理位移呢？\"><a href=\"#针对-Consumer-Group，Kafka-是怎么管理位移呢？\" class=\"headerlink\" title=\"针对 Consumer Group，Kafka 是怎么管理位移呢？\"></a>针对 Consumer Group，Kafka 是怎么管理位移呢？</h3><p>老版本 Consumer Group 把位移保存在 ZooKeeper 中。Apache ZooKeeper 是一个分布式的协调服务框架，Kafka 重度依赖它实现的各种各样的协调管理。将唯一保存到 ZooKeeper 外部系统的做法，最显而易见的好处就是减少了 Kafka Broker 端的状态保存开销。</p>\n<p>但是，慢慢的发现一个问题，即 ZooKeeper 这类元框架其实并不适合进行频繁的写更新，而 Consumer Group 的位移更新是一个非常频繁的操作。这种大吞吐量的写操作会极大拖慢 ZooKeeper 集群的性能。于是，新版本的 Consumer Group 中，Kafka 社区重新设计了 Consumer Group 的位移管理方式，采用将位移保存在 Kafka 内部主题的方法。</p>\n<p>这个内部主题就是_counsumer_offset.</p>\n<h1 id=\"六、消费者策略\"><a href=\"#六、消费者策略\" class=\"headerlink\" title=\"六、消费者策略\"></a>六、消费者策略</h1><p>消费者消费同一主题的哪个分区，是通过消费者策略决定的。</p>\n<h4 id=\"轮询-Round\"><a href=\"#轮询-Round\" class=\"headerlink\" title=\"轮询 Round\"></a>轮询 Round</h4><p>Kakfa 默认的消费者策略——轮询，通过轮询方式，决定消费者消费的分区。</p>\n<p><img src=\"/img/2ca562d1dc3a2d8d06c7c2bfe2c394c8_MD5.png\" alt=\"轮询策略\"></p>\n<h4 id=\"范围计算-Range\"><a href=\"#范围计算-Range\" class=\"headerlink\" title=\"范围计算 Range\"></a>范围计算 Range</h4><p>对一个消费者组来说，决定消费方式是以分区总数除以消费者总数来决定，一般如果不能整除，往往是从头开始将剩余的分区分配开</p>\n<p><img src=\"/img/c3276b5f713b8b0641463b496c196ce2_MD5.png\" alt=\"范围计算\"></p>\n<h4 id=\"范围计算升华版-Sticky\"><a href=\"#范围计算升华版-Sticky\" class=\"headerlink\" title=\"范围计算升华版 Sticky\"></a>范围计算升华版 Sticky</h4><p>是在0.11.x，新增的，它和前面两个不是很一样，它是在Range上的一种升华，且前面两个当同组内有新的消费者加入或者旧的消费者退出的时候，会从新开始决定消费者消费方式，但是Sticky，在同组中有新的新的消费者加入或者旧的消费者退出时，不会直接开始新的Range分配，而是保留现有消费者原来的消费策略，将退出的消费者所消费的分区平均分配给现有消费者，新增消费者同理，同其他现存消费者的消费策略中分离。</p>\n<h1 id=\"七、位移提交\"><a href=\"#七、位移提交\" class=\"headerlink\" title=\"七、位移提交\"></a>七、位移提交</h1><p>假设一个分区中有 10 条消息，唯一分别是 0 到 9.</p>\n<p>某个 Consumer 应用已经消费了 5 条消息，这就说明该 Consumer 消费了位移为 0 到 4 的 5 条消息，此时 Consumer 的位移是 5，指向了下一条消息的位移。因为 Consumer 能够同时消费多个分区的数据，所以位移的提交实际上是在分区粒度上进行的，即 <strong>Consumer 需要为分配给它的每一个分区提交各自的位移数据。</strong></p>\n<p>位移提交分为自动提交和手动提交；从 Consumer 端的角度来说，位移提交分为同步提交和异步提交。</p>\n<p>开启自动提交位移的方法：Consumer 端有一个参数 <code>enable.auto.commint</code>，把它设置为 true 或者不设置它即可。</p>\n<p>如果开启了自动提交，Consumer 端还有个参数：<code>auto.commit.interval.ms</code>。默认为 5 秒，表明 Kafka 每 5 秒会自动提交一次位移。</p>\n<pre><code class=\"language-java\">Properties props = new Properties();\nprops.put(&quot;bootstrap.servers&quot;, &quot;localhost:9092&quot;);\nprops.put(&quot;group.id&quot;, &quot;test&quot;);\n//开启自动提交\nprops.put(&quot;enable.auto.commit&quot;, &quot;true&quot;);\n//自动提交时间间隔\nprops.put(&quot;auto.commit.interval.ms&quot;, &quot;2000&quot;);\nprops.put(&quot;key.deserializer&quot;, &quot;org.apache.kafka.common.serialization.StringDeserializer&quot;);\nprops.put(&quot;value.deserializer&quot;, &quot;org.apache.kafka.common.serialization.StringDeserializer&quot;);\nKafkaConsumer consumer = new KafkaConsumer&lt;&gt;(props);\nconsumer.subscribe(Arrays.asList(&quot;foo&quot;, &quot;bar&quot;));\nwhile (true) &#123;\n    ConsumerRecords records = consumer.poll(100);\n    for (ConsumerRecord record : records)\n        System.out.printf(&quot;offset = %d, key = %s, value = %s%n&quot;, record.offset(), record.key(), record.value());\n&#125;\n</code></pre>\n<p>如果要开启手动提交，只需要将 <code>enable.auto.commit</code> 设置为 <code>false</code> 即可。</p>\n<p>手动提交需要调用相应的 API 手动提交位移。最简单的 API 就是 <code>KafkaConsumer#commitSync()</code> 。该方法会提交 <code>KafkaConsumer#poll()</code> 返回的最新位移。从名字上来看，这是一个同步方法，即该方法会一直等待，直到位移成功提交之后才会返回。如果提交过程中出现异常，该方法会将异常信息抛出。</p>\n<p>下面这段代码展示了 commitSync() 的使用方法：</p>\n<pre><code class=\"language-java\">while (true) &#123;\n        ConsumerRecords records =consumer.poll(Duration.ofSeconds(1));\n        process(records); // 处理消息\n        try &#123;\n            consumer.commitSync();\n        &#125; catch (CommitFailedException e) &#123;\n            handle(e); // 处理提交失败异常\n        &#125;\n&#125;\n</code></pre>\n<p>自动提交时，Kafka 会保证再开始调用 poll 方法时候，提交上次 poll 方法返回的所有消息。从顺序上来说，poll 方法的逻辑是先提交上一批消息的位移，然后在处理下一批消息，因此，自动提交能保证不会出消费丢失的情况。但是自动提交位移的问题在于，<strong>可能出现重复消费。</strong></p>\n<p>手动提交的好处在于更加灵活，可以完全把控位移提交的时机和频率。但是他也有一个缺陷，就是在调用 <code>commitSync()</code> 时候会处于阻塞状态，直到远端 Broker 返回提交结果，这个状态才能结束。</p>\n<p>这时候，手动提交的另一个方法就出现了 <code>KafkaConsumer#commitAsync()</code>。从名字上看，这是个异步操作。调用 <code>commitAsync()</code> 方法之后，它会立即返回，不会阻塞，因此不影响 Consumer 应用的 TPS（吞吐量）。由于它是异步的，Kafka 提供了一个回调函数（callback），供开发者实现提交之后的逻辑，比如记录日志或处理异常。</p>\n<p>下面这段代码展示了调用 commintAsync() 方法：</p>\n<pre><code class=\"language-java\">while (true) &#123;\n            ConsumerRecords records = consumer.poll(Duration.ofSeconds(1));\n            process(records); // 处理消息\n            consumer.commitAsync((offsets, exception) -&gt; &#123;\n\t\t\t\t if (exception != null)\n\t\t\t\t\t handle(exception);\n\t\t\t&#125;);\n&#125;\n</code></pre>\n<p>commitAsync 的问题在于，出了问题时它不会重试。</p>\n<p>显然，如果手动提交，我们需要将 commitSync 和 commitAsync 组合使用才能达到最理想的效果：<br>\t1.我们可以利用 commitSync 的自动动重试来规避那些瞬时错误，比如网络的瞬时都懂，Broker 端的 GC 问题，因为这些问题是短暂的，自动重试通常都会成功。<br>\t2.我们不希望程序总是处于阻塞状态，影响 TPS。</p>\n<p>我们来看一下下面这段代码，它展示的是如何将两个 API 方法结合使用进行手动提交。</p>\n<pre><code class=\"language-java\">try &#123;\n    while(true) &#123;\n        ConsumerRecords records = consumer.poll(Duration.ofSeconds(1));\n        process(records); // 处理消息\n        commitAysnc(); // 使用异步提交规避阻塞\n    &#125;\n&#125; catch(Exception e) &#123;\n        handle(e); // 处理异常\n&#125; finally &#123;\n      try &#123;\n        consumer.commitSync(); // 最后一次提交使用同步阻塞式提交\n&#125; finally &#123;\n \t\tconsumer.close();\n&#125;\n&#125;\n</code></pre>\n<p>试想这样一个场景：poll 方法返回的不是 500 条消息，而是 5000 条。</p>\n<p>那么，你肯定不想把这 5000 条消息处理完之后再提交位移，因为一旦中间出差错，之前处理的全部都要重来一遍。那么我们可以每处理完 100 条消息就提交一次位移，这样避免大批量的消息重新消费。</p>\n<p>Kafka Consumer API 为手动提交提供了这样的方法：<code>commitSync(Map)</code> 和 <code>commitAsync(Map)</code>。它们的参数是一个 Map 对象，键就是 TopicPartition，即消费的分区，而值是一个 OffsetAndMetadata 对象，保存主要是位移数据。</p>\n<p>以 commitAsync 为例，展示一段代码。实际上，commitSync 的调用方法和它一模一样的。</p>\n<pre><code class=\"language-java\">private Map offsets = new HashMap&lt;&gt;();\nint count = 0;\n……\nwhile (true) &#123;\n    ConsumerRecords records = consumer.poll(Duration.ofSeconds(1));\n        for (ConsumerRecord record: records) &#123;\n            process(record);  // 处理消息\n            offsets.put(new TopicPartition(record.topic(), record.partition()),new OffsetAndMetadata(record.offset() + 1)；\n            if（count % 100 == 0）\n                consumer.commitAsync(offsets, null); // 回调处理逻辑是null\n                count++;\n &#125;\n&#125;\n</code></pre>\n<p>与调用无参的 commitAsync 不同，这里调用了带 Map 对象参数的 commitAsync 进行细粒度的位移提交。</p>\n<h1 id=\"八、重平衡\"><a href=\"#八、重平衡\" class=\"headerlink\" title=\"八、重平衡\"></a>八、重平衡</h1><p>重平衡 Rebalance 本质上是一种协议，规定了一个 Consumer Group 如何分配订阅 Topic 的每一个分区。Kafka 在为 Consumer Group 内的 Consumer 分配分区的过程，就是 Rebalance。</p>\n<p>Rebalance 触发条件有三个：</p>\n<ul>\n<li><p>组内成员发生变化，即有新的 Consumer 实例加入组或者离开祖，或者因崩溃而退出组。</p>\n</li>\n<li><p>订阅主题数发生变化，Consumer Group 可以通过正则表达式方式订阅主题，比如 <code>consumer.subscribe(Pattern.compile(&quot;t.*c&quot;))</code> 就表明 Group 订阅所有以字母 t 开头、字母 c 结尾的主题，所以在 Consumer Group 运行过程中，如果创建了满足要求的主题，就会发生 Rebalance。</p>\n</li>\n<li><p>订阅主题的分区发生变化，Kafka 当前只能允许增加一个主题的分区数，当主题的分区数发生变化，就会触发该主题下所有 Group 的 Rebalance。</p>\n</li>\n</ul>\n<h3 id=\"「分配策略」\"><a href=\"#「分配策略」\" class=\"headerlink\" title=\"「分配策略」\"></a>「分配策略」</h3><p>当前Kafka默认提供了3种分配策略，每种策略都有一定的优势和劣势，社区会不断地完善这些策略，保证提供最公平的分配策略，即每个Consumer实例都能够得到较为平均的分区数。</p>\n<h3 id=\"「Coordinator-会在什么情况下确认-Consumer-实例挂掉了从而要退组？」\"><a href=\"#「Coordinator-会在什么情况下确认-Consumer-实例挂掉了从而要退组？」\" class=\"headerlink\" title=\"「Coordinator 会在什么情况下确认 Consumer 实例挂掉了从而要退组？」\"></a>「Coordinator 会在什么情况下确认 Consumer 实例挂掉了从而要退组？」</h3><p>在 Consumer Group 完成 Rebalance 之后，每个 Consumer 实例都会定期的想 Coordinator 发送心跳请求，表明它还活着。如果某个 Consumer 不能及时的发送心跳请求，娜美 Coordinator 就会认为它已经死了，从而将其从 Group 中移除，然后开启新一轮的 Rebalance。</p>\n<p>Consumer 端设置参数里面有个：<code>session.timeout.ms</code>。默认为 10 秒，即如果 Coordinator 在 10 秒内没有收到 Group 的某个 Consumer 的心跳请求，则认为它已经挂了。除了这个参数，还有个允许开发者控制发送心跳的频率的参数，就是 <code>heartbeat.interval.ms</code>。这个参数设置越小，Consumer 发送心跳请求的频率越高。当然，请求频率越高，消耗的带宽资源也就越高。</p>\n<p>除此之外，Consumer 端还有个参数，用于控制 Consumer 实际消费能力对对 Rebalance 的影响，即：<code>max.pool.interval.ms</code> 参数。它限定了 Consumer 端应用程序两次调用 poll 方法的最大时间间隔。默认值为 5 分钟，表示如果 Consumer 在 5 分钟内没有消费完 poll 方法返回的消息，那么 Consumer 会主动发起离开 Group 的请求，Coordinator 则会开启新的 Rebalance。</p>\n<h3 id=\"「如何设置避免-Rebalance」\"><a href=\"#「如何设置避免-Rebalance」\" class=\"headerlink\" title=\"「如何设置避免 Rebalance」\"></a>「如何设置避免 Rebalance」</h3><ol>\n<li><p>如果是因为未能及时发送心跳请求，导致 Consumer 被踢出 Group ，引发的 Rebalance。则可以设置 <code>session.timeout.ms</code> 和 <code>heartbeat.interval.ms</code> 的值。</p>\n<ul>\n<li><p>设置 <code>session.timeout.ms</code> &#x3D; 6s。</p>\n</li>\n<li><p>设置 <code>heartbeat.interval.ms</code> &#x3D; 2s。</p>\n</li>\n<li><p>要保证 Consumer 实例在被判定为 dead 之前，能够发送 3 条心跳请求，即 <code>session.timeout.ms &gt;= 3 * heartbeat.interval.ms</code>。</p>\n</li>\n</ul>\n</li>\n</ol>\n<p>将 <code>session.timeout.ms</code> 设置为 6s 主要是为了让 Coordinator 能更快定位已经挂掉的 Consumer。</p>\n<ol start=\"2\">\n<li>如果是因为 Consumer 消费时间过长导致的 Rebalance。在开发过程中，为业务逻辑处理留足充足的时间，这样 Consumer 就不会因为处理这些消息太长而引起 Rebalance 了。</li>\n</ol>\n<h1 id=\"九、ConsumerOffsets\"><a href=\"#九、ConsumerOffsets\" class=\"headerlink\" title=\"九、ConsumerOffsets\"></a>九、ConsumerOffsets</h1><p><code>_consumer_offsets</code> 是一个 Kafka 的普通主题，它主要是保存 Kafka Consumer 的位移信息。当 Kafka 中的第一个 Consumer 启动时候，就会创建该主题。其默认分区数是 50，副本数是 3。<code>_consumer_offsets</code> 主题是一个普通的 Kafka 主题，开发者可以手动的创建、修改甚至删除它。但是它的消息格式是 Kafka 自己定义的，不能修改。开发者只能按照规定传入消息，否则内部不能成功解析，就会导致 Broker 崩溃。</p>\n<p><code>_consumer_offsets</code> 有 3 中消息格式：</p>\n<ul>\n<li><p>用于保存 Consumer Group 信息的消息。</p>\n</li>\n<li><p>用于删除 Group 过期位移甚至删除 Group 的消息。</p>\n</li>\n<li><p>保存了位移值。</p>\n</li>\n</ul>\n<p>前面已经提到过，Kafka 的提交方式有两种：自动提交和手动提交。</p>\n<p>手动提交：比较灵活可控，通过调用 <code>commitSync()</code> 或者 <code>commitAsync()</code> 等 Kafka Consumer 的 API，Kafka 会向 <code>_consumer_offsets</code> 主题中写入相应的消息。</p>\n<p>自动提交：显著优点就是省事，不用操心位移提交的事情，就能保证消息不会丢失。但是自动提交位移的有个问题，只要 Consumer 一直启动着，它就会无限期的向位移主题写入消息。</p>\n<blockquote>\n<p>假设Consumer当前消费到了某个主题的最新一条消息，位移是100，之后该主题没有任何新消息产生，故Consumer无消息可消费了，所以位移永远保持在100。由于是自动提交位移，位移主题中会不停地写入位移&#x3D;100 的消息。显然 Kafka 只需要保留这类消息中的最新一条就可以了，之前的消息都是可以删除的。</p>\n</blockquote>\n<p>显然，Kafka 必须要有针对位移主题消息特点的消息删除策略，否则这种消息越多，最重撑爆整个磁盘</p>\n<h3 id=\"「Compact-策略」\"><a href=\"#「Compact-策略」\" class=\"headerlink\" title=\"「Compact 策略」\"></a>「Compact 策略」</h3><p>Kafka 通过 Compact 策略来删除 <code>_consumer_offsets</code> 主题中的过期消息，避免该主题无限膨胀。Compact 的过程就是扫描日志的所有消息，剔除过期消息，把剩下消息整理在一起。</p>\n<p>Kafka 提供了专门的后台线程定期的巡检待 Compact 的主题，看看是否存在猫族条件的可删除数据。这个后台线程叫做 <strong>Log cleaner</strong>。如果生产环境中出现了位移主题无限膨胀占用过多磁盘空间问题，请检查一下 Log cleaner 线程是否挂掉了。</p>\n<h1 id=\"十、副本机制\"><a href=\"#十、副本机制\" class=\"headerlink\" title=\"十、副本机制\"></a>十、副本机制</h1><p>根据 Kafka 副本机制定义，同一个分区下面的所有副本保存有相同的消息队列，这些副本是分布在不同 Broker 中，以确保某个 Broker 宕机后其他副本可以正常使用。</p>\n<p>在 Kafka 中，副本分为领导者副本和追随者副本。其中追随者副本不参与什么读写请求操作。追随者副本只异步拉去领导者副本，在领导者副本所在的 Broker 宕机的时候，重新从追随者副本中推选出一个领导者副本。</p>\n<p>追随者副本唯一的工作就是，不断的从领导者副本中拉取消息，然后写入自己的提交日志中。</p>\n<p><img src=\"/img/ff0fd5af97f5f5ad3a954f3ffa4076d0_MD5.png\" alt=\"副本机制\"></p>\n<h1 id=\"十一、ISR-机制\"><a href=\"#十一、ISR-机制\" class=\"headerlink\" title=\"十一、ISR 机制\"></a>十一、ISR 机制</h1><p>in-sync Replicas，也就是所谓的 ISR 副本集合。这个集合是动态的，而非静态不变。</p>\n<p>ISR 中的副本一定是好 Leader 副本同步的，相反不在 ISR 中的副本一定是和 Leader 副本不同步的。</p>\n<p>Leader 副本一定在 ISR 中，Follower 副本不一定在 ISR 中。在 Broker 端有个配置参数 <code>replica.lag.time.max.ms</code>，这个参数的含义是 Follower 副本落后 Leader 副本的时间不连续超过 10 秒，那么 Kafka 认为 Follower 副本和 Leader 是同步的，即使此时 Follower 副本中保存的消息明显少于 Leader 副本中的消息。</p>\n<h1 id=\"十二、Unclean-领导者选举\"><a href=\"#十二、Unclean-领导者选举\" class=\"headerlink\" title=\"十二、Unclean 领导者选举\"></a>十二、Unclean 领导者选举</h1><p>Kafka 将所有不在 ISR 中的副本都认为是非同步副本。在领导者选举的时候，如果选举这种副本的过程称为 Unclean 领导者选举。在 Broker 端中参数 <code>unclean.leader.election.enable</code> 控制是否开启 Unclean 领导者选举。</p>\n<p>Unclean 领导者选举有利有弊。优点在于：因为一个分区中 Leader 副本负责读写请求，如果 Leader 副本挂了，整个分区就改了。开启 Unclean 领导者选取，会使 Leader 副本一直存在，不至于对外停止服务，提高了高可用；缺点在于：因为从 ISR 中选举 Leader 副本，就会出现数据不同步情况，就会导致数据丢失。</p>\n<h1 id=\"十三、副本选举\"><a href=\"#十三、副本选举\" class=\"headerlink\" title=\"十三、副本选举\"></a>十三、副本选举</h1><p>Kafka 在选取 Leader 副本时候，考虑到负载均衡的平衡性，会将不同的分区的 Leader 副本分配到不同的 Broker 中，这样既能避免 Broker 宕机导致多个分区不可用，也能平衡 Broker 的负载。</p>\n<p>Kafka 引入了优先副本的概念，优先副本的意思是，在分区的所有 AR 集合列表中的第一个副本，理想状态下就是该分区的 Leader 副本。</p>\n<p>例如kafka集群由3台broker组成，创建了一个名为 <code>topic-partitions</code> 的topic，设置partition为3，副本数为3，partition0中AR列表为 <code>[1,2,0]</code>，那么分区0的优先副本为1</p>\n<p><img src=\"/img/882565aff441558b043b911c7c240f29_MD5.png\" alt=\"副本选举\"></p>\n<p>当分区leader节点发生故障时，其中的一个follower节点就会选举为新的leader节点。当原来leader的节点恢复之后，它只能成为一个follower节点，此时就导致了集群负载不均衡。比如分区1的leader节点broker2崩溃了，此时选举了在broker1上的分区1follower节点作为新的leader节点。当broker2重新恢复时，此时的kafka集群状态如下：</p>\n<p><img src=\"/img/d9e50eff06b436f7621152f2739a05c5_MD5.png\" alt=\"副本选举\"></p>\n<p>可以看到，此时broker1上负载更大，而broker2上没有负载。</p>\n<p><strong>「为了解决上述负载不均衡的情况，kafka支持了优先副本选举，优先副本指的是一个分区所在的AR集合的第一个副本」</strong>。</p>\n<p>比如上面的分区1，它的AR集合是<code>[2,0,1]</code>，表示分区1的优先副本就是在broker2上。</p>\n<p>理想情况下，优先副本应该就是leader副本，kafka保证了优先副本的均衡分布，而这与broker节点宕机与否没有关系。</p>\n<p><strong>「优先副本选举就是对分区leader副本进行选举的时候，尽可能让优先副本成为leader副本」</strong>，针对上述的情况，只要再触发一次优先副本选举就能保证分区负载均衡。</p>\n<p>kafka支持自动优先副本选举功能，默认每5分钟触发一次优先副本选举操作。</p>\n<h1 id=\"十四、网络通信模型\"><a href=\"#十四、网络通信模型\" class=\"headerlink\" title=\"十四、网络通信模型\"></a>十四、网络通信模型</h1><p><img src=\"/img/93681a72e52523561d8f052cb74d6da0_MD5.png\" alt=\"网络通信模型\"></p>\n<p>Broker 中有个<code>Acceptor(mainReactor)</code>监听新连接的到来，与新连接建连之后轮询选择一个<code>Processor(subReactor)</code>管理这个连接。</p>\n<p>而<code>Processor</code>会监听其管理的连接，当事件到达之后，读取封装成<code>Request</code>，并将<code>Request</code>放入共享请求队列中。</p>\n<p>然后IO线程池不断的从该队列中取出请求，执行真正的处理。处理完之后将响应发送到对应的<code>Processor</code>的响应队列中，然后由<code>Processor</code>将<code>Response</code>返还给客户端。</p>\n<p>每个<code>listener</code>只有一个<code>Acceptor线程</code>，因为它只是作为新连接建连再分发，没有过多的逻辑，很轻量。</p>\n<p><code>Processor</code> 在Kafka中称之为网络线程，默认网络线程池有3个线程，对应的参数是<code>num.network.threads</code>，并且可以根据实际的业务动态增减。</p>\n<p>还有个 IO 线程池，即<code>KafkaRequestHandlerPool</code>，执行真正的处理，对应的参数是<code>num.io.threads</code>，默认值是 8。</p>\n<p>IO线程处理完之后会将<code>Response</code>放入对应的<code>Processor</code>中，由<code>Processor</code>将响应返还给客户端。</p>\n<p>可以看到网络线程和IO线程之间利用的经典的生产者 - 消费者模式，不论是用于处理Request的共享请求队列，还是IO处理完返回的Response。</p>\n<h1 id=\"十五、幂等性\"><a href=\"#十五、幂等性\" class=\"headerlink\" title=\"十五、幂等性\"></a>十五、幂等性</h1><h2 id=\"「幂等性Producer」\"><a href=\"#「幂等性Producer」\" class=\"headerlink\" title=\"「幂等性Producer」\"></a><strong>「幂等性Producer」</strong></h2><p>在 Kafka 中，Producer 默认不是幂等性的，但是我们可以创建幂等性 Producer。<code>enable.idempotence</code> 设置为 True，即可保证 Producer 自动升级成幂等性 Producer，其他所有的代码逻辑都不需要更改。配置后，Kafka 自动做消息的去重操作。</p>\n<p>其实，底层原理非常简单，就是经典的以空间换时间的做法，Broker 多保存一些字段，当 Producer 发送消息请求的时候，Broker 能够判断消息是否重复，进而再丢弃掉重复消息。</p>\n<h2 id=\"「幂等性-Producer-的作用范围」\"><a href=\"#「幂等性-Producer-的作用范围」\" class=\"headerlink\" title=\"「幂等性 Producer 的作用范围」\"></a>「幂等性 Producer 的作用范围」</h2><ul>\n<li><p>幂等性只能保证单个分区上的幂等性，无法实现多分区幂等性。</p>\n</li>\n<li><p>幂等性针对单个会话的幂等性，不会实现跨会话的幂等性。</p>\n</li>\n</ul>\n<blockquote>\n<p>这里的会话，可以理解成 Producer 进程的一次运行，当重启了 Producer 进程之后，这种幂等性就丧失了。</p>\n</blockquote>\n<h1 id=\"十六、事务\"><a href=\"#十六、事务\" class=\"headerlink\" title=\"十六、事务\"></a>十六、事务</h1><p>Kafka 自从 0.11 版本就开始支持事务，目前主要是在 read committed 隔离级别上做事务。它能保证多条消息原子性地写入到目标分区，同时也能保证Consumer 只能看到事务成功提交的消息。</p>\n<h2 id=\"「事务型-Producer」\"><a href=\"#「事务型-Producer」\" class=\"headerlink\" title=\"「事务型 Producer」\"></a>「事务型 Producer」</h2><p>事物型 Producer 能够保证将消息原子性的写入到多个分区中。这批消息要么全部成功，要么全部失败，另外，事务型 Producer 也不怕进程的重启。当 Producer 重启之后，Kafka 仍能保证它们发送消息的精确一次处理。</p>\n<p>设置事务型 Producer 的方式也比较简单，满足两个设置即可：</p>\n<ul>\n<li><p>和幂等性 Producer 一样，开启 <code>enable.idempotence = true</code>。</p>\n</li>\n<li><p>设置 Producer 端参数 <code>transactional.id</code>，最好设置一个有意义的名字。</p>\n</li>\n</ul>\n<p>此外，还需要在 Producer 代码中做一些调整，如这段代码所示：</p>\n<pre><code class=\"language-java\">producer.initTransactions();  \ntry &#123;  \n            producer.beginTransaction();  \n            producer.send(record1);  \n            producer.send(record2);  \n            producer.commitTransaction();  \n&#125; catch (KafkaException e) &#123;  \n            producer.abortTransaction();  \n&#125;\n</code></pre>\n<p>和普通Producer代码相比，事务型Producer的显著特点是调用了一些事务API，如initTransaction、beginTransaction、commitTransaction和abortTransaction，它们分别对应事务的初始化、事务开始、事务提交以及事务终止。</p>\n<p>实际上即使写入失败，Kafka也会把它们写入到底层的日志中，也就是说Consumer还是会看到这些消息。</p>\n<p>有一个 <code>isolation.level</code> 参数，这个参数有两个取值：</p>\n<ol>\n<li><p><code>read_uncommitted</code>：这是默认值，表明Consumer能够读取到Kafka写入的任何消息，不论事务型Producer提交事务还是终止事务，其写入的消息都可以读取，如果你用了事务型Producer，那么对应的Consumer就不要使用这个值。</p>\n</li>\n<li><p><code>read_committed</code>：表明Consumer只会读取事务型Producer成功提交事务写入的消息，它也能看到非事务型Producer写入的所有消息</p>\n</li>\n</ol>\n<h1 id=\"十七、拦截器\"><a href=\"#十七、拦截器\" class=\"headerlink\" title=\"十七、拦截器\"></a>十七、拦截器</h1><p><strong>Kafka 拦截器分为生产者拦截器和消费者拦截器。</strong> 生产者拦截器允许你在发送消息前以及消息提交成功之后植入拦截器逻辑。而消费者拦截器支持消费消息前以及提交位移后编写特定逻辑。可以将一组懒啊节气串联成一个大的拦截器，Kafka 会按照顺序依次执行拦截器逻辑。</p>\n<p>当前 Kafka 拦截器是通过参数配置完成，生产者和消费者两端都有个相同的参数 <code>interceptor.classes</code>，它指定的是一组类的列表，每个类就是特定逻辑的拦截器实现类。</p>\n<pre><code class=\"language-java\">Properties props = new Properties();   \nList interceptors = new ArrayList&lt;&gt;();   \ninterceptors.add(&quot;com.yourcompany.kafkaproject.interceptors.AddTimestampInterceptor&quot;); // 拦截器1   \ninterceptors.add(&quot;com.yourcompany.kafkaproject.interceptors.UpdateCounterInterceptor&quot;); // 拦截器2   \nprops.put(ProducerConfig.INTERCEPTOR_CLASSES_CONFIG, interceptors);\n</code></pre>\n<p>怎么编写 AddTimeStampInterceptor 和 UpdateCounterInterceptor 类呢？</p>\n<p>这两个类以及所有 Producer 端拦截器实现类都要继承 <code>org.apache.kafka.clients.producer.ProducerInterceptor</code> 接口。</p>\n<p>该接口是 Kafka 提供的，里面有两个核心方法：</p>\n<ol>\n<li><p>onSend：该方法在消息发送前被调用。</p>\n</li>\n<li><p>onAcknowledgement：该方法在消息成功提交或者提交失败之后被调用。onAcknowledgement 的调用要早于 callback 的调用。值得注意的是，这个方法和 onSend 方法不在同一个线程中调用，因此如果在这两个方法中调用了共享可变变量，一定要注意线程安全问题。</p>\n</li>\n</ol>\n<p>同理，消费者拦截器也是同样的方法，都要继承 <code>org.apache.kafka.clients.consumer.ConsumerInterceptor</code> 接口，这里也有两个核心方法。</p>\n<ol>\n<li><p>onConsuume：该方法在消息返回给 Consumer 程序之前调用。</p>\n</li>\n<li><p>onCommit：Consumer 在提交位移之后调用该方法。通常做法是在该方法中做一些记账的动作，例如打印日志等。</p>\n</li>\n</ol>\n<h1 id=\"十八、控制器（Controller）\"><a href=\"#十八、控制器（Controller）\" class=\"headerlink\" title=\"十八、控制器（Controller）\"></a>十八、控制器（Controller）</h1><p><strong>控制器组件（controller），主要是用于在 Apache Zookeeper 的帮助下管理和协调整个 Kafka 集群。</strong></p>\n<p>集群中任意一台 Broker 都可以成为控制器角色。在 Kafka 集群启动的时候，第一个在 Zookeeper 中创建&#x2F;controller 节点的 Broker 会被指定为控制器。</p>\n<p>控制器主要的功能如下：</p>\n<ol>\n<li><strong>主题管理（创建，删除，增加分区）</strong></li>\n</ol>\n<p>控制器帮我们完成对 Kafka 主题的创建，删除以及分区增加的操作。</p>\n<ol start=\"2\">\n<li><p><strong>分区重分配</strong></p>\n</li>\n<li><p><strong>Preferred 领导者选举</strong></p>\n</li>\n</ol>\n<p>Preferred 领导者选举主要是 Kafka 为了避免部分 Broker 负载过重而提供的一种换 Leader 的方案。</p>\n<ol start=\"4\">\n<li><strong>集群成员管理（新增 Broker、Broker 主动关闭、Broker 宕机）</strong></li>\n</ol>\n<p>在 Zookeeper 对 Kafka 协助管理工程中，<strong>「Watch 机制」</strong> 和 <strong>「临时节点」</strong> 是两个重要的机制。 </p>\n<p>Broker 的创建时候，Zookeeper 会在 Zookeeper 的 &#x2F;broker&#x2F;ids 下创建专属的 znode 节点，这个节点就是临时节点。一旦节点创建完成，ZooKeeper 就会通过 Watch 机制将消息通知推送给控制器，只要，控制器就能自动感知这个变化，进而开启后续的新增 Broker 作业。</p>\n<p>当Broker宕机或主动关闭后，该Broker与ZooKeeper的会话结束，这个znode会被自动删除。</p>\n<p>同理，ZooKeeper的Watch机制将这一变更推送给控制器，这样控制器就能知道有Broker关闭或宕机了，从而进行善后。</p>\n<ol start=\"5\">\n<li><strong>数据服务</strong></li>\n</ol>\n<p>控制器上保存了最全的集群元数据信息，其他所有Broker会定期接收控制器发来的元数据更新请求，从而更新其内存中的缓存数据。</p>\n<h2 id=\"「控制器故障转移（Failover）」\"><a href=\"#「控制器故障转移（Failover）」\" class=\"headerlink\" title=\"「控制器故障转移（Failover）」\"></a>「控制器故障转移（Failover）」</h2><p><strong>「故障转移指的是，当运行中的控制器突然宕机或意外终止时，Kafka能够快速地感知到，并立即启用备用控制器来代替之前失败的控制器」</strong>。这个过程就被称为Failover，该过程是自动完成的，无需你手动干预。</p>\n<p><img src=\"/img/5711d6da84f2000a181c356e080deec4_MD5.png\" alt=\"控制器故障转移\"></p>\n<p>最开始时，Broker 0是控制器。当Broker 0宕机后，ZooKeeper通过Watch机制感知到并删除了<code>/controller</code>临时节点。</p>\n<p>之后，所有存活的Broker开始竞选新的控制器身份。Broker 3最终赢得了选举，成功地在ZooKeeper上重建了 <code>/controller</code> 节点。之后，Broker 3会从ZooKeeper中读取集群元数据信息，并初始化到自己的缓存中。</p>\n<p>至此，控制器的Failover完成，可以行使正常的工作职责了。</p>\n<h1 id=\"二十、日志存储\"><a href=\"#二十、日志存储\" class=\"headerlink\" title=\"二十、日志存储\"></a>二十、日志存储</h1><p>Kafka中的消息是以主题为基本单位进行归类的，每个主题在逻辑上相互独立。</p>\n<p>每个主题又可以分为一个或多个分区，在不考虑副本的情况下，一个分区会对应一个日志。</p>\n<p>但设计者考虑到随着时间推移，日志文件会不断扩大，因此为了防止Log过大，设计者引入了日志分段（LogSegment）的概念，将Log切分为多个LogSegment，便于后续的消息维护和清理工作。</p>\n<p>下图描绘了主题、分区、副本、Log、LogSegment五者之间的关系。</p>\n<p><img src=\"/img/4cc119f98ed02df15c264d1cf428d32b_MD5.png\" alt=\"关系图解\"></p>\n<p><strong>「LogSegment」</strong></p>\n<p>在Kafka中，每个Log对象又可以划分为多个LogSegment文件，每个LogSegment文件包括一个日志数据文件和两个索引文件（偏移量索引文件和消息时间戳索引文件）。</p>\n<p>其中，每个LogSegment中的日志数据文件大小均相等（该日志数据文件的大小可以通过在Kafka Broker的 <code>config/server.properties</code> 配置文件的中的**「log.segment.bytes」**进行设置，默认为1G大小（1073741824字节），在顺序写入消息时如果超出该设定的阈值，将会创建一组新的日志数据和索引文件）。</p>\n<p><img src=\"/img/5c376d6d6186292ebc461285ce0ac879_MD5.png\" alt=\"日志内部结构\"></p>\n<h1 id=\"常用参数\"><a href=\"#常用参数\" class=\"headerlink\" title=\"常用参数\"></a>常用参数</h1><p><strong>「broker端配置」</strong></p>\n<ul>\n<li><code>broker.id</code></li>\n</ul>\n<p>每个 kafka broker 都有一个唯一的标识来表示，这个唯一的标识符即是 <code>broker.id</code>，它的默认值是 0。</p>\n<p>这个值在 kafka 集群中必须是唯一的，这个值可以任意设定，</p>\n<ul>\n<li><code>port</code></li>\n</ul>\n<p>如果使用配置样本来启动 kafka，它会监听 9092 端口，修改 port 配置参数可以把它设置成任意的端口。</p>\n<p>要注意，如果使用 1024 以下的端口，需要使用 root 权限启动 kakfa。</p>\n<ul>\n<li><code>zookeeper.connect</code></li>\n</ul>\n<p>用于保存 broker 元数据的 Zookeeper 地址是通过 <code>zookeeper.connect</code> 来指定的。</p>\n<p>比如可以这么指定 <code>localhost:2181</code> 表示这个 Zookeeper 是运行在本地 2181 端口上的。</p>\n<p>我们也可以通过 比如我们可以通过 <code>zk1:2181,zk2:2181,zk3:2181</code> 来指定 <code>zookeeper.connect</code> 的多个参数值。</p>\n<p>该配置参数是用冒号分割的一组 <code>hostname:port/path</code> 列表，其含义如下</p>\n<ul>\n<li><p>hostname 是 Zookeeper 服务器的机器名或者 ip 地址。</p>\n</li>\n<li><p>port 是 Zookeeper 客户端的端口号</p>\n</li>\n<li><p>&#x2F;path 是可选择的 Zookeeper 路径，Kafka 路径是使用了 <code>chroot</code> 环境，如果不指定默认使用跟路径。</p>\n</li>\n</ul>\n<blockquote>\n<p>❝<br>如果你有两套 Kafka 集群，假设分别叫它们 kafka1 和 kafka2，那么两套集群的<code>zookeeper.connect</code>参数可以这样指定：<code>zk1:2181,zk2:2181,zk3:2181/kafka1</code>和<code>zk1:2181,zk2:2181,zk3:2181/kafka2</code><br>❞</p>\n</blockquote>\n<ul>\n<li><code>log.dirs</code></li>\n</ul>\n<p>Kafka 把所有的消息都保存到磁盘上，存放这些日志片段的目录是通过 <code>log.dirs</code> 来制定的，它是用一组逗号来分割的本地系统路径，<code>log.dirs</code> 是没有默认值的，<strong>「你必须手动指定他的默认值」</strong>。</p>\n<p>其实还有一个参数是 <code>log.dir</code>，这个配置是没有 <code>s</code> 的，默认情况下只用配置 <code>log.dirs</code> 就好了，比如你可以通过 <code>/home/kafka1,/home/kafka2,/home/kafka3</code> 这样来配置这个参数的值。</p>\n<ul>\n<li><code>auto.create.topics.enable</code></li>\n</ul>\n<p>默认情况下，kafka 会自动创建主题</p>\n<p><code>auto.create.topics.enable</code>参数建议最好设置成 false，即不允许自动创建 Topic。</p>\n<p><strong>「主题相关配置」</strong></p>\n<ul>\n<li><code>num.partitions</code></li>\n</ul>\n<p>num.partitions 参数指定了新创建的主题需要包含多少个分区，该参数的默认值是 1。</p>\n<ul>\n<li><code>default.replication.factor</code></li>\n</ul>\n<p>这个参数比较简单，它表示 kafka保存消息的副本数。</p>\n<ul>\n<li><code>log.retention.ms</code></li>\n</ul>\n<p>Kafka 常根据时间来决定数据可以保留多久。</p>\n<p>默认使用<code>log.retention.hours</code>参数来配置时间，默认是 168 个小时，也就是一周。</p>\n<p>除此之外，还有两个参数<code>log.retention.minutes</code> 和<code>log.retentiion.ms</code> 。</p>\n<p>这三个参数作用是一样的，都是决定消息多久以后被删除，推荐使用<code>log.retention.ms</code>。</p>\n<ul>\n<li><code>message.max.bytes</code></li>\n</ul>\n<p>broker 通过设置 <code>message.max.bytes</code> 参数来限制单个消息的大小，默认是 1000 000， 也就是 1MB，如果生产者尝试发送的消息超过这个大小，不仅消息不会被接收，还会收到 broker 返回的错误消息。</p>\n<ul>\n<li><code>retention.ms</code></li>\n</ul>\n<p>规定了该主题消息被保存的时常，默认是7天，即该主题只能保存7天的消息，一旦设置了这个值，它会覆盖掉 Broker 端的全局参数值。</p>\n<h1 id=\"消息丢失问题\"><a href=\"#消息丢失问题\" class=\"headerlink\" title=\"消息丢失问题\"></a>消息丢失问题</h1><h2 id=\"「生产者程序丢失数据」\"><a href=\"#「生产者程序丢失数据」\" class=\"headerlink\" title=\"「生产者程序丢失数据」\"></a><strong>「生产者程序丢失数据」</strong></h2><p>目前Kafka Producer是异步发送消息的，也就是说如果你调用的是<code>producer.send(msg)</code>这个API，那么它通常会立即返回，但此时你不能认为消息发送已成功完成。</p>\n<p><strong>如果用这个方式，可能会有哪些因素导致消息没有发送成功呢？</strong></p>\n<p>其实原因有很多：</p>\n<ol>\n<li>例如网络抖动，导致消息压根就没有发送到Broker端；</li>\n</ol>\n<p>如果是网络抖动导致的失败，可以通过 Producer 中的参数 <code>retries</code> (重试次数)设置比较合理的值来解决，一般来说为 3。同时，建议还要设置重试间隔 <code>retry.backoff.ms</code> 来避免 3 次重试间隔太短导致多次失败。</p>\n<ol start=\"2\">\n<li>或者消息本身不合格导致Broker拒绝接收（比如消息太大了，超过了Broker的承受能力）等。</li>\n</ol>\n<p>实际上，解决此问题的方法非常简单：Producer永远要使用带有回调通知的发送API，也就是说不要使用 <code>producer.send(msg)</code>，而要使用 <code>producer.send(msg, callback)</code>。在 SpringBoot 中可以用类似的方式来处理：</p>\n<pre><code class=\"language-java\">ListenableFuture&lt;SendResult&lt;String, Object&gt;&gt; future = kafkaTemplate.send(smsBusiPrediction, msg);  \nfuture.addCallback(new ListenableFutureCallback&lt;SendResult&lt;String, Object&gt;&gt;() &#123;  \n   @Override  \n   public void onSuccess(SendResult&lt;String, Object&gt; result) &#123;  \n      log.info(&quot;=====向kafka推送信息成功=====&quot;);  \n   &#125;  \n   @Override  \n   public void onFailure(Throwable ex) &#123;  \n      log.info(&quot;=====向kafka推送信息失败！！=====&quot;,ex);  \n   &#125;   \n&#125;);\n</code></pre>\n<p>它能准确地告诉你消息是否真的提交成功了。一旦出现消息提交失败的情况，你就可以有针对性地进行处理。</p>\n<h2 id=\"「消费者程序丢失数据」\"><a href=\"#「消费者程序丢失数据」\" class=\"headerlink\" title=\"「消费者程序丢失数据」\"></a><strong>「消费者程序丢失数据」</strong></h2><p>Consumer端丢失数据主要体现在Consumer端要消费的消息不见了。</p>\n<p>下面这张图它清晰地展示了Consumer端的位移数据。</p>\n<p><img src=\"/img/adc9951c2edb1fba60deea2d87fb2d44_MD5.png\" alt=\"Consumer端的位移数据\"></p>\n<p>比如对于Consumer A而言，它当前的位移值就是9；Consumer B的位移值是11。Consumer程序从Kafka获取到消息后开启了多个线程异步处理消息，而Consumer程序自动地向前更新位移。</p>\n<p>假如其中某个线程运行失败了，它负责的消息没有被成功处理，但位移已经被更新了，因此这条消息对于Consumer而言实际上是丢失了。这里的关键在于Consumer自动提交位移。这个问题的解决方案也很简单：<strong>「如果是多线程异步处理消费消息，Consumer程序不要开启自动提交位移，而是要应用程序手动提交位移」</strong>。</p>\n<h2 id=\"「Kafka-内部出现消息丢失」\"><a href=\"#「Kafka-内部出现消息丢失」\" class=\"headerlink\" title=\"「Kafka 内部出现消息丢失」\"></a><strong>「Kafka 内部出现消息丢失」</strong></h2><p>试想一种情况：假如 leader 副本所在的 broker 突然挂掉，那么就要从 follower 副本重新选出一个 leader ，但是 leader 的数据还有一些没有被 follower 副本的同步的话，就会造成消息丢失。</p>\n<p><strong>设置 <code>acks = all</code></strong></p>\n<p>解决办法就是我们设置 <code>acks = all</code>。<code>acks</code> 是 Kafka 生产者(Producer) 很重要的一个参数。</p>\n<p>acks 的默认值即为 1，代表我们的消息被 leader 副本接收之后就算被成功发送。当我们配置 <strong>acks &#x3D; all</strong> 表示只有所有 ISR 列表的副本全部收到消息时，生产者才会接收到来自服务器的响应. 这种模式是最高级别的，也是最安全的，可以确保不止一个 Broker 接收到了消息. 该模式的延迟会很高.</p>\n<p><strong>设置 <code>replication.factor &gt;= 3</code></strong></p>\n<p>为了保证 leader 副本能有 follower 副本能同步消息，我们一般会为 topic 设置 <code>replication.factor &gt;= 3</code>。这样就可以保证每个 分区(partition) 至少有 3 个副本。虽然造成了数据冗余，但是带来了数据的安全性。</p>\n<p><strong>设置 <code>min.insync.replicas &gt; 1</code></strong></p>\n<p>一般情况下我们还需要设置 <strong><code>min.insync.replicas&gt; 1</code></strong> ，这样配置代表消息至少要被写入到 2 个副本才算是被成功发送。<strong>min.insync.replicas</strong> 的默认值为 1 ，在实际生产中应尽量避免默认值 1。</p>\n<p>但是，为了保证整个 Kafka 服务的高可用性，你需要确保 <strong><code>replication.factor &gt; min.insync.replicas</code></strong> 。为什么呢？设想一下假如两者相等的话，只要是有一个副本挂掉，整个分区就无法正常工作了。这明显违反高可用性！一般推荐设置成 <strong><code>replication.factor = min.insync.replicas + 1</code></strong>。</p>\n<p><strong>设置 <code>unclean.leader.election.enable = false</code></strong></p>\n<blockquote>\n<p><strong>Kafka 0.11.0.0 版本开始 unclean.leader.election.enable 参数的默认值由原来的 true 改为 false</strong></p>\n</blockquote>\n<p>我们最开始也说了我们发送的消息会被发送到 leader 副本，然后 follower 副本才能从 leader 副本中拉取消息进行同步。多个 follower 副本之间的消息同步情况不一样，当我们配置了 <strong><code>unclean.leader.election.enable = false</code></strong> 的话，当 leader 副本发生故障时就不会从 follower 副本中和 leader 同步程度达不到要求的副本中选择出 leader ，这样降低了消息丢失的可能性。</p>\n<h2 id=\"「最佳实践」\"><a href=\"#「最佳实践」\" class=\"headerlink\" title=\"「最佳实践」\"></a>「最佳实践」</h2><p>总结Kafka 避免消息丢失的配置：</p>\n<ol>\n<li><p>在 Producer 端：</p>\n<ul>\n<li><p>不要使用 <code>producer.send(msg)</code>，而要使用 <code>producer.send(msg, callback)</code>，一定要使用带有回调通知的 send 方法。</p>\n</li>\n<li><p>设置 <code>retries</code>  为一个较大的值。这里的<code>retries</code>同样是Producer的参数，对应前面提到的Producer自动重试，当出现网络的瞬时抖动时，消息发送可能会失败，此时配置了 <code>retries &gt; 0</code> 的 Producer 能够自动重试消息发送，避免消息丢失。</p>\n</li>\n<li><p>设置 <code>acks = all</code>，acks 是 Producer 的一个参数，代表了你对已提交消息的定义，如果设置成 all，则表明所有副本 Broker 都要接收到消息，该消息才算是已提交。</p>\n</li>\n</ul>\n</li>\n<li><p>在 Consumer 端：</p>\n<ul>\n<li>确保消息消费完成再提交，Consumer端有个参数 <code>enable.auto.commit</code>，最好把它设置成 false，并采用手动提交位移的方式。</li>\n</ul>\n</li>\n<li><p>在 Kafka 内部：</p>\n<ul>\n<li><p>设置 <code>unclean.leader.election.enable = false</code>，这是 Broker 端的参数，它控制的是哪些 Broker 有资格竞选分区的 Leader，如果一个 Broker 落后原先的 Leader 太多，那么它一旦成为新的 Leader，必然会造成消息的丢失，故一般都要将该参数设置成 false，即不允许这种情况的发生。</p>\n</li>\n<li><p>设置 <code>replication.factor &gt;= 3</code>，这也是 Broker 端的参数，将消息多保存几份，目前防止消息丢失的主要机制就是冗余。</p>\n</li>\n<li><p>设置 <code>min.insync.replicas &gt; 1</code>，这依然是 Broker 端参数，控制的是消息至少要被写入到多少个副本才算是已提交，设置成大于 1 可以提升消息持久性，在实际环境中千万不要使用默认值 1。</p>\n</li>\n<li><p>确保 <code>replication.factor &gt; min.insync.replicas</code>，如果两者相等，那么只要有一个副本挂机，整个分区就无法正常工作了，我们不仅要改善消息的持久性，防止数据丢失，还要在不降低可用性的基础上完成，推荐设置成 <code>replication.factor = min.insync.replicas + 1</code>。</p>\n</li>\n</ul>\n</li>\n</ol>\n<h1 id=\"重复消费问题\"><a href=\"#重复消费问题\" class=\"headerlink\" title=\"重复消费问题\"></a>重复消费问题</h1><p><strong>「消费重复的场景」</strong></p>\n<p>在 <code>enable.auto.commit</code> 默认值true情况下，出现重复消费的场景有以下几种：</p>\n<blockquote>\n<p>❝<br>consumer 在消费过程中，应用进程被强制kill掉或发生异常退出。<br>❞</p>\n</blockquote>\n<p>例如在一次poll 500条消息后，消费到200条时，进程被强制kill消费到offset未提交，或出现异常退出导致消费到offset未提交。</p>\n<p>下次重启时，依然会重新拉取500消息，造成之前消费到200条消息重复消费了两次。</p>\n<p>解决方案：在发生异常时正确处理未提交的offset</p>\n<p><strong>「消费者消费时间过长」</strong></p>\n<p><code>max.poll.interval.ms</code>参数定义了两次poll的最大间隔，它的默认值是 5 分钟，表示你的 Consumer 程序如果在 5 分钟之内无法消费完 poll 方法返回的消息，那么 Consumer 会主动发起离开组的请求，Coordinator 也会开启新一轮 Rebalance。</p>\n<p>举例：单次拉取11条消息，每条消息耗时30s，11条消息耗时5分钟30秒，由于<code>max.poll.interval.ms</code>  默认值5分钟，所以消费者无法在5分钟内消费完，consumer会离开组，导致rebalance。</p>\n<p>在消费完11条消息后，consumer会重新连接broker，再次rebalance，因为上次消费的offset未提交，再次拉取的消息是之前消费过的消息，造成重复消费。</p>\n<p><strong>「解决方案：」</strong></p>\n<p>1、提高消费能力，提高单条消息的处理速度；根据实际场景可讲<code>max.poll.interval.ms</code>值设置大一点，避免不必要的rebalance；可适当减小<code>max.poll.records</code>的值，默认值是500，可根据实际消息速率适当调小。</p>\n<p>2、生成消息时，可加入唯一标识符如消息id，在消费端，保存最近的1000条消息id存入到redis或mysql中，消费的消息时通过前置去重。</p>\n<h1 id=\"消息顺序问题\"><a href=\"#消息顺序问题\" class=\"headerlink\" title=\"消息顺序问题\"></a>消息顺序问题</h1><p>我们都知道 <code>kafka</code> 的 <code>topic</code> 是无序的，但是一个 <code>topic</code> 包含多个 <code>partition</code>，每个 <code>partition</code> 内部是有序的（分区内采用尾插法）</p>\n<p><img src=\"/img/466a6f44f4b183a6bae184c90378b300_MD5.png\" alt=\"消息消费顺序\"></p>\n<p><strong>「乱序场景1」</strong></p>\n<p>因为一个topic可以有多个partition，kafka只能保证partition内部有序</p>\n<p><strong>「解决方案」</strong></p>\n<p>1、可以设置topic，有且只有一个partition，<strong>不推荐，这样就违背了 Kafka 的设计初衷，即多分区，多副本的概念。</strong></p>\n<p>2、<strong>（推荐）</strong> 根据业务需要，需要顺序的指定为同一个partition，在 Broker 提交的时候，规定 topic，partition，key，data 四个参数统一。</p>\n<p><strong>「乱序场景2」</strong></p>\n<p>对于同一业务进入了同一个消费者组之后，用了多线程来处理消息，会导致消息的乱序</p>\n<p><strong>「解决方案」</strong></p>\n<p>消费者内部根据线程数量创建等量的内存队列，对于需要顺序的一系列业务数据，根据key或者业务数据，放到同一个内存队列中，然后线程从对应的内存队列中取出并操作</p>\n<p><img src=\"/img/bb94c4025a04733be2eb858d968eaffd_MD5.png\" alt=\"解决方案\"></p>\n<p><strong>「通过设置相同key来保证消息有序性，会有一点缺陷：」</strong></p>\n<p>例如消息发送设置了重试机制，并且异步发送，消息A和B设置相同的key，业务上A先发，B后发，由于网络或者其他原因A发送失败，B发送成功；A由于发送失败就会重试且重试成功，这时候消息顺序B在前A在后，与业务发送顺序不一致，如果需要解决这个问题，需要设置参数 <code>max.in.flight.requests.per.connection=1</code>，其含义是限制客户端在单个连接上能够发送的未响应请求的个数，设置此值是1表示kafka broker在响应请求之前client不能再向同一个broker发送请求，这个参数默认值是5</p>\n<h1 id=\"高性能原因\"><a href=\"#高性能原因\" class=\"headerlink\" title=\"高性能原因\"></a>高性能原因</h1><h2 id=\"「顺序读写」\"><a href=\"#「顺序读写」\" class=\"headerlink\" title=\"「顺序读写」\"></a><strong>「顺序读写」</strong></h2><p>kafka的消息是不断追加到文件中的，这个特性使<code>kafka</code>可以充分利用磁盘的顺序读写性能</p>\n<p>顺序读写不需要硬盘磁头的寻道时间，只需很少的扇区旋转时间，所以速度远快于随机读写</p>\n<p>Kafka 可以配置异步刷盘，不开启同步刷盘，异步刷盘不需要等写入磁盘后返回消息投递的 ACK，所以它提高了消息发送的吞吐量，降低了请求的延时</p>\n<h2 id=\"「零拷贝」\"><a href=\"#「零拷贝」\" class=\"headerlink\" title=\"「零拷贝」\"></a><strong>「零拷贝」</strong></h2><p>传统的 IO 流程，需要先把数据拷贝到内核缓冲区，再从内核缓冲拷贝到用户空间，应用程序处理完成以后，再拷贝回内核缓冲区</p>\n<p>这个过程中发生了多次数据拷贝</p>\n<p>为了减少不必要的拷贝，<code>Kafka</code> 依赖 Linux 内核提供的 <code>Sendfile</code> 系统调用</p>\n<p>在 Sendfile 方法中，数据在内核缓冲区完成输入和输出，不需要拷贝到用户空间处理，这也就避免了重复的数据拷贝</p>\n<p>在具体的操作中，Kafka 把所有的消息都存放在单独的文件里，在消息投递时直接通过 <code>Sendfile</code> 方法发送文件，减少了上下文切换，因此大大提高了性能</p>\n<h2 id=\"「MMAP技术」\"><a href=\"#「MMAP技术」\" class=\"headerlink\" title=\"「MMAP技术」\"></a><strong>「MMAP技术」</strong></h2><p>除了 <code>Sendfile</code> 之外，还有一种零拷贝的实现技术，即 Memory Mapped Files</p>\n<p>Kafka 使用 <code>Memory Mapped Files</code> 完成内存映射，<code>Memory Mapped Files</code> 对文件的操作不是 <code>write/read</code>，而是直接对内存地址的操作，如果是调用文件的 <code>read</code> 操作，则把数据先读取到内核空间中，然后再复制到用户空间，但 <code>MMAP</code>可以将文件直接映射到用户态的内存空间，省去了用户空间到内核空间复制的开销</p>\n<p>Producer生产的数据持久化到broker，采用mmap文件映射，实现顺序的快速写入</p>\n<p>Customer从broker读取数据，采用sendfile，将磁盘文件读到OS内核缓冲区后，直接转到socket buffer进行网络发送。</p>\n<h2 id=\"「批量发送读取」\"><a href=\"#「批量发送读取」\" class=\"headerlink\" title=\"「批量发送读取」\"></a><strong>「批量发送读取」</strong></h2><p>Kafka 的批量包括批量写入、批量发布等。它在消息投递时会将消息缓存起来，然后批量发送</p>\n<p>同样，消费端在消费消息时，也不是一条一条处理的，而是批量进行拉取，提高了消息的处理速度</p>\n<h2 id=\"「数据压缩」\"><a href=\"#「数据压缩」\" class=\"headerlink\" title=\"「数据压缩」\"></a><strong>「数据压缩」</strong></h2><p>Kafka还支持对消息集合进行压缩，<code>Producer</code>可以通过<code>GZIP</code>或<code>Snappy</code>格式对消息集合进行压缩</p>\n<p>压缩的好处就是减少传输的数据量，减轻对网络传输的压力</p>\n<p>Producer压缩之后，在<code>Consumer</code>需进行解压，虽然增加了CPU的工作，但在对大数据处理上，瓶颈在网络上而不是CPU，所以这个成本很值得</p>\n<h2 id=\"「分区机制」\"><a href=\"#「分区机制」\" class=\"headerlink\" title=\"「分区机制」\"></a><strong>「分区机制」</strong></h2><p>kafka中的topic中的内容可以被分为多partition存在，每个partition又分为多个段segment，所以每次操作都是针对一小部分做操作，很轻便，并且增加 <code>并行操作</code> 的能力</p>\n<h1 id=\"常见面试题\"><a href=\"#常见面试题\" class=\"headerlink\" title=\"常见面试题\"></a>常见面试题</h1><h2 id=\"「Kafka是Push还是Pull模式？」\"><a href=\"#「Kafka是Push还是Pull模式？」\" class=\"headerlink\" title=\"「Kafka是Push还是Pull模式？」\"></a><strong>「Kafka是Push还是Pull模式？」</strong></h2><p>Kafka最初考虑的问题是，customer应该从brokes拉取消息还是brokers将消息推送到consumer。</p>\n<p>在这方面，Kafka遵循了一种大部分消息系统共同的传统的设计：producer将消息推送到broker，consumer从broker拉取消息。</p>\n<p>push模式由broker决定消息推送的速率，对于不同消费速率的consumer就不太好处理了。</p>\n<p>消息系统都致力于让consumer以最大的速率最快速的消费消息，push模式下，当broker推送的速率远大于consumer消费的速率时，consumer恐怕就要崩溃了。</p>\n<blockquote>\n<p>❝<br>Kafka中的Producer和Consumer采用的是Push-and-Pull模式，即Producer向Broker Push消息，Consumer从Broker Pull消息。<br>❞</p>\n</blockquote>\n<p>Pull模式的一个好处是consumer可以自主决定是否批量的从broker拉取数据。</p>\n<p>Pull有个缺点是，如果broker没有可供消费的消息，将导致consumer不断在循环中轮询，直到新消息到达。</p>\n<h2 id=\"「Kafka如何保证高可用-」\"><a href=\"#「Kafka如何保证高可用-」\" class=\"headerlink\" title=\"「Kafka如何保证高可用?」\"></a><strong>「Kafka如何保证高可用?」</strong></h2><p><a href=\"https://mp.weixin.qq.com/s?__biz=MzUyOTg1OTkyMA==&mid=2247484980&idx=1&sn=6e0c7112dd72d0edc284009e7503b2ac&scene=21#wechat_redirect\">面试题：Kafka如何保证高可用？有图有真相</a></p>\n<h2 id=\"「Kafk的使用场景」\"><a href=\"#「Kafk的使用场景」\" class=\"headerlink\" title=\"「Kafk的使用场景」\"></a><strong>「Kafk的使用场景」</strong></h2><p>业界Kafka实际应用场景</p>\n<blockquote>\n<p>❝<br>异步通信<br>❞</p>\n</blockquote>\n<p>消息中间件在异步通信中用的最多，很多业务流程中，如果所有步骤都同步进行可能会导致核心流程耗时非常长，更重要的是所有步骤都同步进行一旦非核心步骤失败会导致核心流程整体失败，因此在很多业务流程中Kafka就充当了异步通信角色。</p>\n<blockquote>\n<p>❝<br>日志同步<br>❞</p>\n</blockquote>\n<p>大规模分布式系统中的机器非常多而且分散在不同机房中，分布式系统带来的一个明显问题就是业务日志的查看、追踪和分析等行为变得十分困难，对于集群规模在百台以上的系统，查询线上日志很恐怖。</p>\n<p>为了应对这种场景统一日志系统应运而生，日志数据都是海量数据，通常为了不给系统带来额外负担一般会采用异步上报，这里Kafka以其高吞吐量在日志处理中得到了很好的应用。</p>\n<blockquote>\n<p>❝<br>实时计算<br>❞</p>\n</blockquote>\n<p>随着据量的增加，离线的计算会越来越慢，难以满足用户在某些场景下的实时性要求，因此很多解决方案中引入了实时计算。</p>\n<p>很多时候，即使是海量数据，我们也希望即时去查看一些数据指标，实时流计算应运而生。</p>\n<p>实时流计算有两个特点，一个是实时，随时可以看数据；另一个是流。</p>\n<h2 id=\"「Kafka-的多分区（Partition）以及多副本（Replica）机制有什么好处呢？」\"><a href=\"#「Kafka-的多分区（Partition）以及多副本（Replica）机制有什么好处呢？」\" class=\"headerlink\" title=\"「Kafka 的多分区（Partition）以及多副本（Replica）机制有什么好处呢？」\"></a><strong>「Kafka 的多分区（Partition）以及多副本（Replica）机制有什么好处呢？」</strong></h2><ol>\n<li><p>Kafka 通过给特定 Topic 指定多个 Partition, 而各个 Partition 可以分布在不同的 Broker 上, 这样便能提供比较好的并发能力（负载均衡）。</p>\n</li>\n<li><p>Partition 可以指定对应的 Replica 数, 这也极大地提高了消息存储的安全性, 提高了容灾能力，不过也相应的增加了所需要的存储空间。</p>\n</li>\n</ol>\n<p>参考资料：</p>\n<blockquote>\n<p> <a href=\"https://javaguide.cn/high-performance/message-queue/kafka-questions-01.html\">Kafka常见问题总结</a></p>\n<p> <a href=\"https://mp.weixin.qq.com/s/zfHoSsuSpXWOaxQrm7uvkA\">Kafka核心知识总结！</a></p>\n</blockquote>\n","excerpt":"","more":"<p>Kafka 服务器端的代码是由 Scala 代码编写，支持面向对象编程和函数式数据，编译过后也是普通的 .class 文件。其的作用：提供统一的、高吞吐量、低延迟的平台来处理实时数据</p>\n<h1 id=\"一、基本概念\"><a href=\"#一、基本概念\" class=\"headerlink\" title=\"一、基本概念\"></a>一、基本概念</h1><h2 id=\"「Kafka-是什么？主要应用场景什么？」\"><a href=\"#「Kafka-是什么？主要应用场景什么？」\" class=\"headerlink\" title=\"「Kafka 是什么？主要应用场景什么？」\"></a>「Kafka 是什么？主要应用场景什么？」</h2><p>Kafka 是一个分布式流式处理平台。</p>\n<p><img src=\"/img/6aaf06740442599b6c52bb586545dfb8_MD5.png\" alt=\"Kafka结构示意图\"></p>\n<p><strong>1 . 主题</strong>：发布订阅的对象是主题（Topic），可以为每个业务、每个应用甚至每类数据都创建专属的主题</p>\n<p><strong>2 . 生产者和消费者</strong>：向主题发布消息的客户端应用程序成为生产者，生产者程序通常持续不断地向一个或者多个主题发送消息</p>\n<p><strong>3 . Broker</strong>：集群由多个 Broker 组成，Broker 负责接收和处理客户端发送过来的请求，以及对消息进行持久化。</p>\n<pre><code>虽然多个 Broker 能够运行在同一台机器上，但是常见的做法是将不同的 Broker 分散运行在不同的机器上，这样如果某一台机器宕机，即使在它上面运行的所有 Broker 进程都挂掉了，其他机器上的 Broker 也一眼能够对外提供服务。\n</code></pre>\n<p> <strong>4 . 备份机制</strong>：备份的思想很简单，就是把相同的数据拷贝到多台机器上，而这些相同的数据拷贝被称为副本。</p>\n<pre><code>Kafka 定义了两类副本：领导者副本和追随者副本。\n\n前者对外提供服务，即与客户端程序进行交互；后者只是被动地追随领导者副本而已，不对外进行交互。\n</code></pre>\n<p><strong>5 . 分区</strong>：分区机制指的是将每个主题分成多个分区，每个分区是一组有序的消息日志</p>\n<pre><code>生产者生产的每条消息总会被发送到一个分区中，也就是说如果向一个双分区的主题发送一条消息，该条消息要不在分区 0 中，要不在分区 1 中。\n\n生产者向分区中写入消息，每条消息在分区中的位置信息叫做位移。\n</code></pre>\n<p><strong>6 . 消费者组</strong>：多个消费者实例共同组成一个组来消费一组主题</p>\n<pre><code>这组主题中的每个分区只会被组内的一个消费者实例消费，其他消费者实例不能消费它\n\n消息引擎的两大模型：\n\n\t如果所有实例都属于同一个 Group，那么它实现的就是消息队列模型\n\n\t如果所有实例属于不同的 Group，那么它实现的就是发布/订阅模型\n</code></pre>\n<blockquote>\n<p><strong>RocketMQ 的消息模型和 Kafka 基本是完全一样的。唯一的区别是 Kafka 中没有队列这个概念，与之对应的是 Partition（分区）。</strong></p>\n</blockquote>\n<p><strong>7 . Coordinator：协调者</strong>：负责为 Group 执行 Rebalance 以及提供唯一管理和组成员管理等。</p>\n<p><strong>8 . 消费者位移：Consumer offset</strong>：消费者消费进度，每个消费者都有自己的消费者位移</p>\n<p><strong>9 . 重平衡：Rebalance</strong>：消费者组内某个消费者实例挂掉后，其他消费者实例自动重新分配订阅主题分区的过程。</p>\n<p>Rebalance 是 Kafka 消费者端实现高可用的重要手段</p>\n<p><strong>10 . AR（Assigned Replicas）</strong>：分区中的所有副本统称为 AR。</p>\n<p>所有消息都会先发送到领导者副本，然后追随者副本才能从领导者中拉去信息进行同步</p>\n<p>但是同步期间，追随者副本相对于领导者副本而言有一定程度的滞后，这时候追随者副本和领导者副本并非完全同步状态</p>\n<p><strong>11 . OSR（Out Sync Replicas）</strong>：AR 的一个子集，其中都是追随者副本和领导者副本没有完全同步或者之后的副本集合</p>\n<p><strong>12 . ISR（In Sync Replicas）</strong>：AR 的一个子集，ISR 中的副本都是和领导者副本是保持完全同步的副本。</p>\n<p>如果某一个在 ISR 中的 follower 副本落后于 leader 副本太多，就会从 ISR 中移除，否则如果完全同步，会从 OSR 中移到 ISR 集合中</p>\n<p><strong>13 . HW（High Watermark）</strong>：高水位，标识一个特定的消息偏移量（offset），消费者只能来取这个水位 offset 之前的消息</p>\n<p>下图表示一个日志文件，这个日志文件中只有9条消息，第一条消息的offset（LogStartOffset）为0，最有一条消息的offset为8，offset为9的消息使用虚线表示的，代表下一条待写入的消息。</p>\n<p>日志文件的 HW 为6，表示消费者只能拉取offset在 0 到 5 之间的消息，offset为6的消息对消费者而言是不可见的。</p>\n<p><img src=\"/img/ce77dd7ccc11dc7642aad16560000cb9_MD5.png\" alt=\"消息偏移量展示\"></p>\n<p><strong>14 . LEO（Log End Offset）</strong>：标识当前日志文件中下一条待写入的消息的offset</p>\n<h1 id=\"二、系统架构\"><a href=\"#二、系统架构\" class=\"headerlink\" title=\"二、系统架构\"></a>二、系统架构</h1><p>Kafka 基础框架：一个生产者发送一个消息到 Kafka 的一个 Topic，该 Topic 的消息存放在 Broker 中，消费者订阅这个 Topic，然后从 Broker 中消费消息。</p>\n<p>1.<strong>消息状态</strong>：在 Kafka 中，消息是否被消费的状态保存在消费者中，Broker 不会关系消息是否消费，或者被谁消费，消费者会记录一个 offset 值（指向分区中下一条被消费的消息位置），如果 offset 被错误设置可能会导致同一条消息多次消费或者丢失。</p>\n<p>2.<strong>消息持久化</strong>：Kafka 会把消息持久化到本地文件系统中，并且具有极高的性能。</p>\n<p>3.<strong>批量发送</strong>：Kafka 支持以消息集合为单位进行批量发送，以提高效率。</p>\n<p>4.<strong>Push-and-Pull</strong>：Kafka 中的生产者和消费者采用的是 Push-and-Pull 模式，即生产者向 Broker Push 消息，消费者从 Broker Pull 消息。</p>\n<p>5.<strong>分区机制</strong>：Kafka 的 Broker 是支持分区的，Producer 可以决定将消息放在哪个 Partition，在一个 Partition 中的消息顺序就是 Producer 发送消息的顺序，一个 Topic 中的 Partition 是可以配置的，Partition 是保证 Kafka 高吞吐量的重要保证。</p>\n<p><img src=\"/img/68d9aaa9dd34dbc9d516201de1f2ab55_MD5.png\" alt=\"系统架构\"></p>\n<p>通常情况下，一个 Kafka 体系是包含多个 Producer，多个 Broker，多个 Consumer，以及一个 Zookeeper 集群</p>\n<h1 id=\"三、生产者分区\"><a href=\"#三、生产者分区\" class=\"headerlink\" title=\"三、生产者分区\"></a>三、生产者分区</h1><p>一条 Kafka 消息的的组织架构是三层：主题（Topic）- 分区（Partition）- 消息（Message）</p>\n<p>分区其实是一种负载均衡的做法。因为同一个 Topic 下的不同分区可以在不同 Broker 节点上，并且，数据读写是以分区为粒度，这样的话，每个节点都可以执行自己分区的消息的读写。除此之外，还能通过增加节点来提高吞吐量。</p>\n<h2 id=\"「分区策略」\"><a href=\"#「分区策略」\" class=\"headerlink\" title=\"「分区策略」\"></a>「分区策略」</h2><p>所谓的分区策略其实就是决定生产者将消息发送到哪个分区的算法。</p>\n<h3 id=\"自定义分区策略\"><a href=\"#自定义分区策略\" class=\"headerlink\" title=\"自定义分区策略\"></a>自定义分区策略</h3><p>如果需要自己定义分区策略，在编写生产者程序的时候，可以编写一个具体的实现类<code>org.apache.kafka.clients.producer.Partitioner</code> 接口。这接口也非常简单，只定义了两个方法：partition() 和 close() 方法。通常情况我们只需要实现 partition() 方法即可。</p>\n<pre><code class=\"language-java\">int partition(String topic, Object key, byte[] keyBytes, Object value, byte[] valueBytes, Cluster cluster);\n</code></pre>\n<p>这里的 topic、key、keyBytes、value 和 valueBytes 都属于消息数据，cluster 则是集群信息（比如当前 Kafka 集群共有多少主题、多少 Broker 等）。</p>\n<h3 id=\"轮询策略\"><a href=\"#轮询策略\" class=\"headerlink\" title=\"轮询策略\"></a>轮询策略</h3><p>也称 Round-robin 策略，即顺序分配。轮询策略是 Kafka 生产者 API 默认提供的分区策略。</p>\n<p>轮询策略有非常优秀的负载均衡表现，它总是保证消息最大限度的平均分配到所有的分区上，所以默认下它是最合理的分区策略，也是最常用的分区策略。</p>\n<h3 id=\"随机策略\"><a href=\"#随机策略\" class=\"headerlink\" title=\"随机策略\"></a>随机策略</h3><p>也称 Randomness 策略。想要实现随机策略的 partition 方法，其实很简单，只需要两行代码即可：</p>\n<pre><code class=\"language-java\"> List partitions = cluster.partitionsForTopic(topic);\n return ThreadLocalRandom.current().nextInt(partitions.size());\n</code></pre>\n<p>先计算出该主题的总分区数，然后随机返回一个小于它的正整数。</p>\n<p>随机策略在负载均衡上面略逊于轮询策略。在老的版本里面常用随机策略，再后来的版本更新中被轮询策略所替代。</p>\n<h3 id=\"按消息键保序策略\"><a href=\"#按消息键保序策略\" class=\"headerlink\" title=\"按消息键保序策略\"></a>按消息键保序策略</h3><p>Kafka 允许为每条消息定义消息键，简称 Key。</p>\n<p>Key 可以为具体的业务代码，也可以用来表征消息元数据。在 Kafka 中如果消息定义了 Key，那么就可以保证同一个 Key 的消息进入相同的分区，有序分区下的消息处理是有顺序的，所以这个策略被称为安消息键保存策略。</p>\n<p>实现这个策略的 partition 方法同样简单，只需要下面两行代码即可：</p>\n<pre><code class=\"language-java\"> List partitions = cluster.partitionsForTopic(topic);\n return Math.abs(key.hashCode()) % partitions.size();\n</code></pre>\n<p>其实，Kafka 默认的分区策略是两种：<br>\t如果指定了 Key ，默认实现按消息键保序策略；<br>\t如果未指定 Key，则使用轮询策略。</p>\n<h3 id=\"「其他分区策略」\"><a href=\"#「其他分区策略」\" class=\"headerlink\" title=\"「其他分区策略」\"></a>「其他分区策略」</h3><p>另外还有一种比较常见的，所谓的基于地理位置的分区策略。当然这种策略只针对大规模的 Kafka 集群，特别是跨城市、跨国家甚至是跨大洲的集群。我们可以根据 Broker 所在的 IP 地址实现定制化的分区策略。比如下段代码：</p>\n<pre><code class=\"language-java\">List partitions = cluster.partitionsForTopic(topic);\nreturn partitions.stream().filter(p -&gt; isSouth(p.leader().host())).map(PartitionInfo::partition).findAny().get();\n</code></pre>\n<p>我们可以从所有分区中找出那些 Leader 副本在南方的所有分区，然后随机挑选一个进行消息发送。</p>\n<h1 id=\"四、生产者压缩算法\"><a href=\"#四、生产者压缩算法\" class=\"headerlink\" title=\"四、生产者压缩算法\"></a>四、生产者压缩算法</h1><p>为什么要压缩消息？压缩消息是为了更好的节省网络传输贷款以及 Kafka Broker 端的磁盘占用。</p>\n<h3 id=\"「Kafka-是如何压缩消息的呢？」\"><a href=\"#「Kafka-是如何压缩消息的呢？」\" class=\"headerlink\" title=\"「Kafka 是如何压缩消息的呢？」\"></a>「Kafka 是如何压缩消息的呢？」</h3><p>Kafka 的消息层次分为两层：消息集合和消息。</p>\n<p>??？</p>\n<h3 id=\"「何时压缩？」\"><a href=\"#「何时压缩？」\" class=\"headerlink\" title=\"「何时压缩？」\"></a>「何时压缩？」</h3><p>在 Kafka 中，压缩可能发生在两个地方：生产者端和 Broker 端。</p>\n<p>在生产者程序中配置 compression.type 参数即表示弃用指定类型的压缩算法。</p>\n<p>比如这段代码中展示了如何构建一个开启 GZIP 的 Producer 对象：</p>\n<pre><code class=\"language-java\">Properties props = new Properties();\nprops.put(&quot;bootstrap.servers&quot;, &quot;localhost:9092&quot;);\nprops.put(&quot;acks&quot;, &quot;all&quot;);\nprops.put(&quot;key.serializer&quot;, &quot;org.apache.kafka.common.serialization.StringSerializer&quot;); props.put(&quot;value.serializer&quot;, &quot;org.apache.kafka.common.serialization.StringSerializer&quot;); // 开启GZIP压缩\nprops.put(&quot;compression.type&quot;, &quot;gzip&quot;); //Producer的压缩算法是GZIP\nProducer producer = new KafkaProducer&lt;&gt;(props);\n</code></pre>\n<p>这样 Producer 启动之后生产的每个消息集合都是经 GZIP 压缩过的，故而能很好的节省网络传输贷款以及 Kafka Broker 端的磁盘占用。</p>\n<p>有两种情况可能导致 Broker 重新压缩消息：</p>\n<ul>\n<li>情况一：Broker 端指定了和 Producer 端不同的压缩算法。</li>\n</ul>\n<p>一旦 Broker 端设置了不同的 compression.type 值，就一定要小心了，因为可能会发生预料之外的压缩、解压缩操作，通常表现为 Broker 端 CPU 使用率飙升。</p>\n<ul>\n<li>情况二：Broker 端发生了消息格式转换。</li>\n</ul>\n<p>所谓的消息格式转换主要是为了兼容老版本的消费者程序。在一个生产环境中，Kafka 集群中同时保存多个版本的消息格式非常常见。为了兼容老版本的格式，Broker 端会对新版本消息指向向老版本的转换。这个过程会涉及到消息的解压缩和重新压缩。一般情况下这种消息格式转换成对性能是有很大影响的，除了这里的压缩之外，他还让 Kafka 丧失了 Zero Copy 特性。</p>\n<h3 id=\"「何时解压缩？」\"><a href=\"#「何时解压缩？」\" class=\"headerlink\" title=\"「何时解压缩？」\"></a>「何时解压缩？」</h3><p>有压缩必有解压缩！通常来说解压缩发生在消费者程序中。</p>\n<p><strong>基本过程：Producer 端压缩，Broker 端保持，Consumer 端解压缩。</strong></p>\n<p>注意：除了在 Consumer 端解压缩外，Broker 端也会进行解压缩。</p>\n<p>每个压缩过的消息集合在 Broker 端写入时都要发生解压缩操作，目的就是为了对消息执行各种验证。我们必须承认这种解压缩对 Broker 端性能有一定的影响，特别是对 CPU 的使用率而言。</p>\n<h3 id=\"「各种压缩算法对比」\"><a href=\"#「各种压缩算法对比」\" class=\"headerlink\" title=\"「各种压缩算法对比」\"></a>「各种压缩算法对比」</h3><p>Kafka 支持 4 种压缩算法：GZIP、Snappy 、LZ4 和 zstd(Zstandard 算法)。在实际使用中，各个算法各有千秋。</p>\n<p>吞吐量：LZ4 &gt; Snappy &gt; zst 和 GZIP；</p>\n<p>压缩比：zstd &gt; LZ4 &gt; GZIP &gt; Snappy；</p>\n<p>占用宽带：zstd &lt; LZ4 和 GZIP &lt; Snappy；</p>\n<p>在CPU使用率方面，各个算法表现得差不多，只是在压缩时Snappy算法使用的CPU较多一些，而在解压缩时GZIP算法则可能使用更多的CPU。</p>\n<h1 id=\"五、消费者组\"><a href=\"#五、消费者组\" class=\"headerlink\" title=\"五、消费者组\"></a>五、消费者组</h1><p>Consumer Group 是 Kafka 提供可拓展且具有容错性的消费机制。</p>\n<p>既然是一个组，那么组内必然是可以有多个消费者或者消费者实例，它们共享一个公共的 ID，这个 ID 被称为 Group ID。组内所有的消费者协调在一起来消费订阅主题的所有分区。每个分区只能有同一个消费组内的一个 Consumer 实例来消费。</p>\n<h3 id=\"Consumer-Group-三个特性\"><a href=\"#Consumer-Group-三个特性\" class=\"headerlink\" title=\"Consumer Group 三个特性\"></a>Consumer Group 三个特性</h3><p>1.Consumer Group 下可以有一个或者多个 Consumer 实例，这里的实例可以是一个单独的进程，也可以是同一个进程下的线程。</p>\n<p>2.Group ID 是一个字符串，在一个 Kafka 集群中，它表示唯一的一个 Consumer Group。</p>\n<p>3.Consumer Group 下所有实例订阅的主题的单独分区，只能分配给组内的某个 Consumer 实例消费，这个分区当然也可以被其他的 Group 消费。</p>\n<p>Kafka 仅仅使用 Consumer Group 这一种机制，却同时实现了传统消息引擎系统的两大模型：</p>\n<ul>\n<li><p>如果所有实例都是属于同一个 Group，那么它实现的是消息队列模型；</p>\n</li>\n<li><p>如果所有实例分别属于不同的 Group，那么它实现的就是发布&#x2F;订阅模型。</p>\n</li>\n</ul>\n<h3 id=\"一个-Group-下应该有多少个-Consumer-实例呢？\"><a href=\"#一个-Group-下应该有多少个-Consumer-实例呢？\" class=\"headerlink\" title=\"一个 Group 下应该有多少个 Consumer 实例呢？\"></a>一个 Group 下应该有多少个 Consumer 实例呢？</h3><p>理想情况下，Consumer 实例的数量应该等于 Group 订阅主题的分区总数。</p>\n<blockquote>\n<p>假设一个 Comsumer Group 订阅了 3 个主题，分别是 A、B、C，它们的分区数分别是 1，2，3，那么通常情况下，为改 Group 设置 6 个 Consumer 实例是比较理想的情形，因为它能最大限度的视线高伸缩性。</p>\n</blockquote>\n<h3 id=\"针对-Consumer-Group，Kafka-是怎么管理位移呢？\"><a href=\"#针对-Consumer-Group，Kafka-是怎么管理位移呢？\" class=\"headerlink\" title=\"针对 Consumer Group，Kafka 是怎么管理位移呢？\"></a>针对 Consumer Group，Kafka 是怎么管理位移呢？</h3><p>老版本 Consumer Group 把位移保存在 ZooKeeper 中。Apache ZooKeeper 是一个分布式的协调服务框架，Kafka 重度依赖它实现的各种各样的协调管理。将唯一保存到 ZooKeeper 外部系统的做法，最显而易见的好处就是减少了 Kafka Broker 端的状态保存开销。</p>\n<p>但是，慢慢的发现一个问题，即 ZooKeeper 这类元框架其实并不适合进行频繁的写更新，而 Consumer Group 的位移更新是一个非常频繁的操作。这种大吞吐量的写操作会极大拖慢 ZooKeeper 集群的性能。于是，新版本的 Consumer Group 中，Kafka 社区重新设计了 Consumer Group 的位移管理方式，采用将位移保存在 Kafka 内部主题的方法。</p>\n<p>这个内部主题就是_counsumer_offset.</p>\n<h1 id=\"六、消费者策略\"><a href=\"#六、消费者策略\" class=\"headerlink\" title=\"六、消费者策略\"></a>六、消费者策略</h1><p>消费者消费同一主题的哪个分区，是通过消费者策略决定的。</p>\n<h4 id=\"轮询-Round\"><a href=\"#轮询-Round\" class=\"headerlink\" title=\"轮询 Round\"></a>轮询 Round</h4><p>Kakfa 默认的消费者策略——轮询，通过轮询方式，决定消费者消费的分区。</p>\n<p><img src=\"/img/2ca562d1dc3a2d8d06c7c2bfe2c394c8_MD5.png\" alt=\"轮询策略\"></p>\n<h4 id=\"范围计算-Range\"><a href=\"#范围计算-Range\" class=\"headerlink\" title=\"范围计算 Range\"></a>范围计算 Range</h4><p>对一个消费者组来说，决定消费方式是以分区总数除以消费者总数来决定，一般如果不能整除，往往是从头开始将剩余的分区分配开</p>\n<p><img src=\"/img/c3276b5f713b8b0641463b496c196ce2_MD5.png\" alt=\"范围计算\"></p>\n<h4 id=\"范围计算升华版-Sticky\"><a href=\"#范围计算升华版-Sticky\" class=\"headerlink\" title=\"范围计算升华版 Sticky\"></a>范围计算升华版 Sticky</h4><p>是在0.11.x，新增的，它和前面两个不是很一样，它是在Range上的一种升华，且前面两个当同组内有新的消费者加入或者旧的消费者退出的时候，会从新开始决定消费者消费方式，但是Sticky，在同组中有新的新的消费者加入或者旧的消费者退出时，不会直接开始新的Range分配，而是保留现有消费者原来的消费策略，将退出的消费者所消费的分区平均分配给现有消费者，新增消费者同理，同其他现存消费者的消费策略中分离。</p>\n<h1 id=\"七、位移提交\"><a href=\"#七、位移提交\" class=\"headerlink\" title=\"七、位移提交\"></a>七、位移提交</h1><p>假设一个分区中有 10 条消息，唯一分别是 0 到 9.</p>\n<p>某个 Consumer 应用已经消费了 5 条消息，这就说明该 Consumer 消费了位移为 0 到 4 的 5 条消息，此时 Consumer 的位移是 5，指向了下一条消息的位移。因为 Consumer 能够同时消费多个分区的数据，所以位移的提交实际上是在分区粒度上进行的，即 <strong>Consumer 需要为分配给它的每一个分区提交各自的位移数据。</strong></p>\n<p>位移提交分为自动提交和手动提交；从 Consumer 端的角度来说，位移提交分为同步提交和异步提交。</p>\n<p>开启自动提交位移的方法：Consumer 端有一个参数 <code>enable.auto.commint</code>，把它设置为 true 或者不设置它即可。</p>\n<p>如果开启了自动提交，Consumer 端还有个参数：<code>auto.commit.interval.ms</code>。默认为 5 秒，表明 Kafka 每 5 秒会自动提交一次位移。</p>\n<pre><code class=\"language-java\">Properties props = new Properties();\nprops.put(&quot;bootstrap.servers&quot;, &quot;localhost:9092&quot;);\nprops.put(&quot;group.id&quot;, &quot;test&quot;);\n//开启自动提交\nprops.put(&quot;enable.auto.commit&quot;, &quot;true&quot;);\n//自动提交时间间隔\nprops.put(&quot;auto.commit.interval.ms&quot;, &quot;2000&quot;);\nprops.put(&quot;key.deserializer&quot;, &quot;org.apache.kafka.common.serialization.StringDeserializer&quot;);\nprops.put(&quot;value.deserializer&quot;, &quot;org.apache.kafka.common.serialization.StringDeserializer&quot;);\nKafkaConsumer consumer = new KafkaConsumer&lt;&gt;(props);\nconsumer.subscribe(Arrays.asList(&quot;foo&quot;, &quot;bar&quot;));\nwhile (true) &#123;\n    ConsumerRecords records = consumer.poll(100);\n    for (ConsumerRecord record : records)\n        System.out.printf(&quot;offset = %d, key = %s, value = %s%n&quot;, record.offset(), record.key(), record.value());\n&#125;\n</code></pre>\n<p>如果要开启手动提交，只需要将 <code>enable.auto.commit</code> 设置为 <code>false</code> 即可。</p>\n<p>手动提交需要调用相应的 API 手动提交位移。最简单的 API 就是 <code>KafkaConsumer#commitSync()</code> 。该方法会提交 <code>KafkaConsumer#poll()</code> 返回的最新位移。从名字上来看，这是一个同步方法，即该方法会一直等待，直到位移成功提交之后才会返回。如果提交过程中出现异常，该方法会将异常信息抛出。</p>\n<p>下面这段代码展示了 commitSync() 的使用方法：</p>\n<pre><code class=\"language-java\">while (true) &#123;\n        ConsumerRecords records =consumer.poll(Duration.ofSeconds(1));\n        process(records); // 处理消息\n        try &#123;\n            consumer.commitSync();\n        &#125; catch (CommitFailedException e) &#123;\n            handle(e); // 处理提交失败异常\n        &#125;\n&#125;\n</code></pre>\n<p>自动提交时，Kafka 会保证再开始调用 poll 方法时候，提交上次 poll 方法返回的所有消息。从顺序上来说，poll 方法的逻辑是先提交上一批消息的位移，然后在处理下一批消息，因此，自动提交能保证不会出消费丢失的情况。但是自动提交位移的问题在于，<strong>可能出现重复消费。</strong></p>\n<p>手动提交的好处在于更加灵活，可以完全把控位移提交的时机和频率。但是他也有一个缺陷，就是在调用 <code>commitSync()</code> 时候会处于阻塞状态，直到远端 Broker 返回提交结果，这个状态才能结束。</p>\n<p>这时候，手动提交的另一个方法就出现了 <code>KafkaConsumer#commitAsync()</code>。从名字上看，这是个异步操作。调用 <code>commitAsync()</code> 方法之后，它会立即返回，不会阻塞，因此不影响 Consumer 应用的 TPS（吞吐量）。由于它是异步的，Kafka 提供了一个回调函数（callback），供开发者实现提交之后的逻辑，比如记录日志或处理异常。</p>\n<p>下面这段代码展示了调用 commintAsync() 方法：</p>\n<pre><code class=\"language-java\">while (true) &#123;\n            ConsumerRecords records = consumer.poll(Duration.ofSeconds(1));\n            process(records); // 处理消息\n            consumer.commitAsync((offsets, exception) -&gt; &#123;\n\t\t\t\t if (exception != null)\n\t\t\t\t\t handle(exception);\n\t\t\t&#125;);\n&#125;\n</code></pre>\n<p>commitAsync 的问题在于，出了问题时它不会重试。</p>\n<p>显然，如果手动提交，我们需要将 commitSync 和 commitAsync 组合使用才能达到最理想的效果：<br>\t1.我们可以利用 commitSync 的自动动重试来规避那些瞬时错误，比如网络的瞬时都懂，Broker 端的 GC 问题，因为这些问题是短暂的，自动重试通常都会成功。<br>\t2.我们不希望程序总是处于阻塞状态，影响 TPS。</p>\n<p>我们来看一下下面这段代码，它展示的是如何将两个 API 方法结合使用进行手动提交。</p>\n<pre><code class=\"language-java\">try &#123;\n    while(true) &#123;\n        ConsumerRecords records = consumer.poll(Duration.ofSeconds(1));\n        process(records); // 处理消息\n        commitAysnc(); // 使用异步提交规避阻塞\n    &#125;\n&#125; catch(Exception e) &#123;\n        handle(e); // 处理异常\n&#125; finally &#123;\n      try &#123;\n        consumer.commitSync(); // 最后一次提交使用同步阻塞式提交\n&#125; finally &#123;\n \t\tconsumer.close();\n&#125;\n&#125;\n</code></pre>\n<p>试想这样一个场景：poll 方法返回的不是 500 条消息，而是 5000 条。</p>\n<p>那么，你肯定不想把这 5000 条消息处理完之后再提交位移，因为一旦中间出差错，之前处理的全部都要重来一遍。那么我们可以每处理完 100 条消息就提交一次位移，这样避免大批量的消息重新消费。</p>\n<p>Kafka Consumer API 为手动提交提供了这样的方法：<code>commitSync(Map)</code> 和 <code>commitAsync(Map)</code>。它们的参数是一个 Map 对象，键就是 TopicPartition，即消费的分区，而值是一个 OffsetAndMetadata 对象，保存主要是位移数据。</p>\n<p>以 commitAsync 为例，展示一段代码。实际上，commitSync 的调用方法和它一模一样的。</p>\n<pre><code class=\"language-java\">private Map offsets = new HashMap&lt;&gt;();\nint count = 0;\n……\nwhile (true) &#123;\n    ConsumerRecords records = consumer.poll(Duration.ofSeconds(1));\n        for (ConsumerRecord record: records) &#123;\n            process(record);  // 处理消息\n            offsets.put(new TopicPartition(record.topic(), record.partition()),new OffsetAndMetadata(record.offset() + 1)；\n            if（count % 100 == 0）\n                consumer.commitAsync(offsets, null); // 回调处理逻辑是null\n                count++;\n &#125;\n&#125;\n</code></pre>\n<p>与调用无参的 commitAsync 不同，这里调用了带 Map 对象参数的 commitAsync 进行细粒度的位移提交。</p>\n<h1 id=\"八、重平衡\"><a href=\"#八、重平衡\" class=\"headerlink\" title=\"八、重平衡\"></a>八、重平衡</h1><p>重平衡 Rebalance 本质上是一种协议，规定了一个 Consumer Group 如何分配订阅 Topic 的每一个分区。Kafka 在为 Consumer Group 内的 Consumer 分配分区的过程，就是 Rebalance。</p>\n<p>Rebalance 触发条件有三个：</p>\n<ul>\n<li><p>组内成员发生变化，即有新的 Consumer 实例加入组或者离开祖，或者因崩溃而退出组。</p>\n</li>\n<li><p>订阅主题数发生变化，Consumer Group 可以通过正则表达式方式订阅主题，比如 <code>consumer.subscribe(Pattern.compile(&quot;t.*c&quot;))</code> 就表明 Group 订阅所有以字母 t 开头、字母 c 结尾的主题，所以在 Consumer Group 运行过程中，如果创建了满足要求的主题，就会发生 Rebalance。</p>\n</li>\n<li><p>订阅主题的分区发生变化，Kafka 当前只能允许增加一个主题的分区数，当主题的分区数发生变化，就会触发该主题下所有 Group 的 Rebalance。</p>\n</li>\n</ul>\n<h3 id=\"「分配策略」\"><a href=\"#「分配策略」\" class=\"headerlink\" title=\"「分配策略」\"></a>「分配策略」</h3><p>当前Kafka默认提供了3种分配策略，每种策略都有一定的优势和劣势，社区会不断地完善这些策略，保证提供最公平的分配策略，即每个Consumer实例都能够得到较为平均的分区数。</p>\n<h3 id=\"「Coordinator-会在什么情况下确认-Consumer-实例挂掉了从而要退组？」\"><a href=\"#「Coordinator-会在什么情况下确认-Consumer-实例挂掉了从而要退组？」\" class=\"headerlink\" title=\"「Coordinator 会在什么情况下确认 Consumer 实例挂掉了从而要退组？」\"></a>「Coordinator 会在什么情况下确认 Consumer 实例挂掉了从而要退组？」</h3><p>在 Consumer Group 完成 Rebalance 之后，每个 Consumer 实例都会定期的想 Coordinator 发送心跳请求，表明它还活着。如果某个 Consumer 不能及时的发送心跳请求，娜美 Coordinator 就会认为它已经死了，从而将其从 Group 中移除，然后开启新一轮的 Rebalance。</p>\n<p>Consumer 端设置参数里面有个：<code>session.timeout.ms</code>。默认为 10 秒，即如果 Coordinator 在 10 秒内没有收到 Group 的某个 Consumer 的心跳请求，则认为它已经挂了。除了这个参数，还有个允许开发者控制发送心跳的频率的参数，就是 <code>heartbeat.interval.ms</code>。这个参数设置越小，Consumer 发送心跳请求的频率越高。当然，请求频率越高，消耗的带宽资源也就越高。</p>\n<p>除此之外，Consumer 端还有个参数，用于控制 Consumer 实际消费能力对对 Rebalance 的影响，即：<code>max.pool.interval.ms</code> 参数。它限定了 Consumer 端应用程序两次调用 poll 方法的最大时间间隔。默认值为 5 分钟，表示如果 Consumer 在 5 分钟内没有消费完 poll 方法返回的消息，那么 Consumer 会主动发起离开 Group 的请求，Coordinator 则会开启新的 Rebalance。</p>\n<h3 id=\"「如何设置避免-Rebalance」\"><a href=\"#「如何设置避免-Rebalance」\" class=\"headerlink\" title=\"「如何设置避免 Rebalance」\"></a>「如何设置避免 Rebalance」</h3><ol>\n<li><p>如果是因为未能及时发送心跳请求，导致 Consumer 被踢出 Group ，引发的 Rebalance。则可以设置 <code>session.timeout.ms</code> 和 <code>heartbeat.interval.ms</code> 的值。</p>\n<ul>\n<li><p>设置 <code>session.timeout.ms</code> &#x3D; 6s。</p>\n</li>\n<li><p>设置 <code>heartbeat.interval.ms</code> &#x3D; 2s。</p>\n</li>\n<li><p>要保证 Consumer 实例在被判定为 dead 之前，能够发送 3 条心跳请求，即 <code>session.timeout.ms &gt;= 3 * heartbeat.interval.ms</code>。</p>\n</li>\n</ul>\n</li>\n</ol>\n<p>将 <code>session.timeout.ms</code> 设置为 6s 主要是为了让 Coordinator 能更快定位已经挂掉的 Consumer。</p>\n<ol start=\"2\">\n<li>如果是因为 Consumer 消费时间过长导致的 Rebalance。在开发过程中，为业务逻辑处理留足充足的时间，这样 Consumer 就不会因为处理这些消息太长而引起 Rebalance 了。</li>\n</ol>\n<h1 id=\"九、ConsumerOffsets\"><a href=\"#九、ConsumerOffsets\" class=\"headerlink\" title=\"九、ConsumerOffsets\"></a>九、ConsumerOffsets</h1><p><code>_consumer_offsets</code> 是一个 Kafka 的普通主题，它主要是保存 Kafka Consumer 的位移信息。当 Kafka 中的第一个 Consumer 启动时候，就会创建该主题。其默认分区数是 50，副本数是 3。<code>_consumer_offsets</code> 主题是一个普通的 Kafka 主题，开发者可以手动的创建、修改甚至删除它。但是它的消息格式是 Kafka 自己定义的，不能修改。开发者只能按照规定传入消息，否则内部不能成功解析，就会导致 Broker 崩溃。</p>\n<p><code>_consumer_offsets</code> 有 3 中消息格式：</p>\n<ul>\n<li><p>用于保存 Consumer Group 信息的消息。</p>\n</li>\n<li><p>用于删除 Group 过期位移甚至删除 Group 的消息。</p>\n</li>\n<li><p>保存了位移值。</p>\n</li>\n</ul>\n<p>前面已经提到过，Kafka 的提交方式有两种：自动提交和手动提交。</p>\n<p>手动提交：比较灵活可控，通过调用 <code>commitSync()</code> 或者 <code>commitAsync()</code> 等 Kafka Consumer 的 API，Kafka 会向 <code>_consumer_offsets</code> 主题中写入相应的消息。</p>\n<p>自动提交：显著优点就是省事，不用操心位移提交的事情，就能保证消息不会丢失。但是自动提交位移的有个问题，只要 Consumer 一直启动着，它就会无限期的向位移主题写入消息。</p>\n<blockquote>\n<p>假设Consumer当前消费到了某个主题的最新一条消息，位移是100，之后该主题没有任何新消息产生，故Consumer无消息可消费了，所以位移永远保持在100。由于是自动提交位移，位移主题中会不停地写入位移&#x3D;100 的消息。显然 Kafka 只需要保留这类消息中的最新一条就可以了，之前的消息都是可以删除的。</p>\n</blockquote>\n<p>显然，Kafka 必须要有针对位移主题消息特点的消息删除策略，否则这种消息越多，最重撑爆整个磁盘</p>\n<h3 id=\"「Compact-策略」\"><a href=\"#「Compact-策略」\" class=\"headerlink\" title=\"「Compact 策略」\"></a>「Compact 策略」</h3><p>Kafka 通过 Compact 策略来删除 <code>_consumer_offsets</code> 主题中的过期消息，避免该主题无限膨胀。Compact 的过程就是扫描日志的所有消息，剔除过期消息，把剩下消息整理在一起。</p>\n<p>Kafka 提供了专门的后台线程定期的巡检待 Compact 的主题，看看是否存在猫族条件的可删除数据。这个后台线程叫做 <strong>Log cleaner</strong>。如果生产环境中出现了位移主题无限膨胀占用过多磁盘空间问题，请检查一下 Log cleaner 线程是否挂掉了。</p>\n<h1 id=\"十、副本机制\"><a href=\"#十、副本机制\" class=\"headerlink\" title=\"十、副本机制\"></a>十、副本机制</h1><p>根据 Kafka 副本机制定义，同一个分区下面的所有副本保存有相同的消息队列，这些副本是分布在不同 Broker 中，以确保某个 Broker 宕机后其他副本可以正常使用。</p>\n<p>在 Kafka 中，副本分为领导者副本和追随者副本。其中追随者副本不参与什么读写请求操作。追随者副本只异步拉去领导者副本，在领导者副本所在的 Broker 宕机的时候，重新从追随者副本中推选出一个领导者副本。</p>\n<p>追随者副本唯一的工作就是，不断的从领导者副本中拉取消息，然后写入自己的提交日志中。</p>\n<p><img src=\"/img/ff0fd5af97f5f5ad3a954f3ffa4076d0_MD5.png\" alt=\"副本机制\"></p>\n<h1 id=\"十一、ISR-机制\"><a href=\"#十一、ISR-机制\" class=\"headerlink\" title=\"十一、ISR 机制\"></a>十一、ISR 机制</h1><p>in-sync Replicas，也就是所谓的 ISR 副本集合。这个集合是动态的，而非静态不变。</p>\n<p>ISR 中的副本一定是好 Leader 副本同步的，相反不在 ISR 中的副本一定是和 Leader 副本不同步的。</p>\n<p>Leader 副本一定在 ISR 中，Follower 副本不一定在 ISR 中。在 Broker 端有个配置参数 <code>replica.lag.time.max.ms</code>，这个参数的含义是 Follower 副本落后 Leader 副本的时间不连续超过 10 秒，那么 Kafka 认为 Follower 副本和 Leader 是同步的，即使此时 Follower 副本中保存的消息明显少于 Leader 副本中的消息。</p>\n<h1 id=\"十二、Unclean-领导者选举\"><a href=\"#十二、Unclean-领导者选举\" class=\"headerlink\" title=\"十二、Unclean 领导者选举\"></a>十二、Unclean 领导者选举</h1><p>Kafka 将所有不在 ISR 中的副本都认为是非同步副本。在领导者选举的时候，如果选举这种副本的过程称为 Unclean 领导者选举。在 Broker 端中参数 <code>unclean.leader.election.enable</code> 控制是否开启 Unclean 领导者选举。</p>\n<p>Unclean 领导者选举有利有弊。优点在于：因为一个分区中 Leader 副本负责读写请求，如果 Leader 副本挂了，整个分区就改了。开启 Unclean 领导者选取，会使 Leader 副本一直存在，不至于对外停止服务，提高了高可用；缺点在于：因为从 ISR 中选举 Leader 副本，就会出现数据不同步情况，就会导致数据丢失。</p>\n<h1 id=\"十三、副本选举\"><a href=\"#十三、副本选举\" class=\"headerlink\" title=\"十三、副本选举\"></a>十三、副本选举</h1><p>Kafka 在选取 Leader 副本时候，考虑到负载均衡的平衡性，会将不同的分区的 Leader 副本分配到不同的 Broker 中，这样既能避免 Broker 宕机导致多个分区不可用，也能平衡 Broker 的负载。</p>\n<p>Kafka 引入了优先副本的概念，优先副本的意思是，在分区的所有 AR 集合列表中的第一个副本，理想状态下就是该分区的 Leader 副本。</p>\n<p>例如kafka集群由3台broker组成，创建了一个名为 <code>topic-partitions</code> 的topic，设置partition为3，副本数为3，partition0中AR列表为 <code>[1,2,0]</code>，那么分区0的优先副本为1</p>\n<p><img src=\"/img/882565aff441558b043b911c7c240f29_MD5.png\" alt=\"副本选举\"></p>\n<p>当分区leader节点发生故障时，其中的一个follower节点就会选举为新的leader节点。当原来leader的节点恢复之后，它只能成为一个follower节点，此时就导致了集群负载不均衡。比如分区1的leader节点broker2崩溃了，此时选举了在broker1上的分区1follower节点作为新的leader节点。当broker2重新恢复时，此时的kafka集群状态如下：</p>\n<p><img src=\"/img/d9e50eff06b436f7621152f2739a05c5_MD5.png\" alt=\"副本选举\"></p>\n<p>可以看到，此时broker1上负载更大，而broker2上没有负载。</p>\n<p><strong>「为了解决上述负载不均衡的情况，kafka支持了优先副本选举，优先副本指的是一个分区所在的AR集合的第一个副本」</strong>。</p>\n<p>比如上面的分区1，它的AR集合是<code>[2,0,1]</code>，表示分区1的优先副本就是在broker2上。</p>\n<p>理想情况下，优先副本应该就是leader副本，kafka保证了优先副本的均衡分布，而这与broker节点宕机与否没有关系。</p>\n<p><strong>「优先副本选举就是对分区leader副本进行选举的时候，尽可能让优先副本成为leader副本」</strong>，针对上述的情况，只要再触发一次优先副本选举就能保证分区负载均衡。</p>\n<p>kafka支持自动优先副本选举功能，默认每5分钟触发一次优先副本选举操作。</p>\n<h1 id=\"十四、网络通信模型\"><a href=\"#十四、网络通信模型\" class=\"headerlink\" title=\"十四、网络通信模型\"></a>十四、网络通信模型</h1><p><img src=\"/img/93681a72e52523561d8f052cb74d6da0_MD5.png\" alt=\"网络通信模型\"></p>\n<p>Broker 中有个<code>Acceptor(mainReactor)</code>监听新连接的到来，与新连接建连之后轮询选择一个<code>Processor(subReactor)</code>管理这个连接。</p>\n<p>而<code>Processor</code>会监听其管理的连接，当事件到达之后，读取封装成<code>Request</code>，并将<code>Request</code>放入共享请求队列中。</p>\n<p>然后IO线程池不断的从该队列中取出请求，执行真正的处理。处理完之后将响应发送到对应的<code>Processor</code>的响应队列中，然后由<code>Processor</code>将<code>Response</code>返还给客户端。</p>\n<p>每个<code>listener</code>只有一个<code>Acceptor线程</code>，因为它只是作为新连接建连再分发，没有过多的逻辑，很轻量。</p>\n<p><code>Processor</code> 在Kafka中称之为网络线程，默认网络线程池有3个线程，对应的参数是<code>num.network.threads</code>，并且可以根据实际的业务动态增减。</p>\n<p>还有个 IO 线程池，即<code>KafkaRequestHandlerPool</code>，执行真正的处理，对应的参数是<code>num.io.threads</code>，默认值是 8。</p>\n<p>IO线程处理完之后会将<code>Response</code>放入对应的<code>Processor</code>中，由<code>Processor</code>将响应返还给客户端。</p>\n<p>可以看到网络线程和IO线程之间利用的经典的生产者 - 消费者模式，不论是用于处理Request的共享请求队列，还是IO处理完返回的Response。</p>\n<h1 id=\"十五、幂等性\"><a href=\"#十五、幂等性\" class=\"headerlink\" title=\"十五、幂等性\"></a>十五、幂等性</h1><h2 id=\"「幂等性Producer」\"><a href=\"#「幂等性Producer」\" class=\"headerlink\" title=\"「幂等性Producer」\"></a><strong>「幂等性Producer」</strong></h2><p>在 Kafka 中，Producer 默认不是幂等性的，但是我们可以创建幂等性 Producer。<code>enable.idempotence</code> 设置为 True，即可保证 Producer 自动升级成幂等性 Producer，其他所有的代码逻辑都不需要更改。配置后，Kafka 自动做消息的去重操作。</p>\n<p>其实，底层原理非常简单，就是经典的以空间换时间的做法，Broker 多保存一些字段，当 Producer 发送消息请求的时候，Broker 能够判断消息是否重复，进而再丢弃掉重复消息。</p>\n<h2 id=\"「幂等性-Producer-的作用范围」\"><a href=\"#「幂等性-Producer-的作用范围」\" class=\"headerlink\" title=\"「幂等性 Producer 的作用范围」\"></a>「幂等性 Producer 的作用范围」</h2><ul>\n<li><p>幂等性只能保证单个分区上的幂等性，无法实现多分区幂等性。</p>\n</li>\n<li><p>幂等性针对单个会话的幂等性，不会实现跨会话的幂等性。</p>\n</li>\n</ul>\n<blockquote>\n<p>这里的会话，可以理解成 Producer 进程的一次运行，当重启了 Producer 进程之后，这种幂等性就丧失了。</p>\n</blockquote>\n<h1 id=\"十六、事务\"><a href=\"#十六、事务\" class=\"headerlink\" title=\"十六、事务\"></a>十六、事务</h1><p>Kafka 自从 0.11 版本就开始支持事务，目前主要是在 read committed 隔离级别上做事务。它能保证多条消息原子性地写入到目标分区，同时也能保证Consumer 只能看到事务成功提交的消息。</p>\n<h2 id=\"「事务型-Producer」\"><a href=\"#「事务型-Producer」\" class=\"headerlink\" title=\"「事务型 Producer」\"></a>「事务型 Producer」</h2><p>事物型 Producer 能够保证将消息原子性的写入到多个分区中。这批消息要么全部成功，要么全部失败，另外，事务型 Producer 也不怕进程的重启。当 Producer 重启之后，Kafka 仍能保证它们发送消息的精确一次处理。</p>\n<p>设置事务型 Producer 的方式也比较简单，满足两个设置即可：</p>\n<ul>\n<li><p>和幂等性 Producer 一样，开启 <code>enable.idempotence = true</code>。</p>\n</li>\n<li><p>设置 Producer 端参数 <code>transactional.id</code>，最好设置一个有意义的名字。</p>\n</li>\n</ul>\n<p>此外，还需要在 Producer 代码中做一些调整，如这段代码所示：</p>\n<pre><code class=\"language-java\">producer.initTransactions();  \ntry &#123;  \n            producer.beginTransaction();  \n            producer.send(record1);  \n            producer.send(record2);  \n            producer.commitTransaction();  \n&#125; catch (KafkaException e) &#123;  \n            producer.abortTransaction();  \n&#125;\n</code></pre>\n<p>和普通Producer代码相比，事务型Producer的显著特点是调用了一些事务API，如initTransaction、beginTransaction、commitTransaction和abortTransaction，它们分别对应事务的初始化、事务开始、事务提交以及事务终止。</p>\n<p>实际上即使写入失败，Kafka也会把它们写入到底层的日志中，也就是说Consumer还是会看到这些消息。</p>\n<p>有一个 <code>isolation.level</code> 参数，这个参数有两个取值：</p>\n<ol>\n<li><p><code>read_uncommitted</code>：这是默认值，表明Consumer能够读取到Kafka写入的任何消息，不论事务型Producer提交事务还是终止事务，其写入的消息都可以读取，如果你用了事务型Producer，那么对应的Consumer就不要使用这个值。</p>\n</li>\n<li><p><code>read_committed</code>：表明Consumer只会读取事务型Producer成功提交事务写入的消息，它也能看到非事务型Producer写入的所有消息</p>\n</li>\n</ol>\n<h1 id=\"十七、拦截器\"><a href=\"#十七、拦截器\" class=\"headerlink\" title=\"十七、拦截器\"></a>十七、拦截器</h1><p><strong>Kafka 拦截器分为生产者拦截器和消费者拦截器。</strong> 生产者拦截器允许你在发送消息前以及消息提交成功之后植入拦截器逻辑。而消费者拦截器支持消费消息前以及提交位移后编写特定逻辑。可以将一组懒啊节气串联成一个大的拦截器，Kafka 会按照顺序依次执行拦截器逻辑。</p>\n<p>当前 Kafka 拦截器是通过参数配置完成，生产者和消费者两端都有个相同的参数 <code>interceptor.classes</code>，它指定的是一组类的列表，每个类就是特定逻辑的拦截器实现类。</p>\n<pre><code class=\"language-java\">Properties props = new Properties();   \nList interceptors = new ArrayList&lt;&gt;();   \ninterceptors.add(&quot;com.yourcompany.kafkaproject.interceptors.AddTimestampInterceptor&quot;); // 拦截器1   \ninterceptors.add(&quot;com.yourcompany.kafkaproject.interceptors.UpdateCounterInterceptor&quot;); // 拦截器2   \nprops.put(ProducerConfig.INTERCEPTOR_CLASSES_CONFIG, interceptors);\n</code></pre>\n<p>怎么编写 AddTimeStampInterceptor 和 UpdateCounterInterceptor 类呢？</p>\n<p>这两个类以及所有 Producer 端拦截器实现类都要继承 <code>org.apache.kafka.clients.producer.ProducerInterceptor</code> 接口。</p>\n<p>该接口是 Kafka 提供的，里面有两个核心方法：</p>\n<ol>\n<li><p>onSend：该方法在消息发送前被调用。</p>\n</li>\n<li><p>onAcknowledgement：该方法在消息成功提交或者提交失败之后被调用。onAcknowledgement 的调用要早于 callback 的调用。值得注意的是，这个方法和 onSend 方法不在同一个线程中调用，因此如果在这两个方法中调用了共享可变变量，一定要注意线程安全问题。</p>\n</li>\n</ol>\n<p>同理，消费者拦截器也是同样的方法，都要继承 <code>org.apache.kafka.clients.consumer.ConsumerInterceptor</code> 接口，这里也有两个核心方法。</p>\n<ol>\n<li><p>onConsuume：该方法在消息返回给 Consumer 程序之前调用。</p>\n</li>\n<li><p>onCommit：Consumer 在提交位移之后调用该方法。通常做法是在该方法中做一些记账的动作，例如打印日志等。</p>\n</li>\n</ol>\n<h1 id=\"十八、控制器（Controller）\"><a href=\"#十八、控制器（Controller）\" class=\"headerlink\" title=\"十八、控制器（Controller）\"></a>十八、控制器（Controller）</h1><p><strong>控制器组件（controller），主要是用于在 Apache Zookeeper 的帮助下管理和协调整个 Kafka 集群。</strong></p>\n<p>集群中任意一台 Broker 都可以成为控制器角色。在 Kafka 集群启动的时候，第一个在 Zookeeper 中创建&#x2F;controller 节点的 Broker 会被指定为控制器。</p>\n<p>控制器主要的功能如下：</p>\n<ol>\n<li><strong>主题管理（创建，删除，增加分区）</strong></li>\n</ol>\n<p>控制器帮我们完成对 Kafka 主题的创建，删除以及分区增加的操作。</p>\n<ol start=\"2\">\n<li><p><strong>分区重分配</strong></p>\n</li>\n<li><p><strong>Preferred 领导者选举</strong></p>\n</li>\n</ol>\n<p>Preferred 领导者选举主要是 Kafka 为了避免部分 Broker 负载过重而提供的一种换 Leader 的方案。</p>\n<ol start=\"4\">\n<li><strong>集群成员管理（新增 Broker、Broker 主动关闭、Broker 宕机）</strong></li>\n</ol>\n<p>在 Zookeeper 对 Kafka 协助管理工程中，<strong>「Watch 机制」</strong> 和 <strong>「临时节点」</strong> 是两个重要的机制。 </p>\n<p>Broker 的创建时候，Zookeeper 会在 Zookeeper 的 &#x2F;broker&#x2F;ids 下创建专属的 znode 节点，这个节点就是临时节点。一旦节点创建完成，ZooKeeper 就会通过 Watch 机制将消息通知推送给控制器，只要，控制器就能自动感知这个变化，进而开启后续的新增 Broker 作业。</p>\n<p>当Broker宕机或主动关闭后，该Broker与ZooKeeper的会话结束，这个znode会被自动删除。</p>\n<p>同理，ZooKeeper的Watch机制将这一变更推送给控制器，这样控制器就能知道有Broker关闭或宕机了，从而进行善后。</p>\n<ol start=\"5\">\n<li><strong>数据服务</strong></li>\n</ol>\n<p>控制器上保存了最全的集群元数据信息，其他所有Broker会定期接收控制器发来的元数据更新请求，从而更新其内存中的缓存数据。</p>\n<h2 id=\"「控制器故障转移（Failover）」\"><a href=\"#「控制器故障转移（Failover）」\" class=\"headerlink\" title=\"「控制器故障转移（Failover）」\"></a>「控制器故障转移（Failover）」</h2><p><strong>「故障转移指的是，当运行中的控制器突然宕机或意外终止时，Kafka能够快速地感知到，并立即启用备用控制器来代替之前失败的控制器」</strong>。这个过程就被称为Failover，该过程是自动完成的，无需你手动干预。</p>\n<p><img src=\"/img/5711d6da84f2000a181c356e080deec4_MD5.png\" alt=\"控制器故障转移\"></p>\n<p>最开始时，Broker 0是控制器。当Broker 0宕机后，ZooKeeper通过Watch机制感知到并删除了<code>/controller</code>临时节点。</p>\n<p>之后，所有存活的Broker开始竞选新的控制器身份。Broker 3最终赢得了选举，成功地在ZooKeeper上重建了 <code>/controller</code> 节点。之后，Broker 3会从ZooKeeper中读取集群元数据信息，并初始化到自己的缓存中。</p>\n<p>至此，控制器的Failover完成，可以行使正常的工作职责了。</p>\n<h1 id=\"二十、日志存储\"><a href=\"#二十、日志存储\" class=\"headerlink\" title=\"二十、日志存储\"></a>二十、日志存储</h1><p>Kafka中的消息是以主题为基本单位进行归类的，每个主题在逻辑上相互独立。</p>\n<p>每个主题又可以分为一个或多个分区，在不考虑副本的情况下，一个分区会对应一个日志。</p>\n<p>但设计者考虑到随着时间推移，日志文件会不断扩大，因此为了防止Log过大，设计者引入了日志分段（LogSegment）的概念，将Log切分为多个LogSegment，便于后续的消息维护和清理工作。</p>\n<p>下图描绘了主题、分区、副本、Log、LogSegment五者之间的关系。</p>\n<p><img src=\"/img/4cc119f98ed02df15c264d1cf428d32b_MD5.png\" alt=\"关系图解\"></p>\n<p><strong>「LogSegment」</strong></p>\n<p>在Kafka中，每个Log对象又可以划分为多个LogSegment文件，每个LogSegment文件包括一个日志数据文件和两个索引文件（偏移量索引文件和消息时间戳索引文件）。</p>\n<p>其中，每个LogSegment中的日志数据文件大小均相等（该日志数据文件的大小可以通过在Kafka Broker的 <code>config/server.properties</code> 配置文件的中的**「log.segment.bytes」**进行设置，默认为1G大小（1073741824字节），在顺序写入消息时如果超出该设定的阈值，将会创建一组新的日志数据和索引文件）。</p>\n<p><img src=\"/img/5c376d6d6186292ebc461285ce0ac879_MD5.png\" alt=\"日志内部结构\"></p>\n<h1 id=\"常用参数\"><a href=\"#常用参数\" class=\"headerlink\" title=\"常用参数\"></a>常用参数</h1><p><strong>「broker端配置」</strong></p>\n<ul>\n<li><code>broker.id</code></li>\n</ul>\n<p>每个 kafka broker 都有一个唯一的标识来表示，这个唯一的标识符即是 <code>broker.id</code>，它的默认值是 0。</p>\n<p>这个值在 kafka 集群中必须是唯一的，这个值可以任意设定，</p>\n<ul>\n<li><code>port</code></li>\n</ul>\n<p>如果使用配置样本来启动 kafka，它会监听 9092 端口，修改 port 配置参数可以把它设置成任意的端口。</p>\n<p>要注意，如果使用 1024 以下的端口，需要使用 root 权限启动 kakfa。</p>\n<ul>\n<li><code>zookeeper.connect</code></li>\n</ul>\n<p>用于保存 broker 元数据的 Zookeeper 地址是通过 <code>zookeeper.connect</code> 来指定的。</p>\n<p>比如可以这么指定 <code>localhost:2181</code> 表示这个 Zookeeper 是运行在本地 2181 端口上的。</p>\n<p>我们也可以通过 比如我们可以通过 <code>zk1:2181,zk2:2181,zk3:2181</code> 来指定 <code>zookeeper.connect</code> 的多个参数值。</p>\n<p>该配置参数是用冒号分割的一组 <code>hostname:port/path</code> 列表，其含义如下</p>\n<ul>\n<li><p>hostname 是 Zookeeper 服务器的机器名或者 ip 地址。</p>\n</li>\n<li><p>port 是 Zookeeper 客户端的端口号</p>\n</li>\n<li><p>&#x2F;path 是可选择的 Zookeeper 路径，Kafka 路径是使用了 <code>chroot</code> 环境，如果不指定默认使用跟路径。</p>\n</li>\n</ul>\n<blockquote>\n<p>❝<br>如果你有两套 Kafka 集群，假设分别叫它们 kafka1 和 kafka2，那么两套集群的<code>zookeeper.connect</code>参数可以这样指定：<code>zk1:2181,zk2:2181,zk3:2181/kafka1</code>和<code>zk1:2181,zk2:2181,zk3:2181/kafka2</code><br>❞</p>\n</blockquote>\n<ul>\n<li><code>log.dirs</code></li>\n</ul>\n<p>Kafka 把所有的消息都保存到磁盘上，存放这些日志片段的目录是通过 <code>log.dirs</code> 来制定的，它是用一组逗号来分割的本地系统路径，<code>log.dirs</code> 是没有默认值的，<strong>「你必须手动指定他的默认值」</strong>。</p>\n<p>其实还有一个参数是 <code>log.dir</code>，这个配置是没有 <code>s</code> 的，默认情况下只用配置 <code>log.dirs</code> 就好了，比如你可以通过 <code>/home/kafka1,/home/kafka2,/home/kafka3</code> 这样来配置这个参数的值。</p>\n<ul>\n<li><code>auto.create.topics.enable</code></li>\n</ul>\n<p>默认情况下，kafka 会自动创建主题</p>\n<p><code>auto.create.topics.enable</code>参数建议最好设置成 false，即不允许自动创建 Topic。</p>\n<p><strong>「主题相关配置」</strong></p>\n<ul>\n<li><code>num.partitions</code></li>\n</ul>\n<p>num.partitions 参数指定了新创建的主题需要包含多少个分区，该参数的默认值是 1。</p>\n<ul>\n<li><code>default.replication.factor</code></li>\n</ul>\n<p>这个参数比较简单，它表示 kafka保存消息的副本数。</p>\n<ul>\n<li><code>log.retention.ms</code></li>\n</ul>\n<p>Kafka 常根据时间来决定数据可以保留多久。</p>\n<p>默认使用<code>log.retention.hours</code>参数来配置时间，默认是 168 个小时，也就是一周。</p>\n<p>除此之外，还有两个参数<code>log.retention.minutes</code> 和<code>log.retentiion.ms</code> 。</p>\n<p>这三个参数作用是一样的，都是决定消息多久以后被删除，推荐使用<code>log.retention.ms</code>。</p>\n<ul>\n<li><code>message.max.bytes</code></li>\n</ul>\n<p>broker 通过设置 <code>message.max.bytes</code> 参数来限制单个消息的大小，默认是 1000 000， 也就是 1MB，如果生产者尝试发送的消息超过这个大小，不仅消息不会被接收，还会收到 broker 返回的错误消息。</p>\n<ul>\n<li><code>retention.ms</code></li>\n</ul>\n<p>规定了该主题消息被保存的时常，默认是7天，即该主题只能保存7天的消息，一旦设置了这个值，它会覆盖掉 Broker 端的全局参数值。</p>\n<h1 id=\"消息丢失问题\"><a href=\"#消息丢失问题\" class=\"headerlink\" title=\"消息丢失问题\"></a>消息丢失问题</h1><h2 id=\"「生产者程序丢失数据」\"><a href=\"#「生产者程序丢失数据」\" class=\"headerlink\" title=\"「生产者程序丢失数据」\"></a><strong>「生产者程序丢失数据」</strong></h2><p>目前Kafka Producer是异步发送消息的，也就是说如果你调用的是<code>producer.send(msg)</code>这个API，那么它通常会立即返回，但此时你不能认为消息发送已成功完成。</p>\n<p><strong>如果用这个方式，可能会有哪些因素导致消息没有发送成功呢？</strong></p>\n<p>其实原因有很多：</p>\n<ol>\n<li>例如网络抖动，导致消息压根就没有发送到Broker端；</li>\n</ol>\n<p>如果是网络抖动导致的失败，可以通过 Producer 中的参数 <code>retries</code> (重试次数)设置比较合理的值来解决，一般来说为 3。同时，建议还要设置重试间隔 <code>retry.backoff.ms</code> 来避免 3 次重试间隔太短导致多次失败。</p>\n<ol start=\"2\">\n<li>或者消息本身不合格导致Broker拒绝接收（比如消息太大了，超过了Broker的承受能力）等。</li>\n</ol>\n<p>实际上，解决此问题的方法非常简单：Producer永远要使用带有回调通知的发送API，也就是说不要使用 <code>producer.send(msg)</code>，而要使用 <code>producer.send(msg, callback)</code>。在 SpringBoot 中可以用类似的方式来处理：</p>\n<pre><code class=\"language-java\">ListenableFuture&lt;SendResult&lt;String, Object&gt;&gt; future = kafkaTemplate.send(smsBusiPrediction, msg);  \nfuture.addCallback(new ListenableFutureCallback&lt;SendResult&lt;String, Object&gt;&gt;() &#123;  \n   @Override  \n   public void onSuccess(SendResult&lt;String, Object&gt; result) &#123;  \n      log.info(&quot;=====向kafka推送信息成功=====&quot;);  \n   &#125;  \n   @Override  \n   public void onFailure(Throwable ex) &#123;  \n      log.info(&quot;=====向kafka推送信息失败！！=====&quot;,ex);  \n   &#125;   \n&#125;);\n</code></pre>\n<p>它能准确地告诉你消息是否真的提交成功了。一旦出现消息提交失败的情况，你就可以有针对性地进行处理。</p>\n<h2 id=\"「消费者程序丢失数据」\"><a href=\"#「消费者程序丢失数据」\" class=\"headerlink\" title=\"「消费者程序丢失数据」\"></a><strong>「消费者程序丢失数据」</strong></h2><p>Consumer端丢失数据主要体现在Consumer端要消费的消息不见了。</p>\n<p>下面这张图它清晰地展示了Consumer端的位移数据。</p>\n<p><img src=\"/img/adc9951c2edb1fba60deea2d87fb2d44_MD5.png\" alt=\"Consumer端的位移数据\"></p>\n<p>比如对于Consumer A而言，它当前的位移值就是9；Consumer B的位移值是11。Consumer程序从Kafka获取到消息后开启了多个线程异步处理消息，而Consumer程序自动地向前更新位移。</p>\n<p>假如其中某个线程运行失败了，它负责的消息没有被成功处理，但位移已经被更新了，因此这条消息对于Consumer而言实际上是丢失了。这里的关键在于Consumer自动提交位移。这个问题的解决方案也很简单：<strong>「如果是多线程异步处理消费消息，Consumer程序不要开启自动提交位移，而是要应用程序手动提交位移」</strong>。</p>\n<h2 id=\"「Kafka-内部出现消息丢失」\"><a href=\"#「Kafka-内部出现消息丢失」\" class=\"headerlink\" title=\"「Kafka 内部出现消息丢失」\"></a><strong>「Kafka 内部出现消息丢失」</strong></h2><p>试想一种情况：假如 leader 副本所在的 broker 突然挂掉，那么就要从 follower 副本重新选出一个 leader ，但是 leader 的数据还有一些没有被 follower 副本的同步的话，就会造成消息丢失。</p>\n<p><strong>设置 <code>acks = all</code></strong></p>\n<p>解决办法就是我们设置 <code>acks = all</code>。<code>acks</code> 是 Kafka 生产者(Producer) 很重要的一个参数。</p>\n<p>acks 的默认值即为 1，代表我们的消息被 leader 副本接收之后就算被成功发送。当我们配置 <strong>acks &#x3D; all</strong> 表示只有所有 ISR 列表的副本全部收到消息时，生产者才会接收到来自服务器的响应. 这种模式是最高级别的，也是最安全的，可以确保不止一个 Broker 接收到了消息. 该模式的延迟会很高.</p>\n<p><strong>设置 <code>replication.factor &gt;= 3</code></strong></p>\n<p>为了保证 leader 副本能有 follower 副本能同步消息，我们一般会为 topic 设置 <code>replication.factor &gt;= 3</code>。这样就可以保证每个 分区(partition) 至少有 3 个副本。虽然造成了数据冗余，但是带来了数据的安全性。</p>\n<p><strong>设置 <code>min.insync.replicas &gt; 1</code></strong></p>\n<p>一般情况下我们还需要设置 <strong><code>min.insync.replicas&gt; 1</code></strong> ，这样配置代表消息至少要被写入到 2 个副本才算是被成功发送。<strong>min.insync.replicas</strong> 的默认值为 1 ，在实际生产中应尽量避免默认值 1。</p>\n<p>但是，为了保证整个 Kafka 服务的高可用性，你需要确保 <strong><code>replication.factor &gt; min.insync.replicas</code></strong> 。为什么呢？设想一下假如两者相等的话，只要是有一个副本挂掉，整个分区就无法正常工作了。这明显违反高可用性！一般推荐设置成 <strong><code>replication.factor = min.insync.replicas + 1</code></strong>。</p>\n<p><strong>设置 <code>unclean.leader.election.enable = false</code></strong></p>\n<blockquote>\n<p><strong>Kafka 0.11.0.0 版本开始 unclean.leader.election.enable 参数的默认值由原来的 true 改为 false</strong></p>\n</blockquote>\n<p>我们最开始也说了我们发送的消息会被发送到 leader 副本，然后 follower 副本才能从 leader 副本中拉取消息进行同步。多个 follower 副本之间的消息同步情况不一样，当我们配置了 <strong><code>unclean.leader.election.enable = false</code></strong> 的话，当 leader 副本发生故障时就不会从 follower 副本中和 leader 同步程度达不到要求的副本中选择出 leader ，这样降低了消息丢失的可能性。</p>\n<h2 id=\"「最佳实践」\"><a href=\"#「最佳实践」\" class=\"headerlink\" title=\"「最佳实践」\"></a>「最佳实践」</h2><p>总结Kafka 避免消息丢失的配置：</p>\n<ol>\n<li><p>在 Producer 端：</p>\n<ul>\n<li><p>不要使用 <code>producer.send(msg)</code>，而要使用 <code>producer.send(msg, callback)</code>，一定要使用带有回调通知的 send 方法。</p>\n</li>\n<li><p>设置 <code>retries</code>  为一个较大的值。这里的<code>retries</code>同样是Producer的参数，对应前面提到的Producer自动重试，当出现网络的瞬时抖动时，消息发送可能会失败，此时配置了 <code>retries &gt; 0</code> 的 Producer 能够自动重试消息发送，避免消息丢失。</p>\n</li>\n<li><p>设置 <code>acks = all</code>，acks 是 Producer 的一个参数，代表了你对已提交消息的定义，如果设置成 all，则表明所有副本 Broker 都要接收到消息，该消息才算是已提交。</p>\n</li>\n</ul>\n</li>\n<li><p>在 Consumer 端：</p>\n<ul>\n<li>确保消息消费完成再提交，Consumer端有个参数 <code>enable.auto.commit</code>，最好把它设置成 false，并采用手动提交位移的方式。</li>\n</ul>\n</li>\n<li><p>在 Kafka 内部：</p>\n<ul>\n<li><p>设置 <code>unclean.leader.election.enable = false</code>，这是 Broker 端的参数，它控制的是哪些 Broker 有资格竞选分区的 Leader，如果一个 Broker 落后原先的 Leader 太多，那么它一旦成为新的 Leader，必然会造成消息的丢失，故一般都要将该参数设置成 false，即不允许这种情况的发生。</p>\n</li>\n<li><p>设置 <code>replication.factor &gt;= 3</code>，这也是 Broker 端的参数，将消息多保存几份，目前防止消息丢失的主要机制就是冗余。</p>\n</li>\n<li><p>设置 <code>min.insync.replicas &gt; 1</code>，这依然是 Broker 端参数，控制的是消息至少要被写入到多少个副本才算是已提交，设置成大于 1 可以提升消息持久性，在实际环境中千万不要使用默认值 1。</p>\n</li>\n<li><p>确保 <code>replication.factor &gt; min.insync.replicas</code>，如果两者相等，那么只要有一个副本挂机，整个分区就无法正常工作了，我们不仅要改善消息的持久性，防止数据丢失，还要在不降低可用性的基础上完成，推荐设置成 <code>replication.factor = min.insync.replicas + 1</code>。</p>\n</li>\n</ul>\n</li>\n</ol>\n<h1 id=\"重复消费问题\"><a href=\"#重复消费问题\" class=\"headerlink\" title=\"重复消费问题\"></a>重复消费问题</h1><p><strong>「消费重复的场景」</strong></p>\n<p>在 <code>enable.auto.commit</code> 默认值true情况下，出现重复消费的场景有以下几种：</p>\n<blockquote>\n<p>❝<br>consumer 在消费过程中，应用进程被强制kill掉或发生异常退出。<br>❞</p>\n</blockquote>\n<p>例如在一次poll 500条消息后，消费到200条时，进程被强制kill消费到offset未提交，或出现异常退出导致消费到offset未提交。</p>\n<p>下次重启时，依然会重新拉取500消息，造成之前消费到200条消息重复消费了两次。</p>\n<p>解决方案：在发生异常时正确处理未提交的offset</p>\n<p><strong>「消费者消费时间过长」</strong></p>\n<p><code>max.poll.interval.ms</code>参数定义了两次poll的最大间隔，它的默认值是 5 分钟，表示你的 Consumer 程序如果在 5 分钟之内无法消费完 poll 方法返回的消息，那么 Consumer 会主动发起离开组的请求，Coordinator 也会开启新一轮 Rebalance。</p>\n<p>举例：单次拉取11条消息，每条消息耗时30s，11条消息耗时5分钟30秒，由于<code>max.poll.interval.ms</code>  默认值5分钟，所以消费者无法在5分钟内消费完，consumer会离开组，导致rebalance。</p>\n<p>在消费完11条消息后，consumer会重新连接broker，再次rebalance，因为上次消费的offset未提交，再次拉取的消息是之前消费过的消息，造成重复消费。</p>\n<p><strong>「解决方案：」</strong></p>\n<p>1、提高消费能力，提高单条消息的处理速度；根据实际场景可讲<code>max.poll.interval.ms</code>值设置大一点，避免不必要的rebalance；可适当减小<code>max.poll.records</code>的值，默认值是500，可根据实际消息速率适当调小。</p>\n<p>2、生成消息时，可加入唯一标识符如消息id，在消费端，保存最近的1000条消息id存入到redis或mysql中，消费的消息时通过前置去重。</p>\n<h1 id=\"消息顺序问题\"><a href=\"#消息顺序问题\" class=\"headerlink\" title=\"消息顺序问题\"></a>消息顺序问题</h1><p>我们都知道 <code>kafka</code> 的 <code>topic</code> 是无序的，但是一个 <code>topic</code> 包含多个 <code>partition</code>，每个 <code>partition</code> 内部是有序的（分区内采用尾插法）</p>\n<p><img src=\"/img/466a6f44f4b183a6bae184c90378b300_MD5.png\" alt=\"消息消费顺序\"></p>\n<p><strong>「乱序场景1」</strong></p>\n<p>因为一个topic可以有多个partition，kafka只能保证partition内部有序</p>\n<p><strong>「解决方案」</strong></p>\n<p>1、可以设置topic，有且只有一个partition，<strong>不推荐，这样就违背了 Kafka 的设计初衷，即多分区，多副本的概念。</strong></p>\n<p>2、<strong>（推荐）</strong> 根据业务需要，需要顺序的指定为同一个partition，在 Broker 提交的时候，规定 topic，partition，key，data 四个参数统一。</p>\n<p><strong>「乱序场景2」</strong></p>\n<p>对于同一业务进入了同一个消费者组之后，用了多线程来处理消息，会导致消息的乱序</p>\n<p><strong>「解决方案」</strong></p>\n<p>消费者内部根据线程数量创建等量的内存队列，对于需要顺序的一系列业务数据，根据key或者业务数据，放到同一个内存队列中，然后线程从对应的内存队列中取出并操作</p>\n<p><img src=\"/img/bb94c4025a04733be2eb858d968eaffd_MD5.png\" alt=\"解决方案\"></p>\n<p><strong>「通过设置相同key来保证消息有序性，会有一点缺陷：」</strong></p>\n<p>例如消息发送设置了重试机制，并且异步发送，消息A和B设置相同的key，业务上A先发，B后发，由于网络或者其他原因A发送失败，B发送成功；A由于发送失败就会重试且重试成功，这时候消息顺序B在前A在后，与业务发送顺序不一致，如果需要解决这个问题，需要设置参数 <code>max.in.flight.requests.per.connection=1</code>，其含义是限制客户端在单个连接上能够发送的未响应请求的个数，设置此值是1表示kafka broker在响应请求之前client不能再向同一个broker发送请求，这个参数默认值是5</p>\n<h1 id=\"高性能原因\"><a href=\"#高性能原因\" class=\"headerlink\" title=\"高性能原因\"></a>高性能原因</h1><h2 id=\"「顺序读写」\"><a href=\"#「顺序读写」\" class=\"headerlink\" title=\"「顺序读写」\"></a><strong>「顺序读写」</strong></h2><p>kafka的消息是不断追加到文件中的，这个特性使<code>kafka</code>可以充分利用磁盘的顺序读写性能</p>\n<p>顺序读写不需要硬盘磁头的寻道时间，只需很少的扇区旋转时间，所以速度远快于随机读写</p>\n<p>Kafka 可以配置异步刷盘，不开启同步刷盘，异步刷盘不需要等写入磁盘后返回消息投递的 ACK，所以它提高了消息发送的吞吐量，降低了请求的延时</p>\n<h2 id=\"「零拷贝」\"><a href=\"#「零拷贝」\" class=\"headerlink\" title=\"「零拷贝」\"></a><strong>「零拷贝」</strong></h2><p>传统的 IO 流程，需要先把数据拷贝到内核缓冲区，再从内核缓冲拷贝到用户空间，应用程序处理完成以后，再拷贝回内核缓冲区</p>\n<p>这个过程中发生了多次数据拷贝</p>\n<p>为了减少不必要的拷贝，<code>Kafka</code> 依赖 Linux 内核提供的 <code>Sendfile</code> 系统调用</p>\n<p>在 Sendfile 方法中，数据在内核缓冲区完成输入和输出，不需要拷贝到用户空间处理，这也就避免了重复的数据拷贝</p>\n<p>在具体的操作中，Kafka 把所有的消息都存放在单独的文件里，在消息投递时直接通过 <code>Sendfile</code> 方法发送文件，减少了上下文切换，因此大大提高了性能</p>\n<h2 id=\"「MMAP技术」\"><a href=\"#「MMAP技术」\" class=\"headerlink\" title=\"「MMAP技术」\"></a><strong>「MMAP技术」</strong></h2><p>除了 <code>Sendfile</code> 之外，还有一种零拷贝的实现技术，即 Memory Mapped Files</p>\n<p>Kafka 使用 <code>Memory Mapped Files</code> 完成内存映射，<code>Memory Mapped Files</code> 对文件的操作不是 <code>write/read</code>，而是直接对内存地址的操作，如果是调用文件的 <code>read</code> 操作，则把数据先读取到内核空间中，然后再复制到用户空间，但 <code>MMAP</code>可以将文件直接映射到用户态的内存空间，省去了用户空间到内核空间复制的开销</p>\n<p>Producer生产的数据持久化到broker，采用mmap文件映射，实现顺序的快速写入</p>\n<p>Customer从broker读取数据，采用sendfile，将磁盘文件读到OS内核缓冲区后，直接转到socket buffer进行网络发送。</p>\n<h2 id=\"「批量发送读取」\"><a href=\"#「批量发送读取」\" class=\"headerlink\" title=\"「批量发送读取」\"></a><strong>「批量发送读取」</strong></h2><p>Kafka 的批量包括批量写入、批量发布等。它在消息投递时会将消息缓存起来，然后批量发送</p>\n<p>同样，消费端在消费消息时，也不是一条一条处理的，而是批量进行拉取，提高了消息的处理速度</p>\n<h2 id=\"「数据压缩」\"><a href=\"#「数据压缩」\" class=\"headerlink\" title=\"「数据压缩」\"></a><strong>「数据压缩」</strong></h2><p>Kafka还支持对消息集合进行压缩，<code>Producer</code>可以通过<code>GZIP</code>或<code>Snappy</code>格式对消息集合进行压缩</p>\n<p>压缩的好处就是减少传输的数据量，减轻对网络传输的压力</p>\n<p>Producer压缩之后，在<code>Consumer</code>需进行解压，虽然增加了CPU的工作，但在对大数据处理上，瓶颈在网络上而不是CPU，所以这个成本很值得</p>\n<h2 id=\"「分区机制」\"><a href=\"#「分区机制」\" class=\"headerlink\" title=\"「分区机制」\"></a><strong>「分区机制」</strong></h2><p>kafka中的topic中的内容可以被分为多partition存在，每个partition又分为多个段segment，所以每次操作都是针对一小部分做操作，很轻便，并且增加 <code>并行操作</code> 的能力</p>\n<h1 id=\"常见面试题\"><a href=\"#常见面试题\" class=\"headerlink\" title=\"常见面试题\"></a>常见面试题</h1><h2 id=\"「Kafka是Push还是Pull模式？」\"><a href=\"#「Kafka是Push还是Pull模式？」\" class=\"headerlink\" title=\"「Kafka是Push还是Pull模式？」\"></a><strong>「Kafka是Push还是Pull模式？」</strong></h2><p>Kafka最初考虑的问题是，customer应该从brokes拉取消息还是brokers将消息推送到consumer。</p>\n<p>在这方面，Kafka遵循了一种大部分消息系统共同的传统的设计：producer将消息推送到broker，consumer从broker拉取消息。</p>\n<p>push模式由broker决定消息推送的速率，对于不同消费速率的consumer就不太好处理了。</p>\n<p>消息系统都致力于让consumer以最大的速率最快速的消费消息，push模式下，当broker推送的速率远大于consumer消费的速率时，consumer恐怕就要崩溃了。</p>\n<blockquote>\n<p>❝<br>Kafka中的Producer和Consumer采用的是Push-and-Pull模式，即Producer向Broker Push消息，Consumer从Broker Pull消息。<br>❞</p>\n</blockquote>\n<p>Pull模式的一个好处是consumer可以自主决定是否批量的从broker拉取数据。</p>\n<p>Pull有个缺点是，如果broker没有可供消费的消息，将导致consumer不断在循环中轮询，直到新消息到达。</p>\n<h2 id=\"「Kafka如何保证高可用-」\"><a href=\"#「Kafka如何保证高可用-」\" class=\"headerlink\" title=\"「Kafka如何保证高可用?」\"></a><strong>「Kafka如何保证高可用?」</strong></h2><p><a href=\"https://mp.weixin.qq.com/s?__biz=MzUyOTg1OTkyMA==&mid=2247484980&idx=1&sn=6e0c7112dd72d0edc284009e7503b2ac&scene=21#wechat_redirect\">面试题：Kafka如何保证高可用？有图有真相</a></p>\n<h2 id=\"「Kafk的使用场景」\"><a href=\"#「Kafk的使用场景」\" class=\"headerlink\" title=\"「Kafk的使用场景」\"></a><strong>「Kafk的使用场景」</strong></h2><p>业界Kafka实际应用场景</p>\n<blockquote>\n<p>❝<br>异步通信<br>❞</p>\n</blockquote>\n<p>消息中间件在异步通信中用的最多，很多业务流程中，如果所有步骤都同步进行可能会导致核心流程耗时非常长，更重要的是所有步骤都同步进行一旦非核心步骤失败会导致核心流程整体失败，因此在很多业务流程中Kafka就充当了异步通信角色。</p>\n<blockquote>\n<p>❝<br>日志同步<br>❞</p>\n</blockquote>\n<p>大规模分布式系统中的机器非常多而且分散在不同机房中，分布式系统带来的一个明显问题就是业务日志的查看、追踪和分析等行为变得十分困难，对于集群规模在百台以上的系统，查询线上日志很恐怖。</p>\n<p>为了应对这种场景统一日志系统应运而生，日志数据都是海量数据，通常为了不给系统带来额外负担一般会采用异步上报，这里Kafka以其高吞吐量在日志处理中得到了很好的应用。</p>\n<blockquote>\n<p>❝<br>实时计算<br>❞</p>\n</blockquote>\n<p>随着据量的增加，离线的计算会越来越慢，难以满足用户在某些场景下的实时性要求，因此很多解决方案中引入了实时计算。</p>\n<p>很多时候，即使是海量数据，我们也希望即时去查看一些数据指标，实时流计算应运而生。</p>\n<p>实时流计算有两个特点，一个是实时，随时可以看数据；另一个是流。</p>\n<h2 id=\"「Kafka-的多分区（Partition）以及多副本（Replica）机制有什么好处呢？」\"><a href=\"#「Kafka-的多分区（Partition）以及多副本（Replica）机制有什么好处呢？」\" class=\"headerlink\" title=\"「Kafka 的多分区（Partition）以及多副本（Replica）机制有什么好处呢？」\"></a><strong>「Kafka 的多分区（Partition）以及多副本（Replica）机制有什么好处呢？」</strong></h2><ol>\n<li><p>Kafka 通过给特定 Topic 指定多个 Partition, 而各个 Partition 可以分布在不同的 Broker 上, 这样便能提供比较好的并发能力（负载均衡）。</p>\n</li>\n<li><p>Partition 可以指定对应的 Replica 数, 这也极大地提高了消息存储的安全性, 提高了容灾能力，不过也相应的增加了所需要的存储空间。</p>\n</li>\n</ol>\n<p>参考资料：</p>\n<blockquote>\n<p> <a href=\"https://javaguide.cn/high-performance/message-queue/kafka-questions-01.html\">Kafka常见问题总结</a></p>\n<p> <a href=\"https://mp.weixin.qq.com/s/zfHoSsuSpXWOaxQrm7uvkA\">Kafka核心知识总结！</a></p>\n</blockquote>\n"},{"title":"为什么总是乱码？来看看编码格式吧","date":"2024-03-20T16:00:00.000Z","id":"7613867548996883","_content":"\n## 一、 #ASCII 码\n\n计算机内所有的信息都是二进制位。一个字节包含 8 个二进制位，可以表示 256 个状态，每个状态表示一个符号。\n\n\n\nASCII 码一共规定了128个字符的编码，比如空格 SPACE 是32（二进制00100000），大写的字母 A 是65（二进制01000001）。这128个符号（包括32个不能打印出来的控制符号）。ASCII 码只占用了一个字节的后面7位，最前面的一位统一规定为0。\n\n\n\n\n\n![ASCII码](img/546b99e807733344235b0b668c3c9e7e_MD5.jpeg)\n\n\n\n## 二、非 ASCII 编码\n\n英语用128个符号编码就够了，但是用来表示其他语言，128个符号是不够的。比如，在法语中，字母上方有注音符号，它就无法用 ASCII 码表示。于是，一些欧洲国家就决定，利用字节中闲置的最高位编入新的符号。比如，法语中的é的编码为130（二进制10000010）。这样一来，这些欧洲国家使用的编码体系，可以表示最多256个符号。\n\n所有这些编码方式中，0-127表示的符号是一样的，不一样的只是128-255的这一段，不同的国家相同的 ASCII 码表示的可能是不同的符号。\n\n至于亚洲国家的文字，使用的符号就更多了，汉字就多达10万左右。一个字节只能表示256种符号，肯定是不够的，就必须使用多个字节表达一个符号。比如，简体中文常见的编码方式是 GB2312 ，使用两个字节表示一个汉字，所以理论上最多可以表示 256 x 256 = 65536 个符号。\n\n## 三、 #Unicode 字符集\n\n将世界上多有文字都进行编码，就形成了 Unicode。Unicode 的规模可以容纳100多万个符号，每个符号的编码都不一样。比如，U+0639表示阿拉伯字母 Ain，U+0041表示英语的大写字母 A，U+4E25表示汉字严。\n\n但是，Unicode 只是字符集，它之规定了符号的二进制代码，却不规定编码方式。比如：汉字严的 Unicode 是十六进制数4E25，转换成二进制数足足有15位（100111000100101），也就是说，这个符号的表示至少需要2个字节（16 位二进制数）。如果将 0 补全之后存储，计算机读取的时候，他不清楚到底是（01001110）+（00100101）两个 ASCII 码，还是 （100111000100101）单个 Unicode 值。那么就出现了其他的编码方式。\n\n## 四、 #UTF-8 编码方式\n\nUTF-8 就是在互联网上使用最广的一种 Unicode 的实现方式。其他实现方式还包括 UTF-16（字符用两个字节或四个字节表示）和 UTF-32（字符用四个字节表示），不过在互联网上基本不用。\n\nUTF-8 最大的一个特点，就是它是一种变长的编码方式。它可以使用1~4个字节表示一个符号，根据不同的符号而变化字节长度。\n\n**UTF-8 的编码规则很简单，只有二条：**\n\n- 1）对于单字节的符号：字节的第一位设为0，后面7位为这个符号的 Unicode 码。因此对于英语字母，UTF-8 编码和 ASCII 码是相同的；\n\n- 2）对于 n 字节的符号（n > 1）：第一个字节的前 n 位都设为 1，第 n + 1 位设为 0，后面字节的前两位一律设为 10。剩下的没有提及的二进制位，全部为这个符号的 Unicode 码。\n\n\n\n![Unicode编码和UTF-8编码方式](img/c17560b740940d095c678b2769092f11_MD5.jpeg)\n\n\n\n**如果一个字节的第一位是0，则这个字节单独就是一个字符；如果第一位是1，则连续有多少个1，就表示当前字符占用多少个字节。**\n\n下面，还是以汉字严为例，演示如何实现 UTF-8 编码。\n\n严的 Unicode 是4E25（100111000100101），根据上表，可以发现4E25处在第三行的范围内（0000 0800 - 0000 FFFF），因此严的 UTF-8 编码需要三个字节，即格式是1110xxxx 10xxxxxx 10xxxxxx。然后，从严的最后一个二进制位开始，依次从后向前填入格式中的 x，多出的位补0。这样就得到了，严的 UTF-8 编码是11100100 10111000 10100101，转换成十六进制就是 E4B8A5。\n\n如果保存的编码模式不同，\"严\"对应的值不同：\n\n- 1）ANSII：文件的编码就是两个字节 D1 CF，这正是严的 GB2312 编码，这也暗示 GB2312 是采用大头方式存储的。\n\n- 2）Unicode：编码是四个字节 FF FE 25 4E，其中 FF FE 表明是小头方式存储，真正的编码是4E25。\n\n- 3）Unicode big endian：编码是四个字节 FE FF 4E 25，其中 FE FF 表明是 大头方式 存储。\n\n- 4）UTF-8：编码是六个字节 EF BB BF E4 B8 A5，前三个字节 EF BB BF 表示这是 UTF-8 编码，后三个 E4B8A5 就是严的具体编码，它的存储顺序与编码顺序是一致的。\n\n\n\n## 五、GB 系列\n\n#### #GB2312 字符集\n\n天朝专家把那些127号之后的奇异符号们（即 EASCII）取消掉，规定：一个小于127的字符的意义与原来相同，但两个大于127的字符连在一起时，就表示一个汉字，前面的一个字节（他称之为高字节）从0xA1用到 0xF7，后面一个字节（低字节）从0xA1到0xFE，这样我们就可以组合出大约7000多个简体汉字了。在这些编码里，还把数学符号、罗马希腊的字母、日文的假名们都编进去了，连在 ASCII 里本来就有的数字、标点、字母都统统重新编了两个字节长的编码，这就是常说的\"全角\"字符，而原来在127号以下的那些就叫\"半角\"字符了。这就是 GB2312， #GBK （即 CP936 字符集）和 #GB18030 是对 GB2312 的拓展。\n\n#### #GBK 编码方式\n\n由于 GB 2312-80只收录6763个汉字，有不少汉字，如部分在 GB 2312-80推出以后才简化的汉字（如\"啰\"），部分人名用字（如中国前总理\\*\\*\\*的\"\\*\"字），台湾及香港使用的繁体字，日语及朝鲜语汉字等，并未有收录在内。于是厂商微软利用 GB 2312-80未使用的编码空间，收录 GB 13000.1-93全部字符制定了 GBK 编码。根据微软资料，GBK 是对 GB2312-80的扩展，也就是 CP936字符集 (Code Page 936)的扩展（之前 CP936和 GB 2312-80一模一样），最早实现于 Windows 95简体中文版。虽然 GBK 收录 GB 13000.1-93的全部字符，但编码方式并不相同。GBK 自身并非国家标准，只是曾由国家技术监督局标准化司、电子工业部科技与质量监督司公布为\"技术规范指导性文件\"。原始 GB13000一直未被业界采用，后续国家标准 #GB18030 技术上兼容 GBK 而非 GB13000。\n\n#### #GB18030 字符集\n\n全称：国家标准 GB 18030-2005《信息技术中文编码字符集》，是中华人民共和国现时最新的内码字集，是 GB 18030-2000《信息技术信息交换用汉字编码字符集的扩充》的修订版。与 GB 2312-1980完全兼容，与 GBK 本兼容，支持 GB 13000及 Unicode 的全部统一汉字，共收录汉字70244个。\n\n\n\n## 六、总结\n\n#### 字符集 ：\n\nASCII 字符集：常规的字符集，表示英文以及部分符号。\n\nUnicode 字符集：表示世界上所有字符，统一的字符集。\n\nGB2312 字符集：适配汉字，ASCII 字符集的中文拓展字符集。\n\nCP936 字符集：GBK 编码方式使用的字符集，GB2312 的拓展表。\n\nGB18030 字符集：GB2312 的拓展表，包含全部汉字。\n\n#编码方式 ：\n\nUTF-8 编码方式：是一种对 Unicode 字符集的编码方式，字符由不定字节长度表示。\n\nUTF-16 编码方式：是一种对 Unicode 字符集的编码方式，字符用两个字节或四个字节表示。\n\nUTF-32 编码方式：是一种对 Unicode 字符集的编码方式，字符用四个字节表示。\n\nGBK 编码方式：使用CP936 编码表，是对 ASCII 表的中文适配。\n\n**简单来说：Unicode、GBK 和 Big5码等就是编码的值（也就是术语“字符集”），而 UTF-8、UTF-16、UTF32之类就是这个值的表现形式（即术语“编码格式”）。**\n\n另外：\n\n**Unicode、GBK和Big5码等字符集是不兼容的，同一个汉字在这三个字符集里的码值是完全不一样的。如＂汉＂的Unicode值与gbk就是不一样的，假设Unicode为a040，GBK为b030。以UTF-8为例，UTF-8码完全只针对Unicode来组织的，如果GBK要转UTF-8必须先转Unicode码，再转UTF-8就OK了。**\n\n即GBK、GB2312等与UTF8之间都必须通过Unicode编码才能相互转换：\n\n> 1）GBK、GB2312 --先转--> Unicode --再转--> UTF8  \n\n> 2）UTF8 --先转--> Unicode --再转--> GBK、GB2312\n\n\n\n## 补充\n\n#### BIG5字符集&编码\n\nBig5，又称为大五码或五大码，是使用繁体中文（正体中文）社区中最常用的电脑汉字字符集标准，共收录13,060个汉字。中文码分为内码及交换码两类，Big5属中文内码，知名的中文交换码有 CCCII、CNS11643。Big5虽普及于台湾、香港与澳门等繁体中文通行区，但长期以来并非当地的国家标准，而只是业界标准。倚天中文系统、Windows 等主要系统的字符集都是以 Big5准，但厂商又各自增加不同的造字与造字区，派生成多种不同版本。2003年，Big5被收录到 CNS11643中文标准交换码的附录当中，取得了较正式的地位。这个最新版本被称为 Big5-2003。\n\nBig5码是一套双字节字符集，使用了双八码存储方法，以两个字节来安放一个字。第一个字节称为\"高位字节\"，第二个字节称为\"低位字节\"。\"高位字节\"使用了0x81-0xFE，\"低位字节\"使用了0x40-0x7E，及0xA1-0xFE。\n\n#### 大头方式、小头方式\n\n上一节已经提到，UCS-2 格式可以存储 Unicode 码（码点不超过0xFFFF）。以汉字严为例，Unicode 码是4E25，需要用两个字节存储，一个字节是4E，另一个字节是25。存储的时候，4E 在前，25在后，这就是 Big endian 方式；25在前，4E 在后，这是 Little endian 方式。\n\n第一个字节在前，就是\"大头方式\"（Big endian），第二个字节在前就是\"小头方式\"（Little endian）。\n\n那么很自然的，就会出现一个问题：计算机怎么知道某一个文件到底采用哪一种方式编码？\n\nUnicode 规范定义，每一个文件的最前面分别加入一个表示编码顺序的字符，这个字符的名字叫做\"零宽度非换行空格\"（zero width no-break space），用FEFF表示。这正好是两个字节，而且FF比FE大1。\n\n如果一个文本文件的头两个字节是 FE FF，就表示该文件采用大头方式；如果头两个字节是 FF FE，就表示该文件采用小头方式。\n\n\n\n\n\n\n\n参考资料：\n\n>  [字符编码技术专题(一)：快速理解ASCII、Unicode、GBK和UTF-8]( https://zhuanlan.zhihu.com/p/658651404 )","source":"_posts/md/为什么总是乱码？来看看编码格式吧.md","raw":"---\ntitle: 为什么总是乱码？来看看编码格式吧\ntag: \n- 编码\ncategory: \n- 后端\ndate: 2024-03-21\nid: 7613867548996883\n---\n\n## 一、 #ASCII 码\n\n计算机内所有的信息都是二进制位。一个字节包含 8 个二进制位，可以表示 256 个状态，每个状态表示一个符号。\n\n\n\nASCII 码一共规定了128个字符的编码，比如空格 SPACE 是32（二进制00100000），大写的字母 A 是65（二进制01000001）。这128个符号（包括32个不能打印出来的控制符号）。ASCII 码只占用了一个字节的后面7位，最前面的一位统一规定为0。\n\n\n\n\n\n![ASCII码](img/546b99e807733344235b0b668c3c9e7e_MD5.jpeg)\n\n\n\n## 二、非 ASCII 编码\n\n英语用128个符号编码就够了，但是用来表示其他语言，128个符号是不够的。比如，在法语中，字母上方有注音符号，它就无法用 ASCII 码表示。于是，一些欧洲国家就决定，利用字节中闲置的最高位编入新的符号。比如，法语中的é的编码为130（二进制10000010）。这样一来，这些欧洲国家使用的编码体系，可以表示最多256个符号。\n\n所有这些编码方式中，0-127表示的符号是一样的，不一样的只是128-255的这一段，不同的国家相同的 ASCII 码表示的可能是不同的符号。\n\n至于亚洲国家的文字，使用的符号就更多了，汉字就多达10万左右。一个字节只能表示256种符号，肯定是不够的，就必须使用多个字节表达一个符号。比如，简体中文常见的编码方式是 GB2312 ，使用两个字节表示一个汉字，所以理论上最多可以表示 256 x 256 = 65536 个符号。\n\n## 三、 #Unicode 字符集\n\n将世界上多有文字都进行编码，就形成了 Unicode。Unicode 的规模可以容纳100多万个符号，每个符号的编码都不一样。比如，U+0639表示阿拉伯字母 Ain，U+0041表示英语的大写字母 A，U+4E25表示汉字严。\n\n但是，Unicode 只是字符集，它之规定了符号的二进制代码，却不规定编码方式。比如：汉字严的 Unicode 是十六进制数4E25，转换成二进制数足足有15位（100111000100101），也就是说，这个符号的表示至少需要2个字节（16 位二进制数）。如果将 0 补全之后存储，计算机读取的时候，他不清楚到底是（01001110）+（00100101）两个 ASCII 码，还是 （100111000100101）单个 Unicode 值。那么就出现了其他的编码方式。\n\n## 四、 #UTF-8 编码方式\n\nUTF-8 就是在互联网上使用最广的一种 Unicode 的实现方式。其他实现方式还包括 UTF-16（字符用两个字节或四个字节表示）和 UTF-32（字符用四个字节表示），不过在互联网上基本不用。\n\nUTF-8 最大的一个特点，就是它是一种变长的编码方式。它可以使用1~4个字节表示一个符号，根据不同的符号而变化字节长度。\n\n**UTF-8 的编码规则很简单，只有二条：**\n\n- 1）对于单字节的符号：字节的第一位设为0，后面7位为这个符号的 Unicode 码。因此对于英语字母，UTF-8 编码和 ASCII 码是相同的；\n\n- 2）对于 n 字节的符号（n > 1）：第一个字节的前 n 位都设为 1，第 n + 1 位设为 0，后面字节的前两位一律设为 10。剩下的没有提及的二进制位，全部为这个符号的 Unicode 码。\n\n\n\n![Unicode编码和UTF-8编码方式](img/c17560b740940d095c678b2769092f11_MD5.jpeg)\n\n\n\n**如果一个字节的第一位是0，则这个字节单独就是一个字符；如果第一位是1，则连续有多少个1，就表示当前字符占用多少个字节。**\n\n下面，还是以汉字严为例，演示如何实现 UTF-8 编码。\n\n严的 Unicode 是4E25（100111000100101），根据上表，可以发现4E25处在第三行的范围内（0000 0800 - 0000 FFFF），因此严的 UTF-8 编码需要三个字节，即格式是1110xxxx 10xxxxxx 10xxxxxx。然后，从严的最后一个二进制位开始，依次从后向前填入格式中的 x，多出的位补0。这样就得到了，严的 UTF-8 编码是11100100 10111000 10100101，转换成十六进制就是 E4B8A5。\n\n如果保存的编码模式不同，\"严\"对应的值不同：\n\n- 1）ANSII：文件的编码就是两个字节 D1 CF，这正是严的 GB2312 编码，这也暗示 GB2312 是采用大头方式存储的。\n\n- 2）Unicode：编码是四个字节 FF FE 25 4E，其中 FF FE 表明是小头方式存储，真正的编码是4E25。\n\n- 3）Unicode big endian：编码是四个字节 FE FF 4E 25，其中 FE FF 表明是 大头方式 存储。\n\n- 4）UTF-8：编码是六个字节 EF BB BF E4 B8 A5，前三个字节 EF BB BF 表示这是 UTF-8 编码，后三个 E4B8A5 就是严的具体编码，它的存储顺序与编码顺序是一致的。\n\n\n\n## 五、GB 系列\n\n#### #GB2312 字符集\n\n天朝专家把那些127号之后的奇异符号们（即 EASCII）取消掉，规定：一个小于127的字符的意义与原来相同，但两个大于127的字符连在一起时，就表示一个汉字，前面的一个字节（他称之为高字节）从0xA1用到 0xF7，后面一个字节（低字节）从0xA1到0xFE，这样我们就可以组合出大约7000多个简体汉字了。在这些编码里，还把数学符号、罗马希腊的字母、日文的假名们都编进去了，连在 ASCII 里本来就有的数字、标点、字母都统统重新编了两个字节长的编码，这就是常说的\"全角\"字符，而原来在127号以下的那些就叫\"半角\"字符了。这就是 GB2312， #GBK （即 CP936 字符集）和 #GB18030 是对 GB2312 的拓展。\n\n#### #GBK 编码方式\n\n由于 GB 2312-80只收录6763个汉字，有不少汉字，如部分在 GB 2312-80推出以后才简化的汉字（如\"啰\"），部分人名用字（如中国前总理\\*\\*\\*的\"\\*\"字），台湾及香港使用的繁体字，日语及朝鲜语汉字等，并未有收录在内。于是厂商微软利用 GB 2312-80未使用的编码空间，收录 GB 13000.1-93全部字符制定了 GBK 编码。根据微软资料，GBK 是对 GB2312-80的扩展，也就是 CP936字符集 (Code Page 936)的扩展（之前 CP936和 GB 2312-80一模一样），最早实现于 Windows 95简体中文版。虽然 GBK 收录 GB 13000.1-93的全部字符，但编码方式并不相同。GBK 自身并非国家标准，只是曾由国家技术监督局标准化司、电子工业部科技与质量监督司公布为\"技术规范指导性文件\"。原始 GB13000一直未被业界采用，后续国家标准 #GB18030 技术上兼容 GBK 而非 GB13000。\n\n#### #GB18030 字符集\n\n全称：国家标准 GB 18030-2005《信息技术中文编码字符集》，是中华人民共和国现时最新的内码字集，是 GB 18030-2000《信息技术信息交换用汉字编码字符集的扩充》的修订版。与 GB 2312-1980完全兼容，与 GBK 本兼容，支持 GB 13000及 Unicode 的全部统一汉字，共收录汉字70244个。\n\n\n\n## 六、总结\n\n#### 字符集 ：\n\nASCII 字符集：常规的字符集，表示英文以及部分符号。\n\nUnicode 字符集：表示世界上所有字符，统一的字符集。\n\nGB2312 字符集：适配汉字，ASCII 字符集的中文拓展字符集。\n\nCP936 字符集：GBK 编码方式使用的字符集，GB2312 的拓展表。\n\nGB18030 字符集：GB2312 的拓展表，包含全部汉字。\n\n#编码方式 ：\n\nUTF-8 编码方式：是一种对 Unicode 字符集的编码方式，字符由不定字节长度表示。\n\nUTF-16 编码方式：是一种对 Unicode 字符集的编码方式，字符用两个字节或四个字节表示。\n\nUTF-32 编码方式：是一种对 Unicode 字符集的编码方式，字符用四个字节表示。\n\nGBK 编码方式：使用CP936 编码表，是对 ASCII 表的中文适配。\n\n**简单来说：Unicode、GBK 和 Big5码等就是编码的值（也就是术语“字符集”），而 UTF-8、UTF-16、UTF32之类就是这个值的表现形式（即术语“编码格式”）。**\n\n另外：\n\n**Unicode、GBK和Big5码等字符集是不兼容的，同一个汉字在这三个字符集里的码值是完全不一样的。如＂汉＂的Unicode值与gbk就是不一样的，假设Unicode为a040，GBK为b030。以UTF-8为例，UTF-8码完全只针对Unicode来组织的，如果GBK要转UTF-8必须先转Unicode码，再转UTF-8就OK了。**\n\n即GBK、GB2312等与UTF8之间都必须通过Unicode编码才能相互转换：\n\n> 1）GBK、GB2312 --先转--> Unicode --再转--> UTF8  \n\n> 2）UTF8 --先转--> Unicode --再转--> GBK、GB2312\n\n\n\n## 补充\n\n#### BIG5字符集&编码\n\nBig5，又称为大五码或五大码，是使用繁体中文（正体中文）社区中最常用的电脑汉字字符集标准，共收录13,060个汉字。中文码分为内码及交换码两类，Big5属中文内码，知名的中文交换码有 CCCII、CNS11643。Big5虽普及于台湾、香港与澳门等繁体中文通行区，但长期以来并非当地的国家标准，而只是业界标准。倚天中文系统、Windows 等主要系统的字符集都是以 Big5准，但厂商又各自增加不同的造字与造字区，派生成多种不同版本。2003年，Big5被收录到 CNS11643中文标准交换码的附录当中，取得了较正式的地位。这个最新版本被称为 Big5-2003。\n\nBig5码是一套双字节字符集，使用了双八码存储方法，以两个字节来安放一个字。第一个字节称为\"高位字节\"，第二个字节称为\"低位字节\"。\"高位字节\"使用了0x81-0xFE，\"低位字节\"使用了0x40-0x7E，及0xA1-0xFE。\n\n#### 大头方式、小头方式\n\n上一节已经提到，UCS-2 格式可以存储 Unicode 码（码点不超过0xFFFF）。以汉字严为例，Unicode 码是4E25，需要用两个字节存储，一个字节是4E，另一个字节是25。存储的时候，4E 在前，25在后，这就是 Big endian 方式；25在前，4E 在后，这是 Little endian 方式。\n\n第一个字节在前，就是\"大头方式\"（Big endian），第二个字节在前就是\"小头方式\"（Little endian）。\n\n那么很自然的，就会出现一个问题：计算机怎么知道某一个文件到底采用哪一种方式编码？\n\nUnicode 规范定义，每一个文件的最前面分别加入一个表示编码顺序的字符，这个字符的名字叫做\"零宽度非换行空格\"（zero width no-break space），用FEFF表示。这正好是两个字节，而且FF比FE大1。\n\n如果一个文本文件的头两个字节是 FE FF，就表示该文件采用大头方式；如果头两个字节是 FF FE，就表示该文件采用小头方式。\n\n\n\n\n\n\n\n参考资料：\n\n>  [字符编码技术专题(一)：快速理解ASCII、Unicode、GBK和UTF-8]( https://zhuanlan.zhihu.com/p/658651404 )","slug":"md/为什么总是乱码？来看看编码格式吧","published":1,"updated":"2025-05-20T07:22:00.347Z","comments":1,"layout":"post","photos":[],"_id":"cmhc3m3uc000bxdp87qlvdcwa","content":"<h2 id=\"一、-ASCII-码\"><a href=\"#一、-ASCII-码\" class=\"headerlink\" title=\"一、 #ASCII 码\"></a>一、 #ASCII 码</h2><p>计算机内所有的信息都是二进制位。一个字节包含 8 个二进制位，可以表示 256 个状态，每个状态表示一个符号。</p>\n<p>ASCII 码一共规定了128个字符的编码，比如空格 SPACE 是32（二进制00100000），大写的字母 A 是65（二进制01000001）。这128个符号（包括32个不能打印出来的控制符号）。ASCII 码只占用了一个字节的后面7位，最前面的一位统一规定为0。</p>\n<p><img src=\"/img/546b99e807733344235b0b668c3c9e7e_MD5.jpeg\" alt=\"ASCII码\"></p>\n<h2 id=\"二、非-ASCII-编码\"><a href=\"#二、非-ASCII-编码\" class=\"headerlink\" title=\"二、非 ASCII 编码\"></a>二、非 ASCII 编码</h2><p>英语用128个符号编码就够了，但是用来表示其他语言，128个符号是不够的。比如，在法语中，字母上方有注音符号，它就无法用 ASCII 码表示。于是，一些欧洲国家就决定，利用字节中闲置的最高位编入新的符号。比如，法语中的é的编码为130（二进制10000010）。这样一来，这些欧洲国家使用的编码体系，可以表示最多256个符号。</p>\n<p>所有这些编码方式中，0-127表示的符号是一样的，不一样的只是128-255的这一段，不同的国家相同的 ASCII 码表示的可能是不同的符号。</p>\n<p>至于亚洲国家的文字，使用的符号就更多了，汉字就多达10万左右。一个字节只能表示256种符号，肯定是不够的，就必须使用多个字节表达一个符号。比如，简体中文常见的编码方式是 GB2312 ，使用两个字节表示一个汉字，所以理论上最多可以表示 256 x 256 &#x3D; 65536 个符号。</p>\n<h2 id=\"三、-Unicode-字符集\"><a href=\"#三、-Unicode-字符集\" class=\"headerlink\" title=\"三、 #Unicode 字符集\"></a>三、 #Unicode 字符集</h2><p>将世界上多有文字都进行编码，就形成了 Unicode。Unicode 的规模可以容纳100多万个符号，每个符号的编码都不一样。比如，U+0639表示阿拉伯字母 Ain，U+0041表示英语的大写字母 A，U+4E25表示汉字严。</p>\n<p>但是，Unicode 只是字符集，它之规定了符号的二进制代码，却不规定编码方式。比如：汉字严的 Unicode 是十六进制数4E25，转换成二进制数足足有15位（100111000100101），也就是说，这个符号的表示至少需要2个字节（16 位二进制数）。如果将 0 补全之后存储，计算机读取的时候，他不清楚到底是（01001110）+（00100101）两个 ASCII 码，还是 （100111000100101）单个 Unicode 值。那么就出现了其他的编码方式。</p>\n<h2 id=\"四、-UTF-8-编码方式\"><a href=\"#四、-UTF-8-编码方式\" class=\"headerlink\" title=\"四、 #UTF-8 编码方式\"></a>四、 #UTF-8 编码方式</h2><p>UTF-8 就是在互联网上使用最广的一种 Unicode 的实现方式。其他实现方式还包括 UTF-16（字符用两个字节或四个字节表示）和 UTF-32（字符用四个字节表示），不过在互联网上基本不用。</p>\n<p>UTF-8 最大的一个特点，就是它是一种变长的编码方式。它可以使用1~4个字节表示一个符号，根据不同的符号而变化字节长度。</p>\n<p><strong>UTF-8 的编码规则很简单，只有二条：</strong></p>\n<ul>\n<li><p>1）对于单字节的符号：字节的第一位设为0，后面7位为这个符号的 Unicode 码。因此对于英语字母，UTF-8 编码和 ASCII 码是相同的；</p>\n</li>\n<li><p>2）对于 n 字节的符号（n &gt; 1）：第一个字节的前 n 位都设为 1，第 n + 1 位设为 0，后面字节的前两位一律设为 10。剩下的没有提及的二进制位，全部为这个符号的 Unicode 码。</p>\n</li>\n</ul>\n<p><img src=\"/img/c17560b740940d095c678b2769092f11_MD5.jpeg\" alt=\"Unicode编码和UTF-8编码方式\"></p>\n<p><strong>如果一个字节的第一位是0，则这个字节单独就是一个字符；如果第一位是1，则连续有多少个1，就表示当前字符占用多少个字节。</strong></p>\n<p>下面，还是以汉字严为例，演示如何实现 UTF-8 编码。</p>\n<p>严的 Unicode 是4E25（100111000100101），根据上表，可以发现4E25处在第三行的范围内（0000 0800 - 0000 FFFF），因此严的 UTF-8 编码需要三个字节，即格式是1110xxxx 10xxxxxx 10xxxxxx。然后，从严的最后一个二进制位开始，依次从后向前填入格式中的 x，多出的位补0。这样就得到了，严的 UTF-8 编码是11100100 10111000 10100101，转换成十六进制就是 E4B8A5。</p>\n<p>如果保存的编码模式不同，”严”对应的值不同：</p>\n<ul>\n<li><p>1）ANSII：文件的编码就是两个字节 D1 CF，这正是严的 GB2312 编码，这也暗示 GB2312 是采用大头方式存储的。</p>\n</li>\n<li><p>2）Unicode：编码是四个字节 FF FE 25 4E，其中 FF FE 表明是小头方式存储，真正的编码是4E25。</p>\n</li>\n<li><p>3）Unicode big endian：编码是四个字节 FE FF 4E 25，其中 FE FF 表明是 大头方式 存储。</p>\n</li>\n<li><p>4）UTF-8：编码是六个字节 EF BB BF E4 B8 A5，前三个字节 EF BB BF 表示这是 UTF-8 编码，后三个 E4B8A5 就是严的具体编码，它的存储顺序与编码顺序是一致的。</p>\n</li>\n</ul>\n<h2 id=\"五、GB-系列\"><a href=\"#五、GB-系列\" class=\"headerlink\" title=\"五、GB 系列\"></a>五、GB 系列</h2><h4 id=\"GB2312-字符集\"><a href=\"#GB2312-字符集\" class=\"headerlink\" title=\"#GB2312 字符集\"></a>#GB2312 字符集</h4><p>天朝专家把那些127号之后的奇异符号们（即 EASCII）取消掉，规定：一个小于127的字符的意义与原来相同，但两个大于127的字符连在一起时，就表示一个汉字，前面的一个字节（他称之为高字节）从0xA1用到 0xF7，后面一个字节（低字节）从0xA1到0xFE，这样我们就可以组合出大约7000多个简体汉字了。在这些编码里，还把数学符号、罗马希腊的字母、日文的假名们都编进去了，连在 ASCII 里本来就有的数字、标点、字母都统统重新编了两个字节长的编码，这就是常说的”全角”字符，而原来在127号以下的那些就叫”半角”字符了。这就是 GB2312， #GBK （即 CP936 字符集）和 #GB18030 是对 GB2312 的拓展。</p>\n<h4 id=\"GBK-编码方式\"><a href=\"#GBK-编码方式\" class=\"headerlink\" title=\"#GBK 编码方式\"></a>#GBK 编码方式</h4><p>由于 GB 2312-80只收录6763个汉字，有不少汉字，如部分在 GB 2312-80推出以后才简化的汉字（如”啰”），部分人名用字（如中国前总理***的”*“字），台湾及香港使用的繁体字，日语及朝鲜语汉字等，并未有收录在内。于是厂商微软利用 GB 2312-80未使用的编码空间，收录 GB 13000.1-93全部字符制定了 GBK 编码。根据微软资料，GBK 是对 GB2312-80的扩展，也就是 CP936字符集 (Code Page 936)的扩展（之前 CP936和 GB 2312-80一模一样），最早实现于 Windows 95简体中文版。虽然 GBK 收录 GB 13000.1-93的全部字符，但编码方式并不相同。GBK 自身并非国家标准，只是曾由国家技术监督局标准化司、电子工业部科技与质量监督司公布为”技术规范指导性文件”。原始 GB13000一直未被业界采用，后续国家标准 #GB18030 技术上兼容 GBK 而非 GB13000。</p>\n<h4 id=\"GB18030-字符集\"><a href=\"#GB18030-字符集\" class=\"headerlink\" title=\"#GB18030 字符集\"></a>#GB18030 字符集</h4><p>全称：国家标准 GB 18030-2005《信息技术中文编码字符集》，是中华人民共和国现时最新的内码字集，是 GB 18030-2000《信息技术信息交换用汉字编码字符集的扩充》的修订版。与 GB 2312-1980完全兼容，与 GBK 本兼容，支持 GB 13000及 Unicode 的全部统一汉字，共收录汉字70244个。</p>\n<h2 id=\"六、总结\"><a href=\"#六、总结\" class=\"headerlink\" title=\"六、总结\"></a>六、总结</h2><h4 id=\"字符集-：\"><a href=\"#字符集-：\" class=\"headerlink\" title=\"字符集 ：\"></a>字符集 ：</h4><p>ASCII 字符集：常规的字符集，表示英文以及部分符号。</p>\n<p>Unicode 字符集：表示世界上所有字符，统一的字符集。</p>\n<p>GB2312 字符集：适配汉字，ASCII 字符集的中文拓展字符集。</p>\n<p>CP936 字符集：GBK 编码方式使用的字符集，GB2312 的拓展表。</p>\n<p>GB18030 字符集：GB2312 的拓展表，包含全部汉字。</p>\n<p>#编码方式 ：</p>\n<p>UTF-8 编码方式：是一种对 Unicode 字符集的编码方式，字符由不定字节长度表示。</p>\n<p>UTF-16 编码方式：是一种对 Unicode 字符集的编码方式，字符用两个字节或四个字节表示。</p>\n<p>UTF-32 编码方式：是一种对 Unicode 字符集的编码方式，字符用四个字节表示。</p>\n<p>GBK 编码方式：使用CP936 编码表，是对 ASCII 表的中文适配。</p>\n<p><strong>简单来说：Unicode、GBK 和 Big5码等就是编码的值（也就是术语“字符集”），而 UTF-8、UTF-16、UTF32之类就是这个值的表现形式（即术语“编码格式”）。</strong></p>\n<p>另外：</p>\n<p><strong>Unicode、GBK和Big5码等字符集是不兼容的，同一个汉字在这三个字符集里的码值是完全不一样的。如＂汉＂的Unicode值与gbk就是不一样的，假设Unicode为a040，GBK为b030。以UTF-8为例，UTF-8码完全只针对Unicode来组织的，如果GBK要转UTF-8必须先转Unicode码，再转UTF-8就OK了。</strong></p>\n<p>即GBK、GB2312等与UTF8之间都必须通过Unicode编码才能相互转换：</p>\n<blockquote>\n<p>1）GBK、GB2312 –先转–&gt; Unicode –再转–&gt; UTF8  </p>\n</blockquote>\n<blockquote>\n<p>2）UTF8 –先转–&gt; Unicode –再转–&gt; GBK、GB2312</p>\n</blockquote>\n<h2 id=\"补充\"><a href=\"#补充\" class=\"headerlink\" title=\"补充\"></a>补充</h2><h4 id=\"BIG5字符集-编码\"><a href=\"#BIG5字符集-编码\" class=\"headerlink\" title=\"BIG5字符集&amp;编码\"></a>BIG5字符集&amp;编码</h4><p>Big5，又称为大五码或五大码，是使用繁体中文（正体中文）社区中最常用的电脑汉字字符集标准，共收录13,060个汉字。中文码分为内码及交换码两类，Big5属中文内码，知名的中文交换码有 CCCII、CNS11643。Big5虽普及于台湾、香港与澳门等繁体中文通行区，但长期以来并非当地的国家标准，而只是业界标准。倚天中文系统、Windows 等主要系统的字符集都是以 Big5准，但厂商又各自增加不同的造字与造字区，派生成多种不同版本。2003年，Big5被收录到 CNS11643中文标准交换码的附录当中，取得了较正式的地位。这个最新版本被称为 Big5-2003。</p>\n<p>Big5码是一套双字节字符集，使用了双八码存储方法，以两个字节来安放一个字。第一个字节称为”高位字节”，第二个字节称为”低位字节”。”高位字节”使用了0x81-0xFE，”低位字节”使用了0x40-0x7E，及0xA1-0xFE。</p>\n<h4 id=\"大头方式、小头方式\"><a href=\"#大头方式、小头方式\" class=\"headerlink\" title=\"大头方式、小头方式\"></a>大头方式、小头方式</h4><p>上一节已经提到，UCS-2 格式可以存储 Unicode 码（码点不超过0xFFFF）。以汉字严为例，Unicode 码是4E25，需要用两个字节存储，一个字节是4E，另一个字节是25。存储的时候，4E 在前，25在后，这就是 Big endian 方式；25在前，4E 在后，这是 Little endian 方式。</p>\n<p>第一个字节在前，就是”大头方式”（Big endian），第二个字节在前就是”小头方式”（Little endian）。</p>\n<p>那么很自然的，就会出现一个问题：计算机怎么知道某一个文件到底采用哪一种方式编码？</p>\n<p>Unicode 规范定义，每一个文件的最前面分别加入一个表示编码顺序的字符，这个字符的名字叫做”零宽度非换行空格”（zero width no-break space），用FEFF表示。这正好是两个字节，而且FF比FE大1。</p>\n<p>如果一个文本文件的头两个字节是 FE FF，就表示该文件采用大头方式；如果头两个字节是 FF FE，就表示该文件采用小头方式。</p>\n<p>参考资料：</p>\n<blockquote>\n<p> <a href=\"https://zhuanlan.zhihu.com/p/658651404\">字符编码技术专题(一)：快速理解ASCII、Unicode、GBK和UTF-8</a></p>\n</blockquote>\n","excerpt":"","more":"<h2 id=\"一、-ASCII-码\"><a href=\"#一、-ASCII-码\" class=\"headerlink\" title=\"一、 #ASCII 码\"></a>一、 #ASCII 码</h2><p>计算机内所有的信息都是二进制位。一个字节包含 8 个二进制位，可以表示 256 个状态，每个状态表示一个符号。</p>\n<p>ASCII 码一共规定了128个字符的编码，比如空格 SPACE 是32（二进制00100000），大写的字母 A 是65（二进制01000001）。这128个符号（包括32个不能打印出来的控制符号）。ASCII 码只占用了一个字节的后面7位，最前面的一位统一规定为0。</p>\n<p><img src=\"/img/546b99e807733344235b0b668c3c9e7e_MD5.jpeg\" alt=\"ASCII码\"></p>\n<h2 id=\"二、非-ASCII-编码\"><a href=\"#二、非-ASCII-编码\" class=\"headerlink\" title=\"二、非 ASCII 编码\"></a>二、非 ASCII 编码</h2><p>英语用128个符号编码就够了，但是用来表示其他语言，128个符号是不够的。比如，在法语中，字母上方有注音符号，它就无法用 ASCII 码表示。于是，一些欧洲国家就决定，利用字节中闲置的最高位编入新的符号。比如，法语中的é的编码为130（二进制10000010）。这样一来，这些欧洲国家使用的编码体系，可以表示最多256个符号。</p>\n<p>所有这些编码方式中，0-127表示的符号是一样的，不一样的只是128-255的这一段，不同的国家相同的 ASCII 码表示的可能是不同的符号。</p>\n<p>至于亚洲国家的文字，使用的符号就更多了，汉字就多达10万左右。一个字节只能表示256种符号，肯定是不够的，就必须使用多个字节表达一个符号。比如，简体中文常见的编码方式是 GB2312 ，使用两个字节表示一个汉字，所以理论上最多可以表示 256 x 256 &#x3D; 65536 个符号。</p>\n<h2 id=\"三、-Unicode-字符集\"><a href=\"#三、-Unicode-字符集\" class=\"headerlink\" title=\"三、 #Unicode 字符集\"></a>三、 #Unicode 字符集</h2><p>将世界上多有文字都进行编码，就形成了 Unicode。Unicode 的规模可以容纳100多万个符号，每个符号的编码都不一样。比如，U+0639表示阿拉伯字母 Ain，U+0041表示英语的大写字母 A，U+4E25表示汉字严。</p>\n<p>但是，Unicode 只是字符集，它之规定了符号的二进制代码，却不规定编码方式。比如：汉字严的 Unicode 是十六进制数4E25，转换成二进制数足足有15位（100111000100101），也就是说，这个符号的表示至少需要2个字节（16 位二进制数）。如果将 0 补全之后存储，计算机读取的时候，他不清楚到底是（01001110）+（00100101）两个 ASCII 码，还是 （100111000100101）单个 Unicode 值。那么就出现了其他的编码方式。</p>\n<h2 id=\"四、-UTF-8-编码方式\"><a href=\"#四、-UTF-8-编码方式\" class=\"headerlink\" title=\"四、 #UTF-8 编码方式\"></a>四、 #UTF-8 编码方式</h2><p>UTF-8 就是在互联网上使用最广的一种 Unicode 的实现方式。其他实现方式还包括 UTF-16（字符用两个字节或四个字节表示）和 UTF-32（字符用四个字节表示），不过在互联网上基本不用。</p>\n<p>UTF-8 最大的一个特点，就是它是一种变长的编码方式。它可以使用1~4个字节表示一个符号，根据不同的符号而变化字节长度。</p>\n<p><strong>UTF-8 的编码规则很简单，只有二条：</strong></p>\n<ul>\n<li><p>1）对于单字节的符号：字节的第一位设为0，后面7位为这个符号的 Unicode 码。因此对于英语字母，UTF-8 编码和 ASCII 码是相同的；</p>\n</li>\n<li><p>2）对于 n 字节的符号（n &gt; 1）：第一个字节的前 n 位都设为 1，第 n + 1 位设为 0，后面字节的前两位一律设为 10。剩下的没有提及的二进制位，全部为这个符号的 Unicode 码。</p>\n</li>\n</ul>\n<p><img src=\"/img/c17560b740940d095c678b2769092f11_MD5.jpeg\" alt=\"Unicode编码和UTF-8编码方式\"></p>\n<p><strong>如果一个字节的第一位是0，则这个字节单独就是一个字符；如果第一位是1，则连续有多少个1，就表示当前字符占用多少个字节。</strong></p>\n<p>下面，还是以汉字严为例，演示如何实现 UTF-8 编码。</p>\n<p>严的 Unicode 是4E25（100111000100101），根据上表，可以发现4E25处在第三行的范围内（0000 0800 - 0000 FFFF），因此严的 UTF-8 编码需要三个字节，即格式是1110xxxx 10xxxxxx 10xxxxxx。然后，从严的最后一个二进制位开始，依次从后向前填入格式中的 x，多出的位补0。这样就得到了，严的 UTF-8 编码是11100100 10111000 10100101，转换成十六进制就是 E4B8A5。</p>\n<p>如果保存的编码模式不同，”严”对应的值不同：</p>\n<ul>\n<li><p>1）ANSII：文件的编码就是两个字节 D1 CF，这正是严的 GB2312 编码，这也暗示 GB2312 是采用大头方式存储的。</p>\n</li>\n<li><p>2）Unicode：编码是四个字节 FF FE 25 4E，其中 FF FE 表明是小头方式存储，真正的编码是4E25。</p>\n</li>\n<li><p>3）Unicode big endian：编码是四个字节 FE FF 4E 25，其中 FE FF 表明是 大头方式 存储。</p>\n</li>\n<li><p>4）UTF-8：编码是六个字节 EF BB BF E4 B8 A5，前三个字节 EF BB BF 表示这是 UTF-8 编码，后三个 E4B8A5 就是严的具体编码，它的存储顺序与编码顺序是一致的。</p>\n</li>\n</ul>\n<h2 id=\"五、GB-系列\"><a href=\"#五、GB-系列\" class=\"headerlink\" title=\"五、GB 系列\"></a>五、GB 系列</h2><h4 id=\"GB2312-字符集\"><a href=\"#GB2312-字符集\" class=\"headerlink\" title=\"#GB2312 字符集\"></a>#GB2312 字符集</h4><p>天朝专家把那些127号之后的奇异符号们（即 EASCII）取消掉，规定：一个小于127的字符的意义与原来相同，但两个大于127的字符连在一起时，就表示一个汉字，前面的一个字节（他称之为高字节）从0xA1用到 0xF7，后面一个字节（低字节）从0xA1到0xFE，这样我们就可以组合出大约7000多个简体汉字了。在这些编码里，还把数学符号、罗马希腊的字母、日文的假名们都编进去了，连在 ASCII 里本来就有的数字、标点、字母都统统重新编了两个字节长的编码，这就是常说的”全角”字符，而原来在127号以下的那些就叫”半角”字符了。这就是 GB2312， #GBK （即 CP936 字符集）和 #GB18030 是对 GB2312 的拓展。</p>\n<h4 id=\"GBK-编码方式\"><a href=\"#GBK-编码方式\" class=\"headerlink\" title=\"#GBK 编码方式\"></a>#GBK 编码方式</h4><p>由于 GB 2312-80只收录6763个汉字，有不少汉字，如部分在 GB 2312-80推出以后才简化的汉字（如”啰”），部分人名用字（如中国前总理***的”*“字），台湾及香港使用的繁体字，日语及朝鲜语汉字等，并未有收录在内。于是厂商微软利用 GB 2312-80未使用的编码空间，收录 GB 13000.1-93全部字符制定了 GBK 编码。根据微软资料，GBK 是对 GB2312-80的扩展，也就是 CP936字符集 (Code Page 936)的扩展（之前 CP936和 GB 2312-80一模一样），最早实现于 Windows 95简体中文版。虽然 GBK 收录 GB 13000.1-93的全部字符，但编码方式并不相同。GBK 自身并非国家标准，只是曾由国家技术监督局标准化司、电子工业部科技与质量监督司公布为”技术规范指导性文件”。原始 GB13000一直未被业界采用，后续国家标准 #GB18030 技术上兼容 GBK 而非 GB13000。</p>\n<h4 id=\"GB18030-字符集\"><a href=\"#GB18030-字符集\" class=\"headerlink\" title=\"#GB18030 字符集\"></a>#GB18030 字符集</h4><p>全称：国家标准 GB 18030-2005《信息技术中文编码字符集》，是中华人民共和国现时最新的内码字集，是 GB 18030-2000《信息技术信息交换用汉字编码字符集的扩充》的修订版。与 GB 2312-1980完全兼容，与 GBK 本兼容，支持 GB 13000及 Unicode 的全部统一汉字，共收录汉字70244个。</p>\n<h2 id=\"六、总结\"><a href=\"#六、总结\" class=\"headerlink\" title=\"六、总结\"></a>六、总结</h2><h4 id=\"字符集-：\"><a href=\"#字符集-：\" class=\"headerlink\" title=\"字符集 ：\"></a>字符集 ：</h4><p>ASCII 字符集：常规的字符集，表示英文以及部分符号。</p>\n<p>Unicode 字符集：表示世界上所有字符，统一的字符集。</p>\n<p>GB2312 字符集：适配汉字，ASCII 字符集的中文拓展字符集。</p>\n<p>CP936 字符集：GBK 编码方式使用的字符集，GB2312 的拓展表。</p>\n<p>GB18030 字符集：GB2312 的拓展表，包含全部汉字。</p>\n<p>#编码方式 ：</p>\n<p>UTF-8 编码方式：是一种对 Unicode 字符集的编码方式，字符由不定字节长度表示。</p>\n<p>UTF-16 编码方式：是一种对 Unicode 字符集的编码方式，字符用两个字节或四个字节表示。</p>\n<p>UTF-32 编码方式：是一种对 Unicode 字符集的编码方式，字符用四个字节表示。</p>\n<p>GBK 编码方式：使用CP936 编码表，是对 ASCII 表的中文适配。</p>\n<p><strong>简单来说：Unicode、GBK 和 Big5码等就是编码的值（也就是术语“字符集”），而 UTF-8、UTF-16、UTF32之类就是这个值的表现形式（即术语“编码格式”）。</strong></p>\n<p>另外：</p>\n<p><strong>Unicode、GBK和Big5码等字符集是不兼容的，同一个汉字在这三个字符集里的码值是完全不一样的。如＂汉＂的Unicode值与gbk就是不一样的，假设Unicode为a040，GBK为b030。以UTF-8为例，UTF-8码完全只针对Unicode来组织的，如果GBK要转UTF-8必须先转Unicode码，再转UTF-8就OK了。</strong></p>\n<p>即GBK、GB2312等与UTF8之间都必须通过Unicode编码才能相互转换：</p>\n<blockquote>\n<p>1）GBK、GB2312 –先转–&gt; Unicode –再转–&gt; UTF8  </p>\n</blockquote>\n<blockquote>\n<p>2）UTF8 –先转–&gt; Unicode –再转–&gt; GBK、GB2312</p>\n</blockquote>\n<h2 id=\"补充\"><a href=\"#补充\" class=\"headerlink\" title=\"补充\"></a>补充</h2><h4 id=\"BIG5字符集-编码\"><a href=\"#BIG5字符集-编码\" class=\"headerlink\" title=\"BIG5字符集&amp;编码\"></a>BIG5字符集&amp;编码</h4><p>Big5，又称为大五码或五大码，是使用繁体中文（正体中文）社区中最常用的电脑汉字字符集标准，共收录13,060个汉字。中文码分为内码及交换码两类，Big5属中文内码，知名的中文交换码有 CCCII、CNS11643。Big5虽普及于台湾、香港与澳门等繁体中文通行区，但长期以来并非当地的国家标准，而只是业界标准。倚天中文系统、Windows 等主要系统的字符集都是以 Big5准，但厂商又各自增加不同的造字与造字区，派生成多种不同版本。2003年，Big5被收录到 CNS11643中文标准交换码的附录当中，取得了较正式的地位。这个最新版本被称为 Big5-2003。</p>\n<p>Big5码是一套双字节字符集，使用了双八码存储方法，以两个字节来安放一个字。第一个字节称为”高位字节”，第二个字节称为”低位字节”。”高位字节”使用了0x81-0xFE，”低位字节”使用了0x40-0x7E，及0xA1-0xFE。</p>\n<h4 id=\"大头方式、小头方式\"><a href=\"#大头方式、小头方式\" class=\"headerlink\" title=\"大头方式、小头方式\"></a>大头方式、小头方式</h4><p>上一节已经提到，UCS-2 格式可以存储 Unicode 码（码点不超过0xFFFF）。以汉字严为例，Unicode 码是4E25，需要用两个字节存储，一个字节是4E，另一个字节是25。存储的时候，4E 在前，25在后，这就是 Big endian 方式；25在前，4E 在后，这是 Little endian 方式。</p>\n<p>第一个字节在前，就是”大头方式”（Big endian），第二个字节在前就是”小头方式”（Little endian）。</p>\n<p>那么很自然的，就会出现一个问题：计算机怎么知道某一个文件到底采用哪一种方式编码？</p>\n<p>Unicode 规范定义，每一个文件的最前面分别加入一个表示编码顺序的字符，这个字符的名字叫做”零宽度非换行空格”（zero width no-break space），用FEFF表示。这正好是两个字节，而且FF比FE大1。</p>\n<p>如果一个文本文件的头两个字节是 FE FF，就表示该文件采用大头方式；如果头两个字节是 FF FE，就表示该文件采用小头方式。</p>\n<p>参考资料：</p>\n<blockquote>\n<p> <a href=\"https://zhuanlan.zhihu.com/p/658651404\">字符编码技术专题(一)：快速理解ASCII、Unicode、GBK和UTF-8</a></p>\n</blockquote>\n"},{"title":"关于oracle中以Blob字段查找重复值问题","date":"2020-08-31T16:00:00.000Z","id":"761386768996883","_content":"\n## 问题产生\n最近在工作当中有个统计问题，统计Oracle数据库里面人员表中简历一致的人的有哪些。很明显，就是查重嘛。说到查重，当然想到就是 `Group by` 方法。\n## 库表结构（简单的还原一下库表）\n\n```sql\ncreate table cs(\nid int PRIMARY KEY not null,\nname NVARCHAR2(50) not null,\njl blob not null\n);\nselect * from cs;\ninsert into cs  select 1,'Tom',to_blob('123412f') from dual;\ninsert into cs  select 2,'King',to_blob('123412f') from dual;\ninsert into cs  select 3,'Leo',to_blob('124123F21F') from dual;\n```\n![库表结构](img/f3627e8bb0dc4f0b8e589df10f6fe863.png)\n## 操作\n#### 1.通过Group by 方式进行查重（操作失败）\n遇到这个问题，我熟啊！写 `group by` 语句就行了呗，然后就写了这样的语句\n```sql\nselect  jl,count(1) from cs group by jl having count(1)>1;\n```\n当我美滋滋开始执行的时候，却出现的问题\n![问题1](img/584082192807448bb4db57a334ebb740.png)\n查了查相关资料知道了，oralce是不能通过blob类型的字段进行 `group by` 的，那我把这个字段用 `to_char()` 转换一下试试看\n```sql\nselect jl,count(1) from cs group by to_char(jl) having count(1)>1;\n```\n![问题2](img/6576c5fe4a184619b7fe4897d6ea30af.png)\n显然，`group by` 也不能后跟 `to_char()` 函数。那我只能是自己写语句吧。\n#### 2.自己写语句查重\n如果不能用group by 进行查重的话，只能是自己写查重语句，然后就写了如下语句\n```sql\nselect * from cs t1 where exists (select 1 from cs t2 where to_char(t2.jl) = to_char(t1.jl) and t2.id !=t1.id);\n```\n需要注意的是blob类型字段是不能直接=，需要 `to_char()` 转换，这个语句就执行成功了。结果如下，问题解决。\n![结果1](img/35a289c650094738966c332480bc7da5.png)","source":"_posts/md/关于oracle中以Blob字段查找重复值问题.md","raw":"---\ntitle: 关于oracle中以Blob字段查找重复值问题\ntag: \n- oracle\n- 开发问题\ncategory: \n- 数据库\ndate: 2020-09-01\nid: 761386768996883\n---\n\n## 问题产生\n最近在工作当中有个统计问题，统计Oracle数据库里面人员表中简历一致的人的有哪些。很明显，就是查重嘛。说到查重，当然想到就是 `Group by` 方法。\n## 库表结构（简单的还原一下库表）\n\n```sql\ncreate table cs(\nid int PRIMARY KEY not null,\nname NVARCHAR2(50) not null,\njl blob not null\n);\nselect * from cs;\ninsert into cs  select 1,'Tom',to_blob('123412f') from dual;\ninsert into cs  select 2,'King',to_blob('123412f') from dual;\ninsert into cs  select 3,'Leo',to_blob('124123F21F') from dual;\n```\n![库表结构](img/f3627e8bb0dc4f0b8e589df10f6fe863.png)\n## 操作\n#### 1.通过Group by 方式进行查重（操作失败）\n遇到这个问题，我熟啊！写 `group by` 语句就行了呗，然后就写了这样的语句\n```sql\nselect  jl,count(1) from cs group by jl having count(1)>1;\n```\n当我美滋滋开始执行的时候，却出现的问题\n![问题1](img/584082192807448bb4db57a334ebb740.png)\n查了查相关资料知道了，oralce是不能通过blob类型的字段进行 `group by` 的，那我把这个字段用 `to_char()` 转换一下试试看\n```sql\nselect jl,count(1) from cs group by to_char(jl) having count(1)>1;\n```\n![问题2](img/6576c5fe4a184619b7fe4897d6ea30af.png)\n显然，`group by` 也不能后跟 `to_char()` 函数。那我只能是自己写语句吧。\n#### 2.自己写语句查重\n如果不能用group by 进行查重的话，只能是自己写查重语句，然后就写了如下语句\n```sql\nselect * from cs t1 where exists (select 1 from cs t2 where to_char(t2.jl) = to_char(t1.jl) and t2.id !=t1.id);\n```\n需要注意的是blob类型字段是不能直接=，需要 `to_char()` 转换，这个语句就执行成功了。结果如下，问题解决。\n![结果1](img/35a289c650094738966c332480bc7da5.png)","slug":"md/关于oracle中以Blob字段查找重复值问题","published":1,"updated":"2025-05-20T07:21:20.742Z","comments":1,"layout":"post","photos":[],"_id":"cmhc3m3ud000gxdp8515m9p6r","content":"<h2 id=\"问题产生\"><a href=\"#问题产生\" class=\"headerlink\" title=\"问题产生\"></a>问题产生</h2><p>最近在工作当中有个统计问题，统计Oracle数据库里面人员表中简历一致的人的有哪些。很明显，就是查重嘛。说到查重，当然想到就是 <code>Group by</code> 方法。</p>\n<h2 id=\"库表结构（简单的还原一下库表）\"><a href=\"#库表结构（简单的还原一下库表）\" class=\"headerlink\" title=\"库表结构（简单的还原一下库表）\"></a>库表结构（简单的还原一下库表）</h2><pre><code class=\"language-sql\">create table cs(\nid int PRIMARY KEY not null,\nname NVARCHAR2(50) not null,\njl blob not null\n);\nselect * from cs;\ninsert into cs  select 1,&#39;Tom&#39;,to_blob(&#39;123412f&#39;) from dual;\ninsert into cs  select 2,&#39;King&#39;,to_blob(&#39;123412f&#39;) from dual;\ninsert into cs  select 3,&#39;Leo&#39;,to_blob(&#39;124123F21F&#39;) from dual;\n</code></pre>\n<p><img src=\"/img/f3627e8bb0dc4f0b8e589df10f6fe863.png\" alt=\"库表结构\"></p>\n<h2 id=\"操作\"><a href=\"#操作\" class=\"headerlink\" title=\"操作\"></a>操作</h2><h4 id=\"1-通过Group-by-方式进行查重（操作失败）\"><a href=\"#1-通过Group-by-方式进行查重（操作失败）\" class=\"headerlink\" title=\"1.通过Group by 方式进行查重（操作失败）\"></a>1.通过Group by 方式进行查重（操作失败）</h4><p>遇到这个问题，我熟啊！写 <code>group by</code> 语句就行了呗，然后就写了这样的语句</p>\n<pre><code class=\"language-sql\">select  jl,count(1) from cs group by jl having count(1)&gt;1;\n</code></pre>\n<p>当我美滋滋开始执行的时候，却出现的问题<br><img src=\"/img/584082192807448bb4db57a334ebb740.png\" alt=\"问题1\"><br>查了查相关资料知道了，oralce是不能通过blob类型的字段进行 <code>group by</code> 的，那我把这个字段用 <code>to_char()</code> 转换一下试试看</p>\n<pre><code class=\"language-sql\">select jl,count(1) from cs group by to_char(jl) having count(1)&gt;1;\n</code></pre>\n<p><img src=\"/img/6576c5fe4a184619b7fe4897d6ea30af.png\" alt=\"问题2\"><br>显然，<code>group by</code> 也不能后跟 <code>to_char()</code> 函数。那我只能是自己写语句吧。</p>\n<h4 id=\"2-自己写语句查重\"><a href=\"#2-自己写语句查重\" class=\"headerlink\" title=\"2.自己写语句查重\"></a>2.自己写语句查重</h4><p>如果不能用group by 进行查重的话，只能是自己写查重语句，然后就写了如下语句</p>\n<pre><code class=\"language-sql\">select * from cs t1 where exists (select 1 from cs t2 where to_char(t2.jl) = to_char(t1.jl) and t2.id !=t1.id);\n</code></pre>\n<p>需要注意的是blob类型字段是不能直接&#x3D;，需要 <code>to_char()</code> 转换，这个语句就执行成功了。结果如下，问题解决。<br><img src=\"/img/35a289c650094738966c332480bc7da5.png\" alt=\"结果1\"></p>\n","excerpt":"","more":"<h2 id=\"问题产生\"><a href=\"#问题产生\" class=\"headerlink\" title=\"问题产生\"></a>问题产生</h2><p>最近在工作当中有个统计问题，统计Oracle数据库里面人员表中简历一致的人的有哪些。很明显，就是查重嘛。说到查重，当然想到就是 <code>Group by</code> 方法。</p>\n<h2 id=\"库表结构（简单的还原一下库表）\"><a href=\"#库表结构（简单的还原一下库表）\" class=\"headerlink\" title=\"库表结构（简单的还原一下库表）\"></a>库表结构（简单的还原一下库表）</h2><pre><code class=\"language-sql\">create table cs(\nid int PRIMARY KEY not null,\nname NVARCHAR2(50) not null,\njl blob not null\n);\nselect * from cs;\ninsert into cs  select 1,&#39;Tom&#39;,to_blob(&#39;123412f&#39;) from dual;\ninsert into cs  select 2,&#39;King&#39;,to_blob(&#39;123412f&#39;) from dual;\ninsert into cs  select 3,&#39;Leo&#39;,to_blob(&#39;124123F21F&#39;) from dual;\n</code></pre>\n<p><img src=\"/img/f3627e8bb0dc4f0b8e589df10f6fe863.png\" alt=\"库表结构\"></p>\n<h2 id=\"操作\"><a href=\"#操作\" class=\"headerlink\" title=\"操作\"></a>操作</h2><h4 id=\"1-通过Group-by-方式进行查重（操作失败）\"><a href=\"#1-通过Group-by-方式进行查重（操作失败）\" class=\"headerlink\" title=\"1.通过Group by 方式进行查重（操作失败）\"></a>1.通过Group by 方式进行查重（操作失败）</h4><p>遇到这个问题，我熟啊！写 <code>group by</code> 语句就行了呗，然后就写了这样的语句</p>\n<pre><code class=\"language-sql\">select  jl,count(1) from cs group by jl having count(1)&gt;1;\n</code></pre>\n<p>当我美滋滋开始执行的时候，却出现的问题<br><img src=\"/img/584082192807448bb4db57a334ebb740.png\" alt=\"问题1\"><br>查了查相关资料知道了，oralce是不能通过blob类型的字段进行 <code>group by</code> 的，那我把这个字段用 <code>to_char()</code> 转换一下试试看</p>\n<pre><code class=\"language-sql\">select jl,count(1) from cs group by to_char(jl) having count(1)&gt;1;\n</code></pre>\n<p><img src=\"/img/6576c5fe4a184619b7fe4897d6ea30af.png\" alt=\"问题2\"><br>显然，<code>group by</code> 也不能后跟 <code>to_char()</code> 函数。那我只能是自己写语句吧。</p>\n<h4 id=\"2-自己写语句查重\"><a href=\"#2-自己写语句查重\" class=\"headerlink\" title=\"2.自己写语句查重\"></a>2.自己写语句查重</h4><p>如果不能用group by 进行查重的话，只能是自己写查重语句，然后就写了如下语句</p>\n<pre><code class=\"language-sql\">select * from cs t1 where exists (select 1 from cs t2 where to_char(t2.jl) = to_char(t1.jl) and t2.id !=t1.id);\n</code></pre>\n<p>需要注意的是blob类型字段是不能直接&#x3D;，需要 <code>to_char()</code> 转换，这个语句就执行成功了。结果如下，问题解决。<br><img src=\"/img/35a289c650094738966c332480bc7da5.png\" alt=\"结果1\"></p>\n"},{"title":"晋城游记","id":"712386768996883","date":"2025-08-30T16:00:00.000Z","_content":"\n> 该篇游记仅记录玉皇庙、关帝庙、晋城博物馆以及原本博物馆相关内容，偏向历史爱好者。\n\n起因是 Amelia 在小红书上看到，郑州去山西晋城的大巴来回免费，且 2.5~3 小时就能到。所以我们就打算当天去，当天回。\n\n\n## 买票和预约\n\n车票可以直接在微信公众号上买，郑州去晋城在**豫州行**微信公众号上买，晋城回郑州则在**大美太行晋城游**。郑州有多个客运站都可以到晋城，如果家附近的客运站没票，可以切换别的客运站试试。同理，晋城到郑州也是分多个客运站，可以多看看。除此之外，还要算好行程，预约景点门票。我们计划去玉皇庙，关帝庙，晋城博物馆，原本博物馆。这几个景点都可以通过**晋城市文化保护研究中心网上预约**微信公众号进行预约。\n\n上述所有车票，门票均免费。\n\n## 行程游记\n\n![星宿之城——晋城](img/IMG_4594.JPG)\n\n\n为了更好的游玩体验，我们决定尽早出发。所以购买了较早的车票。5 点半从家里出发，6 点 20 分的车，8 点 40 分到，可以在车上补觉。尽量轻装上阵，带个小包也可。如果想买特产，最好带双肩包。**一定一定要记住带身份证。**\n\n第一站，建议直接去玉皇庙，因为在门口领通关文牒，方便后续盖章。我们在后续的晋城博物馆看到好几拨人去前台问通关文牒在哪领。\n\n>  **府城玉皇庙**位于中国[山西省](https://zh.wikipedia.org/wiki/%E5%B1%B1%E8%A5%BF%E7%9C%81 \"山西省\")[晋城市](https://zh.wikipedia.org/wiki/%E6%99%8B%E5%9F%8E%E5%B8%82 \"晋城市\")[泽州县](https://zh.wikipedia.org/wiki/%E6%B3%BD%E5%B7%9E%E5%8E%BF \"泽州县\")[金村镇](https://zh.wikipedia.org/wiki/%E9%87%91%E6%9D%91%E9%95%87 \"金村镇\")府城村，1988年被列为[第三批全国重点文物保护单位](https://zh.wikipedia.org/wiki/%E7%AC%AC%E4%B8%89%E6%89%B9%E5%85%A8%E5%9B%BD%E9%87%8D%E7%82%B9%E6%96%87%E7%89%A9%E4%BF%9D%E6%8A%A4%E5%8D%95%E4%BD%8D \"第三批全国重点文物保护单位\")。\n> \n> 府城玉皇庙始建年代不详，[隋朝](https://zh.wikipedia.org/wiki/%E9%9A%8B%E6%9C%9D \"隋朝\")时有祭拜[三清](https://zh.wikipedia.org/wiki/%E4%B8%89%E6%B8%85 \"三清\")的殿宇，[北宋](https://zh.wikipedia.org/wiki/%E5%8C%97%E5%AE%8B \"北宋\")[熙宁](https://zh.wikipedia.org/wiki/%E7%86%99%E5%AE%81 \"熙宁\")九年（1076年）扩建成玉皇庙，[金](https://zh.wikipedia.org/wiki/%E9%87%91%E6%9C%9D \"金朝\")[泰和](https://zh.wikipedia.org/wiki/%E6%B3%B0%E5%92%8C_\\(%E9%87%91\\) \"泰和 (金)\")七年（1207年）重修，[贞祐](https://zh.wikipedia.org/wiki/%E8%B4%9E%E7%A5%90 \"贞祐\")年间部分被毁，[元](https://zh.wikipedia.org/wiki/%E5%85%83%E6%9C%9D \"元朝\")[至元](https://zh.wikipedia.org/wiki/%E8%87%B3%E5%85%83_\\(%E5%85%83%E9%A1%BA%E5%B8%9D\\) \"至元 (元顺帝)\")元年（1335年）重建。庙坐北朝南，占地4000余平方米。主要建筑有山门、仪门、[成汤](https://zh.wikipedia.org/wiki/%E6%88%90%E6%B1%A4 \"成汤\")殿、献亭、[玉皇](https://zh.wikipedia.org/wiki/%E7%8E%89%E7%9A%87 \"玉皇\")殿、东西配殿、[二十八宿](https://zh.wikipedia.org/wiki/%E4%BA%8C%E5%8D%81%E5%85%AB%E5%AE%BF \"二十八宿\")殿、十二辰殿、十三曜星殿、[关帝](https://zh.wikipedia.org/wiki/%E5%85%B3%E5%B8%9D \"关帝\")殿、蚕神殿等，其中玉皇殿为北宋遗构，成汤殿建于金，余为元[明](https://zh.wikipedia.org/wiki/%E6%98%8E \"明\")[清](https://zh.wikipedia.org/wiki/%E6%B8%85 \"清\")建筑。成汤殿面阔三间，进深三间，单檐[悬山顶](https://zh.wikipedia.org/wiki/%E6%82%AC%E5%B1%B1%E9%A1%B6 \"悬山顶\")。玉皇殿面阔进深各三间，单檐悬山顶。各殿内有宋元明塑像三百余尊。\n> \n> ——以上摘自维基百科\n\n![玉皇庙](img/IMG_4788.png)\n\n可以去十一耀星殿找找自己的守护星座，拍照，挺有意思的。《黑神话 · 悟空》里面的亢金星君和小猪就是取自十一耀星殿的亢金龙和室火猪，值得一看。\n\n![十一耀星殿](img/IMG_4808.png)\n\n![我的守护星座](img/IMG_4790.png)\n\n玉皇庙里面三只小猫，一黑一白一橘。有灵性，不惧人。\n\n第二站，关帝庙，从玉皇庙步行 10 分钟就可以到达。关帝庙和玉皇庙大多相似。又不尽相同。步入大门，停留一会，便可以感受身后缕缕穿堂风，头顶钟声随风飘荡。在这刻才能感受到自己不是城市中两点一线的牛马。\n\n![柱子](img/%E6%9F%B1%E5%AD%90.jpg)\n\n中午本地美食，老三样。十小碗应该是首选，但是需要提前排队，要提前饭点1 个小时以上排队。我们 11 点半到的十小碗，被告知要排队 1 个半小时以上，并且不接受排队预约了。索性我们就直接去老三样。\n![老三样](img/IMG_4815.png)\n\n第三站，晋城博物馆。下午天气热，博物馆里面有空调，随意逛逛也比较舒服。\n\n![晋城博物馆——古代建筑艺术](img/IMG_4810.png)\n\n![墙砖](img/IMG_4809.png)\n\n\n第四站，原本博物馆，是一个私人的民办博物馆，需提前预约，基本上没人，馆藏丰富，可以感受一下\n\n![原本博物馆](img/IMG_4811.png)\n\n![馆内收藏](img/IMG_4807.png)\n\n\n第五站，兰花城超市。从原本博物馆出来才下午 3 点半左右，时间还算比较充裕。其他景区离市区较远，我们打算去逛逛市区的兰花城超市买点特产带回去。\n\n晚上本地美食，丁老大牛肉丸，强烈推荐，牛肉超级多。这个是在郑州吃不到，或者说吃不到这么实惠的。其实我更喜欢去一些小县城旅游，因为小县城里没有大城市的浮躁\n\n![牛肉丸](img/IMG_4794.png)\n\n晚上 6 点 50 分的回程，9 点多到郑州。\n\n## 有感\n\n晋城算是山西文旅给想要感受山西文化的河南人的第一站。玉皇庙，关帝庙地势高，逛的时候有种天朗气清的感觉。空气好，可以作为逃离都市的一个好去处。晋城还有其他景点，一天时间肯定是逛不完。单单对于我和 Amelia 这种历史爱好者来说，除了上述几个景点，还有皇城相府，郭峪古城，湘峪古城没有参观。如果想欣赏自然风光，可以爬青莲寺，以及徒步王莽岭景区等。如果喜欢现代生活气息，白马寺山森林公园，晋城大剧院都是值得一看的地方。\n\n\n晋城算是我去过为数不多的体感舒服的城市，整体城市界面干净整洁，交通便捷。市内打车相对便宜，近距离通行也有共享电动车（市区各处都有共享电动车这点对旅游非常友好）。温度适宜，气候舒适，适合养老疗养。美食也有晋城特色，值得尝试。晋城肯定会再次二刷，再来感受一下其他风景。","source":"_posts/md/晋城游记.md","raw":"---\ntitle: 晋城游记\ntag:\n- 游记\n- 郑州\ncategory:\n- 生活\nid:  712386768996883\ndate:  2025-08-31\n---\n\n> 该篇游记仅记录玉皇庙、关帝庙、晋城博物馆以及原本博物馆相关内容，偏向历史爱好者。\n\n起因是 Amelia 在小红书上看到，郑州去山西晋城的大巴来回免费，且 2.5~3 小时就能到。所以我们就打算当天去，当天回。\n\n\n## 买票和预约\n\n车票可以直接在微信公众号上买，郑州去晋城在**豫州行**微信公众号上买，晋城回郑州则在**大美太行晋城游**。郑州有多个客运站都可以到晋城，如果家附近的客运站没票，可以切换别的客运站试试。同理，晋城到郑州也是分多个客运站，可以多看看。除此之外，还要算好行程，预约景点门票。我们计划去玉皇庙，关帝庙，晋城博物馆，原本博物馆。这几个景点都可以通过**晋城市文化保护研究中心网上预约**微信公众号进行预约。\n\n上述所有车票，门票均免费。\n\n## 行程游记\n\n![星宿之城——晋城](img/IMG_4594.JPG)\n\n\n为了更好的游玩体验，我们决定尽早出发。所以购买了较早的车票。5 点半从家里出发，6 点 20 分的车，8 点 40 分到，可以在车上补觉。尽量轻装上阵，带个小包也可。如果想买特产，最好带双肩包。**一定一定要记住带身份证。**\n\n第一站，建议直接去玉皇庙，因为在门口领通关文牒，方便后续盖章。我们在后续的晋城博物馆看到好几拨人去前台问通关文牒在哪领。\n\n>  **府城玉皇庙**位于中国[山西省](https://zh.wikipedia.org/wiki/%E5%B1%B1%E8%A5%BF%E7%9C%81 \"山西省\")[晋城市](https://zh.wikipedia.org/wiki/%E6%99%8B%E5%9F%8E%E5%B8%82 \"晋城市\")[泽州县](https://zh.wikipedia.org/wiki/%E6%B3%BD%E5%B7%9E%E5%8E%BF \"泽州县\")[金村镇](https://zh.wikipedia.org/wiki/%E9%87%91%E6%9D%91%E9%95%87 \"金村镇\")府城村，1988年被列为[第三批全国重点文物保护单位](https://zh.wikipedia.org/wiki/%E7%AC%AC%E4%B8%89%E6%89%B9%E5%85%A8%E5%9B%BD%E9%87%8D%E7%82%B9%E6%96%87%E7%89%A9%E4%BF%9D%E6%8A%A4%E5%8D%95%E4%BD%8D \"第三批全国重点文物保护单位\")。\n> \n> 府城玉皇庙始建年代不详，[隋朝](https://zh.wikipedia.org/wiki/%E9%9A%8B%E6%9C%9D \"隋朝\")时有祭拜[三清](https://zh.wikipedia.org/wiki/%E4%B8%89%E6%B8%85 \"三清\")的殿宇，[北宋](https://zh.wikipedia.org/wiki/%E5%8C%97%E5%AE%8B \"北宋\")[熙宁](https://zh.wikipedia.org/wiki/%E7%86%99%E5%AE%81 \"熙宁\")九年（1076年）扩建成玉皇庙，[金](https://zh.wikipedia.org/wiki/%E9%87%91%E6%9C%9D \"金朝\")[泰和](https://zh.wikipedia.org/wiki/%E6%B3%B0%E5%92%8C_\\(%E9%87%91\\) \"泰和 (金)\")七年（1207年）重修，[贞祐](https://zh.wikipedia.org/wiki/%E8%B4%9E%E7%A5%90 \"贞祐\")年间部分被毁，[元](https://zh.wikipedia.org/wiki/%E5%85%83%E6%9C%9D \"元朝\")[至元](https://zh.wikipedia.org/wiki/%E8%87%B3%E5%85%83_\\(%E5%85%83%E9%A1%BA%E5%B8%9D\\) \"至元 (元顺帝)\")元年（1335年）重建。庙坐北朝南，占地4000余平方米。主要建筑有山门、仪门、[成汤](https://zh.wikipedia.org/wiki/%E6%88%90%E6%B1%A4 \"成汤\")殿、献亭、[玉皇](https://zh.wikipedia.org/wiki/%E7%8E%89%E7%9A%87 \"玉皇\")殿、东西配殿、[二十八宿](https://zh.wikipedia.org/wiki/%E4%BA%8C%E5%8D%81%E5%85%AB%E5%AE%BF \"二十八宿\")殿、十二辰殿、十三曜星殿、[关帝](https://zh.wikipedia.org/wiki/%E5%85%B3%E5%B8%9D \"关帝\")殿、蚕神殿等，其中玉皇殿为北宋遗构，成汤殿建于金，余为元[明](https://zh.wikipedia.org/wiki/%E6%98%8E \"明\")[清](https://zh.wikipedia.org/wiki/%E6%B8%85 \"清\")建筑。成汤殿面阔三间，进深三间，单檐[悬山顶](https://zh.wikipedia.org/wiki/%E6%82%AC%E5%B1%B1%E9%A1%B6 \"悬山顶\")。玉皇殿面阔进深各三间，单檐悬山顶。各殿内有宋元明塑像三百余尊。\n> \n> ——以上摘自维基百科\n\n![玉皇庙](img/IMG_4788.png)\n\n可以去十一耀星殿找找自己的守护星座，拍照，挺有意思的。《黑神话 · 悟空》里面的亢金星君和小猪就是取自十一耀星殿的亢金龙和室火猪，值得一看。\n\n![十一耀星殿](img/IMG_4808.png)\n\n![我的守护星座](img/IMG_4790.png)\n\n玉皇庙里面三只小猫，一黑一白一橘。有灵性，不惧人。\n\n第二站，关帝庙，从玉皇庙步行 10 分钟就可以到达。关帝庙和玉皇庙大多相似。又不尽相同。步入大门，停留一会，便可以感受身后缕缕穿堂风，头顶钟声随风飘荡。在这刻才能感受到自己不是城市中两点一线的牛马。\n\n![柱子](img/%E6%9F%B1%E5%AD%90.jpg)\n\n中午本地美食，老三样。十小碗应该是首选，但是需要提前排队，要提前饭点1 个小时以上排队。我们 11 点半到的十小碗，被告知要排队 1 个半小时以上，并且不接受排队预约了。索性我们就直接去老三样。\n![老三样](img/IMG_4815.png)\n\n第三站，晋城博物馆。下午天气热，博物馆里面有空调，随意逛逛也比较舒服。\n\n![晋城博物馆——古代建筑艺术](img/IMG_4810.png)\n\n![墙砖](img/IMG_4809.png)\n\n\n第四站，原本博物馆，是一个私人的民办博物馆，需提前预约，基本上没人，馆藏丰富，可以感受一下\n\n![原本博物馆](img/IMG_4811.png)\n\n![馆内收藏](img/IMG_4807.png)\n\n\n第五站，兰花城超市。从原本博物馆出来才下午 3 点半左右，时间还算比较充裕。其他景区离市区较远，我们打算去逛逛市区的兰花城超市买点特产带回去。\n\n晚上本地美食，丁老大牛肉丸，强烈推荐，牛肉超级多。这个是在郑州吃不到，或者说吃不到这么实惠的。其实我更喜欢去一些小县城旅游，因为小县城里没有大城市的浮躁\n\n![牛肉丸](img/IMG_4794.png)\n\n晚上 6 点 50 分的回程，9 点多到郑州。\n\n## 有感\n\n晋城算是山西文旅给想要感受山西文化的河南人的第一站。玉皇庙，关帝庙地势高，逛的时候有种天朗气清的感觉。空气好，可以作为逃离都市的一个好去处。晋城还有其他景点，一天时间肯定是逛不完。单单对于我和 Amelia 这种历史爱好者来说，除了上述几个景点，还有皇城相府，郭峪古城，湘峪古城没有参观。如果想欣赏自然风光，可以爬青莲寺，以及徒步王莽岭景区等。如果喜欢现代生活气息，白马寺山森林公园，晋城大剧院都是值得一看的地方。\n\n\n晋城算是我去过为数不多的体感舒服的城市，整体城市界面干净整洁，交通便捷。市内打车相对便宜，近距离通行也有共享电动车（市区各处都有共享电动车这点对旅游非常友好）。温度适宜，气候舒适，适合养老疗养。美食也有晋城特色，值得尝试。晋城肯定会再次二刷，再来感受一下其他风景。","slug":"md/晋城游记","published":1,"updated":"2025-09-01T02:02:22.610Z","comments":1,"layout":"post","photos":[],"_id":"cmhc3m3ud000ixdp87bxf59zh","content":"<blockquote>\n<p>该篇游记仅记录玉皇庙、关帝庙、晋城博物馆以及原本博物馆相关内容，偏向历史爱好者。</p>\n</blockquote>\n<p>起因是 Amelia 在小红书上看到，郑州去山西晋城的大巴来回免费，且 2.5~3 小时就能到。所以我们就打算当天去，当天回。</p>\n<h2 id=\"买票和预约\"><a href=\"#买票和预约\" class=\"headerlink\" title=\"买票和预约\"></a>买票和预约</h2><p>车票可以直接在微信公众号上买，郑州去晋城在<strong>豫州行</strong>微信公众号上买，晋城回郑州则在<strong>大美太行晋城游</strong>。郑州有多个客运站都可以到晋城，如果家附近的客运站没票，可以切换别的客运站试试。同理，晋城到郑州也是分多个客运站，可以多看看。除此之外，还要算好行程，预约景点门票。我们计划去玉皇庙，关帝庙，晋城博物馆，原本博物馆。这几个景点都可以通过<strong>晋城市文化保护研究中心网上预约</strong>微信公众号进行预约。</p>\n<p>上述所有车票，门票均免费。</p>\n<h2 id=\"行程游记\"><a href=\"#行程游记\" class=\"headerlink\" title=\"行程游记\"></a>行程游记</h2><p><img src=\"/img/IMG_4594.JPG\" alt=\"星宿之城——晋城\"></p>\n<p>为了更好的游玩体验，我们决定尽早出发。所以购买了较早的车票。5 点半从家里出发，6 点 20 分的车，8 点 40 分到，可以在车上补觉。尽量轻装上阵，带个小包也可。如果想买特产，最好带双肩包。<strong>一定一定要记住带身份证。</strong></p>\n<p>第一站，建议直接去玉皇庙，因为在门口领通关文牒，方便后续盖章。我们在后续的晋城博物馆看到好几拨人去前台问通关文牒在哪领。</p>\n<blockquote>\n<p> <strong>府城玉皇庙</strong>位于中国<a href=\"https://zh.wikipedia.org/wiki/%E5%B1%B1%E8%A5%BF%E7%9C%81\" title=\"山西省\">山西省</a><a href=\"https://zh.wikipedia.org/wiki/%E6%99%8B%E5%9F%8E%E5%B8%82\" title=\"晋城市\">晋城市</a><a href=\"https://zh.wikipedia.org/wiki/%E6%B3%BD%E5%B7%9E%E5%8E%BF\" title=\"泽州县\">泽州县</a><a href=\"https://zh.wikipedia.org/wiki/%E9%87%91%E6%9D%91%E9%95%87\" title=\"金村镇\">金村镇</a>府城村，1988年被列为<a href=\"https://zh.wikipedia.org/wiki/%E7%AC%AC%E4%B8%89%E6%89%B9%E5%85%A8%E5%9B%BD%E9%87%8D%E7%82%B9%E6%96%87%E7%89%A9%E4%BF%9D%E6%8A%A4%E5%8D%95%E4%BD%8D\" title=\"第三批全国重点文物保护单位\">第三批全国重点文物保护单位</a>。</p>\n<p>府城玉皇庙始建年代不详，<a href=\"https://zh.wikipedia.org/wiki/%E9%9A%8B%E6%9C%9D\" title=\"隋朝\">隋朝</a>时有祭拜<a href=\"https://zh.wikipedia.org/wiki/%E4%B8%89%E6%B8%85\" title=\"三清\">三清</a>的殿宇，<a href=\"https://zh.wikipedia.org/wiki/%E5%8C%97%E5%AE%8B\" title=\"北宋\">北宋</a><a href=\"https://zh.wikipedia.org/wiki/%E7%86%99%E5%AE%81\" title=\"熙宁\">熙宁</a>九年（1076年）扩建成玉皇庙，<a href=\"https://zh.wikipedia.org/wiki/%E9%87%91%E6%9C%9D\" title=\"金朝\">金</a><a href=\"https://zh.wikipedia.org/wiki/%E6%B3%B0%E5%92%8C_(%E9%87%91)\" title=\"泰和 (金)\">泰和</a>七年（1207年）重修，<a href=\"https://zh.wikipedia.org/wiki/%E8%B4%9E%E7%A5%90\" title=\"贞祐\">贞祐</a>年间部分被毁，<a href=\"https://zh.wikipedia.org/wiki/%E5%85%83%E6%9C%9D\" title=\"元朝\">元</a><a href=\"https://zh.wikipedia.org/wiki/%E8%87%B3%E5%85%83_(%E5%85%83%E9%A1%BA%E5%B8%9D)\" title=\"至元 (元顺帝)\">至元</a>元年（1335年）重建。庙坐北朝南，占地4000余平方米。主要建筑有山门、仪门、<a href=\"https://zh.wikipedia.org/wiki/%E6%88%90%E6%B1%A4\" title=\"成汤\">成汤</a>殿、献亭、<a href=\"https://zh.wikipedia.org/wiki/%E7%8E%89%E7%9A%87\" title=\"玉皇\">玉皇</a>殿、东西配殿、<a href=\"https://zh.wikipedia.org/wiki/%E4%BA%8C%E5%8D%81%E5%85%AB%E5%AE%BF\" title=\"二十八宿\">二十八宿</a>殿、十二辰殿、十三曜星殿、<a href=\"https://zh.wikipedia.org/wiki/%E5%85%B3%E5%B8%9D\" title=\"关帝\">关帝</a>殿、蚕神殿等，其中玉皇殿为北宋遗构，成汤殿建于金，余为元<a href=\"https://zh.wikipedia.org/wiki/%E6%98%8E\" title=\"明\">明</a><a href=\"https://zh.wikipedia.org/wiki/%E6%B8%85\" title=\"清\">清</a>建筑。成汤殿面阔三间，进深三间，单檐<a href=\"https://zh.wikipedia.org/wiki/%E6%82%AC%E5%B1%B1%E9%A1%B6\" title=\"悬山顶\">悬山顶</a>。玉皇殿面阔进深各三间，单檐悬山顶。各殿内有宋元明塑像三百余尊。</p>\n<p>——以上摘自维基百科</p>\n</blockquote>\n<p><img src=\"/img/IMG_4788.png\" alt=\"玉皇庙\"></p>\n<p>可以去十一耀星殿找找自己的守护星座，拍照，挺有意思的。《黑神话 · 悟空》里面的亢金星君和小猪就是取自十一耀星殿的亢金龙和室火猪，值得一看。</p>\n<p><img src=\"/img/IMG_4808.png\" alt=\"十一耀星殿\"></p>\n<p><img src=\"/img/IMG_4790.png\" alt=\"我的守护星座\"></p>\n<p>玉皇庙里面三只小猫，一黑一白一橘。有灵性，不惧人。</p>\n<p>第二站，关帝庙，从玉皇庙步行 10 分钟就可以到达。关帝庙和玉皇庙大多相似。又不尽相同。步入大门，停留一会，便可以感受身后缕缕穿堂风，头顶钟声随风飘荡。在这刻才能感受到自己不是城市中两点一线的牛马。</p>\n<p><img src=\"/img/%E6%9F%B1%E5%AD%90.jpg\" alt=\"柱子\"></p>\n<p>中午本地美食，老三样。十小碗应该是首选，但是需要提前排队，要提前饭点1 个小时以上排队。我们 11 点半到的十小碗，被告知要排队 1 个半小时以上，并且不接受排队预约了。索性我们就直接去老三样。<br><img src=\"/img/IMG_4815.png\" alt=\"老三样\"></p>\n<p>第三站，晋城博物馆。下午天气热，博物馆里面有空调，随意逛逛也比较舒服。</p>\n<p><img src=\"/img/IMG_4810.png\" alt=\"晋城博物馆——古代建筑艺术\"></p>\n<p><img src=\"/img/IMG_4809.png\" alt=\"墙砖\"></p>\n<p>第四站，原本博物馆，是一个私人的民办博物馆，需提前预约，基本上没人，馆藏丰富，可以感受一下</p>\n<p><img src=\"/img/IMG_4811.png\" alt=\"原本博物馆\"></p>\n<p><img src=\"/img/IMG_4807.png\" alt=\"馆内收藏\"></p>\n<p>第五站，兰花城超市。从原本博物馆出来才下午 3 点半左右，时间还算比较充裕。其他景区离市区较远，我们打算去逛逛市区的兰花城超市买点特产带回去。</p>\n<p>晚上本地美食，丁老大牛肉丸，强烈推荐，牛肉超级多。这个是在郑州吃不到，或者说吃不到这么实惠的。其实我更喜欢去一些小县城旅游，因为小县城里没有大城市的浮躁</p>\n<p><img src=\"/img/IMG_4794.png\" alt=\"牛肉丸\"></p>\n<p>晚上 6 点 50 分的回程，9 点多到郑州。</p>\n<h2 id=\"有感\"><a href=\"#有感\" class=\"headerlink\" title=\"有感\"></a>有感</h2><p>晋城算是山西文旅给想要感受山西文化的河南人的第一站。玉皇庙，关帝庙地势高，逛的时候有种天朗气清的感觉。空气好，可以作为逃离都市的一个好去处。晋城还有其他景点，一天时间肯定是逛不完。单单对于我和 Amelia 这种历史爱好者来说，除了上述几个景点，还有皇城相府，郭峪古城，湘峪古城没有参观。如果想欣赏自然风光，可以爬青莲寺，以及徒步王莽岭景区等。如果喜欢现代生活气息，白马寺山森林公园，晋城大剧院都是值得一看的地方。</p>\n<p>晋城算是我去过为数不多的体感舒服的城市，整体城市界面干净整洁，交通便捷。市内打车相对便宜，近距离通行也有共享电动车（市区各处都有共享电动车这点对旅游非常友好）。温度适宜，气候舒适，适合养老疗养。美食也有晋城特色，值得尝试。晋城肯定会再次二刷，再来感受一下其他风景。</p>\n","excerpt":"","more":"<blockquote>\n<p>该篇游记仅记录玉皇庙、关帝庙、晋城博物馆以及原本博物馆相关内容，偏向历史爱好者。</p>\n</blockquote>\n<p>起因是 Amelia 在小红书上看到，郑州去山西晋城的大巴来回免费，且 2.5~3 小时就能到。所以我们就打算当天去，当天回。</p>\n<h2 id=\"买票和预约\"><a href=\"#买票和预约\" class=\"headerlink\" title=\"买票和预约\"></a>买票和预约</h2><p>车票可以直接在微信公众号上买，郑州去晋城在<strong>豫州行</strong>微信公众号上买，晋城回郑州则在<strong>大美太行晋城游</strong>。郑州有多个客运站都可以到晋城，如果家附近的客运站没票，可以切换别的客运站试试。同理，晋城到郑州也是分多个客运站，可以多看看。除此之外，还要算好行程，预约景点门票。我们计划去玉皇庙，关帝庙，晋城博物馆，原本博物馆。这几个景点都可以通过<strong>晋城市文化保护研究中心网上预约</strong>微信公众号进行预约。</p>\n<p>上述所有车票，门票均免费。</p>\n<h2 id=\"行程游记\"><a href=\"#行程游记\" class=\"headerlink\" title=\"行程游记\"></a>行程游记</h2><p><img src=\"/img/IMG_4594.JPG\" alt=\"星宿之城——晋城\"></p>\n<p>为了更好的游玩体验，我们决定尽早出发。所以购买了较早的车票。5 点半从家里出发，6 点 20 分的车，8 点 40 分到，可以在车上补觉。尽量轻装上阵，带个小包也可。如果想买特产，最好带双肩包。<strong>一定一定要记住带身份证。</strong></p>\n<p>第一站，建议直接去玉皇庙，因为在门口领通关文牒，方便后续盖章。我们在后续的晋城博物馆看到好几拨人去前台问通关文牒在哪领。</p>\n<blockquote>\n<p> <strong>府城玉皇庙</strong>位于中国<a href=\"https://zh.wikipedia.org/wiki/%E5%B1%B1%E8%A5%BF%E7%9C%81\" title=\"山西省\">山西省</a><a href=\"https://zh.wikipedia.org/wiki/%E6%99%8B%E5%9F%8E%E5%B8%82\" title=\"晋城市\">晋城市</a><a href=\"https://zh.wikipedia.org/wiki/%E6%B3%BD%E5%B7%9E%E5%8E%BF\" title=\"泽州县\">泽州县</a><a href=\"https://zh.wikipedia.org/wiki/%E9%87%91%E6%9D%91%E9%95%87\" title=\"金村镇\">金村镇</a>府城村，1988年被列为<a href=\"https://zh.wikipedia.org/wiki/%E7%AC%AC%E4%B8%89%E6%89%B9%E5%85%A8%E5%9B%BD%E9%87%8D%E7%82%B9%E6%96%87%E7%89%A9%E4%BF%9D%E6%8A%A4%E5%8D%95%E4%BD%8D\" title=\"第三批全国重点文物保护单位\">第三批全国重点文物保护单位</a>。</p>\n<p>府城玉皇庙始建年代不详，<a href=\"https://zh.wikipedia.org/wiki/%E9%9A%8B%E6%9C%9D\" title=\"隋朝\">隋朝</a>时有祭拜<a href=\"https://zh.wikipedia.org/wiki/%E4%B8%89%E6%B8%85\" title=\"三清\">三清</a>的殿宇，<a href=\"https://zh.wikipedia.org/wiki/%E5%8C%97%E5%AE%8B\" title=\"北宋\">北宋</a><a href=\"https://zh.wikipedia.org/wiki/%E7%86%99%E5%AE%81\" title=\"熙宁\">熙宁</a>九年（1076年）扩建成玉皇庙，<a href=\"https://zh.wikipedia.org/wiki/%E9%87%91%E6%9C%9D\" title=\"金朝\">金</a><a href=\"https://zh.wikipedia.org/wiki/%E6%B3%B0%E5%92%8C_(%E9%87%91)\" title=\"泰和 (金)\">泰和</a>七年（1207年）重修，<a href=\"https://zh.wikipedia.org/wiki/%E8%B4%9E%E7%A5%90\" title=\"贞祐\">贞祐</a>年间部分被毁，<a href=\"https://zh.wikipedia.org/wiki/%E5%85%83%E6%9C%9D\" title=\"元朝\">元</a><a href=\"https://zh.wikipedia.org/wiki/%E8%87%B3%E5%85%83_(%E5%85%83%E9%A1%BA%E5%B8%9D)\" title=\"至元 (元顺帝)\">至元</a>元年（1335年）重建。庙坐北朝南，占地4000余平方米。主要建筑有山门、仪门、<a href=\"https://zh.wikipedia.org/wiki/%E6%88%90%E6%B1%A4\" title=\"成汤\">成汤</a>殿、献亭、<a href=\"https://zh.wikipedia.org/wiki/%E7%8E%89%E7%9A%87\" title=\"玉皇\">玉皇</a>殿、东西配殿、<a href=\"https://zh.wikipedia.org/wiki/%E4%BA%8C%E5%8D%81%E5%85%AB%E5%AE%BF\" title=\"二十八宿\">二十八宿</a>殿、十二辰殿、十三曜星殿、<a href=\"https://zh.wikipedia.org/wiki/%E5%85%B3%E5%B8%9D\" title=\"关帝\">关帝</a>殿、蚕神殿等，其中玉皇殿为北宋遗构，成汤殿建于金，余为元<a href=\"https://zh.wikipedia.org/wiki/%E6%98%8E\" title=\"明\">明</a><a href=\"https://zh.wikipedia.org/wiki/%E6%B8%85\" title=\"清\">清</a>建筑。成汤殿面阔三间，进深三间，单檐<a href=\"https://zh.wikipedia.org/wiki/%E6%82%AC%E5%B1%B1%E9%A1%B6\" title=\"悬山顶\">悬山顶</a>。玉皇殿面阔进深各三间，单檐悬山顶。各殿内有宋元明塑像三百余尊。</p>\n<p>——以上摘自维基百科</p>\n</blockquote>\n<p><img src=\"/img/IMG_4788.png\" alt=\"玉皇庙\"></p>\n<p>可以去十一耀星殿找找自己的守护星座，拍照，挺有意思的。《黑神话 · 悟空》里面的亢金星君和小猪就是取自十一耀星殿的亢金龙和室火猪，值得一看。</p>\n<p><img src=\"/img/IMG_4808.png\" alt=\"十一耀星殿\"></p>\n<p><img src=\"/img/IMG_4790.png\" alt=\"我的守护星座\"></p>\n<p>玉皇庙里面三只小猫，一黑一白一橘。有灵性，不惧人。</p>\n<p>第二站，关帝庙，从玉皇庙步行 10 分钟就可以到达。关帝庙和玉皇庙大多相似。又不尽相同。步入大门，停留一会，便可以感受身后缕缕穿堂风，头顶钟声随风飘荡。在这刻才能感受到自己不是城市中两点一线的牛马。</p>\n<p><img src=\"/img/%E6%9F%B1%E5%AD%90.jpg\" alt=\"柱子\"></p>\n<p>中午本地美食，老三样。十小碗应该是首选，但是需要提前排队，要提前饭点1 个小时以上排队。我们 11 点半到的十小碗，被告知要排队 1 个半小时以上，并且不接受排队预约了。索性我们就直接去老三样。<br><img src=\"/img/IMG_4815.png\" alt=\"老三样\"></p>\n<p>第三站，晋城博物馆。下午天气热，博物馆里面有空调，随意逛逛也比较舒服。</p>\n<p><img src=\"/img/IMG_4810.png\" alt=\"晋城博物馆——古代建筑艺术\"></p>\n<p><img src=\"/img/IMG_4809.png\" alt=\"墙砖\"></p>\n<p>第四站，原本博物馆，是一个私人的民办博物馆，需提前预约，基本上没人，馆藏丰富，可以感受一下</p>\n<p><img src=\"/img/IMG_4811.png\" alt=\"原本博物馆\"></p>\n<p><img src=\"/img/IMG_4807.png\" alt=\"馆内收藏\"></p>\n<p>第五站，兰花城超市。从原本博物馆出来才下午 3 点半左右，时间还算比较充裕。其他景区离市区较远，我们打算去逛逛市区的兰花城超市买点特产带回去。</p>\n<p>晚上本地美食，丁老大牛肉丸，强烈推荐，牛肉超级多。这个是在郑州吃不到，或者说吃不到这么实惠的。其实我更喜欢去一些小县城旅游，因为小县城里没有大城市的浮躁</p>\n<p><img src=\"/img/IMG_4794.png\" alt=\"牛肉丸\"></p>\n<p>晚上 6 点 50 分的回程，9 点多到郑州。</p>\n<h2 id=\"有感\"><a href=\"#有感\" class=\"headerlink\" title=\"有感\"></a>有感</h2><p>晋城算是山西文旅给想要感受山西文化的河南人的第一站。玉皇庙，关帝庙地势高，逛的时候有种天朗气清的感觉。空气好，可以作为逃离都市的一个好去处。晋城还有其他景点，一天时间肯定是逛不完。单单对于我和 Amelia 这种历史爱好者来说，除了上述几个景点，还有皇城相府，郭峪古城，湘峪古城没有参观。如果想欣赏自然风光，可以爬青莲寺，以及徒步王莽岭景区等。如果喜欢现代生活气息，白马寺山森林公园，晋城大剧院都是值得一看的地方。</p>\n<p>晋城算是我去过为数不多的体感舒服的城市，整体城市界面干净整洁，交通便捷。市内打车相对便宜，近距离通行也有共享电动车（市区各处都有共享电动车这点对旅游非常友好）。温度适宜，气候舒适，适合养老疗养。美食也有晋城特色，值得尝试。晋城肯定会再次二刷，再来感受一下其他风景。</p>\n"},{"title":"类加载器以及双亲委派模型","date":"2024-08-31T16:00:00.000Z","id":"761386768996885","_content":"\n### 一个类的生命周期（7个阶段）\n\n**加载-验证-准备-解析-初始化-使用-卸载**\n\n![一个类的生命周期](img/20200901134621820.png)\n其中，类的加载过程是十分重要的过程。在这一过程，是由JVM提供的类加载器来完成。\n\n### **类加载器**\n\nJVM提供三层类加载器\n\n**启动类加载器**：Bootstrap Class Loader ，是C++写的，返回为NULL（比如String类），lib/下的jar包，比如rt.jar,jce.jar等\n\n**拓展类加载器**：Extension Class Loader，jre/lib/ext下的jar或者是指定的jar\n\n**应用程序类加载器**：Application  Class Loader，加载calsspath指定内容\n\n当然自己也可以定义加载器，不算入JVM中的，**自定义加载器**：Custom ClassLoader，自定义加载器，支持一些个性化的扩展功能\n\n```text\nXbootclasspath\n设置启动类加载器的路径\n```\n\n### **双亲委派模型**\n\n![双亲委派模型](img/20200901135402519.png)\n每一层的类加载器都有上层的加载器，称为父类加载器，Bootstrap加载器最上层的类加载器，主要加载一些重要的类，如Object类，String类等。当类需要加载的时候子类加载器会依次向上委托父类加载器进行加载，并向上询问是否已经被加载，如果父类没有被加载，则向下尝试子类加载器是否可加载，直到该类被加载，过程结束。这就是双亲委派模型机制。\n\n总结：**向上委托并询问，向下尝试加载**\n\n优势：**稳定**，当自己重写了个基础类（Object类，String类等）进行加载的时候，子类加载器依次向上委托基础类给父类加载器，到了Bootstrap类加载器发现rt.jar中有，然后就直接加载，返回加载成功。这样保证了JVM运行的安全稳定。\n\n**对于任意一个类，都需要由加载它的类加载器和这个类本身一同确立其在 Java 虚拟机中的唯一性，每一个类加载器，都拥有一个独立的类名称空间。**\n\n#### **打破双亲委派模型的示例**\n虽然双亲委派模型能够保证JVM稳定运行，但有些时候根据场景，我们需要打破这种机制。\n##### 1.Tomca类加载机制\n\n\n![Tomcat加载机制](img/20200901160002516.png)\n\nTomcat中自定义的Common加载器：Catalina类+Shared类加载器\n\ntomcat通过war包进行的应用发布，其实时违反了双亲委派机制原则。因为不同的项目可能用到不同版本的第三方，即需要不同webApp类加载器加载不同版本的第三方，需要隔离，所以要破坏双亲委派模型。\n\n**tomcat的设计如何破坏了双亲委派机制？**\n\ntomcat中存在三种类加载器，Common加载器：Catalina类+Shared类加载器，在进行类加载的时候是这样处理的：\n\n1.首先判断这个类是否已经被加载了，如果被加载了就返回，否则下一步；\n\n2.尝试通过Appcalition ClassLoader进行加载，主要是避免一些基础类（Object，String类）被web中的类覆盖，导致不安全，如果加载了就返回，否则下一步；\n\n3.如果前两步都没有加载到类，就启用webApp类加载器进行加载，如果被加载了就返回，否则下一步；\n\n4.最后还没有加载的话，就委托父类加载器Common ClassLoader进行加载。\n\n**但是你自己写一个 ArrayList或者HashMap时候，放在应用目录里，tomcat 依然不会加载（会在第二步时通过Application类加载器进行加载）。Tomca类加载机制只是自定义的加载器顺序不同，但对于顶层来说，还是一样的。**\n\n##### 2.**SPI**（Service Provider Infreface）\n\nJava 中有一个 SPI 机制，全称是 Service Provider Interface，是 Java 提供的一套用来被第三方实现或者扩展的服务提供接口，设计模式：基于接口的编程，是接口+实现类+配置文件\n\n其中最有代表性的，**JDBC，数据库连接**\n\n**如何破环双亲委派？**\n\n原本应该是通过BootStrap ClassLoader进行加载，没有代码进行实现加载，只能获取当前线程上下文加载器，即整个web的Application ClassLoder，所以最后其实在使用的Application类加载器加载\n\n![SPI](img/20200901160256824.png)\n源码分析\n\n```java\npublic class Test{\n//我们在JDBC连接数据库的时候往往通过一行代码就能实现\n//Class.forName(\"xx\");可以不用写\n\n    Connection conn= DriverManager.getConnection(url, user, password);\n//当getConnection被调用的时候，DriverManager中有个static静态代码块进行执行\n    /**\n     * Load the initial JDBC drivers by checking the System property\n     * jdbc.properties and then use the {@code ServiceLoader} mechanism\n     */\n    static {\n        loadInitialDrivers();\n        println(\"JDBC DriverManager initialized\");\n    }\n    //静态代码块执行的方法loadInitialDrivers()\n    private static void loadInitialDrivers() {\n        String drivers;\n        try {\n            drivers = AccessController.doPrivileged(new PrivilegedAction<String>() {\n                public String run() {\n                    return System.getProperty(\"jdbc.drivers\");\n                }\n            });\n        } catch (Exception ex) {\n            drivers = null;\n        }\n        // If the driver is packaged as a Service Provider, load it.\n        // Get all the drivers through the classloader\n        // exposed as a java.sql.Driver.class service.\n        // ServiceLoader.load() replaces the sun.misc.Providers()\n\n        AccessController.doPrivileged(new PrivilegedAction<Void>() {\n            public Void run() {\n                //注意这里！！！加载Driver.class代码\n                ServiceLoader<Driver> loadedDrivers = ServiceLoader.load(Driver.class);\n                Iterator<Driver> driversIterator = loadedDrivers.iterator();\n\n                /* Load these drivers, so that they can be instantiated.\n                 * It may be the case that the driver class may not be there\n                 * i.e. there may be a packaged driver with the service class\n                 * as implementation of java.sql.Driver but the actual class\n                 * may be missing. In that case a java.util.ServiceConfigurationError\n                 * will be thrown at runtime by the VM trying to locate\n                 * and load the service.\n                 *\n                 * Adding a try catch block to catch those runtime errors\n                 * if driver not available in classpath but it's\n                 * packaged as service and that service is there in classpath.\n                 */\n                try{\n                    while(driversIterator.hasNext()) {\n                        driversIterator.next();\n                    }\n                } catch(Throwable t) {\n                    // Do nothing\n                }\n                return null;\n            }\n        });\n\n        println(\"DriverManager.initialize: jdbc.drivers = \" + drivers);\n\n        if (drivers == null || drivers.equals(\"\")) {\n            return;\n        }\n        String[] driversList = drivers.split(\":\");\n        println(\"number of Drivers:\" + driversList.length);\n        for (String aDriver : driversList) {\n            try {\n                println(\"DriverManager.Initialize: loading \" + aDriver);\n                Class.forName(aDriver, true,\n                        ClassLoader.getSystemClassLoader());\n            } catch (Exception ex) {\n                println(\"DriverManager.Initialize: load failed: \" + ex);\n            }\n        }\n    }\n    //进入到ServiceLoader之后的代码\n//能发现，这个加载时是获取当前线程的上下文类加载器进行加载，而这个加载器不是JVM中BootStrap类加载器，而是厂商提供的，所以加载的时候不是在BootStrap类加载器加载，在打破了双亲委派模型~\n    public static <S> ServiceLoader<S> load(Class<S> service) {\n        ClassLoader cl = Thread.currentThread().getContextClassLoader();\n        return ServiceLoader.load(service, cl);\n    }\n}\n\n\n```\n总结：通过源码不难看出，Class.forName(\"xx\");能写且不报错，说明在JVM里面有这个Drive类的加载代码，但是只有接口，没有实现，具体实现是厂商提供的，而这个过程不遵循双亲委派机制。\n\n\n> 对SPI想多点了解，可参考：\n> https://mp.weixin.qq.com/s?__biz=MzIxNDY0MTg2MA==&mid=2247483935&idx=1&sn=e6da46cfe2df2812fd2b9e24253ec246&chksm=97a53fb4a0d2b6a2896b5c0850e83a7852ad08fbe0939bb61d04982bc0d03d3f6da25ee56dbf&scene=21#wechat_redirect\n\n\n##### 3.**OSGi**——模块化（微服务）  安装、启动、停止、卸载。\n\n原理：使类相互之间不可见，相当霸道！（后续补充）\n","source":"_posts/md/类加载器以及双亲委派模型.md","raw":"---\ntitle: 类加载器以及双亲委派模型\ntag: \n- java\n- 类加载器\n- 双亲委派模型\ncategory: \n- 后端\ndate: 2024-09-01\nid: 761386768996885\n---\n\n### 一个类的生命周期（7个阶段）\n\n**加载-验证-准备-解析-初始化-使用-卸载**\n\n![一个类的生命周期](img/20200901134621820.png)\n其中，类的加载过程是十分重要的过程。在这一过程，是由JVM提供的类加载器来完成。\n\n### **类加载器**\n\nJVM提供三层类加载器\n\n**启动类加载器**：Bootstrap Class Loader ，是C++写的，返回为NULL（比如String类），lib/下的jar包，比如rt.jar,jce.jar等\n\n**拓展类加载器**：Extension Class Loader，jre/lib/ext下的jar或者是指定的jar\n\n**应用程序类加载器**：Application  Class Loader，加载calsspath指定内容\n\n当然自己也可以定义加载器，不算入JVM中的，**自定义加载器**：Custom ClassLoader，自定义加载器，支持一些个性化的扩展功能\n\n```text\nXbootclasspath\n设置启动类加载器的路径\n```\n\n### **双亲委派模型**\n\n![双亲委派模型](img/20200901135402519.png)\n每一层的类加载器都有上层的加载器，称为父类加载器，Bootstrap加载器最上层的类加载器，主要加载一些重要的类，如Object类，String类等。当类需要加载的时候子类加载器会依次向上委托父类加载器进行加载，并向上询问是否已经被加载，如果父类没有被加载，则向下尝试子类加载器是否可加载，直到该类被加载，过程结束。这就是双亲委派模型机制。\n\n总结：**向上委托并询问，向下尝试加载**\n\n优势：**稳定**，当自己重写了个基础类（Object类，String类等）进行加载的时候，子类加载器依次向上委托基础类给父类加载器，到了Bootstrap类加载器发现rt.jar中有，然后就直接加载，返回加载成功。这样保证了JVM运行的安全稳定。\n\n**对于任意一个类，都需要由加载它的类加载器和这个类本身一同确立其在 Java 虚拟机中的唯一性，每一个类加载器，都拥有一个独立的类名称空间。**\n\n#### **打破双亲委派模型的示例**\n虽然双亲委派模型能够保证JVM稳定运行，但有些时候根据场景，我们需要打破这种机制。\n##### 1.Tomca类加载机制\n\n\n![Tomcat加载机制](img/20200901160002516.png)\n\nTomcat中自定义的Common加载器：Catalina类+Shared类加载器\n\ntomcat通过war包进行的应用发布，其实时违反了双亲委派机制原则。因为不同的项目可能用到不同版本的第三方，即需要不同webApp类加载器加载不同版本的第三方，需要隔离，所以要破坏双亲委派模型。\n\n**tomcat的设计如何破坏了双亲委派机制？**\n\ntomcat中存在三种类加载器，Common加载器：Catalina类+Shared类加载器，在进行类加载的时候是这样处理的：\n\n1.首先判断这个类是否已经被加载了，如果被加载了就返回，否则下一步；\n\n2.尝试通过Appcalition ClassLoader进行加载，主要是避免一些基础类（Object，String类）被web中的类覆盖，导致不安全，如果加载了就返回，否则下一步；\n\n3.如果前两步都没有加载到类，就启用webApp类加载器进行加载，如果被加载了就返回，否则下一步；\n\n4.最后还没有加载的话，就委托父类加载器Common ClassLoader进行加载。\n\n**但是你自己写一个 ArrayList或者HashMap时候，放在应用目录里，tomcat 依然不会加载（会在第二步时通过Application类加载器进行加载）。Tomca类加载机制只是自定义的加载器顺序不同，但对于顶层来说，还是一样的。**\n\n##### 2.**SPI**（Service Provider Infreface）\n\nJava 中有一个 SPI 机制，全称是 Service Provider Interface，是 Java 提供的一套用来被第三方实现或者扩展的服务提供接口，设计模式：基于接口的编程，是接口+实现类+配置文件\n\n其中最有代表性的，**JDBC，数据库连接**\n\n**如何破环双亲委派？**\n\n原本应该是通过BootStrap ClassLoader进行加载，没有代码进行实现加载，只能获取当前线程上下文加载器，即整个web的Application ClassLoder，所以最后其实在使用的Application类加载器加载\n\n![SPI](img/20200901160256824.png)\n源码分析\n\n```java\npublic class Test{\n//我们在JDBC连接数据库的时候往往通过一行代码就能实现\n//Class.forName(\"xx\");可以不用写\n\n    Connection conn= DriverManager.getConnection(url, user, password);\n//当getConnection被调用的时候，DriverManager中有个static静态代码块进行执行\n    /**\n     * Load the initial JDBC drivers by checking the System property\n     * jdbc.properties and then use the {@code ServiceLoader} mechanism\n     */\n    static {\n        loadInitialDrivers();\n        println(\"JDBC DriverManager initialized\");\n    }\n    //静态代码块执行的方法loadInitialDrivers()\n    private static void loadInitialDrivers() {\n        String drivers;\n        try {\n            drivers = AccessController.doPrivileged(new PrivilegedAction<String>() {\n                public String run() {\n                    return System.getProperty(\"jdbc.drivers\");\n                }\n            });\n        } catch (Exception ex) {\n            drivers = null;\n        }\n        // If the driver is packaged as a Service Provider, load it.\n        // Get all the drivers through the classloader\n        // exposed as a java.sql.Driver.class service.\n        // ServiceLoader.load() replaces the sun.misc.Providers()\n\n        AccessController.doPrivileged(new PrivilegedAction<Void>() {\n            public Void run() {\n                //注意这里！！！加载Driver.class代码\n                ServiceLoader<Driver> loadedDrivers = ServiceLoader.load(Driver.class);\n                Iterator<Driver> driversIterator = loadedDrivers.iterator();\n\n                /* Load these drivers, so that they can be instantiated.\n                 * It may be the case that the driver class may not be there\n                 * i.e. there may be a packaged driver with the service class\n                 * as implementation of java.sql.Driver but the actual class\n                 * may be missing. In that case a java.util.ServiceConfigurationError\n                 * will be thrown at runtime by the VM trying to locate\n                 * and load the service.\n                 *\n                 * Adding a try catch block to catch those runtime errors\n                 * if driver not available in classpath but it's\n                 * packaged as service and that service is there in classpath.\n                 */\n                try{\n                    while(driversIterator.hasNext()) {\n                        driversIterator.next();\n                    }\n                } catch(Throwable t) {\n                    // Do nothing\n                }\n                return null;\n            }\n        });\n\n        println(\"DriverManager.initialize: jdbc.drivers = \" + drivers);\n\n        if (drivers == null || drivers.equals(\"\")) {\n            return;\n        }\n        String[] driversList = drivers.split(\":\");\n        println(\"number of Drivers:\" + driversList.length);\n        for (String aDriver : driversList) {\n            try {\n                println(\"DriverManager.Initialize: loading \" + aDriver);\n                Class.forName(aDriver, true,\n                        ClassLoader.getSystemClassLoader());\n            } catch (Exception ex) {\n                println(\"DriverManager.Initialize: load failed: \" + ex);\n            }\n        }\n    }\n    //进入到ServiceLoader之后的代码\n//能发现，这个加载时是获取当前线程的上下文类加载器进行加载，而这个加载器不是JVM中BootStrap类加载器，而是厂商提供的，所以加载的时候不是在BootStrap类加载器加载，在打破了双亲委派模型~\n    public static <S> ServiceLoader<S> load(Class<S> service) {\n        ClassLoader cl = Thread.currentThread().getContextClassLoader();\n        return ServiceLoader.load(service, cl);\n    }\n}\n\n\n```\n总结：通过源码不难看出，Class.forName(\"xx\");能写且不报错，说明在JVM里面有这个Drive类的加载代码，但是只有接口，没有实现，具体实现是厂商提供的，而这个过程不遵循双亲委派机制。\n\n\n> 对SPI想多点了解，可参考：\n> https://mp.weixin.qq.com/s?__biz=MzIxNDY0MTg2MA==&mid=2247483935&idx=1&sn=e6da46cfe2df2812fd2b9e24253ec246&chksm=97a53fb4a0d2b6a2896b5c0850e83a7852ad08fbe0939bb61d04982bc0d03d3f6da25ee56dbf&scene=21#wechat_redirect\n\n\n##### 3.**OSGi**——模块化（微服务）  安装、启动、停止、卸载。\n\n原理：使类相互之间不可见，相当霸道！（后续补充）\n","slug":"md/类加载器以及双亲委派模型","published":1,"updated":"2025-05-20T07:21:30.943Z","comments":1,"layout":"post","photos":[],"_id":"cmhc3m3ud000nxdp86fbe4yqy","content":"<h3 id=\"一个类的生命周期（7个阶段）\"><a href=\"#一个类的生命周期（7个阶段）\" class=\"headerlink\" title=\"一个类的生命周期（7个阶段）\"></a>一个类的生命周期（7个阶段）</h3><p><strong>加载-验证-准备-解析-初始化-使用-卸载</strong></p>\n<p><img src=\"/img/20200901134621820.png\" alt=\"一个类的生命周期\"><br>其中，类的加载过程是十分重要的过程。在这一过程，是由JVM提供的类加载器来完成。</p>\n<h3 id=\"类加载器\"><a href=\"#类加载器\" class=\"headerlink\" title=\"类加载器\"></a><strong>类加载器</strong></h3><p>JVM提供三层类加载器</p>\n<p><strong>启动类加载器</strong>：Bootstrap Class Loader ，是C++写的，返回为NULL（比如String类），lib&#x2F;下的jar包，比如rt.jar,jce.jar等</p>\n<p><strong>拓展类加载器</strong>：Extension Class Loader，jre&#x2F;lib&#x2F;ext下的jar或者是指定的jar</p>\n<p><strong>应用程序类加载器</strong>：Application  Class Loader，加载calsspath指定内容</p>\n<p>当然自己也可以定义加载器，不算入JVM中的，<strong>自定义加载器</strong>：Custom ClassLoader，自定义加载器，支持一些个性化的扩展功能</p>\n<pre><code class=\"language-text\">Xbootclasspath\n设置启动类加载器的路径\n</code></pre>\n<h3 id=\"双亲委派模型\"><a href=\"#双亲委派模型\" class=\"headerlink\" title=\"双亲委派模型\"></a><strong>双亲委派模型</strong></h3><p><img src=\"/img/20200901135402519.png\" alt=\"双亲委派模型\"><br>每一层的类加载器都有上层的加载器，称为父类加载器，Bootstrap加载器最上层的类加载器，主要加载一些重要的类，如Object类，String类等。当类需要加载的时候子类加载器会依次向上委托父类加载器进行加载，并向上询问是否已经被加载，如果父类没有被加载，则向下尝试子类加载器是否可加载，直到该类被加载，过程结束。这就是双亲委派模型机制。</p>\n<p>总结：<strong>向上委托并询问，向下尝试加载</strong></p>\n<p>优势：<strong>稳定</strong>，当自己重写了个基础类（Object类，String类等）进行加载的时候，子类加载器依次向上委托基础类给父类加载器，到了Bootstrap类加载器发现rt.jar中有，然后就直接加载，返回加载成功。这样保证了JVM运行的安全稳定。</p>\n<p><strong>对于任意一个类，都需要由加载它的类加载器和这个类本身一同确立其在 Java 虚拟机中的唯一性，每一个类加载器，都拥有一个独立的类名称空间。</strong></p>\n<h4 id=\"打破双亲委派模型的示例\"><a href=\"#打破双亲委派模型的示例\" class=\"headerlink\" title=\"打破双亲委派模型的示例\"></a><strong>打破双亲委派模型的示例</strong></h4><p>虽然双亲委派模型能够保证JVM稳定运行，但有些时候根据场景，我们需要打破这种机制。</p>\n<h5 id=\"1-Tomca类加载机制\"><a href=\"#1-Tomca类加载机制\" class=\"headerlink\" title=\"1.Tomca类加载机制\"></a>1.Tomca类加载机制</h5><p><img src=\"/img/20200901160002516.png\" alt=\"Tomcat加载机制\"></p>\n<p>Tomcat中自定义的Common加载器：Catalina类+Shared类加载器</p>\n<p>tomcat通过war包进行的应用发布，其实时违反了双亲委派机制原则。因为不同的项目可能用到不同版本的第三方，即需要不同webApp类加载器加载不同版本的第三方，需要隔离，所以要破坏双亲委派模型。</p>\n<p><strong>tomcat的设计如何破坏了双亲委派机制？</strong></p>\n<p>tomcat中存在三种类加载器，Common加载器：Catalina类+Shared类加载器，在进行类加载的时候是这样处理的：</p>\n<p>1.首先判断这个类是否已经被加载了，如果被加载了就返回，否则下一步；</p>\n<p>2.尝试通过Appcalition ClassLoader进行加载，主要是避免一些基础类（Object，String类）被web中的类覆盖，导致不安全，如果加载了就返回，否则下一步；</p>\n<p>3.如果前两步都没有加载到类，就启用webApp类加载器进行加载，如果被加载了就返回，否则下一步；</p>\n<p>4.最后还没有加载的话，就委托父类加载器Common ClassLoader进行加载。</p>\n<p><strong>但是你自己写一个 ArrayList或者HashMap时候，放在应用目录里，tomcat 依然不会加载（会在第二步时通过Application类加载器进行加载）。Tomca类加载机制只是自定义的加载器顺序不同，但对于顶层来说，还是一样的。</strong></p>\n<h5 id=\"2-SPI（Service-Provider-Infreface）\"><a href=\"#2-SPI（Service-Provider-Infreface）\" class=\"headerlink\" title=\"2.SPI（Service Provider Infreface）\"></a>2.<strong>SPI</strong>（Service Provider Infreface）</h5><p>Java 中有一个 SPI 机制，全称是 Service Provider Interface，是 Java 提供的一套用来被第三方实现或者扩展的服务提供接口，设计模式：基于接口的编程，是接口+实现类+配置文件</p>\n<p>其中最有代表性的，<strong>JDBC，数据库连接</strong></p>\n<p><strong>如何破环双亲委派？</strong></p>\n<p>原本应该是通过BootStrap ClassLoader进行加载，没有代码进行实现加载，只能获取当前线程上下文加载器，即整个web的Application ClassLoder，所以最后其实在使用的Application类加载器加载</p>\n<p><img src=\"/img/20200901160256824.png\" alt=\"SPI\"><br>源码分析</p>\n<pre><code class=\"language-java\">public class Test&#123;\n//我们在JDBC连接数据库的时候往往通过一行代码就能实现\n//Class.forName(&quot;xx&quot;);可以不用写\n\n    Connection conn= DriverManager.getConnection(url, user, password);\n//当getConnection被调用的时候，DriverManager中有个static静态代码块进行执行\n    /**\n     * Load the initial JDBC drivers by checking the System property\n     * jdbc.properties and then use the &#123;@code ServiceLoader&#125; mechanism\n     */\n    static &#123;\n        loadInitialDrivers();\n        println(&quot;JDBC DriverManager initialized&quot;);\n    &#125;\n    //静态代码块执行的方法loadInitialDrivers()\n    private static void loadInitialDrivers() &#123;\n        String drivers;\n        try &#123;\n            drivers = AccessController.doPrivileged(new PrivilegedAction&lt;String&gt;() &#123;\n                public String run() &#123;\n                    return System.getProperty(&quot;jdbc.drivers&quot;);\n                &#125;\n            &#125;);\n        &#125; catch (Exception ex) &#123;\n            drivers = null;\n        &#125;\n        // If the driver is packaged as a Service Provider, load it.\n        // Get all the drivers through the classloader\n        // exposed as a java.sql.Driver.class service.\n        // ServiceLoader.load() replaces the sun.misc.Providers()\n\n        AccessController.doPrivileged(new PrivilegedAction&lt;Void&gt;() &#123;\n            public Void run() &#123;\n                //注意这里！！！加载Driver.class代码\n                ServiceLoader&lt;Driver&gt; loadedDrivers = ServiceLoader.load(Driver.class);\n                Iterator&lt;Driver&gt; driversIterator = loadedDrivers.iterator();\n\n                /* Load these drivers, so that they can be instantiated.\n                 * It may be the case that the driver class may not be there\n                 * i.e. there may be a packaged driver with the service class\n                 * as implementation of java.sql.Driver but the actual class\n                 * may be missing. In that case a java.util.ServiceConfigurationError\n                 * will be thrown at runtime by the VM trying to locate\n                 * and load the service.\n                 *\n                 * Adding a try catch block to catch those runtime errors\n                 * if driver not available in classpath but it&#39;s\n                 * packaged as service and that service is there in classpath.\n                 */\n                try&#123;\n                    while(driversIterator.hasNext()) &#123;\n                        driversIterator.next();\n                    &#125;\n                &#125; catch(Throwable t) &#123;\n                    // Do nothing\n                &#125;\n                return null;\n            &#125;\n        &#125;);\n\n        println(&quot;DriverManager.initialize: jdbc.drivers = &quot; + drivers);\n\n        if (drivers == null || drivers.equals(&quot;&quot;)) &#123;\n            return;\n        &#125;\n        String[] driversList = drivers.split(&quot;:&quot;);\n        println(&quot;number of Drivers:&quot; + driversList.length);\n        for (String aDriver : driversList) &#123;\n            try &#123;\n                println(&quot;DriverManager.Initialize: loading &quot; + aDriver);\n                Class.forName(aDriver, true,\n                        ClassLoader.getSystemClassLoader());\n            &#125; catch (Exception ex) &#123;\n                println(&quot;DriverManager.Initialize: load failed: &quot; + ex);\n            &#125;\n        &#125;\n    &#125;\n    //进入到ServiceLoader之后的代码\n//能发现，这个加载时是获取当前线程的上下文类加载器进行加载，而这个加载器不是JVM中BootStrap类加载器，而是厂商提供的，所以加载的时候不是在BootStrap类加载器加载，在打破了双亲委派模型~\n    public static &lt;S&gt; ServiceLoader&lt;S&gt; load(Class&lt;S&gt; service) &#123;\n        ClassLoader cl = Thread.currentThread().getContextClassLoader();\n        return ServiceLoader.load(service, cl);\n    &#125;\n&#125;\n\n</code></pre>\n<p>总结：通过源码不难看出，Class.forName(“xx”);能写且不报错，说明在JVM里面有这个Drive类的加载代码，但是只有接口，没有实现，具体实现是厂商提供的，而这个过程不遵循双亲委派机制。</p>\n<blockquote>\n<p>对SPI想多点了解，可参考：<br><a href=\"https://mp.weixin.qq.com/s?__biz=MzIxNDY0MTg2MA==&mid=2247483935&idx=1&sn=e6da46cfe2df2812fd2b9e24253ec246&chksm=97a53fb4a0d2b6a2896b5c0850e83a7852ad08fbe0939bb61d04982bc0d03d3f6da25ee56dbf&scene=21#wechat_redirect\">https://mp.weixin.qq.com/s?__biz=MzIxNDY0MTg2MA==&amp;mid=2247483935&amp;idx=1&amp;sn=e6da46cfe2df2812fd2b9e24253ec246&amp;chksm=97a53fb4a0d2b6a2896b5c0850e83a7852ad08fbe0939bb61d04982bc0d03d3f6da25ee56dbf&amp;scene=21#wechat_redirect</a></p>\n</blockquote>\n<h5 id=\"3-OSGi——模块化（微服务）-安装、启动、停止、卸载。\"><a href=\"#3-OSGi——模块化（微服务）-安装、启动、停止、卸载。\" class=\"headerlink\" title=\"3.OSGi——模块化（微服务）  安装、启动、停止、卸载。\"></a>3.<strong>OSGi</strong>——模块化（微服务）  安装、启动、停止、卸载。</h5><p>原理：使类相互之间不可见，相当霸道！（后续补充）</p>\n","excerpt":"","more":"<h3 id=\"一个类的生命周期（7个阶段）\"><a href=\"#一个类的生命周期（7个阶段）\" class=\"headerlink\" title=\"一个类的生命周期（7个阶段）\"></a>一个类的生命周期（7个阶段）</h3><p><strong>加载-验证-准备-解析-初始化-使用-卸载</strong></p>\n<p><img src=\"/img/20200901134621820.png\" alt=\"一个类的生命周期\"><br>其中，类的加载过程是十分重要的过程。在这一过程，是由JVM提供的类加载器来完成。</p>\n<h3 id=\"类加载器\"><a href=\"#类加载器\" class=\"headerlink\" title=\"类加载器\"></a><strong>类加载器</strong></h3><p>JVM提供三层类加载器</p>\n<p><strong>启动类加载器</strong>：Bootstrap Class Loader ，是C++写的，返回为NULL（比如String类），lib&#x2F;下的jar包，比如rt.jar,jce.jar等</p>\n<p><strong>拓展类加载器</strong>：Extension Class Loader，jre&#x2F;lib&#x2F;ext下的jar或者是指定的jar</p>\n<p><strong>应用程序类加载器</strong>：Application  Class Loader，加载calsspath指定内容</p>\n<p>当然自己也可以定义加载器，不算入JVM中的，<strong>自定义加载器</strong>：Custom ClassLoader，自定义加载器，支持一些个性化的扩展功能</p>\n<pre><code class=\"language-text\">Xbootclasspath\n设置启动类加载器的路径\n</code></pre>\n<h3 id=\"双亲委派模型\"><a href=\"#双亲委派模型\" class=\"headerlink\" title=\"双亲委派模型\"></a><strong>双亲委派模型</strong></h3><p><img src=\"/img/20200901135402519.png\" alt=\"双亲委派模型\"><br>每一层的类加载器都有上层的加载器，称为父类加载器，Bootstrap加载器最上层的类加载器，主要加载一些重要的类，如Object类，String类等。当类需要加载的时候子类加载器会依次向上委托父类加载器进行加载，并向上询问是否已经被加载，如果父类没有被加载，则向下尝试子类加载器是否可加载，直到该类被加载，过程结束。这就是双亲委派模型机制。</p>\n<p>总结：<strong>向上委托并询问，向下尝试加载</strong></p>\n<p>优势：<strong>稳定</strong>，当自己重写了个基础类（Object类，String类等）进行加载的时候，子类加载器依次向上委托基础类给父类加载器，到了Bootstrap类加载器发现rt.jar中有，然后就直接加载，返回加载成功。这样保证了JVM运行的安全稳定。</p>\n<p><strong>对于任意一个类，都需要由加载它的类加载器和这个类本身一同确立其在 Java 虚拟机中的唯一性，每一个类加载器，都拥有一个独立的类名称空间。</strong></p>\n<h4 id=\"打破双亲委派模型的示例\"><a href=\"#打破双亲委派模型的示例\" class=\"headerlink\" title=\"打破双亲委派模型的示例\"></a><strong>打破双亲委派模型的示例</strong></h4><p>虽然双亲委派模型能够保证JVM稳定运行，但有些时候根据场景，我们需要打破这种机制。</p>\n<h5 id=\"1-Tomca类加载机制\"><a href=\"#1-Tomca类加载机制\" class=\"headerlink\" title=\"1.Tomca类加载机制\"></a>1.Tomca类加载机制</h5><p><img src=\"/img/20200901160002516.png\" alt=\"Tomcat加载机制\"></p>\n<p>Tomcat中自定义的Common加载器：Catalina类+Shared类加载器</p>\n<p>tomcat通过war包进行的应用发布，其实时违反了双亲委派机制原则。因为不同的项目可能用到不同版本的第三方，即需要不同webApp类加载器加载不同版本的第三方，需要隔离，所以要破坏双亲委派模型。</p>\n<p><strong>tomcat的设计如何破坏了双亲委派机制？</strong></p>\n<p>tomcat中存在三种类加载器，Common加载器：Catalina类+Shared类加载器，在进行类加载的时候是这样处理的：</p>\n<p>1.首先判断这个类是否已经被加载了，如果被加载了就返回，否则下一步；</p>\n<p>2.尝试通过Appcalition ClassLoader进行加载，主要是避免一些基础类（Object，String类）被web中的类覆盖，导致不安全，如果加载了就返回，否则下一步；</p>\n<p>3.如果前两步都没有加载到类，就启用webApp类加载器进行加载，如果被加载了就返回，否则下一步；</p>\n<p>4.最后还没有加载的话，就委托父类加载器Common ClassLoader进行加载。</p>\n<p><strong>但是你自己写一个 ArrayList或者HashMap时候，放在应用目录里，tomcat 依然不会加载（会在第二步时通过Application类加载器进行加载）。Tomca类加载机制只是自定义的加载器顺序不同，但对于顶层来说，还是一样的。</strong></p>\n<h5 id=\"2-SPI（Service-Provider-Infreface）\"><a href=\"#2-SPI（Service-Provider-Infreface）\" class=\"headerlink\" title=\"2.SPI（Service Provider Infreface）\"></a>2.<strong>SPI</strong>（Service Provider Infreface）</h5><p>Java 中有一个 SPI 机制，全称是 Service Provider Interface，是 Java 提供的一套用来被第三方实现或者扩展的服务提供接口，设计模式：基于接口的编程，是接口+实现类+配置文件</p>\n<p>其中最有代表性的，<strong>JDBC，数据库连接</strong></p>\n<p><strong>如何破环双亲委派？</strong></p>\n<p>原本应该是通过BootStrap ClassLoader进行加载，没有代码进行实现加载，只能获取当前线程上下文加载器，即整个web的Application ClassLoder，所以最后其实在使用的Application类加载器加载</p>\n<p><img src=\"/img/20200901160256824.png\" alt=\"SPI\"><br>源码分析</p>\n<pre><code class=\"language-java\">public class Test&#123;\n//我们在JDBC连接数据库的时候往往通过一行代码就能实现\n//Class.forName(&quot;xx&quot;);可以不用写\n\n    Connection conn= DriverManager.getConnection(url, user, password);\n//当getConnection被调用的时候，DriverManager中有个static静态代码块进行执行\n    /**\n     * Load the initial JDBC drivers by checking the System property\n     * jdbc.properties and then use the &#123;@code ServiceLoader&#125; mechanism\n     */\n    static &#123;\n        loadInitialDrivers();\n        println(&quot;JDBC DriverManager initialized&quot;);\n    &#125;\n    //静态代码块执行的方法loadInitialDrivers()\n    private static void loadInitialDrivers() &#123;\n        String drivers;\n        try &#123;\n            drivers = AccessController.doPrivileged(new PrivilegedAction&lt;String&gt;() &#123;\n                public String run() &#123;\n                    return System.getProperty(&quot;jdbc.drivers&quot;);\n                &#125;\n            &#125;);\n        &#125; catch (Exception ex) &#123;\n            drivers = null;\n        &#125;\n        // If the driver is packaged as a Service Provider, load it.\n        // Get all the drivers through the classloader\n        // exposed as a java.sql.Driver.class service.\n        // ServiceLoader.load() replaces the sun.misc.Providers()\n\n        AccessController.doPrivileged(new PrivilegedAction&lt;Void&gt;() &#123;\n            public Void run() &#123;\n                //注意这里！！！加载Driver.class代码\n                ServiceLoader&lt;Driver&gt; loadedDrivers = ServiceLoader.load(Driver.class);\n                Iterator&lt;Driver&gt; driversIterator = loadedDrivers.iterator();\n\n                /* Load these drivers, so that they can be instantiated.\n                 * It may be the case that the driver class may not be there\n                 * i.e. there may be a packaged driver with the service class\n                 * as implementation of java.sql.Driver but the actual class\n                 * may be missing. In that case a java.util.ServiceConfigurationError\n                 * will be thrown at runtime by the VM trying to locate\n                 * and load the service.\n                 *\n                 * Adding a try catch block to catch those runtime errors\n                 * if driver not available in classpath but it&#39;s\n                 * packaged as service and that service is there in classpath.\n                 */\n                try&#123;\n                    while(driversIterator.hasNext()) &#123;\n                        driversIterator.next();\n                    &#125;\n                &#125; catch(Throwable t) &#123;\n                    // Do nothing\n                &#125;\n                return null;\n            &#125;\n        &#125;);\n\n        println(&quot;DriverManager.initialize: jdbc.drivers = &quot; + drivers);\n\n        if (drivers == null || drivers.equals(&quot;&quot;)) &#123;\n            return;\n        &#125;\n        String[] driversList = drivers.split(&quot;:&quot;);\n        println(&quot;number of Drivers:&quot; + driversList.length);\n        for (String aDriver : driversList) &#123;\n            try &#123;\n                println(&quot;DriverManager.Initialize: loading &quot; + aDriver);\n                Class.forName(aDriver, true,\n                        ClassLoader.getSystemClassLoader());\n            &#125; catch (Exception ex) &#123;\n                println(&quot;DriverManager.Initialize: load failed: &quot; + ex);\n            &#125;\n        &#125;\n    &#125;\n    //进入到ServiceLoader之后的代码\n//能发现，这个加载时是获取当前线程的上下文类加载器进行加载，而这个加载器不是JVM中BootStrap类加载器，而是厂商提供的，所以加载的时候不是在BootStrap类加载器加载，在打破了双亲委派模型~\n    public static &lt;S&gt; ServiceLoader&lt;S&gt; load(Class&lt;S&gt; service) &#123;\n        ClassLoader cl = Thread.currentThread().getContextClassLoader();\n        return ServiceLoader.load(service, cl);\n    &#125;\n&#125;\n\n</code></pre>\n<p>总结：通过源码不难看出，Class.forName(“xx”);能写且不报错，说明在JVM里面有这个Drive类的加载代码，但是只有接口，没有实现，具体实现是厂商提供的，而这个过程不遵循双亲委派机制。</p>\n<blockquote>\n<p>对SPI想多点了解，可参考：<br><a href=\"https://mp.weixin.qq.com/s?__biz=MzIxNDY0MTg2MA==&mid=2247483935&idx=1&sn=e6da46cfe2df2812fd2b9e24253ec246&chksm=97a53fb4a0d2b6a2896b5c0850e83a7852ad08fbe0939bb61d04982bc0d03d3f6da25ee56dbf&scene=21#wechat_redirect\">https://mp.weixin.qq.com/s?__biz=MzIxNDY0MTg2MA==&amp;mid=2247483935&amp;idx=1&amp;sn=e6da46cfe2df2812fd2b9e24253ec246&amp;chksm=97a53fb4a0d2b6a2896b5c0850e83a7852ad08fbe0939bb61d04982bc0d03d3f6da25ee56dbf&amp;scene=21#wechat_redirect</a></p>\n</blockquote>\n<h5 id=\"3-OSGi——模块化（微服务）-安装、启动、停止、卸载。\"><a href=\"#3-OSGi——模块化（微服务）-安装、启动、停止、卸载。\" class=\"headerlink\" title=\"3.OSGi——模块化（微服务）  安装、启动、停止、卸载。\"></a>3.<strong>OSGi</strong>——模块化（微服务）  安装、启动、停止、卸载。</h5><p>原理：使类相互之间不可见，相当霸道！（后续补充）</p>\n"},{"title":"javascript中 const，var，let的区别","date":"2024-07-22T16:00:00.000Z","id":"761386768996512","_content":"var、const、let 同样都是声明变量的关键词。\n\n## 一、var 和 let 区别\n\n### 作用域\n\nvar 的作用域只能是全局或者是整个函数块，而 let 的作用域既可以是全局变量或者是整个函数，还可以是 if, while, switch 限定的代码块。\n\n``` javascript\nfunction varTest() {\n\t\n\tvar a = 1;  \n\t{    \n\t\tvar a = 2; // 函数块中，同一个变量 \n\t\tconsole.log(a); // 2  \n\t}  \n\t console.log(a); // 2\n}\n\n function letTest() {  \n\t let a = 1;  \n\t {    \n\t\t let a = 2; // 代码块中，新的变量    \n\t\t console.log(a); // 2  \n\t }  \n\t console.log(a); // 1\n }\n varTest();\n letTest();\n```\n\nlet 声明的变量，可以比 var 声明的变量的作用有更小的限定范围，更加灵活。\n\n### 重复声明\n\n在同一个作用域中，var 允许重复声明，但是 let 不允许重复声明。\n\n```javascript\nvar a = 1;\nvar a = 2;\nconsole.log(a) // 2\nfunction test() { \n var a = 3;  \n var a = 4;  \n console.log(a) // 4\n }\n test()\n\n\nif(false) {  \n\tlet a = 1;  \n\tlet a = 2; // SyntaxError: Identifier 'a' has already been declared}\n}\n\nswitch(index) {  \n\tcase 0:    \n\t\tlet a = 1;  \n\t\tbreak;  \n\tdefault:    \n\t\tlet a = 2; // SyntaxError: Identifier 'a' has already been declared    \n\t\tbreak;\n}\n```\n\n### 绑定全局变量\n\nvar 在全局环境声明变量，会在全局对象里新建一个属性，而 let 在全局环境声明变量，则不会在全局对象里新建一个属性。\n\n```javascript\nvar foo = 'global'\nlet bar = 'global'\nconsole.log(this.foo) // global\nconsole.log(this.bar) // undefined\n```\n\n\n![控制台日志](img/d81d47f1a51cc2ecfe16e8966e7949b8_MD5.jpeg)\n\n由上图可知，let 在全局环境声明变量 bar 保存在\\[\\[Scopes]]\\[0]: Script 这个变量对象的属性中，而 \\[\\[Scopes]]\\[1]: Global 就是我们常说的全局对象。\n\n### 变量提升和暂存死区\n\n了解变量提升，就需要了解到上线文和变量对象。详见[详解：javascript 创建执行释放过程](/md/js/详解：JavaScript创建执行释放过程.md)\n\n#### 变量提升\n\n所有使用 var 声明的变量都会在执行上下文的创建阶段时作为变量对象的属性被创建并初始化，这样才能保证在执行阶段能通过标识符在变量对象里找到对应变量进行赋值操作等。即 var 在声明变量构建变量的时：\n1. 由名称和 undefined（形参）组成一个变量对象的属性创建（创建并初始化）\n2. 如果变量名称和之前的形参或者函数相同，则变量声明不会干扰已经存在的这类属性。\n\n```javascript\nconsole.log(a) // undefined\nvar a = 1;\nconsole.log(a) // 1\n```\n\n为什么 var 变量可以在声明之前使用，因为使用是在执行阶段，而在此之前的创建阶段就已经将声明的变量添加到了变量对象中，所以执行阶段通过标识符可以在变量对象中查找到，也就不会报错。\n\n#### 暂存死区\n\n其实 let 也存在与 var 类似的“变量提升”过程，但与 var 不同的是其在执行上下文的创建阶段，只会创建变量而不会被初始化（undefined），并且 ES6 规定了其初始化过程是在执行上下文的执行阶段（即直到它们的定义被执行时才初始化），使用未被初始化的变量将会报错。\n\n>let and const declarations define variables that are scoped to the running execution context’s LexicalEnvironment. The variables are created when their containing Lexical Environment is instantiated but may not be accessed in any way until the variable’s LexicalBinding is evaluated. A variable defined by a LexicalBinding with an Initializer is assigned the value of its Initializer’s AssignmentExpression when the LexicalBinding is evaluated, not when the variable is created. If a LexicalBinding in a let declaration does not have an Initializer the variable is assigned the value **undefined** when the LexicalBinding is evaluated.\n\n在变量初始化前访问该变量会导致 ReferenceError，因此从进入作用域创建变量，到变量开始可被访问的一段时间（过程），就称为暂存死区(Temporal Dead Zone)。\n\n```javascript\nconsole.log(bar); // undefined\nconsole.log(foo); // ReferenceError: foo is not defined\nvar bar = 1;\nlet foo = 2;\n\n\nvar foo = 33;\n\t{  \n\t\tlet foo = (foo + 55); // ReferenceError: foo is not defined\n\t}\n\n```\n### 小结\n\n1. var 声明的变量在执行上下文创建阶段就会被「创建」和「初始化」，因此对于执行阶段来说，可以在声明之前使用。\n2. let 声明的变量在执行上下文创建阶段只会被「创建」而不会被「初始化」，因此对于执行阶段来说，如果在其定义执行前使用，相当于使用了未被初始化的变量，会报错。\n\n## 二、let 和 const 区别\n\nconst 与 let 很类似，都具有上面提到的 let 的特性，唯一区别就在于 const 声明的是一个只读变量，声明之后不允许改变其值。因此，const 一旦声明必须初始化，否则会报错。\n\n示例代码：\n\n```javascript\nlet a;\nconst b = \"constant\"\na = \"variable\"\nb = 'change' // TypeError: Assignment to constant variable\n```\n**如何理解声明之后不允许改变其值？**\n\n其实 const 其实保证的不是变量的值不变，而是保证变量指向的内存地址所保存的数据不允许改动（即栈内存在的值和地址）。\n\njavascript 的数据类型分为两类：原始值类型和对象（Object类型）。\n\n对于原始值类型（undefined、null、true/false、number、string），值就保存在变量指向的那个内存地址（在栈中），因此 const 声明的原始值类型变量等同于常量。\n\n对于对象类型（object，array，function等），变量指向的内存地址其实是保存了一个指向实际数据的指针，所以 const 只能保证指针是不可修改的，至于指针指向的数据结构是无法保证其不能被修改的（在堆中）。\n\n示例代码：\n\n```javascript\nconst obj = {  value: 1}\nobj.value = 2;\nconsole.log(obj) // { value: 2 }obj = {}\n```\n\n参考资料：\n\n> [深入理解 JS：var、let、const 的异同]( https://zhuanlan.zhihu.com/p/556482226?utm_id=0 )\n\n","source":"_posts/md/详解：JavaScript中const，var，let的区别.md","raw":"---\ntitle: javascript中 const，var，let的区别\ntag: \n- javascript\ncategory: \n- 前端\ndate: 2024-07-23\nid: 761386768996512\n---\nvar、const、let 同样都是声明变量的关键词。\n\n## 一、var 和 let 区别\n\n### 作用域\n\nvar 的作用域只能是全局或者是整个函数块，而 let 的作用域既可以是全局变量或者是整个函数，还可以是 if, while, switch 限定的代码块。\n\n``` javascript\nfunction varTest() {\n\t\n\tvar a = 1;  \n\t{    \n\t\tvar a = 2; // 函数块中，同一个变量 \n\t\tconsole.log(a); // 2  \n\t}  \n\t console.log(a); // 2\n}\n\n function letTest() {  \n\t let a = 1;  \n\t {    \n\t\t let a = 2; // 代码块中，新的变量    \n\t\t console.log(a); // 2  \n\t }  \n\t console.log(a); // 1\n }\n varTest();\n letTest();\n```\n\nlet 声明的变量，可以比 var 声明的变量的作用有更小的限定范围，更加灵活。\n\n### 重复声明\n\n在同一个作用域中，var 允许重复声明，但是 let 不允许重复声明。\n\n```javascript\nvar a = 1;\nvar a = 2;\nconsole.log(a) // 2\nfunction test() { \n var a = 3;  \n var a = 4;  \n console.log(a) // 4\n }\n test()\n\n\nif(false) {  \n\tlet a = 1;  \n\tlet a = 2; // SyntaxError: Identifier 'a' has already been declared}\n}\n\nswitch(index) {  \n\tcase 0:    \n\t\tlet a = 1;  \n\t\tbreak;  \n\tdefault:    \n\t\tlet a = 2; // SyntaxError: Identifier 'a' has already been declared    \n\t\tbreak;\n}\n```\n\n### 绑定全局变量\n\nvar 在全局环境声明变量，会在全局对象里新建一个属性，而 let 在全局环境声明变量，则不会在全局对象里新建一个属性。\n\n```javascript\nvar foo = 'global'\nlet bar = 'global'\nconsole.log(this.foo) // global\nconsole.log(this.bar) // undefined\n```\n\n\n![控制台日志](img/d81d47f1a51cc2ecfe16e8966e7949b8_MD5.jpeg)\n\n由上图可知，let 在全局环境声明变量 bar 保存在\\[\\[Scopes]]\\[0]: Script 这个变量对象的属性中，而 \\[\\[Scopes]]\\[1]: Global 就是我们常说的全局对象。\n\n### 变量提升和暂存死区\n\n了解变量提升，就需要了解到上线文和变量对象。详见[详解：javascript 创建执行释放过程](/md/js/详解：JavaScript创建执行释放过程.md)\n\n#### 变量提升\n\n所有使用 var 声明的变量都会在执行上下文的创建阶段时作为变量对象的属性被创建并初始化，这样才能保证在执行阶段能通过标识符在变量对象里找到对应变量进行赋值操作等。即 var 在声明变量构建变量的时：\n1. 由名称和 undefined（形参）组成一个变量对象的属性创建（创建并初始化）\n2. 如果变量名称和之前的形参或者函数相同，则变量声明不会干扰已经存在的这类属性。\n\n```javascript\nconsole.log(a) // undefined\nvar a = 1;\nconsole.log(a) // 1\n```\n\n为什么 var 变量可以在声明之前使用，因为使用是在执行阶段，而在此之前的创建阶段就已经将声明的变量添加到了变量对象中，所以执行阶段通过标识符可以在变量对象中查找到，也就不会报错。\n\n#### 暂存死区\n\n其实 let 也存在与 var 类似的“变量提升”过程，但与 var 不同的是其在执行上下文的创建阶段，只会创建变量而不会被初始化（undefined），并且 ES6 规定了其初始化过程是在执行上下文的执行阶段（即直到它们的定义被执行时才初始化），使用未被初始化的变量将会报错。\n\n>let and const declarations define variables that are scoped to the running execution context’s LexicalEnvironment. The variables are created when their containing Lexical Environment is instantiated but may not be accessed in any way until the variable’s LexicalBinding is evaluated. A variable defined by a LexicalBinding with an Initializer is assigned the value of its Initializer’s AssignmentExpression when the LexicalBinding is evaluated, not when the variable is created. If a LexicalBinding in a let declaration does not have an Initializer the variable is assigned the value **undefined** when the LexicalBinding is evaluated.\n\n在变量初始化前访问该变量会导致 ReferenceError，因此从进入作用域创建变量，到变量开始可被访问的一段时间（过程），就称为暂存死区(Temporal Dead Zone)。\n\n```javascript\nconsole.log(bar); // undefined\nconsole.log(foo); // ReferenceError: foo is not defined\nvar bar = 1;\nlet foo = 2;\n\n\nvar foo = 33;\n\t{  \n\t\tlet foo = (foo + 55); // ReferenceError: foo is not defined\n\t}\n\n```\n### 小结\n\n1. var 声明的变量在执行上下文创建阶段就会被「创建」和「初始化」，因此对于执行阶段来说，可以在声明之前使用。\n2. let 声明的变量在执行上下文创建阶段只会被「创建」而不会被「初始化」，因此对于执行阶段来说，如果在其定义执行前使用，相当于使用了未被初始化的变量，会报错。\n\n## 二、let 和 const 区别\n\nconst 与 let 很类似，都具有上面提到的 let 的特性，唯一区别就在于 const 声明的是一个只读变量，声明之后不允许改变其值。因此，const 一旦声明必须初始化，否则会报错。\n\n示例代码：\n\n```javascript\nlet a;\nconst b = \"constant\"\na = \"variable\"\nb = 'change' // TypeError: Assignment to constant variable\n```\n**如何理解声明之后不允许改变其值？**\n\n其实 const 其实保证的不是变量的值不变，而是保证变量指向的内存地址所保存的数据不允许改动（即栈内存在的值和地址）。\n\njavascript 的数据类型分为两类：原始值类型和对象（Object类型）。\n\n对于原始值类型（undefined、null、true/false、number、string），值就保存在变量指向的那个内存地址（在栈中），因此 const 声明的原始值类型变量等同于常量。\n\n对于对象类型（object，array，function等），变量指向的内存地址其实是保存了一个指向实际数据的指针，所以 const 只能保证指针是不可修改的，至于指针指向的数据结构是无法保证其不能被修改的（在堆中）。\n\n示例代码：\n\n```javascript\nconst obj = {  value: 1}\nobj.value = 2;\nconsole.log(obj) // { value: 2 }obj = {}\n```\n\n参考资料：\n\n> [深入理解 JS：var、let、const 的异同]( https://zhuanlan.zhihu.com/p/556482226?utm_id=0 )\n\n","slug":"md/详解：JavaScript中const，var，let的区别","published":1,"updated":"2025-08-21T09:28:52.716Z","comments":1,"layout":"post","photos":[],"_id":"cmhc3m3ue000pxdp88q8laiyh","content":"<p>var、const、let 同样都是声明变量的关键词。</p>\n<h2 id=\"一、var-和-let-区别\"><a href=\"#一、var-和-let-区别\" class=\"headerlink\" title=\"一、var 和 let 区别\"></a>一、var 和 let 区别</h2><h3 id=\"作用域\"><a href=\"#作用域\" class=\"headerlink\" title=\"作用域\"></a>作用域</h3><p>var 的作用域只能是全局或者是整个函数块，而 let 的作用域既可以是全局变量或者是整个函数，还可以是 if, while, switch 限定的代码块。</p>\n<pre><code class=\"language-javascript\">function varTest() &#123;\n\t\n\tvar a = 1;  \n\t&#123;    \n\t\tvar a = 2; // 函数块中，同一个变量 \n\t\tconsole.log(a); // 2  \n\t&#125;  \n\t console.log(a); // 2\n&#125;\n\n function letTest() &#123;  \n\t let a = 1;  \n\t &#123;    \n\t\t let a = 2; // 代码块中，新的变量    \n\t\t console.log(a); // 2  \n\t &#125;  \n\t console.log(a); // 1\n &#125;\n varTest();\n letTest();\n</code></pre>\n<p>let 声明的变量，可以比 var 声明的变量的作用有更小的限定范围，更加灵活。</p>\n<h3 id=\"重复声明\"><a href=\"#重复声明\" class=\"headerlink\" title=\"重复声明\"></a>重复声明</h3><p>在同一个作用域中，var 允许重复声明，但是 let 不允许重复声明。</p>\n<pre><code class=\"language-javascript\">var a = 1;\nvar a = 2;\nconsole.log(a) // 2\nfunction test() &#123; \n var a = 3;  \n var a = 4;  \n console.log(a) // 4\n &#125;\n test()\n\n\nif(false) &#123;  \n\tlet a = 1;  \n\tlet a = 2; // SyntaxError: Identifier &#39;a&#39; has already been declared&#125;\n&#125;\n\nswitch(index) &#123;  \n\tcase 0:    \n\t\tlet a = 1;  \n\t\tbreak;  \n\tdefault:    \n\t\tlet a = 2; // SyntaxError: Identifier &#39;a&#39; has already been declared    \n\t\tbreak;\n&#125;\n</code></pre>\n<h3 id=\"绑定全局变量\"><a href=\"#绑定全局变量\" class=\"headerlink\" title=\"绑定全局变量\"></a>绑定全局变量</h3><p>var 在全局环境声明变量，会在全局对象里新建一个属性，而 let 在全局环境声明变量，则不会在全局对象里新建一个属性。</p>\n<pre><code class=\"language-javascript\">var foo = &#39;global&#39;\nlet bar = &#39;global&#39;\nconsole.log(this.foo) // global\nconsole.log(this.bar) // undefined\n</code></pre>\n<p><img src=\"/img/d81d47f1a51cc2ecfe16e8966e7949b8_MD5.jpeg\" alt=\"控制台日志\"></p>\n<p>由上图可知，let 在全局环境声明变量 bar 保存在[[Scopes]][0]: Script 这个变量对象的属性中，而 [[Scopes]][1]: Global 就是我们常说的全局对象。</p>\n<h3 id=\"变量提升和暂存死区\"><a href=\"#变量提升和暂存死区\" class=\"headerlink\" title=\"变量提升和暂存死区\"></a>变量提升和暂存死区</h3><p>了解变量提升，就需要了解到上线文和变量对象。详见<a href=\"/md/js/%E8%AF%A6%E8%A7%A3%EF%BC%9AJavaScript%E5%88%9B%E5%BB%BA%E6%89%A7%E8%A1%8C%E9%87%8A%E6%94%BE%E8%BF%87%E7%A8%8B.md\">详解：javascript 创建执行释放过程</a></p>\n<h4 id=\"变量提升\"><a href=\"#变量提升\" class=\"headerlink\" title=\"变量提升\"></a>变量提升</h4><p>所有使用 var 声明的变量都会在执行上下文的创建阶段时作为变量对象的属性被创建并初始化，这样才能保证在执行阶段能通过标识符在变量对象里找到对应变量进行赋值操作等。即 var 在声明变量构建变量的时：</p>\n<ol>\n<li>由名称和 undefined（形参）组成一个变量对象的属性创建（创建并初始化）</li>\n<li>如果变量名称和之前的形参或者函数相同，则变量声明不会干扰已经存在的这类属性。</li>\n</ol>\n<pre><code class=\"language-javascript\">console.log(a) // undefined\nvar a = 1;\nconsole.log(a) // 1\n</code></pre>\n<p>为什么 var 变量可以在声明之前使用，因为使用是在执行阶段，而在此之前的创建阶段就已经将声明的变量添加到了变量对象中，所以执行阶段通过标识符可以在变量对象中查找到，也就不会报错。</p>\n<h4 id=\"暂存死区\"><a href=\"#暂存死区\" class=\"headerlink\" title=\"暂存死区\"></a>暂存死区</h4><p>其实 let 也存在与 var 类似的“变量提升”过程，但与 var 不同的是其在执行上下文的创建阶段，只会创建变量而不会被初始化（undefined），并且 ES6 规定了其初始化过程是在执行上下文的执行阶段（即直到它们的定义被执行时才初始化），使用未被初始化的变量将会报错。</p>\n<blockquote>\n<p>let and const declarations define variables that are scoped to the running execution context’s LexicalEnvironment. The variables are created when their containing Lexical Environment is instantiated but may not be accessed in any way until the variable’s LexicalBinding is evaluated. A variable defined by a LexicalBinding with an Initializer is assigned the value of its Initializer’s AssignmentExpression when the LexicalBinding is evaluated, not when the variable is created. If a LexicalBinding in a let declaration does not have an Initializer the variable is assigned the value <strong>undefined</strong> when the LexicalBinding is evaluated.</p>\n</blockquote>\n<p>在变量初始化前访问该变量会导致 ReferenceError，因此从进入作用域创建变量，到变量开始可被访问的一段时间（过程），就称为暂存死区(Temporal Dead Zone)。</p>\n<pre><code class=\"language-javascript\">console.log(bar); // undefined\nconsole.log(foo); // ReferenceError: foo is not defined\nvar bar = 1;\nlet foo = 2;\n\n\nvar foo = 33;\n\t&#123;  \n\t\tlet foo = (foo + 55); // ReferenceError: foo is not defined\n\t&#125;\n</code></pre>\n<h3 id=\"小结\"><a href=\"#小结\" class=\"headerlink\" title=\"小结\"></a>小结</h3><ol>\n<li>var 声明的变量在执行上下文创建阶段就会被「创建」和「初始化」，因此对于执行阶段来说，可以在声明之前使用。</li>\n<li>let 声明的变量在执行上下文创建阶段只会被「创建」而不会被「初始化」，因此对于执行阶段来说，如果在其定义执行前使用，相当于使用了未被初始化的变量，会报错。</li>\n</ol>\n<h2 id=\"二、let-和-const-区别\"><a href=\"#二、let-和-const-区别\" class=\"headerlink\" title=\"二、let 和 const 区别\"></a>二、let 和 const 区别</h2><p>const 与 let 很类似，都具有上面提到的 let 的特性，唯一区别就在于 const 声明的是一个只读变量，声明之后不允许改变其值。因此，const 一旦声明必须初始化，否则会报错。</p>\n<p>示例代码：</p>\n<pre><code class=\"language-javascript\">let a;\nconst b = &quot;constant&quot;\na = &quot;variable&quot;\nb = &#39;change&#39; // TypeError: Assignment to constant variable\n</code></pre>\n<p><strong>如何理解声明之后不允许改变其值？</strong></p>\n<p>其实 const 其实保证的不是变量的值不变，而是保证变量指向的内存地址所保存的数据不允许改动（即栈内存在的值和地址）。</p>\n<p>javascript 的数据类型分为两类：原始值类型和对象（Object类型）。</p>\n<p>对于原始值类型（undefined、null、true&#x2F;false、number、string），值就保存在变量指向的那个内存地址（在栈中），因此 const 声明的原始值类型变量等同于常量。</p>\n<p>对于对象类型（object，array，function等），变量指向的内存地址其实是保存了一个指向实际数据的指针，所以 const 只能保证指针是不可修改的，至于指针指向的数据结构是无法保证其不能被修改的（在堆中）。</p>\n<p>示例代码：</p>\n<pre><code class=\"language-javascript\">const obj = &#123;  value: 1&#125;\nobj.value = 2;\nconsole.log(obj) // &#123; value: 2 &#125;obj = &#123;&#125;\n</code></pre>\n<p>参考资料：</p>\n<blockquote>\n<p><a href=\"https://zhuanlan.zhihu.com/p/556482226?utm_id=0\">深入理解 JS：var、let、const 的异同</a></p>\n</blockquote>\n","excerpt":"","more":"<p>var、const、let 同样都是声明变量的关键词。</p>\n<h2 id=\"一、var-和-let-区别\"><a href=\"#一、var-和-let-区别\" class=\"headerlink\" title=\"一、var 和 let 区别\"></a>一、var 和 let 区别</h2><h3 id=\"作用域\"><a href=\"#作用域\" class=\"headerlink\" title=\"作用域\"></a>作用域</h3><p>var 的作用域只能是全局或者是整个函数块，而 let 的作用域既可以是全局变量或者是整个函数，还可以是 if, while, switch 限定的代码块。</p>\n<pre><code class=\"language-javascript\">function varTest() &#123;\n\t\n\tvar a = 1;  \n\t&#123;    \n\t\tvar a = 2; // 函数块中，同一个变量 \n\t\tconsole.log(a); // 2  \n\t&#125;  \n\t console.log(a); // 2\n&#125;\n\n function letTest() &#123;  \n\t let a = 1;  \n\t &#123;    \n\t\t let a = 2; // 代码块中，新的变量    \n\t\t console.log(a); // 2  \n\t &#125;  \n\t console.log(a); // 1\n &#125;\n varTest();\n letTest();\n</code></pre>\n<p>let 声明的变量，可以比 var 声明的变量的作用有更小的限定范围，更加灵活。</p>\n<h3 id=\"重复声明\"><a href=\"#重复声明\" class=\"headerlink\" title=\"重复声明\"></a>重复声明</h3><p>在同一个作用域中，var 允许重复声明，但是 let 不允许重复声明。</p>\n<pre><code class=\"language-javascript\">var a = 1;\nvar a = 2;\nconsole.log(a) // 2\nfunction test() &#123; \n var a = 3;  \n var a = 4;  \n console.log(a) // 4\n &#125;\n test()\n\n\nif(false) &#123;  \n\tlet a = 1;  \n\tlet a = 2; // SyntaxError: Identifier &#39;a&#39; has already been declared&#125;\n&#125;\n\nswitch(index) &#123;  \n\tcase 0:    \n\t\tlet a = 1;  \n\t\tbreak;  \n\tdefault:    \n\t\tlet a = 2; // SyntaxError: Identifier &#39;a&#39; has already been declared    \n\t\tbreak;\n&#125;\n</code></pre>\n<h3 id=\"绑定全局变量\"><a href=\"#绑定全局变量\" class=\"headerlink\" title=\"绑定全局变量\"></a>绑定全局变量</h3><p>var 在全局环境声明变量，会在全局对象里新建一个属性，而 let 在全局环境声明变量，则不会在全局对象里新建一个属性。</p>\n<pre><code class=\"language-javascript\">var foo = &#39;global&#39;\nlet bar = &#39;global&#39;\nconsole.log(this.foo) // global\nconsole.log(this.bar) // undefined\n</code></pre>\n<p><img src=\"/img/d81d47f1a51cc2ecfe16e8966e7949b8_MD5.jpeg\" alt=\"控制台日志\"></p>\n<p>由上图可知，let 在全局环境声明变量 bar 保存在[[Scopes]][0]: Script 这个变量对象的属性中，而 [[Scopes]][1]: Global 就是我们常说的全局对象。</p>\n<h3 id=\"变量提升和暂存死区\"><a href=\"#变量提升和暂存死区\" class=\"headerlink\" title=\"变量提升和暂存死区\"></a>变量提升和暂存死区</h3><p>了解变量提升，就需要了解到上线文和变量对象。详见<a href=\"/md/js/%E8%AF%A6%E8%A7%A3%EF%BC%9AJavaScript%E5%88%9B%E5%BB%BA%E6%89%A7%E8%A1%8C%E9%87%8A%E6%94%BE%E8%BF%87%E7%A8%8B.md\">详解：javascript 创建执行释放过程</a></p>\n<h4 id=\"变量提升\"><a href=\"#变量提升\" class=\"headerlink\" title=\"变量提升\"></a>变量提升</h4><p>所有使用 var 声明的变量都会在执行上下文的创建阶段时作为变量对象的属性被创建并初始化，这样才能保证在执行阶段能通过标识符在变量对象里找到对应变量进行赋值操作等。即 var 在声明变量构建变量的时：</p>\n<ol>\n<li>由名称和 undefined（形参）组成一个变量对象的属性创建（创建并初始化）</li>\n<li>如果变量名称和之前的形参或者函数相同，则变量声明不会干扰已经存在的这类属性。</li>\n</ol>\n<pre><code class=\"language-javascript\">console.log(a) // undefined\nvar a = 1;\nconsole.log(a) // 1\n</code></pre>\n<p>为什么 var 变量可以在声明之前使用，因为使用是在执行阶段，而在此之前的创建阶段就已经将声明的变量添加到了变量对象中，所以执行阶段通过标识符可以在变量对象中查找到，也就不会报错。</p>\n<h4 id=\"暂存死区\"><a href=\"#暂存死区\" class=\"headerlink\" title=\"暂存死区\"></a>暂存死区</h4><p>其实 let 也存在与 var 类似的“变量提升”过程，但与 var 不同的是其在执行上下文的创建阶段，只会创建变量而不会被初始化（undefined），并且 ES6 规定了其初始化过程是在执行上下文的执行阶段（即直到它们的定义被执行时才初始化），使用未被初始化的变量将会报错。</p>\n<blockquote>\n<p>let and const declarations define variables that are scoped to the running execution context’s LexicalEnvironment. The variables are created when their containing Lexical Environment is instantiated but may not be accessed in any way until the variable’s LexicalBinding is evaluated. A variable defined by a LexicalBinding with an Initializer is assigned the value of its Initializer’s AssignmentExpression when the LexicalBinding is evaluated, not when the variable is created. If a LexicalBinding in a let declaration does not have an Initializer the variable is assigned the value <strong>undefined</strong> when the LexicalBinding is evaluated.</p>\n</blockquote>\n<p>在变量初始化前访问该变量会导致 ReferenceError，因此从进入作用域创建变量，到变量开始可被访问的一段时间（过程），就称为暂存死区(Temporal Dead Zone)。</p>\n<pre><code class=\"language-javascript\">console.log(bar); // undefined\nconsole.log(foo); // ReferenceError: foo is not defined\nvar bar = 1;\nlet foo = 2;\n\n\nvar foo = 33;\n\t&#123;  \n\t\tlet foo = (foo + 55); // ReferenceError: foo is not defined\n\t&#125;\n</code></pre>\n<h3 id=\"小结\"><a href=\"#小结\" class=\"headerlink\" title=\"小结\"></a>小结</h3><ol>\n<li>var 声明的变量在执行上下文创建阶段就会被「创建」和「初始化」，因此对于执行阶段来说，可以在声明之前使用。</li>\n<li>let 声明的变量在执行上下文创建阶段只会被「创建」而不会被「初始化」，因此对于执行阶段来说，如果在其定义执行前使用，相当于使用了未被初始化的变量，会报错。</li>\n</ol>\n<h2 id=\"二、let-和-const-区别\"><a href=\"#二、let-和-const-区别\" class=\"headerlink\" title=\"二、let 和 const 区别\"></a>二、let 和 const 区别</h2><p>const 与 let 很类似，都具有上面提到的 let 的特性，唯一区别就在于 const 声明的是一个只读变量，声明之后不允许改变其值。因此，const 一旦声明必须初始化，否则会报错。</p>\n<p>示例代码：</p>\n<pre><code class=\"language-javascript\">let a;\nconst b = &quot;constant&quot;\na = &quot;variable&quot;\nb = &#39;change&#39; // TypeError: Assignment to constant variable\n</code></pre>\n<p><strong>如何理解声明之后不允许改变其值？</strong></p>\n<p>其实 const 其实保证的不是变量的值不变，而是保证变量指向的内存地址所保存的数据不允许改动（即栈内存在的值和地址）。</p>\n<p>javascript 的数据类型分为两类：原始值类型和对象（Object类型）。</p>\n<p>对于原始值类型（undefined、null、true&#x2F;false、number、string），值就保存在变量指向的那个内存地址（在栈中），因此 const 声明的原始值类型变量等同于常量。</p>\n<p>对于对象类型（object，array，function等），变量指向的内存地址其实是保存了一个指向实际数据的指针，所以 const 只能保证指针是不可修改的，至于指针指向的数据结构是无法保证其不能被修改的（在堆中）。</p>\n<p>示例代码：</p>\n<pre><code class=\"language-javascript\">const obj = &#123;  value: 1&#125;\nobj.value = 2;\nconsole.log(obj) // &#123; value: 2 &#125;obj = &#123;&#125;\n</code></pre>\n<p>参考资料：</p>\n<blockquote>\n<p><a href=\"https://zhuanlan.zhihu.com/p/556482226?utm_id=0\">深入理解 JS：var、let、const 的异同</a></p>\n</blockquote>\n"},{"title":"聊聊Java IO的那些事","date":"2024-11-30T16:00:00.000Z","id":"761386768996841","_content":"\n|      | BIO  |     NIO     |  AIO  |\n| :--: | :--: | :---------: | :---: |\n| IO模型 | 同步阻塞 | 同步非阻塞（多路复用） | 异步非阻塞 |\n| 编程难度 |  简单  |     复杂      |  复杂   |\n| 可靠性  |  差   |      好      |   好   |\n| 吞吐量  |  低   |      高      |   高   |\n# 阅前须知\n\n`阻塞 IO` 和 `非阻塞 IO`\n\n这两个概念是 `程序级别` 的。主要描述是程序请求操作系统 IO 操作之后，如果 IO 资源没有准备好，那么程序如何处理问题：前者等待，后者继续执行（并且使用线程一直轮询，直到有 IO 资源准备好）\n\n`同步 IO ` 和 `非同步IO`\n\n这两个概念是`操作系统级别`的。主要描述的是操作系统在收到程序请求 IO 操作后，如果 IO 资源没有准备好，该如何相应程序的问题：前者不响应，后者返回一个标记，当 IO 资源准备好之后，在用事件机制返回给程序。\n\n# 一、BIO（Blocking I/O）\n\n## 基本概念\n\nJava BIO：同步并阻塞（传统阻塞性），应用程序中进程在发起 IO 调用后至内核执行 IO 操作返回结果之前，若发起系统调用的线程一直处于等待状态，则此次 IO 操作为阻塞 IO。阻塞 IO 简称 BIO，Blocking IO。\n\n以前大多数网络通信方式都是阻塞模式，即：\n- 客户端向服务器端发送请求后，客户端会一直等待（不会再做其他事情），直到服务器端返回结果或者网络出现问题。\n- 服务端同样的，当在处理某个客户端 A 发来的请求是，另一个客户端 B 发来的请求会等待，直到服务器端的这个处理线程完成上个处理。\n\n ![BIO请求流程图](img/acea8af4268c8d552741ccebcb2d34ec_MD5.png )\n\n## 使用实例\n\n1. 服务器启动一个 ServerSocket。\n2. 客户端启动 Socket 对服务器进行通信，默认情况下服务器端需要对每个客户建立一个线程与之通讯。\n2. 客户端发出请求后，先咨询服务器是否有线程响应，如果没有则会等待，或者被拒绝。\n3. 如果有响应，客户端线程会等待请求结束后，再继续执行。\n\n```java\npackage com.atguigu.bio;\n\nimport java.io.InputStream;\nimport java.net.ServerSocket;\nimport java.net.Socket;\nimport java.util.concurrent.ExecutorService;\nimport java.util.concurrent.Executors;\n\npublic class BIOServer {\n    \n    public static void main(String[] args) throws Exception {\n        //线程池机制\n        //思路\n        //1. 创建一个线程池\n        //2. 如果有客户端连接，就创建一个线程，与之通讯(单独写一个方法)\n        ExecutorService newCachedThreadPool = Executors.newCachedThreadPool();\n        //创建ServerSocket\n        ServerSocket serverSocket = new ServerSocket(6666);\n        System.out.println(\"服务器启动了\");\n        while (true) {\n            System.out.println(\"线程信息id = \" + Thread.currentThread().getId() + \"名字 = \" + Thread.currentThread().getName());\n            //监听，等待客户端连接\n            System.out.println(\"等待连接....\");\n            //会阻塞在accept()\n            final Socket socket = serverSocket.accept();\n            System.out.println(\"连接到一个客户端\");\n            //就创建一个线程，与之通讯(单独写一个方法)\n            newCachedThreadPool.execute(new Runnable() {\n                public void run() {//我们重写\n                    //可以和客户端通讯\n                    handler(socket);\n                }\n            });\n        } \n    }\n    \n    //编写一个handler方法，和客户端通讯\n    public static void handler(Socket socket) {\n        try {\n            System.out.println(\"线程信息id = \" + Thread.currentThread().getId() + \"名字 = \" + Thread.currentThread().getName());\n            byte[] bytes = new byte[1024];\n            //通过socket获取输入流\n            InputStream inputStream = socket.getInputStream();\n            //循环的读取客户端发送的数据\n            while (true) {\n                System.out.println(\"线程信息id = \" + Thread.currentThread().getId() + \"名字 = \" + Thread.currentThread().getName());\n                System.out.println(\"read....\");\n                int read = inputStream.read(bytes);\n                if (read != -1) {\n                    System.out.println(new String(bytes, 0, read));//输出客户端发送的数据\n                } else {\n                    break;\n                }\n            }\n        } catch (Exception e) {\n            e.printStackTrace();\n        } finally {\n            System.out.println(\"关闭和client的连接\");\n            try {\n                socket.close();\n            } catch (Exception e) {\n                e.printStackTrace();\n            }\n        }\n    }\n}\n```\n\n## 问题分析\n\n传统的 IO 模型，其主要是一个 Server 对接 N 个客户端，在客户端连接之后，为每个客户端分配一个子线程。如图所示：\n\n ![传统IO模型](img/0fb77c535fcbf8f4264b6eff292fd210_MD5.png)\n\n从图中可以看出，传统 IO 的特点在于：\n\n- 每个客户端连接到达时，服务端会分配一个线程给该客户端，该线程处理包括读取数据，解码，业务计算，编码，以及发送数据整个过程\n- 同一时刻，服务端的吞吐量与服务器所提供的线程数量呈线性关系的。\n\n如果并发量不大，运行没有问题，但是如果海量并发时候，就会出现问题：\n\n1. 每次请求都要创建独立的线程，与对应的客户端进行数据的Read，业务处理，数据Write、\n2. 当并发数较大时，需要创建大量线程处理连接，资源占用较大。\n3. 连接建立后，如果当前线程展示没有数据可读，则线程就阻塞在Read操作上，造成线程资源浪费。\n\n## 改进：多线程方式 - 伪异步方式\n\n上述说的情况只是服务器只有一个线程的情况，那么如果引入多线程是不是可以解决这个问题：\n\n- 当服务器收到客户端 X 的请求后，（读取到所有的请求数据后）将这个请求送入到一个独立线程进行处理，然后主线程继续接收客户端 Y 的请求。\n- 客户端侧，也可以用一个子线程和服务器端进行通信。这样客户端主线程的其他工作不受影响，当服务器有响应信息时候再有这个子线程通过 `监听模式/观察模式`（等其他设计模式）通知主线程。\n\n ![多线程方式 - 伪异步](img/ed84ace61748c9dbdaf3f9718f21ff21_MD5.png )\n\n但是多线程解决这个问题有局限性：\n\n- 操作系统通知accept() 的方式还是单个，即：服务器收到数据报文之后的“业务处理过程”可以多线程，但是报文的接收还是需要一个个来\n- 在操作系统中，线程是有限的。线程越多，CPU 切换所需时间也越长，用来处理真正业务的需求也就越少。\n- 创建线程需要较大的资源消耗。JVM 创建一个线程，即使不进行任何工作，也需要分配一个堆栈空间（128k）。\n- 如果程序中使用了大量的长连接，线程是不会关闭的，资源消耗更容易失控。\n\n> 为啥 `serverSocket. accept()` 会出现阻塞？\n\n是因为 Java 通过 JNI 调用的系统层面的 `accept0()` 方法，`accept0()` 规定如果发现套间字从指定的端口来，就会等待。其实就是内部实现是操作系统级别的同步 IO。\n\n# 二、NIO（non-Blocking I/O）\n\n了解 NIO 之前我们先来看看标准 I/O（Standard I/O）。\n\nStandard I/O 是对字节的读写，在进行 I/O 之前，首先创建一个流对象，流对象的读写操作都是按字节，一个字节一个字节的读或者写。而 NIO 把 I/O 抽象成块，类似磁盘的读写，每次 I/O 操作的单位都是一个块，块被读入内存之后就是一个 ` byte[]`，NIO 一次可以读或者写多个字节。\n\n## 流和块\n\nIO 和 NIO 最重要的区别就是对数据的打包和传输的方式，IO 是以流的方式处理数据，而 NIO 以块的方式处理数据。\n\n面向流的 IO 一次性处理一个字节数据：一个输入流产生一个字节数据，一个输出流消费一个字节数据。为流式数据创建过滤器非常容易，链接几个过滤器，以便每个过滤器只负责复杂处理机制的一部分。不利的一面是，面向流的 IO 通常处理非常慢。\n\n面向块的 I/O 一次性处理一个数据块：按块处理数据比按流处理数据要快的多，但是面向块的 I/O 确实一些面向流的 I/O 所具有的优雅和简单。\n\nI/O 包和 NIO 已经很好的集成了，`java.io.*` 中已经以 NIO 重新实现了，可以利用一些 NIO 的特性。例如：在 `java.io.*` 中某些类包含以块的形式读写数据的操作，这使得及时在面向流的系统中，处理数据也会更快。\n\n## 基本概念\n\nJava NIO：同步非阻塞，服务器实现模式为一个线程处理多个请求（连接），即客户端发送的连接请求都会注册到多路复用器上，多路复用器轮训到连接有 I/O 请求就进行处理。\n\n**核心概念：**\n\n1. **三大核心：** Channel（通道）、Buffer（缓冲区）、Selector（选择器）。\n2. **面向缓冲区，或者是面向块编程。** 数据读取到一个它稍后处理的缓冲区，需要时可在缓冲区中前后移动，这就增加了处理过程中的灵活性，使用它可以提供非阻塞式的高伸缩弹性网络。\n3. **非阻塞模式**， 使一个线程从某个通道发送请求或者读取数据，但是他仅能得到目前可用的数据，如果目前没有数据可用，就什么都不会获取，而不是保持线程阻塞。所以知道数据变得可读取之前，该线程还可以去做其他实行。\n4. **Channel 和 Buffer 一一对应。**\n5. **一个线程只有一个 Selector，一个线程对应对个 Channel（连接）**。\n6. 程序切换到哪个 Channel 是由事件决定，Event 就是个重要概念。\n7. Selector 会根据不同的事件，在各个通道上切换。\n8. **Buffer 是一个内存块，底层就是一个数组**。\n9. 数据读写都是通过 Buffer，区别于 BIO 的输入输出流，且**双向**，需要 `flip` 方法切换 `Channel` 是双向的 。\n\n## 编程原理\n\n1. 当客户端连接时，会通过 ServerSocketChannel 得到 SocketChannel。\n2. Selector 进行监听 select 方法，返回有事件发生的通道个数。\n3. 将 SocketChannel 注册到 Selector 上（`register(Selector selector, int ops)`），一个 Selector 可以注册多个 SocketChannel。\n4. 注册后返回 SelectionKey，会和该 Selector 关联（集合）。\n5. 当有事件发生时，进一步得到各个 SelectionKey。\n6. 通过channel () 方法，用 SelectionKey 反向获取 SocketChannel。\n7. 可以通过得到的 channel，完成业务处理。\n\n## 1. 缓冲区（Buffer）\n\n### Buffer 类及其子类\n\n`ByteBuffer` 字节数据；`ShortBuffer` 字符串数据；`CharBuffer` 字符数据；`IntBuffer` 整数；`LongBuffer` 长整数；`DoubleBuffer` 小数；`FloatBuffer` 小数\n\n### Buffer 属性和方法\n\nBuffer 类提供了 4 个属性来提供数据元素信息：`capacity（容量）`：缓存区的最大容量，`Limit（终点）`：缓存区最大可操作位置，`Position（位置）` ：缓存区当前在操作的位置，`Mark（标记）`：标记位置\n\n```java\npublic abstract class Buffer{\n\tpublic final int capacity();\n\tpublic final int position();\n\tpublic final Buffer position(int newPosition);\n\tpublic final int limit();\n\tpublic final Buffer limit(int newLimit);\n\t\n}\n//其中比较常用的就是ByteBuffer（二进制数据），该类主要有以下方法\npublic abstract class ByteBuffer(){\n\tpublic static ByteBuffer allocateDirect(int capacity);//直接创建缓冲区\n\tpublic static ByteBuffer allocate(int capacity);//设置缓冲区的初始容量\n\tpublic static ByteBuffer wrap(byte[] array);//把一个数组放入到缓冲区使用\n\t//构造初始化位置offset和上界length的缓冲区\n\tpublic static ByteBuffer wrap(byte[] array,int offset,int length);\n\t//缓冲区读取相关API\n\tpublic abstract byte get();//从当前位置position上get，get之后，positon会+1\n\tpublic abstract byte get(int index);//从绝对位置获取\n\tpublic abstract ByteBuffer put(byte b);//当前位置上put，put之后，position会+1\n\tpublic abstract ByteBuffer put(int index,byte b);//从绝对位置put\t\n}\n```\n\n状态变量的改变过程举例:\n\n① 新建一个大小为 8 个字节的缓冲区，此时 position 为 0，而 limit = capacity = 8。capacity 变量不会改变，下面的讨论会忽略它。\n\n ![状态变量的改变过程1](img/a8f0d4502adb087892e11866bdac7d57_MD5.png )\n\n② 从输入通道中读取 5 个字节数据写入缓冲区中，此时 position 移动设置为 5，limit 保持不变。\n\n ![状态变量的改变过程2](img/5ee1af7a6012fd34b62704d5b2867320_MD5.png )\n\n③ 在将缓冲区的数据写到输出通道之前，需要先调用 flip() 方法，这个方法将 limit 设置为当前 position，并将 position 设置为 0。\n\n ![状态变量的改变过程3](img/5cd2995739f1b0e1f4b355a2471c38aa_MD5.png )\n\n④ 从缓冲区中取 4 个字节到输出缓冲中，此时 position 设为 4。\n\n ![状态变量的改变过程4](img/0d87f8ba4e770fbdcd6c6fc61fb84862_MD5.png )\n\n⑤ 最后需要调用 clear() 方法来清空缓冲区，此时 position 和 limit 都被设置为最初位置。\n\n ![状态变量的改变过程5](img/f6ef08bdd8b4ff67a419bfe9b7dbc0f2_MD5.png )\n\n### 文件 NIO 实例\n\n以下展示了使用 NIO 快速复制文件的实例：\n\n```java\npublic static void fastCopy(String src, String dist) throws IOException {\n\n    /* 获得源文件的输入字节流 */\n    FileInputStream fin = new FileInputStream(src);\n\n    /* 获取输入字节流的文件通道 */\n    FileChannel fcin = fin.getChannel();\n\n    /* 获取目标文件的输出字节流 */\n    FileOutputStream fout = new FileOutputStream(dist);\n\n    /* 获取输出字节流的通道 */\n    FileChannel fcout = fout.getChannel();\n\n    /* 为缓冲区分配 1024 个字节 */\n    ByteBuffer buffer = ByteBuffer.allocateDirect(1024);\n\n    while (true) {\n\n        /* 从输入通道中读取数据到缓冲区中 */\n        int r = fcin.read(buffer);\n\n        /* read() 返回 -1 表示 EOF */\n        if (r == -1) {\n            break;\n        }\n\n        /* 切换读写 */\n        buffer.flip();\n\n        /* 把缓冲区的内容写入输出文件中 */\n        fcout.write(buffer);\n        \n        /* 清空缓冲区 */\n        buffer.clear();\n    }\n}\n```\n\n\n## 2. 通道（Channel）\n\n通道类似流，但是有如下区别：\n\n- 通道可以同时读写，而流只能读或写\n- 通道可以实现异步读写数据\n- 通道可以从缓冲区读数据，也可以写数据到缓冲区\n\n### 通道分类\n\nChannel 在 NIO 中是一个接口 `public interface Channle extends Closeable{}`。其中，常用的 Channel 类有：\n\n1. `FileChannel`：用于文件的数据读写；\n2. `DatagramChannel`：用于 UDP 的数据读写；\n3. `ServerSocketChannel`：可以监听新来的连接，对每一个新进来的连接都会创建一个 SocketChannel。只有通过这个通道，应用程序才能箱操作系统注册支持“多路复用 IO”的端口减轻。支持 TCP 和 UDP 协议；\n4. `SocketChannel`：TCP Socket 套接字的监听通道，用于 TCP 的数据读写\n5. 其他的通道包括：\n\n ![其他通道](img/94530647a3be7da4d2de055fff8bacaf_MD5.png )\n### FileChannel 类\n\n对本地文件进行 IO 操作，常用方法及实例应用：\n\n```java\n//从通道读取数据并放到缓冲区内\npublic int read(ByteBuffer content);\n//从缓冲区写数据到通道中\npublic int write(ByteBuffer content);\n//从目标通道中复制数据到当前通道内\npublic long transferFrom(ReadableByteChannel src,long position,long count);\n//把数据从当前通道复制到目标通道\npublic long transferTo(long position,long count,WritabelByteChannel target);\n\n```\n\n1 . 写入文件，使用之前 `ByteBuffer` 和 `FileChannel` 类\n\n``` java\n//使用之前ByteBuffer和FileChannel类，写入文件\nimport java.io.FileOutputStream;\nimport java.nio.ByteBuffer;\nimport java.nio.channels.FileChannel;\n\npublic class NIOFileChannel{\n\tpublic static void main(String[] args) throws Exception{\n\t\tString str = \"hello,world\";\n\t\t//创一个输出流 -> channel\n\t\tFileOutputStream stream = new FileOutputStream(\"d:\\\\file.txt\");\n\t\t//通过 stream 获取对应的 FileChannel\n\t\t//这个 fileChannel 真实类型是 FileChannelImpl\n\t\tFileChannel fileChannel = stream.getChannel();\n\n\t\t//创建一个缓冲区 ByteBuffer\n\t\tByteBuffer byteBuffer = ByteBuffer.allocate(1024);\n\t\t//将 str 放入到缓冲区\n\t\tbyteBuffer.put(str.getBytes());\n\t\t//对 byteBuffer 进行 flip\n\t\tbyteBuffer.flip();\n\n\t\t//将 byteBuffer 写入到 fileChannel\n\t\tfileChannel.write(byteBuffer);\n\t\tfileOutputStream.close();\n\t}\n\n}\n```\n\n2 . 读取文件数据并展示，使用之前 `ByteBuffer` 和 `FileChannel` 类\n\n```java\n//读取本地文件\nimport java.io.FileOutputStream;\nimport java.nio.ByteBuffer;\nimport java.nio.channels.FileChannel;\n\npublic class NIOFileChannel{\n\tpublic static void main(String[] args) throws Exception{\n\t\t//创一个输出流 -> channel\n\t\tFile file = new File(\"d:\\\\file.txt\");\n\t\tFileOutputStream stream = new FileOutputStream(file);\n\t\t//通过 stream 获取对应的 FileChannel\n\t\t//这个 fileChannel 真实类型是 FileChannelImpl\n\t\tFileChannel fileChannel = stream.getChannel();\n\n\t\t//创建一个缓冲区 ByteBuffer\n\t\tByteBuffer byteBuffer = ByteBuffer.allocate((int)file.length());\n\n\t\t//将 byteBuffer 写入到 fileChannel\n\t\tfileChannel.read(byteBuffer);\n\t\t//将 byteBuffer的字节转化成String\n\t\tSystem.out.println(new String(byteBuffer.array()));\n\t\tfileOutputStream.close();\n\t}\n\n}\n\n```\n\n\n3 . 使用一个 `Buffer` 完成文件的读取、写入\n\n```java\nimport java.io.FileInputStream;\nimport java.io.FileOutputStream;\nimport java.nio.ByteBuffer;\nimport java.nio.channels.FileChannel;\n\npublic class NIOFileChannel03 {\n\n    public static void main(String[] args) throws Exception {\n\n        FileInputStream fileInputStream = new FileInputStream(\"1.txt\");\n        FileChannel fileChannel01 = fileInputStream.getChannel();\n        FileOutputStream fileOutputStream = new FileOutputStream(\"2.txt\");\n        FileChannel fileChannel02 = fileOutputStream.getChannel();\n\n        ByteBuffer byteBuffer = ByteBuffer.allocate(512);\n        \n        while (true) { //循环读取\n\n            //这里有一个重要的操作，一定不要忘了\n            /*\n            public final Buffer clear() {\n                position = 0;\n                limit = capacity;\n                mark = -1;\n                return this;\n            }\n            */\n            byteBuffer.clear(); //清空 buffer\n            int read = fileChannel01.read(byteBuffer);\n            System.out.println(\"read = \" + read);\n            if (read == -1) { //表示读完\n                break;\n            }\n\n            //将 buffer 中的数据写入到 fileChannel02--2.txt\n            byteBuffer.flip();\n            fileChannel02.write(byteBuffer);\n        }\n\n        //关闭相关的流\n        fileInputStream.close();\n        fileOutputStream.close();\n    }\n}\n```\n\n4 . 拷贝文件transferFrom 方法\n\n```java\nimport java.io.FileInputStream;\nimport java.io.FileOutputStream;\nimport java.nio.channels.FileChannel;\n\npublic class NIOFileChannel04 {\n\n    public static void main(String[] args) throws Exception {\n\n        //创建相关流\n        FileInputStream fileInputStream = new FileInputStream(\"d:\\\\a.jpg\");\n        FileOutputStream fileOutputStream = new FileOutputStream(\"d:\\\\a2.jpg\");\n        \n        //获取各个流对应的 FileChannel\n        FileChannel sourceCh = fileInputStream.getChannel();\n        FileChannel destCh = fileOutputStream.getChannel();\n\n        //使用 transferForm 完成拷贝\n        destCh.transferFrom(sourceCh, 0, sourceCh.size());\n\n        //关闭相关通道和流\n        sourceCh.close();\n        destCh.close();\n        fileInputStream.close();\n        fileOutputStream.close();\n    }\n}\n```\n\n###  Buffer 和 Channel 注意事项\n\n**1. ByteBuffer 支持类型化的 put 和 get，put 放什么，get 取出什么，不然出现 BufferUnderflowException 异常**\n\n```java\nimport java.nio.ByteBuffer;\n\npublic class NIOByteBufferPutGet {\n\n    public static void main(String[] args) {\n        \n        //创建一个 Buffer\n        ByteBuffer buffer = ByteBuffer.allocate(64);\n\n        //类型化方式放入数据\n        buffer.putInt(100);\n        buffer.putLong(9);\n        buffer.putChar('尚');\n        buffer.putShort((short) 4);\n\n        //取出\n        buffer.flip();\n        \n        System.out.println();\n        \n        System.out.println(buffer.getInt());\n        System.out.println(buffer.getLong());\n        System.out.println(buffer.getChar());\n        System.out.println(buffer.getShort());\n    }\n}\n```\n\n**2. 普通 Buffer 转成只读 Buffer**\n\n```java\n\nimport java.nio.ByteBuffer;\n\npublic class ReadOnlyBuffer {\n\n    public static void main(String[] args) {\n\n        //创建一个 buffer\n        ByteBuffer buffer = ByteBuffer.allocate(64);\n\n        for (int i = 0; i < 64; i++) {\n            buffer.put((byte) i);\n        }\n\n        //读取\n        buffer.flip();\n\n        //得到一个只读的 Buffer\n        ByteBuffer readOnlyBuffer = buffer.asReadOnlyBuffer();\n        System.out.println(readOnlyBuffer.getClass());\n\n        //读取\n        while (readOnlyBuffer.hasRemaining()) {\n            System.out.println(readOnlyBuffer.get());\n        }\n\n        readOnlyBuffer.put((byte) 100); //ReadOnlyBufferException\n    }\n}\n```\n\n**3. NIO 中 MappedByteBuffer，可以让文件直接在堆外内存修改**\n\n```java\n\nimport java.io.RandomAccessFile;\nimport java.nio.MappedByteBuffer;\nimport java.nio.channels.FileChannel;\n\n/**\n * 说明 1.MappedByteBuffer 可让文件直接在内存（堆外内存）修改,操作系统不需要拷贝一次\n */\npublic class MappedByteBufferTest {\n\n    public static void main(String[] args) throws Exception {\n\n        RandomAccessFile randomAccessFile = new RandomAccessFile(\"1.txt\", \"rw\");\n        //获取对应的通道\n        FileChannel channel = randomAccessFile.getChannel();\n\n        /**\n         * 参数 1:FileChannel.MapMode.READ_WRITE 使用的读写模式\n         * 参数 2：0：可以直接修改的起始位置\n         * 参数 3:5: 是映射到内存的大小（不是索引位置），即将 1.txt 的多少个字节映射到内存\n         * 可以直接修改的范围就是 0-5\n         * 实际类型 DirectByteBuffer\n         */\n        MappedByteBuffer mappedByteBuffer = channel.map(FileChannel.MapMode.READ_WRITE, 0, 5);\n\n        mappedByteBuffer.put(0, (byte) 'H');\n        mappedByteBuffer.put(3, (byte) '9');\n        mappedByteBuffer.put(5, (byte) 'Y');//IndexOutOfBoundsException\n\n        randomAccessFile.close();\n        System.out.println(\"修改成功~~\");\n    }\n}\n```\n\n4. **NIO 还支持通过多个 Buffer（即 Buffer数组）完成读写操作，即 Scattering 和 Gathering**\n\n```java\nimport java.net.InetSocketAddress;\nimport java.nio.ByteBuffer;\nimport java.nio.channels.ServerSocketChannel;\nimport java.nio.channels.SocketChannel;\nimport java.util.Arrays;\n\n/**\n * Scattering：将数据写入到 buffer 时，可以采用 buffer 数组，依次写入 [分散]\n * Gathering：从 buffer 读取数据时，可以采用 buffer 数组，依次读\n */\npublic class ScatteringAndGatheringTest {\n\n    public static void main(String[] args) throws Exception {\n        \n        //使用 ServerSocketChannel 和 SocketChannel 网络\n        ServerSocketChannel serverSocketChannel = ServerSocketChannel.open();\n        InetSocketAddress inetSocketAddress = new InetSocketAddress(7000);\n\n        //绑定端口到 socket，并启动\n        serverSocketChannel.socket().bind(inetSocketAddress);\n\n        //创建 buffer 数组\n        ByteBuffer[] byteBuffers = new ByteBuffer[2];\n        byteBuffers[0] = ByteBuffer.allocate(5);\n        byteBuffers[1] = ByteBuffer.allocate(3);\n\n        //等客户端连接 (telnet)\n        SocketChannel socketChannel = serverSocketChannel.accept();\n\n        int messageLength = 8; //假定从客户端接收 8 个字节\n\n        //循环的读取\n        while (true) {\n            int byteRead = 0;\n\n            while (byteRead < messageLength) {\n                long l = socketChannel.read(byteBuffers);\n                byteRead += l; //累计读取的字节数\n                System.out.println(\"byteRead = \" + byteRead);\n                //使用流打印,看看当前的这个 buffer 的 position 和 limit\n                Arrays.asList(byteBuffers).stream().map(buffer -> \"position = \" + buffer.position() + \", limit = \" + buffer.limit()).forEach(System.out::println);\n            }\n\n            //将所有的 buffer 进行 flip\n            Arrays.asList(byteBuffers).forEach(buffer -> buffer.flip());\n            //将数据读出显示到客户端\n            long byteWirte = 0;\n            while (byteWirte < messageLength) {\n                long l = socketChannel.write(byteBuffers);//\n                byteWirte += l;\n            }\n            \n            //将所有的buffer进行clear\n            Arrays.asList(byteBuffers).forEach(buffer -> {\n                buffer.clear();\n            });\n            \n            System.out.println(\"byteRead = \" + byteRead + \", byteWrite = \" + byteWirte + \", messagelength = \" + messageLength);\n        }\n    }\n}\n```\n\n## 3. Selector（选择器）\n\n### 基本概念\n\nNIO 常常被叫做非阻塞 IO，主要是因为 NIO 在网络通信中的非阻塞特性被广泛使用。NIO 实现了 IO 多路复用中的 Reator 模型，一个线程 Thread 使用一个选择器 Selector 通过轮询的方式去监听多个 Channel 上的事件，从而让一个线程能够处理多个事件。\n\n通过配置监听的通道 Channel 为非阻塞，那么当 Channel 上的 IO 事件还未到达时，就不会进入到阻塞状态一直等待，而是鸡血轮询其他 Channel，找到 IO 事件已经到达的 Channel 执行。\n\n以为创建和切换线程的开销很大，因此使用一个线程处理多个事件显然比一个线程处理一个事件具有更好的性能。\n\n ![选择器](img/0b37a3b751ec9aa08efa75ace30e23c4_MD5.png )\n\n1. Java 中的 NIO 可以用一个线程，处理多个客户端连接，就会使用到 Selector（选择器）\n2. 多个 Channel 以事件的方式注册到 Selector\n3. 只有在连接通道有真正的读写事件的时候，才会进行读写，减少系统开销\n4. 避免了`多线程之间的上下文切换导致的开销`\n\n```java\n//Selector 类是一个抽象类，常用方法和说明如下：\npublic abstract class Selector implements Closeable{\n\tpublic static Selector open();//监控所有注册的通道，当其中有IO操作可以进行时，将SelectionKey加入到内部的集合中并返回，参数用来设置超时时间\n\tpublic Set<SelectionKey> selectedKey();//从内部集合中得到所有的SelectionKey\t\n}\n ```\n\n### 使用方法\n\n1. **创建选择器**\n\n```java\nSelector selector = Selector.open();\n```\n\n2. **将通道注册到选择器上**\n\n```java\nServerSocketChannel ssChannel = ServerSocketChannel.open();\nssChannel.configureBlocking(false);\nssChannel.register(selector,SelectionKey.OP_ACCEPT);\n```\n\n将通道注册到选择器上，还需要指定要注册的具体事件，主要有以下几类：\n\n`SelectionKey. OP_CONNECT`、`SelectionKey. OP_ACCEPT`、`SelectionKey. OP_READ`、 `SelectionKey. OP_WRITE`\n\n他们在 SelectionKey 的定义如下：\n\n```java\npublic static final int OP_READ = 1 << 0;\npublic static final int OP_WRITE = 1 << 2;\npublic static final int OP_CONNECT = 1 << 3;\npublic static final int OP_ACCEPT = 1 << 4;\n```\n\n可以看出每个事件都能当成一个位域，从而组成事件集整数。例如：\n\n```java\nint intersetSet = SelectionKey.OP_READ | SelectionKey.OP_WRITE;\n```\n\n3. **监听事件**\n\n```java\nint num = selector.select();\n```\n\n使用 `select()` 方法来监听到达的事件，它会一直阻塞知道有至少一件事件到达。\n\n4. **获取到达的事件**\n\n```java\nSet<SelectionKey> keys = selector.selectedKeys();\nIterator<SelectionKey> keyIterator = keys.iterator();\nwhile(keyIterator.hasNext()){\n\tSelectionKey keyu = keyIterator.next();\n\tif(key.isAcceptabnle()){\n\t// ...\n\t}else if(key.isReadable()){\n\t// ...\n\t}\n\tkeyIterator.remove();\n}\n```\n\n5. **时间循环**\n\n因为一次 select() 调动不能处理完所有的事件，并且服务器端有可能需要一直监听事件，因此服务器端处理时间的代码一般会放在一个死循环内。\n\n```java\nwhile (true) { \n\tint num = selector.select(); \n\tSet<SelectionKey> keys = selector.selectedKeys(); \n\tIterator<SelectionKey> keyIterator = keys.iterator(); \n\twhile (keyIterator.hasNext()) { \n\t\tSelectionKey key = keyIterator.next(); \n\t\tif (key.isAcceptable()) { \n\t\t  // ... \n\t\t} else if (key.isReadable()) {\n\t\t  // ... \n\t\t} \n\t\tkeyIterator.remove(); \n\t}\n}\n```\n\n### 套接字 NIO 实例\n\n```java\npublic class NIOServer {\n \tpublic static void main(String[] args) throws IOException {\n\t\tSelector selector = Selector.open();\n\t\tServerSocketChannel ssChannel = ServerSocketChannel.open();\n\t\tssChannel.configureBlocking(false);\n\t\tssChannel.register(selector, SelectionKey.OP_ACCEPT);\n\t\tServerSocket serverSocket = ssChannel.socket();\n\t\tInetSocketAddress address = new InetSocketAddress(\"127.0.0.1\", 8888);\n\t\tserverSocket.bind(address);\n\t\twhile(true){\n\t\t\tselector.select();\n\t\t\tSet<SelectionKey> keys = selector.selectedKeys();\n\t\t\tIterator<SelectionKey> keyIterator = keys.iterator();\n\t\t\twhile (keyIterator.hasNext()){\n\t\t\t\tSelectionKey key = keyIterator.next();\n\t\t\t\tif (key.isAcceptable()) {\n\t\t\t\t\tServerSocketChannel ssChannel1 = (ServerSocketChannel) key.channel();// 服务器会为每个新连接创建一个 SocketChannel SocketChannel sChannel = ssChannel1.accept();\n\t\t\t\t\tsChannel.configureBlocking(false);// 这个新连接主要用于从客户端读取数据 \n\t\t\t\t\tsChannel.register(selector, SelectionKey.OP_READ);\n\t\t\t\t}else if (key.isReadable()) {\n\t\t\t\t\tSocketChannel sChannel = (SocketChannel) key.channel();\n\t\t\t\t\tSystem.out.println(readDataFromSocketChannel(sChannel));\n\t\t\t\t\tsChannel.close();\n\t\t\t\t}\n \t\t\tkeyIterator.remove();\n\t\t\t}\n\t\t}\n \t}\n\tprivate static String readDataFromSocketChannel(SocketChannel sChannel) throws IOException {\n\t\tByteBuffer buffer = ByteBuffer.allocate(1024);\n\t\tStringBuilder data = new StringBuilder();\n\t\twhile(true) {\n\t\t\tbuffer.clear();\n\t\t\tint n = sChannel.read(buffer);\n\t\t\tif (n == -1) {\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tbuffer.flip();\n\t\t\tint limit = buffer.limit();\n\t\t\tchar[] dst = new char[limit];\n\t\t\tfor (int i = 0;i < limit;i++) {\n\t\t\t\tdst[i] = (char) buffer.get(i);\n\t\t\t}\n\t\t\tdata.append(dst);\n\t\t\tbuffer.clear();\n \t\t}\n \t\treturn data.toString();\n \t}\n }\n```\n```java\npublic class NIOClient {\n\tpublic static void main(String[] args) throws IOException{\n\t\tSocket socket = new Socket(\"127.0.0.1\"，8888);\n\t\tOutputStream out = socket.getOutputStream();\n\t\tString s = \"hello world\";\n\t\tout.write(s.getBytes());\n\t\tout.close();\n\t}\n}\n```\n## 典型的多路复用 IO 实现\n\n目前流程的多路复用 IO 实现主要宝库了四种：select、poll、epoll、kqueue。以下是其特性及区别：\n\n| IO 模型  | 相对性能 |       关键思路       |   操作系统    |                                             Java 支持情况                                              |\n| :----: | :--: | :--------------: | :-------: | :------------------------------------------------------------------------------------------------: |\n| select |  较高  |     Reactor      | Win/Linux | 支持，Reactor 模式（反应器设计模式）。Linux kernels 2.4 内核版本之前，默认用的是 select ；目前 windows 下对吧同步 IO 的支持，都是 select 模型 |\n|  poll  |  较高  |     Reactor      |   Linux   |            Linux 下的 Java 的 NIO 框架，Linux kernels 2.6 内核版本之前使用 poll 进行支持。也是使用的 Reactor 模式            |\n| epoll  |  高   | Reactor/Proactor |   Linux   |                               Linux kernels 2.6 内核版本之后使用 epoll 进行支持                                |\n| kqueue |  高   |     Proactor     |   Linux   |                                           目前 Java 版本不支持                                            |\n\n### 1. Reactor事件驱动模型\n\n ![Reactor事件驱动模型](img/10d0080498aba2649f1c04067965b579_MD5.png )\n\n从图上可知：一个完整的 Reactor 事件驱动模型是有四个部分组成：客户端 Client，Reactor，Acceptor 和时间处理 Handler。其中 Acceptor 会不间断的接收客户端的连接请求，然后通过 Reactor 分发到不同 Handler 进行处理。改进后的 Reactor 有如下优点：\n\n- 虽然同是由一个线程接收连接请求进行网络读写，但是 Reactor 将客户端连接，网络读写，业务处理三大部分拆分，从而极大提高工作效率。\n- Reactor 是以事件驱动的，相比传统 IO 阻塞式的，不必等待，大大提升了效率。\n\n### 2. Reactor 模型——业务处理和 IO 分离\n\n在上面的处理模型中，由于网络读写是在同一个线程里面。在高并发情况下，会出现两个瓶颈：\n\n- 高频率的读写事件处理\n- 大量的业务处理\n\n基于上述瓶颈，可以将业务处理和 IO 读写分离出来：\n\n ![Reactor模型-业务处理和IO分离](img/37b1874d4aabb48cd6b511cba09fa70b_MD5.png )\n\n如图可以看出，相对基础 Reactor 模型，该模型有如下特点：\n\n- 使用一个线程进行客户端连接和网络读写\n- 客户端连接之后，将该连接交给线程池进行加解码以及业务处理\n\n这种模型在接收请求进行网络读写的同时，也在进行业务处理，大大提高了系统的吞吐量。但是也有不足的地方：\n- 网络读写是一个比较消耗 CPU 的操作，在高并发的情况下，将有大量的客户端需要网络读写，此时一个线程处理不了这么多的请求。\n\n### 3. Reactor——并发读写\n\n由于高并发的网络读写是系统一个瓶颈，所以针对这种情况，改进了模型，如图所示：\n\n ![Reactor-并发读写](img/870a39b7312d1d18324d3aefa613ab37_MD5.png )\n由图可以看出，在原有 Reactor 模型上，同时将 Reactor 拆分成 mainReactor 和 subReactor 。其中 mainReactor 主要负责客户端的请求连接，subReactor 通过一个线程池进行支撑，主要负责网络读写，因为线程池的原因，可以进行多线程并发读写，大大提升了网络读写的效率。业务处理也是通过线程池进行。通过这种方式，可以进行百万级别的连接。\n\n### 4. Reactor 模型示例\n\n对于上述的 Reactor 模型，主要有三个核心需要实现：Acceptor，Reactor 和 Handler。具体实现代码如下：\n\n```java\npublic class Reactor implements Runnable{\n\tprivate final Selector selector;\n\tprivate final ServerSocketChannel serverSocket;\n\n\tpublic Reactor(int port) throws IOException{\n\t\tserverSocket = ServerSocketChannel.open();//创建服务端的ServerSocketChannel\n\t\tserverSocket.configureBlocking(false);//设置为非阻塞模式\n\t\tselector = Selector.open();//创建一个selector选择器\n\t\tSelectionKey key = serverSocket.register(selector,SelectionKey.OP_ACCEPT);\n\t\tserverSocket.bind(new InetSocketAddress(port));//绑定服务端端口\n\t\tkey.attach(new Acceptor(serverSocket));//为服务端Channel绑定一个Acceptor\n\t}\n\t@Override\n\tpublic void run(){\n\t\ttry{\n\t\t\twhile(！Thread.interrupted()){\n\t\t\t\tselector.select();//服务端使用一个线程不停接收连接请求\n\t\t\t\tSet<SelectionKey> keys = selector.selectedKeys();\n\t\t\t\tIterator<SelectionKey> itetrator = keys.iterator();\n\t\t\t\twhile(iterator.hasNext()){\n\t\t\t\t\tdispatch(iterator.next());\n\t\t\t\t\titerator.remove();\n\t\t\t\t\t}\n\t\t\t\tselector.selectNow();\n\t\t\t\t}\n\t\t}catch(IOException e){\n\t\t\te.printStackTrace();\n\t\t}\n\t}\n\n\tprivate void dispatch(SelectionKey key) throws IOException{\n\t\t//这里的attachment也即前面的为服务端Channel绑定的Acceptor，调用其run()方法进行分发\n\t\tRunnable attachment = (Runable)key.attachment();\n\t\tattachment.run();\n\t}\n\n}\n\n```\n这里Reactor首先开启了一个ServerSocketChannel，然后将其绑定到指定的端口，并且注册到了一个多路复用器上。接着在一个线程中，其会在多路复用器上等待客户端连接。当有客户端连接到达后，Reactor就会将其派发给一个Acceptor，由该Acceptor专门进行客户端连接的获取。下面我们继续看一下Acceptor的代码：\n```java\npublic class Acceptor implements Runnable{\n\tprivate final ExecuteorService executor = Exxcutors.newFixedThreadPool(20);\n\n\tprivate final ServerSocketChannel serverSocket;\n\n\tpublic Acceptor(ServerSocketChannel serverSocket){\n\t\tthis.serverSocket = serverSocket;\n\t\t}\n\n\t@Override\n\tpublic void run(){\n\t\ttry{\n\t\t\tSocketChannel channel = serverSocket.accept();\n\t\t\tif(null != channel){\n\t\t\t\texecutor.execute(new Handler(channel));\n\t\t\t}\n\t\t}catch(IOException e){\n\t\t\te.printStackTrace();\n\t\t}\n\t}\n}\n```\n\n这里可以看到，在Acceptor获取到客户端连接之后，其就将其交由线程池进行网络读写了，而这里的主线程只是不断监听客户端连接事件。下面我们看看Handler的具体逻辑：\n\n```java\npublic class Handler implements Runnable{\n\tprivate volatile static Selector selector;\n\tprivate final SocketChannel channel;\n\tprivate SelectionKey key;\n\tprivate volatile ByteBuffer input = ByteBuffer.allocate(1024);\n\tprivate volatile ByteBuffer output = ByteBuffer.allocate(1024);\n\n\tpublic Handle(SocketChannel channel) throws IOException{\n\t\tthis.channel = channel;\n\t\tchannel.configureBlocking(false);//设置客户端连接为非阻塞模式\n\t\tselector = Selector.open();//为客户端创建一个选择器\n\t\tkey = channel.register(selector,SelectionKey.OP_READ);//注册客户端Channel的读事件\t\n\t}\n\n\t@Override\n\tpublic void run(){\n\t\ttry{\n\t\t\twhile(selector.isOpen() && channel.isOpen()){\n\t\t\t \tSet<SelectionKey> keys = select();//等待客户端事件发生\n\t\t\t \tIterator<SelectionKey> iterator = keys.iterator();\n\t\t\t\twhile(iterator.hasNext()){\n\t\t\t\t\tSelectionKey key = iterator.next();\n\t\t\t\t\titerator.remove();\n\n\t\t\t\t\t//如果当前是读事件，则读取数据\n\t\t\t\t\tif(key.isReadable()){\n\t\t\t\t\t\tread(key);\n\t\t\t\t\t}else if(key.isWritable()){\n\t\t\t\t\t\twrite(key)\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\t\n\t\t}catch(IOException e){\n\t\te.printStackTrace();\n\t\t}\n\t}\n\t//读取客户端发送的数据\n\n\tprivate void read(SelectionKey key) throws IOException{\n\t\tchannel.read(input);\n\t\tif(input.position() == 0){\n\t\t\treturn ;\n\t\t}\n\t\tinput.flip();\n\t\tprocess();//对读数据进行业务处理\n\t\tinput.clear();\n\t\tkey.interstOps(SelectionKey.OP_WRITE);//读取完成后监听写入事件\n\t}\n\tprivate void write(SelectionKey key) throws IOException{\n\t\toutput.flip();\n\t\tif(channel.isOpen()){\n\t\t\tchannel.write(output);//当有写入事件时，将业务处理的结果写入到客户端Channel中\n\t\t\tkey.channel();\n\t\t\tchannel.close();\n\t\t\toutput.clear();\n\t\t}\n\t}\n\t//进行业务处理，并且获取处理结果。本质上，基于Reactor模型，如果这里成为处理瓶颈，则将处理过程放入到线程池里面即可，并且使用一个Future获取处理结果，最后写入到客户端Channel中\n\tprivate void process(){\n\t\tbyte[] bytes = new byte[input.remaining()];\n\t\tinput.get(bytes);\n\t\tString message = new String(bytes,CharsetUtil.UTF_8);\n\t\tSystem.out.println(\"receive message from client: \\n\" +message);\n\t\toutput.put(\"hello client\".getBytes());\n\t}\n}\n```\n\n在 Handler 中，主要进行的就是每个客户端 Channel 创建一个 Selector，并且监听该 Channel 的网络读写事件。当有事件到达时，进行数据的读写，而业务操作交友具体的业务线程池处理。\n\n# 三、AIO（ Asynchronous I/O）\n\n1. JDK7 引入了 Asynchronous I/O，即 AIO。在进行 I/O 编程中，常用到两种模式：Reactor 和 Proactor。Java 的 NIO 就是 Reactor，当有事件触发时，服务器端得到通知，进行相应的处理\n2. AIO 即 NIO2.0，叫做异步不阻塞的 IO。AIO 引入异步通道的概念，采用了 Proactor 模式，简化了程序编写，有效的请求才启动线程，它的特点是先由操作系统完成后才通知服务端程序启动线程去处理，一般适用于连接数较多且连接时间较长的应用\n\n### 异步 IO\n\n之前主要介绍了阻塞式同步 IO，非阻塞式同步 IO，多路复用 IO 这三种 IO 模型。而异步 IO 是采用“订阅-通知”模式，即应用程序向操作系统注册 IO 监听，然后继续做自己的事情。当操作系统发生 IO 事件，并且准备好数据后，主动通知应用程序，触发相应的函数：\n\n ![异步IO](img/3a01157436842562f7f21f8b4c4549d4_MD5.png )\n\n和同步 IO 一样，异步 IO 也是由操作系统进行支持的。Windows 系统提供了一种异步 IO 技术：IOCP（I/O Completion Port，I/O 完成端口）；\nLinux 下由于没有这种异步 IO 技术，所以使用的是 epoll（上文介绍过的一种多路复用 IO 技术的实现）对异步 IO 进行模拟。\n\n### Java AIO 框架解析\n\n ![Java AIO](img/2ff37cd0e1f5f734f8d6209396a08897_MD5.png )\n\n以上结构主要是说明 JAVA AIO 中类设计和操作系统的相关性。\n\n> 上述所有代码仓库地址：https://github.com/z1gui/netty_io\n\n参考资料：\n\n> [BIO、NIO、AIO区别详解](https://zhuanlan.zhihu.com/p/520809188?utm_id=0)\n>\n> [♥Java IO知识体系详解♥](https://pdai.tech/md/java/io/java-io-overview.html)\n\n\n","source":"_posts/md/聊聊JavaIO的那些事.md","raw":"---\ntitle: 聊聊Java IO的那些事\ntag: \n- java\n- IO\n- NIO\n- BIO\ncategory: \n- 后端\ndate: 2024-12-01\nid: 761386768996841\n---\n\n|      | BIO  |     NIO     |  AIO  |\n| :--: | :--: | :---------: | :---: |\n| IO模型 | 同步阻塞 | 同步非阻塞（多路复用） | 异步非阻塞 |\n| 编程难度 |  简单  |     复杂      |  复杂   |\n| 可靠性  |  差   |      好      |   好   |\n| 吞吐量  |  低   |      高      |   高   |\n# 阅前须知\n\n`阻塞 IO` 和 `非阻塞 IO`\n\n这两个概念是 `程序级别` 的。主要描述是程序请求操作系统 IO 操作之后，如果 IO 资源没有准备好，那么程序如何处理问题：前者等待，后者继续执行（并且使用线程一直轮询，直到有 IO 资源准备好）\n\n`同步 IO ` 和 `非同步IO`\n\n这两个概念是`操作系统级别`的。主要描述的是操作系统在收到程序请求 IO 操作后，如果 IO 资源没有准备好，该如何相应程序的问题：前者不响应，后者返回一个标记，当 IO 资源准备好之后，在用事件机制返回给程序。\n\n# 一、BIO（Blocking I/O）\n\n## 基本概念\n\nJava BIO：同步并阻塞（传统阻塞性），应用程序中进程在发起 IO 调用后至内核执行 IO 操作返回结果之前，若发起系统调用的线程一直处于等待状态，则此次 IO 操作为阻塞 IO。阻塞 IO 简称 BIO，Blocking IO。\n\n以前大多数网络通信方式都是阻塞模式，即：\n- 客户端向服务器端发送请求后，客户端会一直等待（不会再做其他事情），直到服务器端返回结果或者网络出现问题。\n- 服务端同样的，当在处理某个客户端 A 发来的请求是，另一个客户端 B 发来的请求会等待，直到服务器端的这个处理线程完成上个处理。\n\n ![BIO请求流程图](img/acea8af4268c8d552741ccebcb2d34ec_MD5.png )\n\n## 使用实例\n\n1. 服务器启动一个 ServerSocket。\n2. 客户端启动 Socket 对服务器进行通信，默认情况下服务器端需要对每个客户建立一个线程与之通讯。\n2. 客户端发出请求后，先咨询服务器是否有线程响应，如果没有则会等待，或者被拒绝。\n3. 如果有响应，客户端线程会等待请求结束后，再继续执行。\n\n```java\npackage com.atguigu.bio;\n\nimport java.io.InputStream;\nimport java.net.ServerSocket;\nimport java.net.Socket;\nimport java.util.concurrent.ExecutorService;\nimport java.util.concurrent.Executors;\n\npublic class BIOServer {\n    \n    public static void main(String[] args) throws Exception {\n        //线程池机制\n        //思路\n        //1. 创建一个线程池\n        //2. 如果有客户端连接，就创建一个线程，与之通讯(单独写一个方法)\n        ExecutorService newCachedThreadPool = Executors.newCachedThreadPool();\n        //创建ServerSocket\n        ServerSocket serverSocket = new ServerSocket(6666);\n        System.out.println(\"服务器启动了\");\n        while (true) {\n            System.out.println(\"线程信息id = \" + Thread.currentThread().getId() + \"名字 = \" + Thread.currentThread().getName());\n            //监听，等待客户端连接\n            System.out.println(\"等待连接....\");\n            //会阻塞在accept()\n            final Socket socket = serverSocket.accept();\n            System.out.println(\"连接到一个客户端\");\n            //就创建一个线程，与之通讯(单独写一个方法)\n            newCachedThreadPool.execute(new Runnable() {\n                public void run() {//我们重写\n                    //可以和客户端通讯\n                    handler(socket);\n                }\n            });\n        } \n    }\n    \n    //编写一个handler方法，和客户端通讯\n    public static void handler(Socket socket) {\n        try {\n            System.out.println(\"线程信息id = \" + Thread.currentThread().getId() + \"名字 = \" + Thread.currentThread().getName());\n            byte[] bytes = new byte[1024];\n            //通过socket获取输入流\n            InputStream inputStream = socket.getInputStream();\n            //循环的读取客户端发送的数据\n            while (true) {\n                System.out.println(\"线程信息id = \" + Thread.currentThread().getId() + \"名字 = \" + Thread.currentThread().getName());\n                System.out.println(\"read....\");\n                int read = inputStream.read(bytes);\n                if (read != -1) {\n                    System.out.println(new String(bytes, 0, read));//输出客户端发送的数据\n                } else {\n                    break;\n                }\n            }\n        } catch (Exception e) {\n            e.printStackTrace();\n        } finally {\n            System.out.println(\"关闭和client的连接\");\n            try {\n                socket.close();\n            } catch (Exception e) {\n                e.printStackTrace();\n            }\n        }\n    }\n}\n```\n\n## 问题分析\n\n传统的 IO 模型，其主要是一个 Server 对接 N 个客户端，在客户端连接之后，为每个客户端分配一个子线程。如图所示：\n\n ![传统IO模型](img/0fb77c535fcbf8f4264b6eff292fd210_MD5.png)\n\n从图中可以看出，传统 IO 的特点在于：\n\n- 每个客户端连接到达时，服务端会分配一个线程给该客户端，该线程处理包括读取数据，解码，业务计算，编码，以及发送数据整个过程\n- 同一时刻，服务端的吞吐量与服务器所提供的线程数量呈线性关系的。\n\n如果并发量不大，运行没有问题，但是如果海量并发时候，就会出现问题：\n\n1. 每次请求都要创建独立的线程，与对应的客户端进行数据的Read，业务处理，数据Write、\n2. 当并发数较大时，需要创建大量线程处理连接，资源占用较大。\n3. 连接建立后，如果当前线程展示没有数据可读，则线程就阻塞在Read操作上，造成线程资源浪费。\n\n## 改进：多线程方式 - 伪异步方式\n\n上述说的情况只是服务器只有一个线程的情况，那么如果引入多线程是不是可以解决这个问题：\n\n- 当服务器收到客户端 X 的请求后，（读取到所有的请求数据后）将这个请求送入到一个独立线程进行处理，然后主线程继续接收客户端 Y 的请求。\n- 客户端侧，也可以用一个子线程和服务器端进行通信。这样客户端主线程的其他工作不受影响，当服务器有响应信息时候再有这个子线程通过 `监听模式/观察模式`（等其他设计模式）通知主线程。\n\n ![多线程方式 - 伪异步](img/ed84ace61748c9dbdaf3f9718f21ff21_MD5.png )\n\n但是多线程解决这个问题有局限性：\n\n- 操作系统通知accept() 的方式还是单个，即：服务器收到数据报文之后的“业务处理过程”可以多线程，但是报文的接收还是需要一个个来\n- 在操作系统中，线程是有限的。线程越多，CPU 切换所需时间也越长，用来处理真正业务的需求也就越少。\n- 创建线程需要较大的资源消耗。JVM 创建一个线程，即使不进行任何工作，也需要分配一个堆栈空间（128k）。\n- 如果程序中使用了大量的长连接，线程是不会关闭的，资源消耗更容易失控。\n\n> 为啥 `serverSocket. accept()` 会出现阻塞？\n\n是因为 Java 通过 JNI 调用的系统层面的 `accept0()` 方法，`accept0()` 规定如果发现套间字从指定的端口来，就会等待。其实就是内部实现是操作系统级别的同步 IO。\n\n# 二、NIO（non-Blocking I/O）\n\n了解 NIO 之前我们先来看看标准 I/O（Standard I/O）。\n\nStandard I/O 是对字节的读写，在进行 I/O 之前，首先创建一个流对象，流对象的读写操作都是按字节，一个字节一个字节的读或者写。而 NIO 把 I/O 抽象成块，类似磁盘的读写，每次 I/O 操作的单位都是一个块，块被读入内存之后就是一个 ` byte[]`，NIO 一次可以读或者写多个字节。\n\n## 流和块\n\nIO 和 NIO 最重要的区别就是对数据的打包和传输的方式，IO 是以流的方式处理数据，而 NIO 以块的方式处理数据。\n\n面向流的 IO 一次性处理一个字节数据：一个输入流产生一个字节数据，一个输出流消费一个字节数据。为流式数据创建过滤器非常容易，链接几个过滤器，以便每个过滤器只负责复杂处理机制的一部分。不利的一面是，面向流的 IO 通常处理非常慢。\n\n面向块的 I/O 一次性处理一个数据块：按块处理数据比按流处理数据要快的多，但是面向块的 I/O 确实一些面向流的 I/O 所具有的优雅和简单。\n\nI/O 包和 NIO 已经很好的集成了，`java.io.*` 中已经以 NIO 重新实现了，可以利用一些 NIO 的特性。例如：在 `java.io.*` 中某些类包含以块的形式读写数据的操作，这使得及时在面向流的系统中，处理数据也会更快。\n\n## 基本概念\n\nJava NIO：同步非阻塞，服务器实现模式为一个线程处理多个请求（连接），即客户端发送的连接请求都会注册到多路复用器上，多路复用器轮训到连接有 I/O 请求就进行处理。\n\n**核心概念：**\n\n1. **三大核心：** Channel（通道）、Buffer（缓冲区）、Selector（选择器）。\n2. **面向缓冲区，或者是面向块编程。** 数据读取到一个它稍后处理的缓冲区，需要时可在缓冲区中前后移动，这就增加了处理过程中的灵活性，使用它可以提供非阻塞式的高伸缩弹性网络。\n3. **非阻塞模式**， 使一个线程从某个通道发送请求或者读取数据，但是他仅能得到目前可用的数据，如果目前没有数据可用，就什么都不会获取，而不是保持线程阻塞。所以知道数据变得可读取之前，该线程还可以去做其他实行。\n4. **Channel 和 Buffer 一一对应。**\n5. **一个线程只有一个 Selector，一个线程对应对个 Channel（连接）**。\n6. 程序切换到哪个 Channel 是由事件决定，Event 就是个重要概念。\n7. Selector 会根据不同的事件，在各个通道上切换。\n8. **Buffer 是一个内存块，底层就是一个数组**。\n9. 数据读写都是通过 Buffer，区别于 BIO 的输入输出流，且**双向**，需要 `flip` 方法切换 `Channel` 是双向的 。\n\n## 编程原理\n\n1. 当客户端连接时，会通过 ServerSocketChannel 得到 SocketChannel。\n2. Selector 进行监听 select 方法，返回有事件发生的通道个数。\n3. 将 SocketChannel 注册到 Selector 上（`register(Selector selector, int ops)`），一个 Selector 可以注册多个 SocketChannel。\n4. 注册后返回 SelectionKey，会和该 Selector 关联（集合）。\n5. 当有事件发生时，进一步得到各个 SelectionKey。\n6. 通过channel () 方法，用 SelectionKey 反向获取 SocketChannel。\n7. 可以通过得到的 channel，完成业务处理。\n\n## 1. 缓冲区（Buffer）\n\n### Buffer 类及其子类\n\n`ByteBuffer` 字节数据；`ShortBuffer` 字符串数据；`CharBuffer` 字符数据；`IntBuffer` 整数；`LongBuffer` 长整数；`DoubleBuffer` 小数；`FloatBuffer` 小数\n\n### Buffer 属性和方法\n\nBuffer 类提供了 4 个属性来提供数据元素信息：`capacity（容量）`：缓存区的最大容量，`Limit（终点）`：缓存区最大可操作位置，`Position（位置）` ：缓存区当前在操作的位置，`Mark（标记）`：标记位置\n\n```java\npublic abstract class Buffer{\n\tpublic final int capacity();\n\tpublic final int position();\n\tpublic final Buffer position(int newPosition);\n\tpublic final int limit();\n\tpublic final Buffer limit(int newLimit);\n\t\n}\n//其中比较常用的就是ByteBuffer（二进制数据），该类主要有以下方法\npublic abstract class ByteBuffer(){\n\tpublic static ByteBuffer allocateDirect(int capacity);//直接创建缓冲区\n\tpublic static ByteBuffer allocate(int capacity);//设置缓冲区的初始容量\n\tpublic static ByteBuffer wrap(byte[] array);//把一个数组放入到缓冲区使用\n\t//构造初始化位置offset和上界length的缓冲区\n\tpublic static ByteBuffer wrap(byte[] array,int offset,int length);\n\t//缓冲区读取相关API\n\tpublic abstract byte get();//从当前位置position上get，get之后，positon会+1\n\tpublic abstract byte get(int index);//从绝对位置获取\n\tpublic abstract ByteBuffer put(byte b);//当前位置上put，put之后，position会+1\n\tpublic abstract ByteBuffer put(int index,byte b);//从绝对位置put\t\n}\n```\n\n状态变量的改变过程举例:\n\n① 新建一个大小为 8 个字节的缓冲区，此时 position 为 0，而 limit = capacity = 8。capacity 变量不会改变，下面的讨论会忽略它。\n\n ![状态变量的改变过程1](img/a8f0d4502adb087892e11866bdac7d57_MD5.png )\n\n② 从输入通道中读取 5 个字节数据写入缓冲区中，此时 position 移动设置为 5，limit 保持不变。\n\n ![状态变量的改变过程2](img/5ee1af7a6012fd34b62704d5b2867320_MD5.png )\n\n③ 在将缓冲区的数据写到输出通道之前，需要先调用 flip() 方法，这个方法将 limit 设置为当前 position，并将 position 设置为 0。\n\n ![状态变量的改变过程3](img/5cd2995739f1b0e1f4b355a2471c38aa_MD5.png )\n\n④ 从缓冲区中取 4 个字节到输出缓冲中，此时 position 设为 4。\n\n ![状态变量的改变过程4](img/0d87f8ba4e770fbdcd6c6fc61fb84862_MD5.png )\n\n⑤ 最后需要调用 clear() 方法来清空缓冲区，此时 position 和 limit 都被设置为最初位置。\n\n ![状态变量的改变过程5](img/f6ef08bdd8b4ff67a419bfe9b7dbc0f2_MD5.png )\n\n### 文件 NIO 实例\n\n以下展示了使用 NIO 快速复制文件的实例：\n\n```java\npublic static void fastCopy(String src, String dist) throws IOException {\n\n    /* 获得源文件的输入字节流 */\n    FileInputStream fin = new FileInputStream(src);\n\n    /* 获取输入字节流的文件通道 */\n    FileChannel fcin = fin.getChannel();\n\n    /* 获取目标文件的输出字节流 */\n    FileOutputStream fout = new FileOutputStream(dist);\n\n    /* 获取输出字节流的通道 */\n    FileChannel fcout = fout.getChannel();\n\n    /* 为缓冲区分配 1024 个字节 */\n    ByteBuffer buffer = ByteBuffer.allocateDirect(1024);\n\n    while (true) {\n\n        /* 从输入通道中读取数据到缓冲区中 */\n        int r = fcin.read(buffer);\n\n        /* read() 返回 -1 表示 EOF */\n        if (r == -1) {\n            break;\n        }\n\n        /* 切换读写 */\n        buffer.flip();\n\n        /* 把缓冲区的内容写入输出文件中 */\n        fcout.write(buffer);\n        \n        /* 清空缓冲区 */\n        buffer.clear();\n    }\n}\n```\n\n\n## 2. 通道（Channel）\n\n通道类似流，但是有如下区别：\n\n- 通道可以同时读写，而流只能读或写\n- 通道可以实现异步读写数据\n- 通道可以从缓冲区读数据，也可以写数据到缓冲区\n\n### 通道分类\n\nChannel 在 NIO 中是一个接口 `public interface Channle extends Closeable{}`。其中，常用的 Channel 类有：\n\n1. `FileChannel`：用于文件的数据读写；\n2. `DatagramChannel`：用于 UDP 的数据读写；\n3. `ServerSocketChannel`：可以监听新来的连接，对每一个新进来的连接都会创建一个 SocketChannel。只有通过这个通道，应用程序才能箱操作系统注册支持“多路复用 IO”的端口减轻。支持 TCP 和 UDP 协议；\n4. `SocketChannel`：TCP Socket 套接字的监听通道，用于 TCP 的数据读写\n5. 其他的通道包括：\n\n ![其他通道](img/94530647a3be7da4d2de055fff8bacaf_MD5.png )\n### FileChannel 类\n\n对本地文件进行 IO 操作，常用方法及实例应用：\n\n```java\n//从通道读取数据并放到缓冲区内\npublic int read(ByteBuffer content);\n//从缓冲区写数据到通道中\npublic int write(ByteBuffer content);\n//从目标通道中复制数据到当前通道内\npublic long transferFrom(ReadableByteChannel src,long position,long count);\n//把数据从当前通道复制到目标通道\npublic long transferTo(long position,long count,WritabelByteChannel target);\n\n```\n\n1 . 写入文件，使用之前 `ByteBuffer` 和 `FileChannel` 类\n\n``` java\n//使用之前ByteBuffer和FileChannel类，写入文件\nimport java.io.FileOutputStream;\nimport java.nio.ByteBuffer;\nimport java.nio.channels.FileChannel;\n\npublic class NIOFileChannel{\n\tpublic static void main(String[] args) throws Exception{\n\t\tString str = \"hello,world\";\n\t\t//创一个输出流 -> channel\n\t\tFileOutputStream stream = new FileOutputStream(\"d:\\\\file.txt\");\n\t\t//通过 stream 获取对应的 FileChannel\n\t\t//这个 fileChannel 真实类型是 FileChannelImpl\n\t\tFileChannel fileChannel = stream.getChannel();\n\n\t\t//创建一个缓冲区 ByteBuffer\n\t\tByteBuffer byteBuffer = ByteBuffer.allocate(1024);\n\t\t//将 str 放入到缓冲区\n\t\tbyteBuffer.put(str.getBytes());\n\t\t//对 byteBuffer 进行 flip\n\t\tbyteBuffer.flip();\n\n\t\t//将 byteBuffer 写入到 fileChannel\n\t\tfileChannel.write(byteBuffer);\n\t\tfileOutputStream.close();\n\t}\n\n}\n```\n\n2 . 读取文件数据并展示，使用之前 `ByteBuffer` 和 `FileChannel` 类\n\n```java\n//读取本地文件\nimport java.io.FileOutputStream;\nimport java.nio.ByteBuffer;\nimport java.nio.channels.FileChannel;\n\npublic class NIOFileChannel{\n\tpublic static void main(String[] args) throws Exception{\n\t\t//创一个输出流 -> channel\n\t\tFile file = new File(\"d:\\\\file.txt\");\n\t\tFileOutputStream stream = new FileOutputStream(file);\n\t\t//通过 stream 获取对应的 FileChannel\n\t\t//这个 fileChannel 真实类型是 FileChannelImpl\n\t\tFileChannel fileChannel = stream.getChannel();\n\n\t\t//创建一个缓冲区 ByteBuffer\n\t\tByteBuffer byteBuffer = ByteBuffer.allocate((int)file.length());\n\n\t\t//将 byteBuffer 写入到 fileChannel\n\t\tfileChannel.read(byteBuffer);\n\t\t//将 byteBuffer的字节转化成String\n\t\tSystem.out.println(new String(byteBuffer.array()));\n\t\tfileOutputStream.close();\n\t}\n\n}\n\n```\n\n\n3 . 使用一个 `Buffer` 完成文件的读取、写入\n\n```java\nimport java.io.FileInputStream;\nimport java.io.FileOutputStream;\nimport java.nio.ByteBuffer;\nimport java.nio.channels.FileChannel;\n\npublic class NIOFileChannel03 {\n\n    public static void main(String[] args) throws Exception {\n\n        FileInputStream fileInputStream = new FileInputStream(\"1.txt\");\n        FileChannel fileChannel01 = fileInputStream.getChannel();\n        FileOutputStream fileOutputStream = new FileOutputStream(\"2.txt\");\n        FileChannel fileChannel02 = fileOutputStream.getChannel();\n\n        ByteBuffer byteBuffer = ByteBuffer.allocate(512);\n        \n        while (true) { //循环读取\n\n            //这里有一个重要的操作，一定不要忘了\n            /*\n            public final Buffer clear() {\n                position = 0;\n                limit = capacity;\n                mark = -1;\n                return this;\n            }\n            */\n            byteBuffer.clear(); //清空 buffer\n            int read = fileChannel01.read(byteBuffer);\n            System.out.println(\"read = \" + read);\n            if (read == -1) { //表示读完\n                break;\n            }\n\n            //将 buffer 中的数据写入到 fileChannel02--2.txt\n            byteBuffer.flip();\n            fileChannel02.write(byteBuffer);\n        }\n\n        //关闭相关的流\n        fileInputStream.close();\n        fileOutputStream.close();\n    }\n}\n```\n\n4 . 拷贝文件transferFrom 方法\n\n```java\nimport java.io.FileInputStream;\nimport java.io.FileOutputStream;\nimport java.nio.channels.FileChannel;\n\npublic class NIOFileChannel04 {\n\n    public static void main(String[] args) throws Exception {\n\n        //创建相关流\n        FileInputStream fileInputStream = new FileInputStream(\"d:\\\\a.jpg\");\n        FileOutputStream fileOutputStream = new FileOutputStream(\"d:\\\\a2.jpg\");\n        \n        //获取各个流对应的 FileChannel\n        FileChannel sourceCh = fileInputStream.getChannel();\n        FileChannel destCh = fileOutputStream.getChannel();\n\n        //使用 transferForm 完成拷贝\n        destCh.transferFrom(sourceCh, 0, sourceCh.size());\n\n        //关闭相关通道和流\n        sourceCh.close();\n        destCh.close();\n        fileInputStream.close();\n        fileOutputStream.close();\n    }\n}\n```\n\n###  Buffer 和 Channel 注意事项\n\n**1. ByteBuffer 支持类型化的 put 和 get，put 放什么，get 取出什么，不然出现 BufferUnderflowException 异常**\n\n```java\nimport java.nio.ByteBuffer;\n\npublic class NIOByteBufferPutGet {\n\n    public static void main(String[] args) {\n        \n        //创建一个 Buffer\n        ByteBuffer buffer = ByteBuffer.allocate(64);\n\n        //类型化方式放入数据\n        buffer.putInt(100);\n        buffer.putLong(9);\n        buffer.putChar('尚');\n        buffer.putShort((short) 4);\n\n        //取出\n        buffer.flip();\n        \n        System.out.println();\n        \n        System.out.println(buffer.getInt());\n        System.out.println(buffer.getLong());\n        System.out.println(buffer.getChar());\n        System.out.println(buffer.getShort());\n    }\n}\n```\n\n**2. 普通 Buffer 转成只读 Buffer**\n\n```java\n\nimport java.nio.ByteBuffer;\n\npublic class ReadOnlyBuffer {\n\n    public static void main(String[] args) {\n\n        //创建一个 buffer\n        ByteBuffer buffer = ByteBuffer.allocate(64);\n\n        for (int i = 0; i < 64; i++) {\n            buffer.put((byte) i);\n        }\n\n        //读取\n        buffer.flip();\n\n        //得到一个只读的 Buffer\n        ByteBuffer readOnlyBuffer = buffer.asReadOnlyBuffer();\n        System.out.println(readOnlyBuffer.getClass());\n\n        //读取\n        while (readOnlyBuffer.hasRemaining()) {\n            System.out.println(readOnlyBuffer.get());\n        }\n\n        readOnlyBuffer.put((byte) 100); //ReadOnlyBufferException\n    }\n}\n```\n\n**3. NIO 中 MappedByteBuffer，可以让文件直接在堆外内存修改**\n\n```java\n\nimport java.io.RandomAccessFile;\nimport java.nio.MappedByteBuffer;\nimport java.nio.channels.FileChannel;\n\n/**\n * 说明 1.MappedByteBuffer 可让文件直接在内存（堆外内存）修改,操作系统不需要拷贝一次\n */\npublic class MappedByteBufferTest {\n\n    public static void main(String[] args) throws Exception {\n\n        RandomAccessFile randomAccessFile = new RandomAccessFile(\"1.txt\", \"rw\");\n        //获取对应的通道\n        FileChannel channel = randomAccessFile.getChannel();\n\n        /**\n         * 参数 1:FileChannel.MapMode.READ_WRITE 使用的读写模式\n         * 参数 2：0：可以直接修改的起始位置\n         * 参数 3:5: 是映射到内存的大小（不是索引位置），即将 1.txt 的多少个字节映射到内存\n         * 可以直接修改的范围就是 0-5\n         * 实际类型 DirectByteBuffer\n         */\n        MappedByteBuffer mappedByteBuffer = channel.map(FileChannel.MapMode.READ_WRITE, 0, 5);\n\n        mappedByteBuffer.put(0, (byte) 'H');\n        mappedByteBuffer.put(3, (byte) '9');\n        mappedByteBuffer.put(5, (byte) 'Y');//IndexOutOfBoundsException\n\n        randomAccessFile.close();\n        System.out.println(\"修改成功~~\");\n    }\n}\n```\n\n4. **NIO 还支持通过多个 Buffer（即 Buffer数组）完成读写操作，即 Scattering 和 Gathering**\n\n```java\nimport java.net.InetSocketAddress;\nimport java.nio.ByteBuffer;\nimport java.nio.channels.ServerSocketChannel;\nimport java.nio.channels.SocketChannel;\nimport java.util.Arrays;\n\n/**\n * Scattering：将数据写入到 buffer 时，可以采用 buffer 数组，依次写入 [分散]\n * Gathering：从 buffer 读取数据时，可以采用 buffer 数组，依次读\n */\npublic class ScatteringAndGatheringTest {\n\n    public static void main(String[] args) throws Exception {\n        \n        //使用 ServerSocketChannel 和 SocketChannel 网络\n        ServerSocketChannel serverSocketChannel = ServerSocketChannel.open();\n        InetSocketAddress inetSocketAddress = new InetSocketAddress(7000);\n\n        //绑定端口到 socket，并启动\n        serverSocketChannel.socket().bind(inetSocketAddress);\n\n        //创建 buffer 数组\n        ByteBuffer[] byteBuffers = new ByteBuffer[2];\n        byteBuffers[0] = ByteBuffer.allocate(5);\n        byteBuffers[1] = ByteBuffer.allocate(3);\n\n        //等客户端连接 (telnet)\n        SocketChannel socketChannel = serverSocketChannel.accept();\n\n        int messageLength = 8; //假定从客户端接收 8 个字节\n\n        //循环的读取\n        while (true) {\n            int byteRead = 0;\n\n            while (byteRead < messageLength) {\n                long l = socketChannel.read(byteBuffers);\n                byteRead += l; //累计读取的字节数\n                System.out.println(\"byteRead = \" + byteRead);\n                //使用流打印,看看当前的这个 buffer 的 position 和 limit\n                Arrays.asList(byteBuffers).stream().map(buffer -> \"position = \" + buffer.position() + \", limit = \" + buffer.limit()).forEach(System.out::println);\n            }\n\n            //将所有的 buffer 进行 flip\n            Arrays.asList(byteBuffers).forEach(buffer -> buffer.flip());\n            //将数据读出显示到客户端\n            long byteWirte = 0;\n            while (byteWirte < messageLength) {\n                long l = socketChannel.write(byteBuffers);//\n                byteWirte += l;\n            }\n            \n            //将所有的buffer进行clear\n            Arrays.asList(byteBuffers).forEach(buffer -> {\n                buffer.clear();\n            });\n            \n            System.out.println(\"byteRead = \" + byteRead + \", byteWrite = \" + byteWirte + \", messagelength = \" + messageLength);\n        }\n    }\n}\n```\n\n## 3. Selector（选择器）\n\n### 基本概念\n\nNIO 常常被叫做非阻塞 IO，主要是因为 NIO 在网络通信中的非阻塞特性被广泛使用。NIO 实现了 IO 多路复用中的 Reator 模型，一个线程 Thread 使用一个选择器 Selector 通过轮询的方式去监听多个 Channel 上的事件，从而让一个线程能够处理多个事件。\n\n通过配置监听的通道 Channel 为非阻塞，那么当 Channel 上的 IO 事件还未到达时，就不会进入到阻塞状态一直等待，而是鸡血轮询其他 Channel，找到 IO 事件已经到达的 Channel 执行。\n\n以为创建和切换线程的开销很大，因此使用一个线程处理多个事件显然比一个线程处理一个事件具有更好的性能。\n\n ![选择器](img/0b37a3b751ec9aa08efa75ace30e23c4_MD5.png )\n\n1. Java 中的 NIO 可以用一个线程，处理多个客户端连接，就会使用到 Selector（选择器）\n2. 多个 Channel 以事件的方式注册到 Selector\n3. 只有在连接通道有真正的读写事件的时候，才会进行读写，减少系统开销\n4. 避免了`多线程之间的上下文切换导致的开销`\n\n```java\n//Selector 类是一个抽象类，常用方法和说明如下：\npublic abstract class Selector implements Closeable{\n\tpublic static Selector open();//监控所有注册的通道，当其中有IO操作可以进行时，将SelectionKey加入到内部的集合中并返回，参数用来设置超时时间\n\tpublic Set<SelectionKey> selectedKey();//从内部集合中得到所有的SelectionKey\t\n}\n ```\n\n### 使用方法\n\n1. **创建选择器**\n\n```java\nSelector selector = Selector.open();\n```\n\n2. **将通道注册到选择器上**\n\n```java\nServerSocketChannel ssChannel = ServerSocketChannel.open();\nssChannel.configureBlocking(false);\nssChannel.register(selector,SelectionKey.OP_ACCEPT);\n```\n\n将通道注册到选择器上，还需要指定要注册的具体事件，主要有以下几类：\n\n`SelectionKey. OP_CONNECT`、`SelectionKey. OP_ACCEPT`、`SelectionKey. OP_READ`、 `SelectionKey. OP_WRITE`\n\n他们在 SelectionKey 的定义如下：\n\n```java\npublic static final int OP_READ = 1 << 0;\npublic static final int OP_WRITE = 1 << 2;\npublic static final int OP_CONNECT = 1 << 3;\npublic static final int OP_ACCEPT = 1 << 4;\n```\n\n可以看出每个事件都能当成一个位域，从而组成事件集整数。例如：\n\n```java\nint intersetSet = SelectionKey.OP_READ | SelectionKey.OP_WRITE;\n```\n\n3. **监听事件**\n\n```java\nint num = selector.select();\n```\n\n使用 `select()` 方法来监听到达的事件，它会一直阻塞知道有至少一件事件到达。\n\n4. **获取到达的事件**\n\n```java\nSet<SelectionKey> keys = selector.selectedKeys();\nIterator<SelectionKey> keyIterator = keys.iterator();\nwhile(keyIterator.hasNext()){\n\tSelectionKey keyu = keyIterator.next();\n\tif(key.isAcceptabnle()){\n\t// ...\n\t}else if(key.isReadable()){\n\t// ...\n\t}\n\tkeyIterator.remove();\n}\n```\n\n5. **时间循环**\n\n因为一次 select() 调动不能处理完所有的事件，并且服务器端有可能需要一直监听事件，因此服务器端处理时间的代码一般会放在一个死循环内。\n\n```java\nwhile (true) { \n\tint num = selector.select(); \n\tSet<SelectionKey> keys = selector.selectedKeys(); \n\tIterator<SelectionKey> keyIterator = keys.iterator(); \n\twhile (keyIterator.hasNext()) { \n\t\tSelectionKey key = keyIterator.next(); \n\t\tif (key.isAcceptable()) { \n\t\t  // ... \n\t\t} else if (key.isReadable()) {\n\t\t  // ... \n\t\t} \n\t\tkeyIterator.remove(); \n\t}\n}\n```\n\n### 套接字 NIO 实例\n\n```java\npublic class NIOServer {\n \tpublic static void main(String[] args) throws IOException {\n\t\tSelector selector = Selector.open();\n\t\tServerSocketChannel ssChannel = ServerSocketChannel.open();\n\t\tssChannel.configureBlocking(false);\n\t\tssChannel.register(selector, SelectionKey.OP_ACCEPT);\n\t\tServerSocket serverSocket = ssChannel.socket();\n\t\tInetSocketAddress address = new InetSocketAddress(\"127.0.0.1\", 8888);\n\t\tserverSocket.bind(address);\n\t\twhile(true){\n\t\t\tselector.select();\n\t\t\tSet<SelectionKey> keys = selector.selectedKeys();\n\t\t\tIterator<SelectionKey> keyIterator = keys.iterator();\n\t\t\twhile (keyIterator.hasNext()){\n\t\t\t\tSelectionKey key = keyIterator.next();\n\t\t\t\tif (key.isAcceptable()) {\n\t\t\t\t\tServerSocketChannel ssChannel1 = (ServerSocketChannel) key.channel();// 服务器会为每个新连接创建一个 SocketChannel SocketChannel sChannel = ssChannel1.accept();\n\t\t\t\t\tsChannel.configureBlocking(false);// 这个新连接主要用于从客户端读取数据 \n\t\t\t\t\tsChannel.register(selector, SelectionKey.OP_READ);\n\t\t\t\t}else if (key.isReadable()) {\n\t\t\t\t\tSocketChannel sChannel = (SocketChannel) key.channel();\n\t\t\t\t\tSystem.out.println(readDataFromSocketChannel(sChannel));\n\t\t\t\t\tsChannel.close();\n\t\t\t\t}\n \t\t\tkeyIterator.remove();\n\t\t\t}\n\t\t}\n \t}\n\tprivate static String readDataFromSocketChannel(SocketChannel sChannel) throws IOException {\n\t\tByteBuffer buffer = ByteBuffer.allocate(1024);\n\t\tStringBuilder data = new StringBuilder();\n\t\twhile(true) {\n\t\t\tbuffer.clear();\n\t\t\tint n = sChannel.read(buffer);\n\t\t\tif (n == -1) {\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tbuffer.flip();\n\t\t\tint limit = buffer.limit();\n\t\t\tchar[] dst = new char[limit];\n\t\t\tfor (int i = 0;i < limit;i++) {\n\t\t\t\tdst[i] = (char) buffer.get(i);\n\t\t\t}\n\t\t\tdata.append(dst);\n\t\t\tbuffer.clear();\n \t\t}\n \t\treturn data.toString();\n \t}\n }\n```\n```java\npublic class NIOClient {\n\tpublic static void main(String[] args) throws IOException{\n\t\tSocket socket = new Socket(\"127.0.0.1\"，8888);\n\t\tOutputStream out = socket.getOutputStream();\n\t\tString s = \"hello world\";\n\t\tout.write(s.getBytes());\n\t\tout.close();\n\t}\n}\n```\n## 典型的多路复用 IO 实现\n\n目前流程的多路复用 IO 实现主要宝库了四种：select、poll、epoll、kqueue。以下是其特性及区别：\n\n| IO 模型  | 相对性能 |       关键思路       |   操作系统    |                                             Java 支持情况                                              |\n| :----: | :--: | :--------------: | :-------: | :------------------------------------------------------------------------------------------------: |\n| select |  较高  |     Reactor      | Win/Linux | 支持，Reactor 模式（反应器设计模式）。Linux kernels 2.4 内核版本之前，默认用的是 select ；目前 windows 下对吧同步 IO 的支持，都是 select 模型 |\n|  poll  |  较高  |     Reactor      |   Linux   |            Linux 下的 Java 的 NIO 框架，Linux kernels 2.6 内核版本之前使用 poll 进行支持。也是使用的 Reactor 模式            |\n| epoll  |  高   | Reactor/Proactor |   Linux   |                               Linux kernels 2.6 内核版本之后使用 epoll 进行支持                                |\n| kqueue |  高   |     Proactor     |   Linux   |                                           目前 Java 版本不支持                                            |\n\n### 1. Reactor事件驱动模型\n\n ![Reactor事件驱动模型](img/10d0080498aba2649f1c04067965b579_MD5.png )\n\n从图上可知：一个完整的 Reactor 事件驱动模型是有四个部分组成：客户端 Client，Reactor，Acceptor 和时间处理 Handler。其中 Acceptor 会不间断的接收客户端的连接请求，然后通过 Reactor 分发到不同 Handler 进行处理。改进后的 Reactor 有如下优点：\n\n- 虽然同是由一个线程接收连接请求进行网络读写，但是 Reactor 将客户端连接，网络读写，业务处理三大部分拆分，从而极大提高工作效率。\n- Reactor 是以事件驱动的，相比传统 IO 阻塞式的，不必等待，大大提升了效率。\n\n### 2. Reactor 模型——业务处理和 IO 分离\n\n在上面的处理模型中，由于网络读写是在同一个线程里面。在高并发情况下，会出现两个瓶颈：\n\n- 高频率的读写事件处理\n- 大量的业务处理\n\n基于上述瓶颈，可以将业务处理和 IO 读写分离出来：\n\n ![Reactor模型-业务处理和IO分离](img/37b1874d4aabb48cd6b511cba09fa70b_MD5.png )\n\n如图可以看出，相对基础 Reactor 模型，该模型有如下特点：\n\n- 使用一个线程进行客户端连接和网络读写\n- 客户端连接之后，将该连接交给线程池进行加解码以及业务处理\n\n这种模型在接收请求进行网络读写的同时，也在进行业务处理，大大提高了系统的吞吐量。但是也有不足的地方：\n- 网络读写是一个比较消耗 CPU 的操作，在高并发的情况下，将有大量的客户端需要网络读写，此时一个线程处理不了这么多的请求。\n\n### 3. Reactor——并发读写\n\n由于高并发的网络读写是系统一个瓶颈，所以针对这种情况，改进了模型，如图所示：\n\n ![Reactor-并发读写](img/870a39b7312d1d18324d3aefa613ab37_MD5.png )\n由图可以看出，在原有 Reactor 模型上，同时将 Reactor 拆分成 mainReactor 和 subReactor 。其中 mainReactor 主要负责客户端的请求连接，subReactor 通过一个线程池进行支撑，主要负责网络读写，因为线程池的原因，可以进行多线程并发读写，大大提升了网络读写的效率。业务处理也是通过线程池进行。通过这种方式，可以进行百万级别的连接。\n\n### 4. Reactor 模型示例\n\n对于上述的 Reactor 模型，主要有三个核心需要实现：Acceptor，Reactor 和 Handler。具体实现代码如下：\n\n```java\npublic class Reactor implements Runnable{\n\tprivate final Selector selector;\n\tprivate final ServerSocketChannel serverSocket;\n\n\tpublic Reactor(int port) throws IOException{\n\t\tserverSocket = ServerSocketChannel.open();//创建服务端的ServerSocketChannel\n\t\tserverSocket.configureBlocking(false);//设置为非阻塞模式\n\t\tselector = Selector.open();//创建一个selector选择器\n\t\tSelectionKey key = serverSocket.register(selector,SelectionKey.OP_ACCEPT);\n\t\tserverSocket.bind(new InetSocketAddress(port));//绑定服务端端口\n\t\tkey.attach(new Acceptor(serverSocket));//为服务端Channel绑定一个Acceptor\n\t}\n\t@Override\n\tpublic void run(){\n\t\ttry{\n\t\t\twhile(！Thread.interrupted()){\n\t\t\t\tselector.select();//服务端使用一个线程不停接收连接请求\n\t\t\t\tSet<SelectionKey> keys = selector.selectedKeys();\n\t\t\t\tIterator<SelectionKey> itetrator = keys.iterator();\n\t\t\t\twhile(iterator.hasNext()){\n\t\t\t\t\tdispatch(iterator.next());\n\t\t\t\t\titerator.remove();\n\t\t\t\t\t}\n\t\t\t\tselector.selectNow();\n\t\t\t\t}\n\t\t}catch(IOException e){\n\t\t\te.printStackTrace();\n\t\t}\n\t}\n\n\tprivate void dispatch(SelectionKey key) throws IOException{\n\t\t//这里的attachment也即前面的为服务端Channel绑定的Acceptor，调用其run()方法进行分发\n\t\tRunnable attachment = (Runable)key.attachment();\n\t\tattachment.run();\n\t}\n\n}\n\n```\n这里Reactor首先开启了一个ServerSocketChannel，然后将其绑定到指定的端口，并且注册到了一个多路复用器上。接着在一个线程中，其会在多路复用器上等待客户端连接。当有客户端连接到达后，Reactor就会将其派发给一个Acceptor，由该Acceptor专门进行客户端连接的获取。下面我们继续看一下Acceptor的代码：\n```java\npublic class Acceptor implements Runnable{\n\tprivate final ExecuteorService executor = Exxcutors.newFixedThreadPool(20);\n\n\tprivate final ServerSocketChannel serverSocket;\n\n\tpublic Acceptor(ServerSocketChannel serverSocket){\n\t\tthis.serverSocket = serverSocket;\n\t\t}\n\n\t@Override\n\tpublic void run(){\n\t\ttry{\n\t\t\tSocketChannel channel = serverSocket.accept();\n\t\t\tif(null != channel){\n\t\t\t\texecutor.execute(new Handler(channel));\n\t\t\t}\n\t\t}catch(IOException e){\n\t\t\te.printStackTrace();\n\t\t}\n\t}\n}\n```\n\n这里可以看到，在Acceptor获取到客户端连接之后，其就将其交由线程池进行网络读写了，而这里的主线程只是不断监听客户端连接事件。下面我们看看Handler的具体逻辑：\n\n```java\npublic class Handler implements Runnable{\n\tprivate volatile static Selector selector;\n\tprivate final SocketChannel channel;\n\tprivate SelectionKey key;\n\tprivate volatile ByteBuffer input = ByteBuffer.allocate(1024);\n\tprivate volatile ByteBuffer output = ByteBuffer.allocate(1024);\n\n\tpublic Handle(SocketChannel channel) throws IOException{\n\t\tthis.channel = channel;\n\t\tchannel.configureBlocking(false);//设置客户端连接为非阻塞模式\n\t\tselector = Selector.open();//为客户端创建一个选择器\n\t\tkey = channel.register(selector,SelectionKey.OP_READ);//注册客户端Channel的读事件\t\n\t}\n\n\t@Override\n\tpublic void run(){\n\t\ttry{\n\t\t\twhile(selector.isOpen() && channel.isOpen()){\n\t\t\t \tSet<SelectionKey> keys = select();//等待客户端事件发生\n\t\t\t \tIterator<SelectionKey> iterator = keys.iterator();\n\t\t\t\twhile(iterator.hasNext()){\n\t\t\t\t\tSelectionKey key = iterator.next();\n\t\t\t\t\titerator.remove();\n\n\t\t\t\t\t//如果当前是读事件，则读取数据\n\t\t\t\t\tif(key.isReadable()){\n\t\t\t\t\t\tread(key);\n\t\t\t\t\t}else if(key.isWritable()){\n\t\t\t\t\t\twrite(key)\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\t\n\t\t}catch(IOException e){\n\t\te.printStackTrace();\n\t\t}\n\t}\n\t//读取客户端发送的数据\n\n\tprivate void read(SelectionKey key) throws IOException{\n\t\tchannel.read(input);\n\t\tif(input.position() == 0){\n\t\t\treturn ;\n\t\t}\n\t\tinput.flip();\n\t\tprocess();//对读数据进行业务处理\n\t\tinput.clear();\n\t\tkey.interstOps(SelectionKey.OP_WRITE);//读取完成后监听写入事件\n\t}\n\tprivate void write(SelectionKey key) throws IOException{\n\t\toutput.flip();\n\t\tif(channel.isOpen()){\n\t\t\tchannel.write(output);//当有写入事件时，将业务处理的结果写入到客户端Channel中\n\t\t\tkey.channel();\n\t\t\tchannel.close();\n\t\t\toutput.clear();\n\t\t}\n\t}\n\t//进行业务处理，并且获取处理结果。本质上，基于Reactor模型，如果这里成为处理瓶颈，则将处理过程放入到线程池里面即可，并且使用一个Future获取处理结果，最后写入到客户端Channel中\n\tprivate void process(){\n\t\tbyte[] bytes = new byte[input.remaining()];\n\t\tinput.get(bytes);\n\t\tString message = new String(bytes,CharsetUtil.UTF_8);\n\t\tSystem.out.println(\"receive message from client: \\n\" +message);\n\t\toutput.put(\"hello client\".getBytes());\n\t}\n}\n```\n\n在 Handler 中，主要进行的就是每个客户端 Channel 创建一个 Selector，并且监听该 Channel 的网络读写事件。当有事件到达时，进行数据的读写，而业务操作交友具体的业务线程池处理。\n\n# 三、AIO（ Asynchronous I/O）\n\n1. JDK7 引入了 Asynchronous I/O，即 AIO。在进行 I/O 编程中，常用到两种模式：Reactor 和 Proactor。Java 的 NIO 就是 Reactor，当有事件触发时，服务器端得到通知，进行相应的处理\n2. AIO 即 NIO2.0，叫做异步不阻塞的 IO。AIO 引入异步通道的概念，采用了 Proactor 模式，简化了程序编写，有效的请求才启动线程，它的特点是先由操作系统完成后才通知服务端程序启动线程去处理，一般适用于连接数较多且连接时间较长的应用\n\n### 异步 IO\n\n之前主要介绍了阻塞式同步 IO，非阻塞式同步 IO，多路复用 IO 这三种 IO 模型。而异步 IO 是采用“订阅-通知”模式，即应用程序向操作系统注册 IO 监听，然后继续做自己的事情。当操作系统发生 IO 事件，并且准备好数据后，主动通知应用程序，触发相应的函数：\n\n ![异步IO](img/3a01157436842562f7f21f8b4c4549d4_MD5.png )\n\n和同步 IO 一样，异步 IO 也是由操作系统进行支持的。Windows 系统提供了一种异步 IO 技术：IOCP（I/O Completion Port，I/O 完成端口）；\nLinux 下由于没有这种异步 IO 技术，所以使用的是 epoll（上文介绍过的一种多路复用 IO 技术的实现）对异步 IO 进行模拟。\n\n### Java AIO 框架解析\n\n ![Java AIO](img/2ff37cd0e1f5f734f8d6209396a08897_MD5.png )\n\n以上结构主要是说明 JAVA AIO 中类设计和操作系统的相关性。\n\n> 上述所有代码仓库地址：https://github.com/z1gui/netty_io\n\n参考资料：\n\n> [BIO、NIO、AIO区别详解](https://zhuanlan.zhihu.com/p/520809188?utm_id=0)\n>\n> [♥Java IO知识体系详解♥](https://pdai.tech/md/java/io/java-io-overview.html)\n\n\n","slug":"md/聊聊JavaIO的那些事","published":1,"updated":"2025-08-20T09:55:37.258Z","comments":1,"layout":"post","photos":[],"_id":"cmhc3m3ue000txdp898ge3rnw","content":"<table>\n<thead>\n<tr>\n<th align=\"center\"></th>\n<th align=\"center\">BIO</th>\n<th align=\"center\">NIO</th>\n<th align=\"center\">AIO</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"center\">IO模型</td>\n<td align=\"center\">同步阻塞</td>\n<td align=\"center\">同步非阻塞（多路复用）</td>\n<td align=\"center\">异步非阻塞</td>\n</tr>\n<tr>\n<td align=\"center\">编程难度</td>\n<td align=\"center\">简单</td>\n<td align=\"center\">复杂</td>\n<td align=\"center\">复杂</td>\n</tr>\n<tr>\n<td align=\"center\">可靠性</td>\n<td align=\"center\">差</td>\n<td align=\"center\">好</td>\n<td align=\"center\">好</td>\n</tr>\n<tr>\n<td align=\"center\">吞吐量</td>\n<td align=\"center\">低</td>\n<td align=\"center\">高</td>\n<td align=\"center\">高</td>\n</tr>\n</tbody></table>\n<h1 id=\"阅前须知\"><a href=\"#阅前须知\" class=\"headerlink\" title=\"阅前须知\"></a>阅前须知</h1><p><code>阻塞 IO</code> 和 <code>非阻塞 IO</code></p>\n<p>这两个概念是 <code>程序级别</code> 的。主要描述是程序请求操作系统 IO 操作之后，如果 IO 资源没有准备好，那么程序如何处理问题：前者等待，后者继续执行（并且使用线程一直轮询，直到有 IO 资源准备好）</p>\n<p><code>同步 IO </code> 和 <code>非同步IO</code></p>\n<p>这两个概念是<code>操作系统级别</code>的。主要描述的是操作系统在收到程序请求 IO 操作后，如果 IO 资源没有准备好，该如何相应程序的问题：前者不响应，后者返回一个标记，当 IO 资源准备好之后，在用事件机制返回给程序。</p>\n<h1 id=\"一、BIO（Blocking-I-O）\"><a href=\"#一、BIO（Blocking-I-O）\" class=\"headerlink\" title=\"一、BIO（Blocking I&#x2F;O）\"></a>一、BIO（Blocking I&#x2F;O）</h1><h2 id=\"基本概念\"><a href=\"#基本概念\" class=\"headerlink\" title=\"基本概念\"></a>基本概念</h2><p>Java BIO：同步并阻塞（传统阻塞性），应用程序中进程在发起 IO 调用后至内核执行 IO 操作返回结果之前，若发起系统调用的线程一直处于等待状态，则此次 IO 操作为阻塞 IO。阻塞 IO 简称 BIO，Blocking IO。</p>\n<p>以前大多数网络通信方式都是阻塞模式，即：</p>\n<ul>\n<li>客户端向服务器端发送请求后，客户端会一直等待（不会再做其他事情），直到服务器端返回结果或者网络出现问题。</li>\n<li>服务端同样的，当在处理某个客户端 A 发来的请求是，另一个客户端 B 发来的请求会等待，直到服务器端的这个处理线程完成上个处理。</li>\n</ul>\n<p> <img src=\"/img/acea8af4268c8d552741ccebcb2d34ec_MD5.png\" alt=\"BIO请求流程图\"></p>\n<h2 id=\"使用实例\"><a href=\"#使用实例\" class=\"headerlink\" title=\"使用实例\"></a>使用实例</h2><ol>\n<li>服务器启动一个 ServerSocket。</li>\n<li>客户端启动 Socket 对服务器进行通信，默认情况下服务器端需要对每个客户建立一个线程与之通讯。</li>\n<li>客户端发出请求后，先咨询服务器是否有线程响应，如果没有则会等待，或者被拒绝。</li>\n<li>如果有响应，客户端线程会等待请求结束后，再继续执行。</li>\n</ol>\n<pre><code class=\"language-java\">package com.atguigu.bio;\n\nimport java.io.InputStream;\nimport java.net.ServerSocket;\nimport java.net.Socket;\nimport java.util.concurrent.ExecutorService;\nimport java.util.concurrent.Executors;\n\npublic class BIOServer &#123;\n    \n    public static void main(String[] args) throws Exception &#123;\n        //线程池机制\n        //思路\n        //1. 创建一个线程池\n        //2. 如果有客户端连接，就创建一个线程，与之通讯(单独写一个方法)\n        ExecutorService newCachedThreadPool = Executors.newCachedThreadPool();\n        //创建ServerSocket\n        ServerSocket serverSocket = new ServerSocket(6666);\n        System.out.println(&quot;服务器启动了&quot;);\n        while (true) &#123;\n            System.out.println(&quot;线程信息id = &quot; + Thread.currentThread().getId() + &quot;名字 = &quot; + Thread.currentThread().getName());\n            //监听，等待客户端连接\n            System.out.println(&quot;等待连接....&quot;);\n            //会阻塞在accept()\n            final Socket socket = serverSocket.accept();\n            System.out.println(&quot;连接到一个客户端&quot;);\n            //就创建一个线程，与之通讯(单独写一个方法)\n            newCachedThreadPool.execute(new Runnable() &#123;\n                public void run() &#123;//我们重写\n                    //可以和客户端通讯\n                    handler(socket);\n                &#125;\n            &#125;);\n        &#125; \n    &#125;\n    \n    //编写一个handler方法，和客户端通讯\n    public static void handler(Socket socket) &#123;\n        try &#123;\n            System.out.println(&quot;线程信息id = &quot; + Thread.currentThread().getId() + &quot;名字 = &quot; + Thread.currentThread().getName());\n            byte[] bytes = new byte[1024];\n            //通过socket获取输入流\n            InputStream inputStream = socket.getInputStream();\n            //循环的读取客户端发送的数据\n            while (true) &#123;\n                System.out.println(&quot;线程信息id = &quot; + Thread.currentThread().getId() + &quot;名字 = &quot; + Thread.currentThread().getName());\n                System.out.println(&quot;read....&quot;);\n                int read = inputStream.read(bytes);\n                if (read != -1) &#123;\n                    System.out.println(new String(bytes, 0, read));//输出客户端发送的数据\n                &#125; else &#123;\n                    break;\n                &#125;\n            &#125;\n        &#125; catch (Exception e) &#123;\n            e.printStackTrace();\n        &#125; finally &#123;\n            System.out.println(&quot;关闭和client的连接&quot;);\n            try &#123;\n                socket.close();\n            &#125; catch (Exception e) &#123;\n                e.printStackTrace();\n            &#125;\n        &#125;\n    &#125;\n&#125;\n</code></pre>\n<h2 id=\"问题分析\"><a href=\"#问题分析\" class=\"headerlink\" title=\"问题分析\"></a>问题分析</h2><p>传统的 IO 模型，其主要是一个 Server 对接 N 个客户端，在客户端连接之后，为每个客户端分配一个子线程。如图所示：</p>\n<p> <img src=\"/img/0fb77c535fcbf8f4264b6eff292fd210_MD5.png\" alt=\"传统IO模型\"></p>\n<p>从图中可以看出，传统 IO 的特点在于：</p>\n<ul>\n<li>每个客户端连接到达时，服务端会分配一个线程给该客户端，该线程处理包括读取数据，解码，业务计算，编码，以及发送数据整个过程</li>\n<li>同一时刻，服务端的吞吐量与服务器所提供的线程数量呈线性关系的。</li>\n</ul>\n<p>如果并发量不大，运行没有问题，但是如果海量并发时候，就会出现问题：</p>\n<ol>\n<li>每次请求都要创建独立的线程，与对应的客户端进行数据的Read，业务处理，数据Write、</li>\n<li>当并发数较大时，需要创建大量线程处理连接，资源占用较大。</li>\n<li>连接建立后，如果当前线程展示没有数据可读，则线程就阻塞在Read操作上，造成线程资源浪费。</li>\n</ol>\n<h2 id=\"改进：多线程方式-伪异步方式\"><a href=\"#改进：多线程方式-伪异步方式\" class=\"headerlink\" title=\"改进：多线程方式 - 伪异步方式\"></a>改进：多线程方式 - 伪异步方式</h2><p>上述说的情况只是服务器只有一个线程的情况，那么如果引入多线程是不是可以解决这个问题：</p>\n<ul>\n<li>当服务器收到客户端 X 的请求后，（读取到所有的请求数据后）将这个请求送入到一个独立线程进行处理，然后主线程继续接收客户端 Y 的请求。</li>\n<li>客户端侧，也可以用一个子线程和服务器端进行通信。这样客户端主线程的其他工作不受影响，当服务器有响应信息时候再有这个子线程通过 <code>监听模式/观察模式</code>（等其他设计模式）通知主线程。</li>\n</ul>\n<p> <img src=\"/img/ed84ace61748c9dbdaf3f9718f21ff21_MD5.png\" alt=\"多线程方式 - 伪异步\"></p>\n<p>但是多线程解决这个问题有局限性：</p>\n<ul>\n<li>操作系统通知accept() 的方式还是单个，即：服务器收到数据报文之后的“业务处理过程”可以多线程，但是报文的接收还是需要一个个来</li>\n<li>在操作系统中，线程是有限的。线程越多，CPU 切换所需时间也越长，用来处理真正业务的需求也就越少。</li>\n<li>创建线程需要较大的资源消耗。JVM 创建一个线程，即使不进行任何工作，也需要分配一个堆栈空间（128k）。</li>\n<li>如果程序中使用了大量的长连接，线程是不会关闭的，资源消耗更容易失控。</li>\n</ul>\n<blockquote>\n<p>为啥 <code>serverSocket. accept()</code> 会出现阻塞？</p>\n</blockquote>\n<p>是因为 Java 通过 JNI 调用的系统层面的 <code>accept0()</code> 方法，<code>accept0()</code> 规定如果发现套间字从指定的端口来，就会等待。其实就是内部实现是操作系统级别的同步 IO。</p>\n<h1 id=\"二、NIO（non-Blocking-I-O）\"><a href=\"#二、NIO（non-Blocking-I-O）\" class=\"headerlink\" title=\"二、NIO（non-Blocking I&#x2F;O）\"></a>二、NIO（non-Blocking I&#x2F;O）</h1><p>了解 NIO 之前我们先来看看标准 I&#x2F;O（Standard I&#x2F;O）。</p>\n<p>Standard I&#x2F;O 是对字节的读写，在进行 I&#x2F;O 之前，首先创建一个流对象，流对象的读写操作都是按字节，一个字节一个字节的读或者写。而 NIO 把 I&#x2F;O 抽象成块，类似磁盘的读写，每次 I&#x2F;O 操作的单位都是一个块，块被读入内存之后就是一个 <code> byte[]</code>，NIO 一次可以读或者写多个字节。</p>\n<h2 id=\"流和块\"><a href=\"#流和块\" class=\"headerlink\" title=\"流和块\"></a>流和块</h2><p>IO 和 NIO 最重要的区别就是对数据的打包和传输的方式，IO 是以流的方式处理数据，而 NIO 以块的方式处理数据。</p>\n<p>面向流的 IO 一次性处理一个字节数据：一个输入流产生一个字节数据，一个输出流消费一个字节数据。为流式数据创建过滤器非常容易，链接几个过滤器，以便每个过滤器只负责复杂处理机制的一部分。不利的一面是，面向流的 IO 通常处理非常慢。</p>\n<p>面向块的 I&#x2F;O 一次性处理一个数据块：按块处理数据比按流处理数据要快的多，但是面向块的 I&#x2F;O 确实一些面向流的 I&#x2F;O 所具有的优雅和简单。</p>\n<p>I&#x2F;O 包和 NIO 已经很好的集成了，<code>java.io.*</code> 中已经以 NIO 重新实现了，可以利用一些 NIO 的特性。例如：在 <code>java.io.*</code> 中某些类包含以块的形式读写数据的操作，这使得及时在面向流的系统中，处理数据也会更快。</p>\n<h2 id=\"基本概念-1\"><a href=\"#基本概念-1\" class=\"headerlink\" title=\"基本概念\"></a>基本概念</h2><p>Java NIO：同步非阻塞，服务器实现模式为一个线程处理多个请求（连接），即客户端发送的连接请求都会注册到多路复用器上，多路复用器轮训到连接有 I&#x2F;O 请求就进行处理。</p>\n<p><strong>核心概念：</strong></p>\n<ol>\n<li><strong>三大核心：</strong> Channel（通道）、Buffer（缓冲区）、Selector（选择器）。</li>\n<li><strong>面向缓冲区，或者是面向块编程。</strong> 数据读取到一个它稍后处理的缓冲区，需要时可在缓冲区中前后移动，这就增加了处理过程中的灵活性，使用它可以提供非阻塞式的高伸缩弹性网络。</li>\n<li><strong>非阻塞模式</strong>， 使一个线程从某个通道发送请求或者读取数据，但是他仅能得到目前可用的数据，如果目前没有数据可用，就什么都不会获取，而不是保持线程阻塞。所以知道数据变得可读取之前，该线程还可以去做其他实行。</li>\n<li><strong>Channel 和 Buffer 一一对应。</strong></li>\n<li><strong>一个线程只有一个 Selector，一个线程对应对个 Channel（连接）</strong>。</li>\n<li>程序切换到哪个 Channel 是由事件决定，Event 就是个重要概念。</li>\n<li>Selector 会根据不同的事件，在各个通道上切换。</li>\n<li><strong>Buffer 是一个内存块，底层就是一个数组</strong>。</li>\n<li>数据读写都是通过 Buffer，区别于 BIO 的输入输出流，且<strong>双向</strong>，需要 <code>flip</code> 方法切换 <code>Channel</code> 是双向的 。</li>\n</ol>\n<h2 id=\"编程原理\"><a href=\"#编程原理\" class=\"headerlink\" title=\"编程原理\"></a>编程原理</h2><ol>\n<li>当客户端连接时，会通过 ServerSocketChannel 得到 SocketChannel。</li>\n<li>Selector 进行监听 select 方法，返回有事件发生的通道个数。</li>\n<li>将 SocketChannel 注册到 Selector 上（<code>register(Selector selector, int ops)</code>），一个 Selector 可以注册多个 SocketChannel。</li>\n<li>注册后返回 SelectionKey，会和该 Selector 关联（集合）。</li>\n<li>当有事件发生时，进一步得到各个 SelectionKey。</li>\n<li>通过channel () 方法，用 SelectionKey 反向获取 SocketChannel。</li>\n<li>可以通过得到的 channel，完成业务处理。</li>\n</ol>\n<h2 id=\"1-缓冲区（Buffer）\"><a href=\"#1-缓冲区（Buffer）\" class=\"headerlink\" title=\"1. 缓冲区（Buffer）\"></a>1. 缓冲区（Buffer）</h2><h3 id=\"Buffer-类及其子类\"><a href=\"#Buffer-类及其子类\" class=\"headerlink\" title=\"Buffer 类及其子类\"></a>Buffer 类及其子类</h3><p><code>ByteBuffer</code> 字节数据；<code>ShortBuffer</code> 字符串数据；<code>CharBuffer</code> 字符数据；<code>IntBuffer</code> 整数；<code>LongBuffer</code> 长整数；<code>DoubleBuffer</code> 小数；<code>FloatBuffer</code> 小数</p>\n<h3 id=\"Buffer-属性和方法\"><a href=\"#Buffer-属性和方法\" class=\"headerlink\" title=\"Buffer 属性和方法\"></a>Buffer 属性和方法</h3><p>Buffer 类提供了 4 个属性来提供数据元素信息：<code>capacity（容量）</code>：缓存区的最大容量，<code>Limit（终点）</code>：缓存区最大可操作位置，<code>Position（位置）</code> ：缓存区当前在操作的位置，<code>Mark（标记）</code>：标记位置</p>\n<pre><code class=\"language-java\">public abstract class Buffer&#123;\n\tpublic final int capacity();\n\tpublic final int position();\n\tpublic final Buffer position(int newPosition);\n\tpublic final int limit();\n\tpublic final Buffer limit(int newLimit);\n\t\n&#125;\n//其中比较常用的就是ByteBuffer（二进制数据），该类主要有以下方法\npublic abstract class ByteBuffer()&#123;\n\tpublic static ByteBuffer allocateDirect(int capacity);//直接创建缓冲区\n\tpublic static ByteBuffer allocate(int capacity);//设置缓冲区的初始容量\n\tpublic static ByteBuffer wrap(byte[] array);//把一个数组放入到缓冲区使用\n\t//构造初始化位置offset和上界length的缓冲区\n\tpublic static ByteBuffer wrap(byte[] array,int offset,int length);\n\t//缓冲区读取相关API\n\tpublic abstract byte get();//从当前位置position上get，get之后，positon会+1\n\tpublic abstract byte get(int index);//从绝对位置获取\n\tpublic abstract ByteBuffer put(byte b);//当前位置上put，put之后，position会+1\n\tpublic abstract ByteBuffer put(int index,byte b);//从绝对位置put\t\n&#125;\n</code></pre>\n<p>状态变量的改变过程举例:</p>\n<p>① 新建一个大小为 8 个字节的缓冲区，此时 position 为 0，而 limit &#x3D; capacity &#x3D; 8。capacity 变量不会改变，下面的讨论会忽略它。</p>\n<p> <img src=\"/img/a8f0d4502adb087892e11866bdac7d57_MD5.png\" alt=\"状态变量的改变过程1\"></p>\n<p>② 从输入通道中读取 5 个字节数据写入缓冲区中，此时 position 移动设置为 5，limit 保持不变。</p>\n<p> <img src=\"/img/5ee1af7a6012fd34b62704d5b2867320_MD5.png\" alt=\"状态变量的改变过程2\"></p>\n<p>③ 在将缓冲区的数据写到输出通道之前，需要先调用 flip() 方法，这个方法将 limit 设置为当前 position，并将 position 设置为 0。</p>\n<p> <img src=\"/img/5cd2995739f1b0e1f4b355a2471c38aa_MD5.png\" alt=\"状态变量的改变过程3\"></p>\n<p>④ 从缓冲区中取 4 个字节到输出缓冲中，此时 position 设为 4。</p>\n<p> <img src=\"/img/0d87f8ba4e770fbdcd6c6fc61fb84862_MD5.png\" alt=\"状态变量的改变过程4\"></p>\n<p>⑤ 最后需要调用 clear() 方法来清空缓冲区，此时 position 和 limit 都被设置为最初位置。</p>\n<p> <img src=\"/img/f6ef08bdd8b4ff67a419bfe9b7dbc0f2_MD5.png\" alt=\"状态变量的改变过程5\"></p>\n<h3 id=\"文件-NIO-实例\"><a href=\"#文件-NIO-实例\" class=\"headerlink\" title=\"文件 NIO 实例\"></a>文件 NIO 实例</h3><p>以下展示了使用 NIO 快速复制文件的实例：</p>\n<pre><code class=\"language-java\">public static void fastCopy(String src, String dist) throws IOException &#123;\n\n    /* 获得源文件的输入字节流 */\n    FileInputStream fin = new FileInputStream(src);\n\n    /* 获取输入字节流的文件通道 */\n    FileChannel fcin = fin.getChannel();\n\n    /* 获取目标文件的输出字节流 */\n    FileOutputStream fout = new FileOutputStream(dist);\n\n    /* 获取输出字节流的通道 */\n    FileChannel fcout = fout.getChannel();\n\n    /* 为缓冲区分配 1024 个字节 */\n    ByteBuffer buffer = ByteBuffer.allocateDirect(1024);\n\n    while (true) &#123;\n\n        /* 从输入通道中读取数据到缓冲区中 */\n        int r = fcin.read(buffer);\n\n        /* read() 返回 -1 表示 EOF */\n        if (r == -1) &#123;\n            break;\n        &#125;\n\n        /* 切换读写 */\n        buffer.flip();\n\n        /* 把缓冲区的内容写入输出文件中 */\n        fcout.write(buffer);\n        \n        /* 清空缓冲区 */\n        buffer.clear();\n    &#125;\n&#125;\n</code></pre>\n<h2 id=\"2-通道（Channel）\"><a href=\"#2-通道（Channel）\" class=\"headerlink\" title=\"2. 通道（Channel）\"></a>2. 通道（Channel）</h2><p>通道类似流，但是有如下区别：</p>\n<ul>\n<li>通道可以同时读写，而流只能读或写</li>\n<li>通道可以实现异步读写数据</li>\n<li>通道可以从缓冲区读数据，也可以写数据到缓冲区</li>\n</ul>\n<h3 id=\"通道分类\"><a href=\"#通道分类\" class=\"headerlink\" title=\"通道分类\"></a>通道分类</h3><p>Channel 在 NIO 中是一个接口 <code>public interface Channle extends Closeable&#123;&#125;</code>。其中，常用的 Channel 类有：</p>\n<ol>\n<li><code>FileChannel</code>：用于文件的数据读写；</li>\n<li><code>DatagramChannel</code>：用于 UDP 的数据读写；</li>\n<li><code>ServerSocketChannel</code>：可以监听新来的连接，对每一个新进来的连接都会创建一个 SocketChannel。只有通过这个通道，应用程序才能箱操作系统注册支持“多路复用 IO”的端口减轻。支持 TCP 和 UDP 协议；</li>\n<li><code>SocketChannel</code>：TCP Socket 套接字的监听通道，用于 TCP 的数据读写</li>\n<li>其他的通道包括：</li>\n</ol>\n<p> <img src=\"/img/94530647a3be7da4d2de055fff8bacaf_MD5.png\" alt=\"其他通道\"></p>\n<h3 id=\"FileChannel-类\"><a href=\"#FileChannel-类\" class=\"headerlink\" title=\"FileChannel 类\"></a>FileChannel 类</h3><p>对本地文件进行 IO 操作，常用方法及实例应用：</p>\n<pre><code class=\"language-java\">//从通道读取数据并放到缓冲区内\npublic int read(ByteBuffer content);\n//从缓冲区写数据到通道中\npublic int write(ByteBuffer content);\n//从目标通道中复制数据到当前通道内\npublic long transferFrom(ReadableByteChannel src,long position,long count);\n//把数据从当前通道复制到目标通道\npublic long transferTo(long position,long count,WritabelByteChannel target);\n</code></pre>\n<p>1 . 写入文件，使用之前 <code>ByteBuffer</code> 和 <code>FileChannel</code> 类</p>\n<pre><code class=\"language-java\">//使用之前ByteBuffer和FileChannel类，写入文件\nimport java.io.FileOutputStream;\nimport java.nio.ByteBuffer;\nimport java.nio.channels.FileChannel;\n\npublic class NIOFileChannel&#123;\n\tpublic static void main(String[] args) throws Exception&#123;\n\t\tString str = &quot;hello,world&quot;;\n\t\t//创一个输出流 -&gt; channel\n\t\tFileOutputStream stream = new FileOutputStream(&quot;d:\\\\file.txt&quot;);\n\t\t//通过 stream 获取对应的 FileChannel\n\t\t//这个 fileChannel 真实类型是 FileChannelImpl\n\t\tFileChannel fileChannel = stream.getChannel();\n\n\t\t//创建一个缓冲区 ByteBuffer\n\t\tByteBuffer byteBuffer = ByteBuffer.allocate(1024);\n\t\t//将 str 放入到缓冲区\n\t\tbyteBuffer.put(str.getBytes());\n\t\t//对 byteBuffer 进行 flip\n\t\tbyteBuffer.flip();\n\n\t\t//将 byteBuffer 写入到 fileChannel\n\t\tfileChannel.write(byteBuffer);\n\t\tfileOutputStream.close();\n\t&#125;\n\n&#125;\n</code></pre>\n<p>2 . 读取文件数据并展示，使用之前 <code>ByteBuffer</code> 和 <code>FileChannel</code> 类</p>\n<pre><code class=\"language-java\">//读取本地文件\nimport java.io.FileOutputStream;\nimport java.nio.ByteBuffer;\nimport java.nio.channels.FileChannel;\n\npublic class NIOFileChannel&#123;\n\tpublic static void main(String[] args) throws Exception&#123;\n\t\t//创一个输出流 -&gt; channel\n\t\tFile file = new File(&quot;d:\\\\file.txt&quot;);\n\t\tFileOutputStream stream = new FileOutputStream(file);\n\t\t//通过 stream 获取对应的 FileChannel\n\t\t//这个 fileChannel 真实类型是 FileChannelImpl\n\t\tFileChannel fileChannel = stream.getChannel();\n\n\t\t//创建一个缓冲区 ByteBuffer\n\t\tByteBuffer byteBuffer = ByteBuffer.allocate((int)file.length());\n\n\t\t//将 byteBuffer 写入到 fileChannel\n\t\tfileChannel.read(byteBuffer);\n\t\t//将 byteBuffer的字节转化成String\n\t\tSystem.out.println(new String(byteBuffer.array()));\n\t\tfileOutputStream.close();\n\t&#125;\n\n&#125;\n</code></pre>\n<p>3 . 使用一个 <code>Buffer</code> 完成文件的读取、写入</p>\n<pre><code class=\"language-java\">import java.io.FileInputStream;\nimport java.io.FileOutputStream;\nimport java.nio.ByteBuffer;\nimport java.nio.channels.FileChannel;\n\npublic class NIOFileChannel03 &#123;\n\n    public static void main(String[] args) throws Exception &#123;\n\n        FileInputStream fileInputStream = new FileInputStream(&quot;1.txt&quot;);\n        FileChannel fileChannel01 = fileInputStream.getChannel();\n        FileOutputStream fileOutputStream = new FileOutputStream(&quot;2.txt&quot;);\n        FileChannel fileChannel02 = fileOutputStream.getChannel();\n\n        ByteBuffer byteBuffer = ByteBuffer.allocate(512);\n        \n        while (true) &#123; //循环读取\n\n            //这里有一个重要的操作，一定不要忘了\n            /*\n            public final Buffer clear() &#123;\n                position = 0;\n                limit = capacity;\n                mark = -1;\n                return this;\n            &#125;\n            */\n            byteBuffer.clear(); //清空 buffer\n            int read = fileChannel01.read(byteBuffer);\n            System.out.println(&quot;read = &quot; + read);\n            if (read == -1) &#123; //表示读完\n                break;\n            &#125;\n\n            //将 buffer 中的数据写入到 fileChannel02--2.txt\n            byteBuffer.flip();\n            fileChannel02.write(byteBuffer);\n        &#125;\n\n        //关闭相关的流\n        fileInputStream.close();\n        fileOutputStream.close();\n    &#125;\n&#125;\n</code></pre>\n<p>4 . 拷贝文件transferFrom 方法</p>\n<pre><code class=\"language-java\">import java.io.FileInputStream;\nimport java.io.FileOutputStream;\nimport java.nio.channels.FileChannel;\n\npublic class NIOFileChannel04 &#123;\n\n    public static void main(String[] args) throws Exception &#123;\n\n        //创建相关流\n        FileInputStream fileInputStream = new FileInputStream(&quot;d:\\\\a.jpg&quot;);\n        FileOutputStream fileOutputStream = new FileOutputStream(&quot;d:\\\\a2.jpg&quot;);\n        \n        //获取各个流对应的 FileChannel\n        FileChannel sourceCh = fileInputStream.getChannel();\n        FileChannel destCh = fileOutputStream.getChannel();\n\n        //使用 transferForm 完成拷贝\n        destCh.transferFrom(sourceCh, 0, sourceCh.size());\n\n        //关闭相关通道和流\n        sourceCh.close();\n        destCh.close();\n        fileInputStream.close();\n        fileOutputStream.close();\n    &#125;\n&#125;\n</code></pre>\n<h3 id=\"Buffer-和-Channel-注意事项\"><a href=\"#Buffer-和-Channel-注意事项\" class=\"headerlink\" title=\"Buffer 和 Channel 注意事项\"></a>Buffer 和 Channel 注意事项</h3><p><strong>1. ByteBuffer 支持类型化的 put 和 get，put 放什么，get 取出什么，不然出现 BufferUnderflowException 异常</strong></p>\n<pre><code class=\"language-java\">import java.nio.ByteBuffer;\n\npublic class NIOByteBufferPutGet &#123;\n\n    public static void main(String[] args) &#123;\n        \n        //创建一个 Buffer\n        ByteBuffer buffer = ByteBuffer.allocate(64);\n\n        //类型化方式放入数据\n        buffer.putInt(100);\n        buffer.putLong(9);\n        buffer.putChar(&#39;尚&#39;);\n        buffer.putShort((short) 4);\n\n        //取出\n        buffer.flip();\n        \n        System.out.println();\n        \n        System.out.println(buffer.getInt());\n        System.out.println(buffer.getLong());\n        System.out.println(buffer.getChar());\n        System.out.println(buffer.getShort());\n    &#125;\n&#125;\n</code></pre>\n<p><strong>2. 普通 Buffer 转成只读 Buffer</strong></p>\n<pre><code class=\"language-java\">\nimport java.nio.ByteBuffer;\n\npublic class ReadOnlyBuffer &#123;\n\n    public static void main(String[] args) &#123;\n\n        //创建一个 buffer\n        ByteBuffer buffer = ByteBuffer.allocate(64);\n\n        for (int i = 0; i &lt; 64; i++) &#123;\n            buffer.put((byte) i);\n        &#125;\n\n        //读取\n        buffer.flip();\n\n        //得到一个只读的 Buffer\n        ByteBuffer readOnlyBuffer = buffer.asReadOnlyBuffer();\n        System.out.println(readOnlyBuffer.getClass());\n\n        //读取\n        while (readOnlyBuffer.hasRemaining()) &#123;\n            System.out.println(readOnlyBuffer.get());\n        &#125;\n\n        readOnlyBuffer.put((byte) 100); //ReadOnlyBufferException\n    &#125;\n&#125;\n</code></pre>\n<p><strong>3. NIO 中 MappedByteBuffer，可以让文件直接在堆外内存修改</strong></p>\n<pre><code class=\"language-java\">\nimport java.io.RandomAccessFile;\nimport java.nio.MappedByteBuffer;\nimport java.nio.channels.FileChannel;\n\n/**\n * 说明 1.MappedByteBuffer 可让文件直接在内存（堆外内存）修改,操作系统不需要拷贝一次\n */\npublic class MappedByteBufferTest &#123;\n\n    public static void main(String[] args) throws Exception &#123;\n\n        RandomAccessFile randomAccessFile = new RandomAccessFile(&quot;1.txt&quot;, &quot;rw&quot;);\n        //获取对应的通道\n        FileChannel channel = randomAccessFile.getChannel();\n\n        /**\n         * 参数 1:FileChannel.MapMode.READ_WRITE 使用的读写模式\n         * 参数 2：0：可以直接修改的起始位置\n         * 参数 3:5: 是映射到内存的大小（不是索引位置），即将 1.txt 的多少个字节映射到内存\n         * 可以直接修改的范围就是 0-5\n         * 实际类型 DirectByteBuffer\n         */\n        MappedByteBuffer mappedByteBuffer = channel.map(FileChannel.MapMode.READ_WRITE, 0, 5);\n\n        mappedByteBuffer.put(0, (byte) &#39;H&#39;);\n        mappedByteBuffer.put(3, (byte) &#39;9&#39;);\n        mappedByteBuffer.put(5, (byte) &#39;Y&#39;);//IndexOutOfBoundsException\n\n        randomAccessFile.close();\n        System.out.println(&quot;修改成功~~&quot;);\n    &#125;\n&#125;\n</code></pre>\n<ol start=\"4\">\n<li><strong>NIO 还支持通过多个 Buffer（即 Buffer数组）完成读写操作，即 Scattering 和 Gathering</strong></li>\n</ol>\n<pre><code class=\"language-java\">import java.net.InetSocketAddress;\nimport java.nio.ByteBuffer;\nimport java.nio.channels.ServerSocketChannel;\nimport java.nio.channels.SocketChannel;\nimport java.util.Arrays;\n\n/**\n * Scattering：将数据写入到 buffer 时，可以采用 buffer 数组，依次写入 [分散]\n * Gathering：从 buffer 读取数据时，可以采用 buffer 数组，依次读\n */\npublic class ScatteringAndGatheringTest &#123;\n\n    public static void main(String[] args) throws Exception &#123;\n        \n        //使用 ServerSocketChannel 和 SocketChannel 网络\n        ServerSocketChannel serverSocketChannel = ServerSocketChannel.open();\n        InetSocketAddress inetSocketAddress = new InetSocketAddress(7000);\n\n        //绑定端口到 socket，并启动\n        serverSocketChannel.socket().bind(inetSocketAddress);\n\n        //创建 buffer 数组\n        ByteBuffer[] byteBuffers = new ByteBuffer[2];\n        byteBuffers[0] = ByteBuffer.allocate(5);\n        byteBuffers[1] = ByteBuffer.allocate(3);\n\n        //等客户端连接 (telnet)\n        SocketChannel socketChannel = serverSocketChannel.accept();\n\n        int messageLength = 8; //假定从客户端接收 8 个字节\n\n        //循环的读取\n        while (true) &#123;\n            int byteRead = 0;\n\n            while (byteRead &lt; messageLength) &#123;\n                long l = socketChannel.read(byteBuffers);\n                byteRead += l; //累计读取的字节数\n                System.out.println(&quot;byteRead = &quot; + byteRead);\n                //使用流打印,看看当前的这个 buffer 的 position 和 limit\n                Arrays.asList(byteBuffers).stream().map(buffer -&gt; &quot;position = &quot; + buffer.position() + &quot;, limit = &quot; + buffer.limit()).forEach(System.out::println);\n            &#125;\n\n            //将所有的 buffer 进行 flip\n            Arrays.asList(byteBuffers).forEach(buffer -&gt; buffer.flip());\n            //将数据读出显示到客户端\n            long byteWirte = 0;\n            while (byteWirte &lt; messageLength) &#123;\n                long l = socketChannel.write(byteBuffers);//\n                byteWirte += l;\n            &#125;\n            \n            //将所有的buffer进行clear\n            Arrays.asList(byteBuffers).forEach(buffer -&gt; &#123;\n                buffer.clear();\n            &#125;);\n            \n            System.out.println(&quot;byteRead = &quot; + byteRead + &quot;, byteWrite = &quot; + byteWirte + &quot;, messagelength = &quot; + messageLength);\n        &#125;\n    &#125;\n&#125;\n</code></pre>\n<h2 id=\"3-Selector（选择器）\"><a href=\"#3-Selector（选择器）\" class=\"headerlink\" title=\"3. Selector（选择器）\"></a>3. Selector（选择器）</h2><h3 id=\"基本概念-2\"><a href=\"#基本概念-2\" class=\"headerlink\" title=\"基本概念\"></a>基本概念</h3><p>NIO 常常被叫做非阻塞 IO，主要是因为 NIO 在网络通信中的非阻塞特性被广泛使用。NIO 实现了 IO 多路复用中的 Reator 模型，一个线程 Thread 使用一个选择器 Selector 通过轮询的方式去监听多个 Channel 上的事件，从而让一个线程能够处理多个事件。</p>\n<p>通过配置监听的通道 Channel 为非阻塞，那么当 Channel 上的 IO 事件还未到达时，就不会进入到阻塞状态一直等待，而是鸡血轮询其他 Channel，找到 IO 事件已经到达的 Channel 执行。</p>\n<p>以为创建和切换线程的开销很大，因此使用一个线程处理多个事件显然比一个线程处理一个事件具有更好的性能。</p>\n<p> <img src=\"/img/0b37a3b751ec9aa08efa75ace30e23c4_MD5.png\" alt=\"选择器\"></p>\n<ol>\n<li>Java 中的 NIO 可以用一个线程，处理多个客户端连接，就会使用到 Selector（选择器）</li>\n<li>多个 Channel 以事件的方式注册到 Selector</li>\n<li>只有在连接通道有真正的读写事件的时候，才会进行读写，减少系统开销</li>\n<li>避免了<code>多线程之间的上下文切换导致的开销</code></li>\n</ol>\n<pre><code class=\"language-java\">//Selector 类是一个抽象类，常用方法和说明如下：\npublic abstract class Selector implements Closeable&#123;\n\tpublic static Selector open();//监控所有注册的通道，当其中有IO操作可以进行时，将SelectionKey加入到内部的集合中并返回，参数用来设置超时时间\n\tpublic Set&lt;SelectionKey&gt; selectedKey();//从内部集合中得到所有的SelectionKey\t\n&#125;\n</code></pre>\n<h3 id=\"使用方法\"><a href=\"#使用方法\" class=\"headerlink\" title=\"使用方法\"></a>使用方法</h3><ol>\n<li><strong>创建选择器</strong></li>\n</ol>\n<pre><code class=\"language-java\">Selector selector = Selector.open();\n</code></pre>\n<ol start=\"2\">\n<li><strong>将通道注册到选择器上</strong></li>\n</ol>\n<pre><code class=\"language-java\">ServerSocketChannel ssChannel = ServerSocketChannel.open();\nssChannel.configureBlocking(false);\nssChannel.register(selector,SelectionKey.OP_ACCEPT);\n</code></pre>\n<p>将通道注册到选择器上，还需要指定要注册的具体事件，主要有以下几类：</p>\n<p><code>SelectionKey. OP_CONNECT</code>、<code>SelectionKey. OP_ACCEPT</code>、<code>SelectionKey. OP_READ</code>、 <code>SelectionKey. OP_WRITE</code></p>\n<p>他们在 SelectionKey 的定义如下：</p>\n<pre><code class=\"language-java\">public static final int OP_READ = 1 &lt;&lt; 0;\npublic static final int OP_WRITE = 1 &lt;&lt; 2;\npublic static final int OP_CONNECT = 1 &lt;&lt; 3;\npublic static final int OP_ACCEPT = 1 &lt;&lt; 4;\n</code></pre>\n<p>可以看出每个事件都能当成一个位域，从而组成事件集整数。例如：</p>\n<pre><code class=\"language-java\">int intersetSet = SelectionKey.OP_READ | SelectionKey.OP_WRITE;\n</code></pre>\n<ol start=\"3\">\n<li><strong>监听事件</strong></li>\n</ol>\n<pre><code class=\"language-java\">int num = selector.select();\n</code></pre>\n<p>使用 <code>select()</code> 方法来监听到达的事件，它会一直阻塞知道有至少一件事件到达。</p>\n<ol start=\"4\">\n<li><strong>获取到达的事件</strong></li>\n</ol>\n<pre><code class=\"language-java\">Set&lt;SelectionKey&gt; keys = selector.selectedKeys();\nIterator&lt;SelectionKey&gt; keyIterator = keys.iterator();\nwhile(keyIterator.hasNext())&#123;\n\tSelectionKey keyu = keyIterator.next();\n\tif(key.isAcceptabnle())&#123;\n\t// ...\n\t&#125;else if(key.isReadable())&#123;\n\t// ...\n\t&#125;\n\tkeyIterator.remove();\n&#125;\n</code></pre>\n<ol start=\"5\">\n<li><strong>时间循环</strong></li>\n</ol>\n<p>因为一次 select() 调动不能处理完所有的事件，并且服务器端有可能需要一直监听事件，因此服务器端处理时间的代码一般会放在一个死循环内。</p>\n<pre><code class=\"language-java\">while (true) &#123; \n\tint num = selector.select(); \n\tSet&lt;SelectionKey&gt; keys = selector.selectedKeys(); \n\tIterator&lt;SelectionKey&gt; keyIterator = keys.iterator(); \n\twhile (keyIterator.hasNext()) &#123; \n\t\tSelectionKey key = keyIterator.next(); \n\t\tif (key.isAcceptable()) &#123; \n\t\t  // ... \n\t\t&#125; else if (key.isReadable()) &#123;\n\t\t  // ... \n\t\t&#125; \n\t\tkeyIterator.remove(); \n\t&#125;\n&#125;\n</code></pre>\n<h3 id=\"套接字-NIO-实例\"><a href=\"#套接字-NIO-实例\" class=\"headerlink\" title=\"套接字 NIO 实例\"></a>套接字 NIO 实例</h3><pre><code class=\"language-java\">public class NIOServer &#123;\n \tpublic static void main(String[] args) throws IOException &#123;\n\t\tSelector selector = Selector.open();\n\t\tServerSocketChannel ssChannel = ServerSocketChannel.open();\n\t\tssChannel.configureBlocking(false);\n\t\tssChannel.register(selector, SelectionKey.OP_ACCEPT);\n\t\tServerSocket serverSocket = ssChannel.socket();\n\t\tInetSocketAddress address = new InetSocketAddress(&quot;127.0.0.1&quot;, 8888);\n\t\tserverSocket.bind(address);\n\t\twhile(true)&#123;\n\t\t\tselector.select();\n\t\t\tSet&lt;SelectionKey&gt; keys = selector.selectedKeys();\n\t\t\tIterator&lt;SelectionKey&gt; keyIterator = keys.iterator();\n\t\t\twhile (keyIterator.hasNext())&#123;\n\t\t\t\tSelectionKey key = keyIterator.next();\n\t\t\t\tif (key.isAcceptable()) &#123;\n\t\t\t\t\tServerSocketChannel ssChannel1 = (ServerSocketChannel) key.channel();// 服务器会为每个新连接创建一个 SocketChannel SocketChannel sChannel = ssChannel1.accept();\n\t\t\t\t\tsChannel.configureBlocking(false);// 这个新连接主要用于从客户端读取数据 \n\t\t\t\t\tsChannel.register(selector, SelectionKey.OP_READ);\n\t\t\t\t&#125;else if (key.isReadable()) &#123;\n\t\t\t\t\tSocketChannel sChannel = (SocketChannel) key.channel();\n\t\t\t\t\tSystem.out.println(readDataFromSocketChannel(sChannel));\n\t\t\t\t\tsChannel.close();\n\t\t\t\t&#125;\n \t\t\tkeyIterator.remove();\n\t\t\t&#125;\n\t\t&#125;\n \t&#125;\n\tprivate static String readDataFromSocketChannel(SocketChannel sChannel) throws IOException &#123;\n\t\tByteBuffer buffer = ByteBuffer.allocate(1024);\n\t\tStringBuilder data = new StringBuilder();\n\t\twhile(true) &#123;\n\t\t\tbuffer.clear();\n\t\t\tint n = sChannel.read(buffer);\n\t\t\tif (n == -1) &#123;\n\t\t\t\tbreak;\n\t\t\t&#125;\n\t\t\tbuffer.flip();\n\t\t\tint limit = buffer.limit();\n\t\t\tchar[] dst = new char[limit];\n\t\t\tfor (int i = 0;i &lt; limit;i++) &#123;\n\t\t\t\tdst[i] = (char) buffer.get(i);\n\t\t\t&#125;\n\t\t\tdata.append(dst);\n\t\t\tbuffer.clear();\n \t\t&#125;\n \t\treturn data.toString();\n \t&#125;\n &#125;\n</code></pre>\n<pre><code class=\"language-java\">public class NIOClient &#123;\n\tpublic static void main(String[] args) throws IOException&#123;\n\t\tSocket socket = new Socket(&quot;127.0.0.1&quot;，8888);\n\t\tOutputStream out = socket.getOutputStream();\n\t\tString s = &quot;hello world&quot;;\n\t\tout.write(s.getBytes());\n\t\tout.close();\n\t&#125;\n&#125;\n</code></pre>\n<h2 id=\"典型的多路复用-IO-实现\"><a href=\"#典型的多路复用-IO-实现\" class=\"headerlink\" title=\"典型的多路复用 IO 实现\"></a>典型的多路复用 IO 实现</h2><p>目前流程的多路复用 IO 实现主要宝库了四种：select、poll、epoll、kqueue。以下是其特性及区别：</p>\n<table>\n<thead>\n<tr>\n<th align=\"center\">IO 模型</th>\n<th align=\"center\">相对性能</th>\n<th align=\"center\">关键思路</th>\n<th align=\"center\">操作系统</th>\n<th align=\"center\">Java 支持情况</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"center\">select</td>\n<td align=\"center\">较高</td>\n<td align=\"center\">Reactor</td>\n<td align=\"center\">Win&#x2F;Linux</td>\n<td align=\"center\">支持，Reactor 模式（反应器设计模式）。Linux kernels 2.4 内核版本之前，默认用的是 select ；目前 windows 下对吧同步 IO 的支持，都是 select 模型</td>\n</tr>\n<tr>\n<td align=\"center\">poll</td>\n<td align=\"center\">较高</td>\n<td align=\"center\">Reactor</td>\n<td align=\"center\">Linux</td>\n<td align=\"center\">Linux 下的 Java 的 NIO 框架，Linux kernels 2.6 内核版本之前使用 poll 进行支持。也是使用的 Reactor 模式</td>\n</tr>\n<tr>\n<td align=\"center\">epoll</td>\n<td align=\"center\">高</td>\n<td align=\"center\">Reactor&#x2F;Proactor</td>\n<td align=\"center\">Linux</td>\n<td align=\"center\">Linux kernels 2.6 内核版本之后使用 epoll 进行支持</td>\n</tr>\n<tr>\n<td align=\"center\">kqueue</td>\n<td align=\"center\">高</td>\n<td align=\"center\">Proactor</td>\n<td align=\"center\">Linux</td>\n<td align=\"center\">目前 Java 版本不支持</td>\n</tr>\n</tbody></table>\n<h3 id=\"1-Reactor事件驱动模型\"><a href=\"#1-Reactor事件驱动模型\" class=\"headerlink\" title=\"1. Reactor事件驱动模型\"></a>1. Reactor事件驱动模型</h3><p> <img src=\"/img/10d0080498aba2649f1c04067965b579_MD5.png\" alt=\"Reactor事件驱动模型\"></p>\n<p>从图上可知：一个完整的 Reactor 事件驱动模型是有四个部分组成：客户端 Client，Reactor，Acceptor 和时间处理 Handler。其中 Acceptor 会不间断的接收客户端的连接请求，然后通过 Reactor 分发到不同 Handler 进行处理。改进后的 Reactor 有如下优点：</p>\n<ul>\n<li>虽然同是由一个线程接收连接请求进行网络读写，但是 Reactor 将客户端连接，网络读写，业务处理三大部分拆分，从而极大提高工作效率。</li>\n<li>Reactor 是以事件驱动的，相比传统 IO 阻塞式的，不必等待，大大提升了效率。</li>\n</ul>\n<h3 id=\"2-Reactor-模型——业务处理和-IO-分离\"><a href=\"#2-Reactor-模型——业务处理和-IO-分离\" class=\"headerlink\" title=\"2. Reactor 模型——业务处理和 IO 分离\"></a>2. Reactor 模型——业务处理和 IO 分离</h3><p>在上面的处理模型中，由于网络读写是在同一个线程里面。在高并发情况下，会出现两个瓶颈：</p>\n<ul>\n<li>高频率的读写事件处理</li>\n<li>大量的业务处理</li>\n</ul>\n<p>基于上述瓶颈，可以将业务处理和 IO 读写分离出来：</p>\n<p> <img src=\"/img/37b1874d4aabb48cd6b511cba09fa70b_MD5.png\" alt=\"Reactor模型-业务处理和IO分离\"></p>\n<p>如图可以看出，相对基础 Reactor 模型，该模型有如下特点：</p>\n<ul>\n<li>使用一个线程进行客户端连接和网络读写</li>\n<li>客户端连接之后，将该连接交给线程池进行加解码以及业务处理</li>\n</ul>\n<p>这种模型在接收请求进行网络读写的同时，也在进行业务处理，大大提高了系统的吞吐量。但是也有不足的地方：</p>\n<ul>\n<li>网络读写是一个比较消耗 CPU 的操作，在高并发的情况下，将有大量的客户端需要网络读写，此时一个线程处理不了这么多的请求。</li>\n</ul>\n<h3 id=\"3-Reactor——并发读写\"><a href=\"#3-Reactor——并发读写\" class=\"headerlink\" title=\"3. Reactor——并发读写\"></a>3. Reactor——并发读写</h3><p>由于高并发的网络读写是系统一个瓶颈，所以针对这种情况，改进了模型，如图所示：</p>\n<p> <img src=\"/img/870a39b7312d1d18324d3aefa613ab37_MD5.png\" alt=\"Reactor-并发读写\"><br>由图可以看出，在原有 Reactor 模型上，同时将 Reactor 拆分成 mainReactor 和 subReactor 。其中 mainReactor 主要负责客户端的请求连接，subReactor 通过一个线程池进行支撑，主要负责网络读写，因为线程池的原因，可以进行多线程并发读写，大大提升了网络读写的效率。业务处理也是通过线程池进行。通过这种方式，可以进行百万级别的连接。</p>\n<h3 id=\"4-Reactor-模型示例\"><a href=\"#4-Reactor-模型示例\" class=\"headerlink\" title=\"4. Reactor 模型示例\"></a>4. Reactor 模型示例</h3><p>对于上述的 Reactor 模型，主要有三个核心需要实现：Acceptor，Reactor 和 Handler。具体实现代码如下：</p>\n<pre><code class=\"language-java\">public class Reactor implements Runnable&#123;\n\tprivate final Selector selector;\n\tprivate final ServerSocketChannel serverSocket;\n\n\tpublic Reactor(int port) throws IOException&#123;\n\t\tserverSocket = ServerSocketChannel.open();//创建服务端的ServerSocketChannel\n\t\tserverSocket.configureBlocking(false);//设置为非阻塞模式\n\t\tselector = Selector.open();//创建一个selector选择器\n\t\tSelectionKey key = serverSocket.register(selector,SelectionKey.OP_ACCEPT);\n\t\tserverSocket.bind(new InetSocketAddress(port));//绑定服务端端口\n\t\tkey.attach(new Acceptor(serverSocket));//为服务端Channel绑定一个Acceptor\n\t&#125;\n\t@Override\n\tpublic void run()&#123;\n\t\ttry&#123;\n\t\t\twhile(！Thread.interrupted())&#123;\n\t\t\t\tselector.select();//服务端使用一个线程不停接收连接请求\n\t\t\t\tSet&lt;SelectionKey&gt; keys = selector.selectedKeys();\n\t\t\t\tIterator&lt;SelectionKey&gt; itetrator = keys.iterator();\n\t\t\t\twhile(iterator.hasNext())&#123;\n\t\t\t\t\tdispatch(iterator.next());\n\t\t\t\t\titerator.remove();\n\t\t\t\t\t&#125;\n\t\t\t\tselector.selectNow();\n\t\t\t\t&#125;\n\t\t&#125;catch(IOException e)&#123;\n\t\t\te.printStackTrace();\n\t\t&#125;\n\t&#125;\n\n\tprivate void dispatch(SelectionKey key) throws IOException&#123;\n\t\t//这里的attachment也即前面的为服务端Channel绑定的Acceptor，调用其run()方法进行分发\n\t\tRunnable attachment = (Runable)key.attachment();\n\t\tattachment.run();\n\t&#125;\n\n&#125;\n</code></pre>\n<p>这里Reactor首先开启了一个ServerSocketChannel，然后将其绑定到指定的端口，并且注册到了一个多路复用器上。接着在一个线程中，其会在多路复用器上等待客户端连接。当有客户端连接到达后，Reactor就会将其派发给一个Acceptor，由该Acceptor专门进行客户端连接的获取。下面我们继续看一下Acceptor的代码：</p>\n<pre><code class=\"language-java\">public class Acceptor implements Runnable&#123;\n\tprivate final ExecuteorService executor = Exxcutors.newFixedThreadPool(20);\n\n\tprivate final ServerSocketChannel serverSocket;\n\n\tpublic Acceptor(ServerSocketChannel serverSocket)&#123;\n\t\tthis.serverSocket = serverSocket;\n\t\t&#125;\n\n\t@Override\n\tpublic void run()&#123;\n\t\ttry&#123;\n\t\t\tSocketChannel channel = serverSocket.accept();\n\t\t\tif(null != channel)&#123;\n\t\t\t\texecutor.execute(new Handler(channel));\n\t\t\t&#125;\n\t\t&#125;catch(IOException e)&#123;\n\t\t\te.printStackTrace();\n\t\t&#125;\n\t&#125;\n&#125;\n</code></pre>\n<p>这里可以看到，在Acceptor获取到客户端连接之后，其就将其交由线程池进行网络读写了，而这里的主线程只是不断监听客户端连接事件。下面我们看看Handler的具体逻辑：</p>\n<pre><code class=\"language-java\">public class Handler implements Runnable&#123;\n\tprivate volatile static Selector selector;\n\tprivate final SocketChannel channel;\n\tprivate SelectionKey key;\n\tprivate volatile ByteBuffer input = ByteBuffer.allocate(1024);\n\tprivate volatile ByteBuffer output = ByteBuffer.allocate(1024);\n\n\tpublic Handle(SocketChannel channel) throws IOException&#123;\n\t\tthis.channel = channel;\n\t\tchannel.configureBlocking(false);//设置客户端连接为非阻塞模式\n\t\tselector = Selector.open();//为客户端创建一个选择器\n\t\tkey = channel.register(selector,SelectionKey.OP_READ);//注册客户端Channel的读事件\t\n\t&#125;\n\n\t@Override\n\tpublic void run()&#123;\n\t\ttry&#123;\n\t\t\twhile(selector.isOpen() &amp;&amp; channel.isOpen())&#123;\n\t\t\t \tSet&lt;SelectionKey&gt; keys = select();//等待客户端事件发生\n\t\t\t \tIterator&lt;SelectionKey&gt; iterator = keys.iterator();\n\t\t\t\twhile(iterator.hasNext())&#123;\n\t\t\t\t\tSelectionKey key = iterator.next();\n\t\t\t\t\titerator.remove();\n\n\t\t\t\t\t//如果当前是读事件，则读取数据\n\t\t\t\t\tif(key.isReadable())&#123;\n\t\t\t\t\t\tread(key);\n\t\t\t\t\t&#125;else if(key.isWritable())&#123;\n\t\t\t\t\t\twrite(key)\n\t\t\t\t\t&#125;\n\t\t\t\t&#125;\n\t\t\t&#125;\t\n\t\t&#125;catch(IOException e)&#123;\n\t\te.printStackTrace();\n\t\t&#125;\n\t&#125;\n\t//读取客户端发送的数据\n\n\tprivate void read(SelectionKey key) throws IOException&#123;\n\t\tchannel.read(input);\n\t\tif(input.position() == 0)&#123;\n\t\t\treturn ;\n\t\t&#125;\n\t\tinput.flip();\n\t\tprocess();//对读数据进行业务处理\n\t\tinput.clear();\n\t\tkey.interstOps(SelectionKey.OP_WRITE);//读取完成后监听写入事件\n\t&#125;\n\tprivate void write(SelectionKey key) throws IOException&#123;\n\t\toutput.flip();\n\t\tif(channel.isOpen())&#123;\n\t\t\tchannel.write(output);//当有写入事件时，将业务处理的结果写入到客户端Channel中\n\t\t\tkey.channel();\n\t\t\tchannel.close();\n\t\t\toutput.clear();\n\t\t&#125;\n\t&#125;\n\t//进行业务处理，并且获取处理结果。本质上，基于Reactor模型，如果这里成为处理瓶颈，则将处理过程放入到线程池里面即可，并且使用一个Future获取处理结果，最后写入到客户端Channel中\n\tprivate void process()&#123;\n\t\tbyte[] bytes = new byte[input.remaining()];\n\t\tinput.get(bytes);\n\t\tString message = new String(bytes,CharsetUtil.UTF_8);\n\t\tSystem.out.println(&quot;receive message from client: \\n&quot; +message);\n\t\toutput.put(&quot;hello client&quot;.getBytes());\n\t&#125;\n&#125;\n</code></pre>\n<p>在 Handler 中，主要进行的就是每个客户端 Channel 创建一个 Selector，并且监听该 Channel 的网络读写事件。当有事件到达时，进行数据的读写，而业务操作交友具体的业务线程池处理。</p>\n<h1 id=\"三、AIO（-Asynchronous-I-O）\"><a href=\"#三、AIO（-Asynchronous-I-O）\" class=\"headerlink\" title=\"三、AIO（ Asynchronous I&#x2F;O）\"></a>三、AIO（ Asynchronous I&#x2F;O）</h1><ol>\n<li>JDK7 引入了 Asynchronous I&#x2F;O，即 AIO。在进行 I&#x2F;O 编程中，常用到两种模式：Reactor 和 Proactor。Java 的 NIO 就是 Reactor，当有事件触发时，服务器端得到通知，进行相应的处理</li>\n<li>AIO 即 NIO2.0，叫做异步不阻塞的 IO。AIO 引入异步通道的概念，采用了 Proactor 模式，简化了程序编写，有效的请求才启动线程，它的特点是先由操作系统完成后才通知服务端程序启动线程去处理，一般适用于连接数较多且连接时间较长的应用</li>\n</ol>\n<h3 id=\"异步-IO\"><a href=\"#异步-IO\" class=\"headerlink\" title=\"异步 IO\"></a>异步 IO</h3><p>之前主要介绍了阻塞式同步 IO，非阻塞式同步 IO，多路复用 IO 这三种 IO 模型。而异步 IO 是采用“订阅-通知”模式，即应用程序向操作系统注册 IO 监听，然后继续做自己的事情。当操作系统发生 IO 事件，并且准备好数据后，主动通知应用程序，触发相应的函数：</p>\n<p> <img src=\"/img/3a01157436842562f7f21f8b4c4549d4_MD5.png\" alt=\"异步IO\"></p>\n<p>和同步 IO 一样，异步 IO 也是由操作系统进行支持的。Windows 系统提供了一种异步 IO 技术：IOCP（I&#x2F;O Completion Port，I&#x2F;O 完成端口）；<br>Linux 下由于没有这种异步 IO 技术，所以使用的是 epoll（上文介绍过的一种多路复用 IO 技术的实现）对异步 IO 进行模拟。</p>\n<h3 id=\"Java-AIO-框架解析\"><a href=\"#Java-AIO-框架解析\" class=\"headerlink\" title=\"Java AIO 框架解析\"></a>Java AIO 框架解析</h3><p> <img src=\"/img/2ff37cd0e1f5f734f8d6209396a08897_MD5.png\" alt=\"Java AIO\"></p>\n<p>以上结构主要是说明 JAVA AIO 中类设计和操作系统的相关性。</p>\n<blockquote>\n<p>上述所有代码仓库地址：<a href=\"https://github.com/z1gui/netty_io\">https://github.com/z1gui/netty_io</a></p>\n</blockquote>\n<p>参考资料：</p>\n<blockquote>\n<p><a href=\"https://zhuanlan.zhihu.com/p/520809188?utm_id=0\">BIO、NIO、AIO区别详解</a></p>\n<p><a href=\"https://pdai.tech/md/java/io/java-io-overview.html\">♥Java IO知识体系详解♥</a></p>\n</blockquote>\n","excerpt":"","more":"<table>\n<thead>\n<tr>\n<th align=\"center\"></th>\n<th align=\"center\">BIO</th>\n<th align=\"center\">NIO</th>\n<th align=\"center\">AIO</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"center\">IO模型</td>\n<td align=\"center\">同步阻塞</td>\n<td align=\"center\">同步非阻塞（多路复用）</td>\n<td align=\"center\">异步非阻塞</td>\n</tr>\n<tr>\n<td align=\"center\">编程难度</td>\n<td align=\"center\">简单</td>\n<td align=\"center\">复杂</td>\n<td align=\"center\">复杂</td>\n</tr>\n<tr>\n<td align=\"center\">可靠性</td>\n<td align=\"center\">差</td>\n<td align=\"center\">好</td>\n<td align=\"center\">好</td>\n</tr>\n<tr>\n<td align=\"center\">吞吐量</td>\n<td align=\"center\">低</td>\n<td align=\"center\">高</td>\n<td align=\"center\">高</td>\n</tr>\n</tbody></table>\n<h1 id=\"阅前须知\"><a href=\"#阅前须知\" class=\"headerlink\" title=\"阅前须知\"></a>阅前须知</h1><p><code>阻塞 IO</code> 和 <code>非阻塞 IO</code></p>\n<p>这两个概念是 <code>程序级别</code> 的。主要描述是程序请求操作系统 IO 操作之后，如果 IO 资源没有准备好，那么程序如何处理问题：前者等待，后者继续执行（并且使用线程一直轮询，直到有 IO 资源准备好）</p>\n<p><code>同步 IO </code> 和 <code>非同步IO</code></p>\n<p>这两个概念是<code>操作系统级别</code>的。主要描述的是操作系统在收到程序请求 IO 操作后，如果 IO 资源没有准备好，该如何相应程序的问题：前者不响应，后者返回一个标记，当 IO 资源准备好之后，在用事件机制返回给程序。</p>\n<h1 id=\"一、BIO（Blocking-I-O）\"><a href=\"#一、BIO（Blocking-I-O）\" class=\"headerlink\" title=\"一、BIO（Blocking I&#x2F;O）\"></a>一、BIO（Blocking I&#x2F;O）</h1><h2 id=\"基本概念\"><a href=\"#基本概念\" class=\"headerlink\" title=\"基本概念\"></a>基本概念</h2><p>Java BIO：同步并阻塞（传统阻塞性），应用程序中进程在发起 IO 调用后至内核执行 IO 操作返回结果之前，若发起系统调用的线程一直处于等待状态，则此次 IO 操作为阻塞 IO。阻塞 IO 简称 BIO，Blocking IO。</p>\n<p>以前大多数网络通信方式都是阻塞模式，即：</p>\n<ul>\n<li>客户端向服务器端发送请求后，客户端会一直等待（不会再做其他事情），直到服务器端返回结果或者网络出现问题。</li>\n<li>服务端同样的，当在处理某个客户端 A 发来的请求是，另一个客户端 B 发来的请求会等待，直到服务器端的这个处理线程完成上个处理。</li>\n</ul>\n<p> <img src=\"/img/acea8af4268c8d552741ccebcb2d34ec_MD5.png\" alt=\"BIO请求流程图\"></p>\n<h2 id=\"使用实例\"><a href=\"#使用实例\" class=\"headerlink\" title=\"使用实例\"></a>使用实例</h2><ol>\n<li>服务器启动一个 ServerSocket。</li>\n<li>客户端启动 Socket 对服务器进行通信，默认情况下服务器端需要对每个客户建立一个线程与之通讯。</li>\n<li>客户端发出请求后，先咨询服务器是否有线程响应，如果没有则会等待，或者被拒绝。</li>\n<li>如果有响应，客户端线程会等待请求结束后，再继续执行。</li>\n</ol>\n<pre><code class=\"language-java\">package com.atguigu.bio;\n\nimport java.io.InputStream;\nimport java.net.ServerSocket;\nimport java.net.Socket;\nimport java.util.concurrent.ExecutorService;\nimport java.util.concurrent.Executors;\n\npublic class BIOServer &#123;\n    \n    public static void main(String[] args) throws Exception &#123;\n        //线程池机制\n        //思路\n        //1. 创建一个线程池\n        //2. 如果有客户端连接，就创建一个线程，与之通讯(单独写一个方法)\n        ExecutorService newCachedThreadPool = Executors.newCachedThreadPool();\n        //创建ServerSocket\n        ServerSocket serverSocket = new ServerSocket(6666);\n        System.out.println(&quot;服务器启动了&quot;);\n        while (true) &#123;\n            System.out.println(&quot;线程信息id = &quot; + Thread.currentThread().getId() + &quot;名字 = &quot; + Thread.currentThread().getName());\n            //监听，等待客户端连接\n            System.out.println(&quot;等待连接....&quot;);\n            //会阻塞在accept()\n            final Socket socket = serverSocket.accept();\n            System.out.println(&quot;连接到一个客户端&quot;);\n            //就创建一个线程，与之通讯(单独写一个方法)\n            newCachedThreadPool.execute(new Runnable() &#123;\n                public void run() &#123;//我们重写\n                    //可以和客户端通讯\n                    handler(socket);\n                &#125;\n            &#125;);\n        &#125; \n    &#125;\n    \n    //编写一个handler方法，和客户端通讯\n    public static void handler(Socket socket) &#123;\n        try &#123;\n            System.out.println(&quot;线程信息id = &quot; + Thread.currentThread().getId() + &quot;名字 = &quot; + Thread.currentThread().getName());\n            byte[] bytes = new byte[1024];\n            //通过socket获取输入流\n            InputStream inputStream = socket.getInputStream();\n            //循环的读取客户端发送的数据\n            while (true) &#123;\n                System.out.println(&quot;线程信息id = &quot; + Thread.currentThread().getId() + &quot;名字 = &quot; + Thread.currentThread().getName());\n                System.out.println(&quot;read....&quot;);\n                int read = inputStream.read(bytes);\n                if (read != -1) &#123;\n                    System.out.println(new String(bytes, 0, read));//输出客户端发送的数据\n                &#125; else &#123;\n                    break;\n                &#125;\n            &#125;\n        &#125; catch (Exception e) &#123;\n            e.printStackTrace();\n        &#125; finally &#123;\n            System.out.println(&quot;关闭和client的连接&quot;);\n            try &#123;\n                socket.close();\n            &#125; catch (Exception e) &#123;\n                e.printStackTrace();\n            &#125;\n        &#125;\n    &#125;\n&#125;\n</code></pre>\n<h2 id=\"问题分析\"><a href=\"#问题分析\" class=\"headerlink\" title=\"问题分析\"></a>问题分析</h2><p>传统的 IO 模型，其主要是一个 Server 对接 N 个客户端，在客户端连接之后，为每个客户端分配一个子线程。如图所示：</p>\n<p> <img src=\"/img/0fb77c535fcbf8f4264b6eff292fd210_MD5.png\" alt=\"传统IO模型\"></p>\n<p>从图中可以看出，传统 IO 的特点在于：</p>\n<ul>\n<li>每个客户端连接到达时，服务端会分配一个线程给该客户端，该线程处理包括读取数据，解码，业务计算，编码，以及发送数据整个过程</li>\n<li>同一时刻，服务端的吞吐量与服务器所提供的线程数量呈线性关系的。</li>\n</ul>\n<p>如果并发量不大，运行没有问题，但是如果海量并发时候，就会出现问题：</p>\n<ol>\n<li>每次请求都要创建独立的线程，与对应的客户端进行数据的Read，业务处理，数据Write、</li>\n<li>当并发数较大时，需要创建大量线程处理连接，资源占用较大。</li>\n<li>连接建立后，如果当前线程展示没有数据可读，则线程就阻塞在Read操作上，造成线程资源浪费。</li>\n</ol>\n<h2 id=\"改进：多线程方式-伪异步方式\"><a href=\"#改进：多线程方式-伪异步方式\" class=\"headerlink\" title=\"改进：多线程方式 - 伪异步方式\"></a>改进：多线程方式 - 伪异步方式</h2><p>上述说的情况只是服务器只有一个线程的情况，那么如果引入多线程是不是可以解决这个问题：</p>\n<ul>\n<li>当服务器收到客户端 X 的请求后，（读取到所有的请求数据后）将这个请求送入到一个独立线程进行处理，然后主线程继续接收客户端 Y 的请求。</li>\n<li>客户端侧，也可以用一个子线程和服务器端进行通信。这样客户端主线程的其他工作不受影响，当服务器有响应信息时候再有这个子线程通过 <code>监听模式/观察模式</code>（等其他设计模式）通知主线程。</li>\n</ul>\n<p> <img src=\"/img/ed84ace61748c9dbdaf3f9718f21ff21_MD5.png\" alt=\"多线程方式 - 伪异步\"></p>\n<p>但是多线程解决这个问题有局限性：</p>\n<ul>\n<li>操作系统通知accept() 的方式还是单个，即：服务器收到数据报文之后的“业务处理过程”可以多线程，但是报文的接收还是需要一个个来</li>\n<li>在操作系统中，线程是有限的。线程越多，CPU 切换所需时间也越长，用来处理真正业务的需求也就越少。</li>\n<li>创建线程需要较大的资源消耗。JVM 创建一个线程，即使不进行任何工作，也需要分配一个堆栈空间（128k）。</li>\n<li>如果程序中使用了大量的长连接，线程是不会关闭的，资源消耗更容易失控。</li>\n</ul>\n<blockquote>\n<p>为啥 <code>serverSocket. accept()</code> 会出现阻塞？</p>\n</blockquote>\n<p>是因为 Java 通过 JNI 调用的系统层面的 <code>accept0()</code> 方法，<code>accept0()</code> 规定如果发现套间字从指定的端口来，就会等待。其实就是内部实现是操作系统级别的同步 IO。</p>\n<h1 id=\"二、NIO（non-Blocking-I-O）\"><a href=\"#二、NIO（non-Blocking-I-O）\" class=\"headerlink\" title=\"二、NIO（non-Blocking I&#x2F;O）\"></a>二、NIO（non-Blocking I&#x2F;O）</h1><p>了解 NIO 之前我们先来看看标准 I&#x2F;O（Standard I&#x2F;O）。</p>\n<p>Standard I&#x2F;O 是对字节的读写，在进行 I&#x2F;O 之前，首先创建一个流对象，流对象的读写操作都是按字节，一个字节一个字节的读或者写。而 NIO 把 I&#x2F;O 抽象成块，类似磁盘的读写，每次 I&#x2F;O 操作的单位都是一个块，块被读入内存之后就是一个 <code> byte[]</code>，NIO 一次可以读或者写多个字节。</p>\n<h2 id=\"流和块\"><a href=\"#流和块\" class=\"headerlink\" title=\"流和块\"></a>流和块</h2><p>IO 和 NIO 最重要的区别就是对数据的打包和传输的方式，IO 是以流的方式处理数据，而 NIO 以块的方式处理数据。</p>\n<p>面向流的 IO 一次性处理一个字节数据：一个输入流产生一个字节数据，一个输出流消费一个字节数据。为流式数据创建过滤器非常容易，链接几个过滤器，以便每个过滤器只负责复杂处理机制的一部分。不利的一面是，面向流的 IO 通常处理非常慢。</p>\n<p>面向块的 I&#x2F;O 一次性处理一个数据块：按块处理数据比按流处理数据要快的多，但是面向块的 I&#x2F;O 确实一些面向流的 I&#x2F;O 所具有的优雅和简单。</p>\n<p>I&#x2F;O 包和 NIO 已经很好的集成了，<code>java.io.*</code> 中已经以 NIO 重新实现了，可以利用一些 NIO 的特性。例如：在 <code>java.io.*</code> 中某些类包含以块的形式读写数据的操作，这使得及时在面向流的系统中，处理数据也会更快。</p>\n<h2 id=\"基本概念-1\"><a href=\"#基本概念-1\" class=\"headerlink\" title=\"基本概念\"></a>基本概念</h2><p>Java NIO：同步非阻塞，服务器实现模式为一个线程处理多个请求（连接），即客户端发送的连接请求都会注册到多路复用器上，多路复用器轮训到连接有 I&#x2F;O 请求就进行处理。</p>\n<p><strong>核心概念：</strong></p>\n<ol>\n<li><strong>三大核心：</strong> Channel（通道）、Buffer（缓冲区）、Selector（选择器）。</li>\n<li><strong>面向缓冲区，或者是面向块编程。</strong> 数据读取到一个它稍后处理的缓冲区，需要时可在缓冲区中前后移动，这就增加了处理过程中的灵活性，使用它可以提供非阻塞式的高伸缩弹性网络。</li>\n<li><strong>非阻塞模式</strong>， 使一个线程从某个通道发送请求或者读取数据，但是他仅能得到目前可用的数据，如果目前没有数据可用，就什么都不会获取，而不是保持线程阻塞。所以知道数据变得可读取之前，该线程还可以去做其他实行。</li>\n<li><strong>Channel 和 Buffer 一一对应。</strong></li>\n<li><strong>一个线程只有一个 Selector，一个线程对应对个 Channel（连接）</strong>。</li>\n<li>程序切换到哪个 Channel 是由事件决定，Event 就是个重要概念。</li>\n<li>Selector 会根据不同的事件，在各个通道上切换。</li>\n<li><strong>Buffer 是一个内存块，底层就是一个数组</strong>。</li>\n<li>数据读写都是通过 Buffer，区别于 BIO 的输入输出流，且<strong>双向</strong>，需要 <code>flip</code> 方法切换 <code>Channel</code> 是双向的 。</li>\n</ol>\n<h2 id=\"编程原理\"><a href=\"#编程原理\" class=\"headerlink\" title=\"编程原理\"></a>编程原理</h2><ol>\n<li>当客户端连接时，会通过 ServerSocketChannel 得到 SocketChannel。</li>\n<li>Selector 进行监听 select 方法，返回有事件发生的通道个数。</li>\n<li>将 SocketChannel 注册到 Selector 上（<code>register(Selector selector, int ops)</code>），一个 Selector 可以注册多个 SocketChannel。</li>\n<li>注册后返回 SelectionKey，会和该 Selector 关联（集合）。</li>\n<li>当有事件发生时，进一步得到各个 SelectionKey。</li>\n<li>通过channel () 方法，用 SelectionKey 反向获取 SocketChannel。</li>\n<li>可以通过得到的 channel，完成业务处理。</li>\n</ol>\n<h2 id=\"1-缓冲区（Buffer）\"><a href=\"#1-缓冲区（Buffer）\" class=\"headerlink\" title=\"1. 缓冲区（Buffer）\"></a>1. 缓冲区（Buffer）</h2><h3 id=\"Buffer-类及其子类\"><a href=\"#Buffer-类及其子类\" class=\"headerlink\" title=\"Buffer 类及其子类\"></a>Buffer 类及其子类</h3><p><code>ByteBuffer</code> 字节数据；<code>ShortBuffer</code> 字符串数据；<code>CharBuffer</code> 字符数据；<code>IntBuffer</code> 整数；<code>LongBuffer</code> 长整数；<code>DoubleBuffer</code> 小数；<code>FloatBuffer</code> 小数</p>\n<h3 id=\"Buffer-属性和方法\"><a href=\"#Buffer-属性和方法\" class=\"headerlink\" title=\"Buffer 属性和方法\"></a>Buffer 属性和方法</h3><p>Buffer 类提供了 4 个属性来提供数据元素信息：<code>capacity（容量）</code>：缓存区的最大容量，<code>Limit（终点）</code>：缓存区最大可操作位置，<code>Position（位置）</code> ：缓存区当前在操作的位置，<code>Mark（标记）</code>：标记位置</p>\n<pre><code class=\"language-java\">public abstract class Buffer&#123;\n\tpublic final int capacity();\n\tpublic final int position();\n\tpublic final Buffer position(int newPosition);\n\tpublic final int limit();\n\tpublic final Buffer limit(int newLimit);\n\t\n&#125;\n//其中比较常用的就是ByteBuffer（二进制数据），该类主要有以下方法\npublic abstract class ByteBuffer()&#123;\n\tpublic static ByteBuffer allocateDirect(int capacity);//直接创建缓冲区\n\tpublic static ByteBuffer allocate(int capacity);//设置缓冲区的初始容量\n\tpublic static ByteBuffer wrap(byte[] array);//把一个数组放入到缓冲区使用\n\t//构造初始化位置offset和上界length的缓冲区\n\tpublic static ByteBuffer wrap(byte[] array,int offset,int length);\n\t//缓冲区读取相关API\n\tpublic abstract byte get();//从当前位置position上get，get之后，positon会+1\n\tpublic abstract byte get(int index);//从绝对位置获取\n\tpublic abstract ByteBuffer put(byte b);//当前位置上put，put之后，position会+1\n\tpublic abstract ByteBuffer put(int index,byte b);//从绝对位置put\t\n&#125;\n</code></pre>\n<p>状态变量的改变过程举例:</p>\n<p>① 新建一个大小为 8 个字节的缓冲区，此时 position 为 0，而 limit &#x3D; capacity &#x3D; 8。capacity 变量不会改变，下面的讨论会忽略它。</p>\n<p> <img src=\"/img/a8f0d4502adb087892e11866bdac7d57_MD5.png\" alt=\"状态变量的改变过程1\"></p>\n<p>② 从输入通道中读取 5 个字节数据写入缓冲区中，此时 position 移动设置为 5，limit 保持不变。</p>\n<p> <img src=\"/img/5ee1af7a6012fd34b62704d5b2867320_MD5.png\" alt=\"状态变量的改变过程2\"></p>\n<p>③ 在将缓冲区的数据写到输出通道之前，需要先调用 flip() 方法，这个方法将 limit 设置为当前 position，并将 position 设置为 0。</p>\n<p> <img src=\"/img/5cd2995739f1b0e1f4b355a2471c38aa_MD5.png\" alt=\"状态变量的改变过程3\"></p>\n<p>④ 从缓冲区中取 4 个字节到输出缓冲中，此时 position 设为 4。</p>\n<p> <img src=\"/img/0d87f8ba4e770fbdcd6c6fc61fb84862_MD5.png\" alt=\"状态变量的改变过程4\"></p>\n<p>⑤ 最后需要调用 clear() 方法来清空缓冲区，此时 position 和 limit 都被设置为最初位置。</p>\n<p> <img src=\"/img/f6ef08bdd8b4ff67a419bfe9b7dbc0f2_MD5.png\" alt=\"状态变量的改变过程5\"></p>\n<h3 id=\"文件-NIO-实例\"><a href=\"#文件-NIO-实例\" class=\"headerlink\" title=\"文件 NIO 实例\"></a>文件 NIO 实例</h3><p>以下展示了使用 NIO 快速复制文件的实例：</p>\n<pre><code class=\"language-java\">public static void fastCopy(String src, String dist) throws IOException &#123;\n\n    /* 获得源文件的输入字节流 */\n    FileInputStream fin = new FileInputStream(src);\n\n    /* 获取输入字节流的文件通道 */\n    FileChannel fcin = fin.getChannel();\n\n    /* 获取目标文件的输出字节流 */\n    FileOutputStream fout = new FileOutputStream(dist);\n\n    /* 获取输出字节流的通道 */\n    FileChannel fcout = fout.getChannel();\n\n    /* 为缓冲区分配 1024 个字节 */\n    ByteBuffer buffer = ByteBuffer.allocateDirect(1024);\n\n    while (true) &#123;\n\n        /* 从输入通道中读取数据到缓冲区中 */\n        int r = fcin.read(buffer);\n\n        /* read() 返回 -1 表示 EOF */\n        if (r == -1) &#123;\n            break;\n        &#125;\n\n        /* 切换读写 */\n        buffer.flip();\n\n        /* 把缓冲区的内容写入输出文件中 */\n        fcout.write(buffer);\n        \n        /* 清空缓冲区 */\n        buffer.clear();\n    &#125;\n&#125;\n</code></pre>\n<h2 id=\"2-通道（Channel）\"><a href=\"#2-通道（Channel）\" class=\"headerlink\" title=\"2. 通道（Channel）\"></a>2. 通道（Channel）</h2><p>通道类似流，但是有如下区别：</p>\n<ul>\n<li>通道可以同时读写，而流只能读或写</li>\n<li>通道可以实现异步读写数据</li>\n<li>通道可以从缓冲区读数据，也可以写数据到缓冲区</li>\n</ul>\n<h3 id=\"通道分类\"><a href=\"#通道分类\" class=\"headerlink\" title=\"通道分类\"></a>通道分类</h3><p>Channel 在 NIO 中是一个接口 <code>public interface Channle extends Closeable&#123;&#125;</code>。其中，常用的 Channel 类有：</p>\n<ol>\n<li><code>FileChannel</code>：用于文件的数据读写；</li>\n<li><code>DatagramChannel</code>：用于 UDP 的数据读写；</li>\n<li><code>ServerSocketChannel</code>：可以监听新来的连接，对每一个新进来的连接都会创建一个 SocketChannel。只有通过这个通道，应用程序才能箱操作系统注册支持“多路复用 IO”的端口减轻。支持 TCP 和 UDP 协议；</li>\n<li><code>SocketChannel</code>：TCP Socket 套接字的监听通道，用于 TCP 的数据读写</li>\n<li>其他的通道包括：</li>\n</ol>\n<p> <img src=\"/img/94530647a3be7da4d2de055fff8bacaf_MD5.png\" alt=\"其他通道\"></p>\n<h3 id=\"FileChannel-类\"><a href=\"#FileChannel-类\" class=\"headerlink\" title=\"FileChannel 类\"></a>FileChannel 类</h3><p>对本地文件进行 IO 操作，常用方法及实例应用：</p>\n<pre><code class=\"language-java\">//从通道读取数据并放到缓冲区内\npublic int read(ByteBuffer content);\n//从缓冲区写数据到通道中\npublic int write(ByteBuffer content);\n//从目标通道中复制数据到当前通道内\npublic long transferFrom(ReadableByteChannel src,long position,long count);\n//把数据从当前通道复制到目标通道\npublic long transferTo(long position,long count,WritabelByteChannel target);\n</code></pre>\n<p>1 . 写入文件，使用之前 <code>ByteBuffer</code> 和 <code>FileChannel</code> 类</p>\n<pre><code class=\"language-java\">//使用之前ByteBuffer和FileChannel类，写入文件\nimport java.io.FileOutputStream;\nimport java.nio.ByteBuffer;\nimport java.nio.channels.FileChannel;\n\npublic class NIOFileChannel&#123;\n\tpublic static void main(String[] args) throws Exception&#123;\n\t\tString str = &quot;hello,world&quot;;\n\t\t//创一个输出流 -&gt; channel\n\t\tFileOutputStream stream = new FileOutputStream(&quot;d:\\\\file.txt&quot;);\n\t\t//通过 stream 获取对应的 FileChannel\n\t\t//这个 fileChannel 真实类型是 FileChannelImpl\n\t\tFileChannel fileChannel = stream.getChannel();\n\n\t\t//创建一个缓冲区 ByteBuffer\n\t\tByteBuffer byteBuffer = ByteBuffer.allocate(1024);\n\t\t//将 str 放入到缓冲区\n\t\tbyteBuffer.put(str.getBytes());\n\t\t//对 byteBuffer 进行 flip\n\t\tbyteBuffer.flip();\n\n\t\t//将 byteBuffer 写入到 fileChannel\n\t\tfileChannel.write(byteBuffer);\n\t\tfileOutputStream.close();\n\t&#125;\n\n&#125;\n</code></pre>\n<p>2 . 读取文件数据并展示，使用之前 <code>ByteBuffer</code> 和 <code>FileChannel</code> 类</p>\n<pre><code class=\"language-java\">//读取本地文件\nimport java.io.FileOutputStream;\nimport java.nio.ByteBuffer;\nimport java.nio.channels.FileChannel;\n\npublic class NIOFileChannel&#123;\n\tpublic static void main(String[] args) throws Exception&#123;\n\t\t//创一个输出流 -&gt; channel\n\t\tFile file = new File(&quot;d:\\\\file.txt&quot;);\n\t\tFileOutputStream stream = new FileOutputStream(file);\n\t\t//通过 stream 获取对应的 FileChannel\n\t\t//这个 fileChannel 真实类型是 FileChannelImpl\n\t\tFileChannel fileChannel = stream.getChannel();\n\n\t\t//创建一个缓冲区 ByteBuffer\n\t\tByteBuffer byteBuffer = ByteBuffer.allocate((int)file.length());\n\n\t\t//将 byteBuffer 写入到 fileChannel\n\t\tfileChannel.read(byteBuffer);\n\t\t//将 byteBuffer的字节转化成String\n\t\tSystem.out.println(new String(byteBuffer.array()));\n\t\tfileOutputStream.close();\n\t&#125;\n\n&#125;\n</code></pre>\n<p>3 . 使用一个 <code>Buffer</code> 完成文件的读取、写入</p>\n<pre><code class=\"language-java\">import java.io.FileInputStream;\nimport java.io.FileOutputStream;\nimport java.nio.ByteBuffer;\nimport java.nio.channels.FileChannel;\n\npublic class NIOFileChannel03 &#123;\n\n    public static void main(String[] args) throws Exception &#123;\n\n        FileInputStream fileInputStream = new FileInputStream(&quot;1.txt&quot;);\n        FileChannel fileChannel01 = fileInputStream.getChannel();\n        FileOutputStream fileOutputStream = new FileOutputStream(&quot;2.txt&quot;);\n        FileChannel fileChannel02 = fileOutputStream.getChannel();\n\n        ByteBuffer byteBuffer = ByteBuffer.allocate(512);\n        \n        while (true) &#123; //循环读取\n\n            //这里有一个重要的操作，一定不要忘了\n            /*\n            public final Buffer clear() &#123;\n                position = 0;\n                limit = capacity;\n                mark = -1;\n                return this;\n            &#125;\n            */\n            byteBuffer.clear(); //清空 buffer\n            int read = fileChannel01.read(byteBuffer);\n            System.out.println(&quot;read = &quot; + read);\n            if (read == -1) &#123; //表示读完\n                break;\n            &#125;\n\n            //将 buffer 中的数据写入到 fileChannel02--2.txt\n            byteBuffer.flip();\n            fileChannel02.write(byteBuffer);\n        &#125;\n\n        //关闭相关的流\n        fileInputStream.close();\n        fileOutputStream.close();\n    &#125;\n&#125;\n</code></pre>\n<p>4 . 拷贝文件transferFrom 方法</p>\n<pre><code class=\"language-java\">import java.io.FileInputStream;\nimport java.io.FileOutputStream;\nimport java.nio.channels.FileChannel;\n\npublic class NIOFileChannel04 &#123;\n\n    public static void main(String[] args) throws Exception &#123;\n\n        //创建相关流\n        FileInputStream fileInputStream = new FileInputStream(&quot;d:\\\\a.jpg&quot;);\n        FileOutputStream fileOutputStream = new FileOutputStream(&quot;d:\\\\a2.jpg&quot;);\n        \n        //获取各个流对应的 FileChannel\n        FileChannel sourceCh = fileInputStream.getChannel();\n        FileChannel destCh = fileOutputStream.getChannel();\n\n        //使用 transferForm 完成拷贝\n        destCh.transferFrom(sourceCh, 0, sourceCh.size());\n\n        //关闭相关通道和流\n        sourceCh.close();\n        destCh.close();\n        fileInputStream.close();\n        fileOutputStream.close();\n    &#125;\n&#125;\n</code></pre>\n<h3 id=\"Buffer-和-Channel-注意事项\"><a href=\"#Buffer-和-Channel-注意事项\" class=\"headerlink\" title=\"Buffer 和 Channel 注意事项\"></a>Buffer 和 Channel 注意事项</h3><p><strong>1. ByteBuffer 支持类型化的 put 和 get，put 放什么，get 取出什么，不然出现 BufferUnderflowException 异常</strong></p>\n<pre><code class=\"language-java\">import java.nio.ByteBuffer;\n\npublic class NIOByteBufferPutGet &#123;\n\n    public static void main(String[] args) &#123;\n        \n        //创建一个 Buffer\n        ByteBuffer buffer = ByteBuffer.allocate(64);\n\n        //类型化方式放入数据\n        buffer.putInt(100);\n        buffer.putLong(9);\n        buffer.putChar(&#39;尚&#39;);\n        buffer.putShort((short) 4);\n\n        //取出\n        buffer.flip();\n        \n        System.out.println();\n        \n        System.out.println(buffer.getInt());\n        System.out.println(buffer.getLong());\n        System.out.println(buffer.getChar());\n        System.out.println(buffer.getShort());\n    &#125;\n&#125;\n</code></pre>\n<p><strong>2. 普通 Buffer 转成只读 Buffer</strong></p>\n<pre><code class=\"language-java\">\nimport java.nio.ByteBuffer;\n\npublic class ReadOnlyBuffer &#123;\n\n    public static void main(String[] args) &#123;\n\n        //创建一个 buffer\n        ByteBuffer buffer = ByteBuffer.allocate(64);\n\n        for (int i = 0; i &lt; 64; i++) &#123;\n            buffer.put((byte) i);\n        &#125;\n\n        //读取\n        buffer.flip();\n\n        //得到一个只读的 Buffer\n        ByteBuffer readOnlyBuffer = buffer.asReadOnlyBuffer();\n        System.out.println(readOnlyBuffer.getClass());\n\n        //读取\n        while (readOnlyBuffer.hasRemaining()) &#123;\n            System.out.println(readOnlyBuffer.get());\n        &#125;\n\n        readOnlyBuffer.put((byte) 100); //ReadOnlyBufferException\n    &#125;\n&#125;\n</code></pre>\n<p><strong>3. NIO 中 MappedByteBuffer，可以让文件直接在堆外内存修改</strong></p>\n<pre><code class=\"language-java\">\nimport java.io.RandomAccessFile;\nimport java.nio.MappedByteBuffer;\nimport java.nio.channels.FileChannel;\n\n/**\n * 说明 1.MappedByteBuffer 可让文件直接在内存（堆外内存）修改,操作系统不需要拷贝一次\n */\npublic class MappedByteBufferTest &#123;\n\n    public static void main(String[] args) throws Exception &#123;\n\n        RandomAccessFile randomAccessFile = new RandomAccessFile(&quot;1.txt&quot;, &quot;rw&quot;);\n        //获取对应的通道\n        FileChannel channel = randomAccessFile.getChannel();\n\n        /**\n         * 参数 1:FileChannel.MapMode.READ_WRITE 使用的读写模式\n         * 参数 2：0：可以直接修改的起始位置\n         * 参数 3:5: 是映射到内存的大小（不是索引位置），即将 1.txt 的多少个字节映射到内存\n         * 可以直接修改的范围就是 0-5\n         * 实际类型 DirectByteBuffer\n         */\n        MappedByteBuffer mappedByteBuffer = channel.map(FileChannel.MapMode.READ_WRITE, 0, 5);\n\n        mappedByteBuffer.put(0, (byte) &#39;H&#39;);\n        mappedByteBuffer.put(3, (byte) &#39;9&#39;);\n        mappedByteBuffer.put(5, (byte) &#39;Y&#39;);//IndexOutOfBoundsException\n\n        randomAccessFile.close();\n        System.out.println(&quot;修改成功~~&quot;);\n    &#125;\n&#125;\n</code></pre>\n<ol start=\"4\">\n<li><strong>NIO 还支持通过多个 Buffer（即 Buffer数组）完成读写操作，即 Scattering 和 Gathering</strong></li>\n</ol>\n<pre><code class=\"language-java\">import java.net.InetSocketAddress;\nimport java.nio.ByteBuffer;\nimport java.nio.channels.ServerSocketChannel;\nimport java.nio.channels.SocketChannel;\nimport java.util.Arrays;\n\n/**\n * Scattering：将数据写入到 buffer 时，可以采用 buffer 数组，依次写入 [分散]\n * Gathering：从 buffer 读取数据时，可以采用 buffer 数组，依次读\n */\npublic class ScatteringAndGatheringTest &#123;\n\n    public static void main(String[] args) throws Exception &#123;\n        \n        //使用 ServerSocketChannel 和 SocketChannel 网络\n        ServerSocketChannel serverSocketChannel = ServerSocketChannel.open();\n        InetSocketAddress inetSocketAddress = new InetSocketAddress(7000);\n\n        //绑定端口到 socket，并启动\n        serverSocketChannel.socket().bind(inetSocketAddress);\n\n        //创建 buffer 数组\n        ByteBuffer[] byteBuffers = new ByteBuffer[2];\n        byteBuffers[0] = ByteBuffer.allocate(5);\n        byteBuffers[1] = ByteBuffer.allocate(3);\n\n        //等客户端连接 (telnet)\n        SocketChannel socketChannel = serverSocketChannel.accept();\n\n        int messageLength = 8; //假定从客户端接收 8 个字节\n\n        //循环的读取\n        while (true) &#123;\n            int byteRead = 0;\n\n            while (byteRead &lt; messageLength) &#123;\n                long l = socketChannel.read(byteBuffers);\n                byteRead += l; //累计读取的字节数\n                System.out.println(&quot;byteRead = &quot; + byteRead);\n                //使用流打印,看看当前的这个 buffer 的 position 和 limit\n                Arrays.asList(byteBuffers).stream().map(buffer -&gt; &quot;position = &quot; + buffer.position() + &quot;, limit = &quot; + buffer.limit()).forEach(System.out::println);\n            &#125;\n\n            //将所有的 buffer 进行 flip\n            Arrays.asList(byteBuffers).forEach(buffer -&gt; buffer.flip());\n            //将数据读出显示到客户端\n            long byteWirte = 0;\n            while (byteWirte &lt; messageLength) &#123;\n                long l = socketChannel.write(byteBuffers);//\n                byteWirte += l;\n            &#125;\n            \n            //将所有的buffer进行clear\n            Arrays.asList(byteBuffers).forEach(buffer -&gt; &#123;\n                buffer.clear();\n            &#125;);\n            \n            System.out.println(&quot;byteRead = &quot; + byteRead + &quot;, byteWrite = &quot; + byteWirte + &quot;, messagelength = &quot; + messageLength);\n        &#125;\n    &#125;\n&#125;\n</code></pre>\n<h2 id=\"3-Selector（选择器）\"><a href=\"#3-Selector（选择器）\" class=\"headerlink\" title=\"3. Selector（选择器）\"></a>3. Selector（选择器）</h2><h3 id=\"基本概念-2\"><a href=\"#基本概念-2\" class=\"headerlink\" title=\"基本概念\"></a>基本概念</h3><p>NIO 常常被叫做非阻塞 IO，主要是因为 NIO 在网络通信中的非阻塞特性被广泛使用。NIO 实现了 IO 多路复用中的 Reator 模型，一个线程 Thread 使用一个选择器 Selector 通过轮询的方式去监听多个 Channel 上的事件，从而让一个线程能够处理多个事件。</p>\n<p>通过配置监听的通道 Channel 为非阻塞，那么当 Channel 上的 IO 事件还未到达时，就不会进入到阻塞状态一直等待，而是鸡血轮询其他 Channel，找到 IO 事件已经到达的 Channel 执行。</p>\n<p>以为创建和切换线程的开销很大，因此使用一个线程处理多个事件显然比一个线程处理一个事件具有更好的性能。</p>\n<p> <img src=\"/img/0b37a3b751ec9aa08efa75ace30e23c4_MD5.png\" alt=\"选择器\"></p>\n<ol>\n<li>Java 中的 NIO 可以用一个线程，处理多个客户端连接，就会使用到 Selector（选择器）</li>\n<li>多个 Channel 以事件的方式注册到 Selector</li>\n<li>只有在连接通道有真正的读写事件的时候，才会进行读写，减少系统开销</li>\n<li>避免了<code>多线程之间的上下文切换导致的开销</code></li>\n</ol>\n<pre><code class=\"language-java\">//Selector 类是一个抽象类，常用方法和说明如下：\npublic abstract class Selector implements Closeable&#123;\n\tpublic static Selector open();//监控所有注册的通道，当其中有IO操作可以进行时，将SelectionKey加入到内部的集合中并返回，参数用来设置超时时间\n\tpublic Set&lt;SelectionKey&gt; selectedKey();//从内部集合中得到所有的SelectionKey\t\n&#125;\n</code></pre>\n<h3 id=\"使用方法\"><a href=\"#使用方法\" class=\"headerlink\" title=\"使用方法\"></a>使用方法</h3><ol>\n<li><strong>创建选择器</strong></li>\n</ol>\n<pre><code class=\"language-java\">Selector selector = Selector.open();\n</code></pre>\n<ol start=\"2\">\n<li><strong>将通道注册到选择器上</strong></li>\n</ol>\n<pre><code class=\"language-java\">ServerSocketChannel ssChannel = ServerSocketChannel.open();\nssChannel.configureBlocking(false);\nssChannel.register(selector,SelectionKey.OP_ACCEPT);\n</code></pre>\n<p>将通道注册到选择器上，还需要指定要注册的具体事件，主要有以下几类：</p>\n<p><code>SelectionKey. OP_CONNECT</code>、<code>SelectionKey. OP_ACCEPT</code>、<code>SelectionKey. OP_READ</code>、 <code>SelectionKey. OP_WRITE</code></p>\n<p>他们在 SelectionKey 的定义如下：</p>\n<pre><code class=\"language-java\">public static final int OP_READ = 1 &lt;&lt; 0;\npublic static final int OP_WRITE = 1 &lt;&lt; 2;\npublic static final int OP_CONNECT = 1 &lt;&lt; 3;\npublic static final int OP_ACCEPT = 1 &lt;&lt; 4;\n</code></pre>\n<p>可以看出每个事件都能当成一个位域，从而组成事件集整数。例如：</p>\n<pre><code class=\"language-java\">int intersetSet = SelectionKey.OP_READ | SelectionKey.OP_WRITE;\n</code></pre>\n<ol start=\"3\">\n<li><strong>监听事件</strong></li>\n</ol>\n<pre><code class=\"language-java\">int num = selector.select();\n</code></pre>\n<p>使用 <code>select()</code> 方法来监听到达的事件，它会一直阻塞知道有至少一件事件到达。</p>\n<ol start=\"4\">\n<li><strong>获取到达的事件</strong></li>\n</ol>\n<pre><code class=\"language-java\">Set&lt;SelectionKey&gt; keys = selector.selectedKeys();\nIterator&lt;SelectionKey&gt; keyIterator = keys.iterator();\nwhile(keyIterator.hasNext())&#123;\n\tSelectionKey keyu = keyIterator.next();\n\tif(key.isAcceptabnle())&#123;\n\t// ...\n\t&#125;else if(key.isReadable())&#123;\n\t// ...\n\t&#125;\n\tkeyIterator.remove();\n&#125;\n</code></pre>\n<ol start=\"5\">\n<li><strong>时间循环</strong></li>\n</ol>\n<p>因为一次 select() 调动不能处理完所有的事件，并且服务器端有可能需要一直监听事件，因此服务器端处理时间的代码一般会放在一个死循环内。</p>\n<pre><code class=\"language-java\">while (true) &#123; \n\tint num = selector.select(); \n\tSet&lt;SelectionKey&gt; keys = selector.selectedKeys(); \n\tIterator&lt;SelectionKey&gt; keyIterator = keys.iterator(); \n\twhile (keyIterator.hasNext()) &#123; \n\t\tSelectionKey key = keyIterator.next(); \n\t\tif (key.isAcceptable()) &#123; \n\t\t  // ... \n\t\t&#125; else if (key.isReadable()) &#123;\n\t\t  // ... \n\t\t&#125; \n\t\tkeyIterator.remove(); \n\t&#125;\n&#125;\n</code></pre>\n<h3 id=\"套接字-NIO-实例\"><a href=\"#套接字-NIO-实例\" class=\"headerlink\" title=\"套接字 NIO 实例\"></a>套接字 NIO 实例</h3><pre><code class=\"language-java\">public class NIOServer &#123;\n \tpublic static void main(String[] args) throws IOException &#123;\n\t\tSelector selector = Selector.open();\n\t\tServerSocketChannel ssChannel = ServerSocketChannel.open();\n\t\tssChannel.configureBlocking(false);\n\t\tssChannel.register(selector, SelectionKey.OP_ACCEPT);\n\t\tServerSocket serverSocket = ssChannel.socket();\n\t\tInetSocketAddress address = new InetSocketAddress(&quot;127.0.0.1&quot;, 8888);\n\t\tserverSocket.bind(address);\n\t\twhile(true)&#123;\n\t\t\tselector.select();\n\t\t\tSet&lt;SelectionKey&gt; keys = selector.selectedKeys();\n\t\t\tIterator&lt;SelectionKey&gt; keyIterator = keys.iterator();\n\t\t\twhile (keyIterator.hasNext())&#123;\n\t\t\t\tSelectionKey key = keyIterator.next();\n\t\t\t\tif (key.isAcceptable()) &#123;\n\t\t\t\t\tServerSocketChannel ssChannel1 = (ServerSocketChannel) key.channel();// 服务器会为每个新连接创建一个 SocketChannel SocketChannel sChannel = ssChannel1.accept();\n\t\t\t\t\tsChannel.configureBlocking(false);// 这个新连接主要用于从客户端读取数据 \n\t\t\t\t\tsChannel.register(selector, SelectionKey.OP_READ);\n\t\t\t\t&#125;else if (key.isReadable()) &#123;\n\t\t\t\t\tSocketChannel sChannel = (SocketChannel) key.channel();\n\t\t\t\t\tSystem.out.println(readDataFromSocketChannel(sChannel));\n\t\t\t\t\tsChannel.close();\n\t\t\t\t&#125;\n \t\t\tkeyIterator.remove();\n\t\t\t&#125;\n\t\t&#125;\n \t&#125;\n\tprivate static String readDataFromSocketChannel(SocketChannel sChannel) throws IOException &#123;\n\t\tByteBuffer buffer = ByteBuffer.allocate(1024);\n\t\tStringBuilder data = new StringBuilder();\n\t\twhile(true) &#123;\n\t\t\tbuffer.clear();\n\t\t\tint n = sChannel.read(buffer);\n\t\t\tif (n == -1) &#123;\n\t\t\t\tbreak;\n\t\t\t&#125;\n\t\t\tbuffer.flip();\n\t\t\tint limit = buffer.limit();\n\t\t\tchar[] dst = new char[limit];\n\t\t\tfor (int i = 0;i &lt; limit;i++) &#123;\n\t\t\t\tdst[i] = (char) buffer.get(i);\n\t\t\t&#125;\n\t\t\tdata.append(dst);\n\t\t\tbuffer.clear();\n \t\t&#125;\n \t\treturn data.toString();\n \t&#125;\n &#125;\n</code></pre>\n<pre><code class=\"language-java\">public class NIOClient &#123;\n\tpublic static void main(String[] args) throws IOException&#123;\n\t\tSocket socket = new Socket(&quot;127.0.0.1&quot;，8888);\n\t\tOutputStream out = socket.getOutputStream();\n\t\tString s = &quot;hello world&quot;;\n\t\tout.write(s.getBytes());\n\t\tout.close();\n\t&#125;\n&#125;\n</code></pre>\n<h2 id=\"典型的多路复用-IO-实现\"><a href=\"#典型的多路复用-IO-实现\" class=\"headerlink\" title=\"典型的多路复用 IO 实现\"></a>典型的多路复用 IO 实现</h2><p>目前流程的多路复用 IO 实现主要宝库了四种：select、poll、epoll、kqueue。以下是其特性及区别：</p>\n<table>\n<thead>\n<tr>\n<th align=\"center\">IO 模型</th>\n<th align=\"center\">相对性能</th>\n<th align=\"center\">关键思路</th>\n<th align=\"center\">操作系统</th>\n<th align=\"center\">Java 支持情况</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"center\">select</td>\n<td align=\"center\">较高</td>\n<td align=\"center\">Reactor</td>\n<td align=\"center\">Win&#x2F;Linux</td>\n<td align=\"center\">支持，Reactor 模式（反应器设计模式）。Linux kernels 2.4 内核版本之前，默认用的是 select ；目前 windows 下对吧同步 IO 的支持，都是 select 模型</td>\n</tr>\n<tr>\n<td align=\"center\">poll</td>\n<td align=\"center\">较高</td>\n<td align=\"center\">Reactor</td>\n<td align=\"center\">Linux</td>\n<td align=\"center\">Linux 下的 Java 的 NIO 框架，Linux kernels 2.6 内核版本之前使用 poll 进行支持。也是使用的 Reactor 模式</td>\n</tr>\n<tr>\n<td align=\"center\">epoll</td>\n<td align=\"center\">高</td>\n<td align=\"center\">Reactor&#x2F;Proactor</td>\n<td align=\"center\">Linux</td>\n<td align=\"center\">Linux kernels 2.6 内核版本之后使用 epoll 进行支持</td>\n</tr>\n<tr>\n<td align=\"center\">kqueue</td>\n<td align=\"center\">高</td>\n<td align=\"center\">Proactor</td>\n<td align=\"center\">Linux</td>\n<td align=\"center\">目前 Java 版本不支持</td>\n</tr>\n</tbody></table>\n<h3 id=\"1-Reactor事件驱动模型\"><a href=\"#1-Reactor事件驱动模型\" class=\"headerlink\" title=\"1. Reactor事件驱动模型\"></a>1. Reactor事件驱动模型</h3><p> <img src=\"/img/10d0080498aba2649f1c04067965b579_MD5.png\" alt=\"Reactor事件驱动模型\"></p>\n<p>从图上可知：一个完整的 Reactor 事件驱动模型是有四个部分组成：客户端 Client，Reactor，Acceptor 和时间处理 Handler。其中 Acceptor 会不间断的接收客户端的连接请求，然后通过 Reactor 分发到不同 Handler 进行处理。改进后的 Reactor 有如下优点：</p>\n<ul>\n<li>虽然同是由一个线程接收连接请求进行网络读写，但是 Reactor 将客户端连接，网络读写，业务处理三大部分拆分，从而极大提高工作效率。</li>\n<li>Reactor 是以事件驱动的，相比传统 IO 阻塞式的，不必等待，大大提升了效率。</li>\n</ul>\n<h3 id=\"2-Reactor-模型——业务处理和-IO-分离\"><a href=\"#2-Reactor-模型——业务处理和-IO-分离\" class=\"headerlink\" title=\"2. Reactor 模型——业务处理和 IO 分离\"></a>2. Reactor 模型——业务处理和 IO 分离</h3><p>在上面的处理模型中，由于网络读写是在同一个线程里面。在高并发情况下，会出现两个瓶颈：</p>\n<ul>\n<li>高频率的读写事件处理</li>\n<li>大量的业务处理</li>\n</ul>\n<p>基于上述瓶颈，可以将业务处理和 IO 读写分离出来：</p>\n<p> <img src=\"/img/37b1874d4aabb48cd6b511cba09fa70b_MD5.png\" alt=\"Reactor模型-业务处理和IO分离\"></p>\n<p>如图可以看出，相对基础 Reactor 模型，该模型有如下特点：</p>\n<ul>\n<li>使用一个线程进行客户端连接和网络读写</li>\n<li>客户端连接之后，将该连接交给线程池进行加解码以及业务处理</li>\n</ul>\n<p>这种模型在接收请求进行网络读写的同时，也在进行业务处理，大大提高了系统的吞吐量。但是也有不足的地方：</p>\n<ul>\n<li>网络读写是一个比较消耗 CPU 的操作，在高并发的情况下，将有大量的客户端需要网络读写，此时一个线程处理不了这么多的请求。</li>\n</ul>\n<h3 id=\"3-Reactor——并发读写\"><a href=\"#3-Reactor——并发读写\" class=\"headerlink\" title=\"3. Reactor——并发读写\"></a>3. Reactor——并发读写</h3><p>由于高并发的网络读写是系统一个瓶颈，所以针对这种情况，改进了模型，如图所示：</p>\n<p> <img src=\"/img/870a39b7312d1d18324d3aefa613ab37_MD5.png\" alt=\"Reactor-并发读写\"><br>由图可以看出，在原有 Reactor 模型上，同时将 Reactor 拆分成 mainReactor 和 subReactor 。其中 mainReactor 主要负责客户端的请求连接，subReactor 通过一个线程池进行支撑，主要负责网络读写，因为线程池的原因，可以进行多线程并发读写，大大提升了网络读写的效率。业务处理也是通过线程池进行。通过这种方式，可以进行百万级别的连接。</p>\n<h3 id=\"4-Reactor-模型示例\"><a href=\"#4-Reactor-模型示例\" class=\"headerlink\" title=\"4. Reactor 模型示例\"></a>4. Reactor 模型示例</h3><p>对于上述的 Reactor 模型，主要有三个核心需要实现：Acceptor，Reactor 和 Handler。具体实现代码如下：</p>\n<pre><code class=\"language-java\">public class Reactor implements Runnable&#123;\n\tprivate final Selector selector;\n\tprivate final ServerSocketChannel serverSocket;\n\n\tpublic Reactor(int port) throws IOException&#123;\n\t\tserverSocket = ServerSocketChannel.open();//创建服务端的ServerSocketChannel\n\t\tserverSocket.configureBlocking(false);//设置为非阻塞模式\n\t\tselector = Selector.open();//创建一个selector选择器\n\t\tSelectionKey key = serverSocket.register(selector,SelectionKey.OP_ACCEPT);\n\t\tserverSocket.bind(new InetSocketAddress(port));//绑定服务端端口\n\t\tkey.attach(new Acceptor(serverSocket));//为服务端Channel绑定一个Acceptor\n\t&#125;\n\t@Override\n\tpublic void run()&#123;\n\t\ttry&#123;\n\t\t\twhile(！Thread.interrupted())&#123;\n\t\t\t\tselector.select();//服务端使用一个线程不停接收连接请求\n\t\t\t\tSet&lt;SelectionKey&gt; keys = selector.selectedKeys();\n\t\t\t\tIterator&lt;SelectionKey&gt; itetrator = keys.iterator();\n\t\t\t\twhile(iterator.hasNext())&#123;\n\t\t\t\t\tdispatch(iterator.next());\n\t\t\t\t\titerator.remove();\n\t\t\t\t\t&#125;\n\t\t\t\tselector.selectNow();\n\t\t\t\t&#125;\n\t\t&#125;catch(IOException e)&#123;\n\t\t\te.printStackTrace();\n\t\t&#125;\n\t&#125;\n\n\tprivate void dispatch(SelectionKey key) throws IOException&#123;\n\t\t//这里的attachment也即前面的为服务端Channel绑定的Acceptor，调用其run()方法进行分发\n\t\tRunnable attachment = (Runable)key.attachment();\n\t\tattachment.run();\n\t&#125;\n\n&#125;\n</code></pre>\n<p>这里Reactor首先开启了一个ServerSocketChannel，然后将其绑定到指定的端口，并且注册到了一个多路复用器上。接着在一个线程中，其会在多路复用器上等待客户端连接。当有客户端连接到达后，Reactor就会将其派发给一个Acceptor，由该Acceptor专门进行客户端连接的获取。下面我们继续看一下Acceptor的代码：</p>\n<pre><code class=\"language-java\">public class Acceptor implements Runnable&#123;\n\tprivate final ExecuteorService executor = Exxcutors.newFixedThreadPool(20);\n\n\tprivate final ServerSocketChannel serverSocket;\n\n\tpublic Acceptor(ServerSocketChannel serverSocket)&#123;\n\t\tthis.serverSocket = serverSocket;\n\t\t&#125;\n\n\t@Override\n\tpublic void run()&#123;\n\t\ttry&#123;\n\t\t\tSocketChannel channel = serverSocket.accept();\n\t\t\tif(null != channel)&#123;\n\t\t\t\texecutor.execute(new Handler(channel));\n\t\t\t&#125;\n\t\t&#125;catch(IOException e)&#123;\n\t\t\te.printStackTrace();\n\t\t&#125;\n\t&#125;\n&#125;\n</code></pre>\n<p>这里可以看到，在Acceptor获取到客户端连接之后，其就将其交由线程池进行网络读写了，而这里的主线程只是不断监听客户端连接事件。下面我们看看Handler的具体逻辑：</p>\n<pre><code class=\"language-java\">public class Handler implements Runnable&#123;\n\tprivate volatile static Selector selector;\n\tprivate final SocketChannel channel;\n\tprivate SelectionKey key;\n\tprivate volatile ByteBuffer input = ByteBuffer.allocate(1024);\n\tprivate volatile ByteBuffer output = ByteBuffer.allocate(1024);\n\n\tpublic Handle(SocketChannel channel) throws IOException&#123;\n\t\tthis.channel = channel;\n\t\tchannel.configureBlocking(false);//设置客户端连接为非阻塞模式\n\t\tselector = Selector.open();//为客户端创建一个选择器\n\t\tkey = channel.register(selector,SelectionKey.OP_READ);//注册客户端Channel的读事件\t\n\t&#125;\n\n\t@Override\n\tpublic void run()&#123;\n\t\ttry&#123;\n\t\t\twhile(selector.isOpen() &amp;&amp; channel.isOpen())&#123;\n\t\t\t \tSet&lt;SelectionKey&gt; keys = select();//等待客户端事件发生\n\t\t\t \tIterator&lt;SelectionKey&gt; iterator = keys.iterator();\n\t\t\t\twhile(iterator.hasNext())&#123;\n\t\t\t\t\tSelectionKey key = iterator.next();\n\t\t\t\t\titerator.remove();\n\n\t\t\t\t\t//如果当前是读事件，则读取数据\n\t\t\t\t\tif(key.isReadable())&#123;\n\t\t\t\t\t\tread(key);\n\t\t\t\t\t&#125;else if(key.isWritable())&#123;\n\t\t\t\t\t\twrite(key)\n\t\t\t\t\t&#125;\n\t\t\t\t&#125;\n\t\t\t&#125;\t\n\t\t&#125;catch(IOException e)&#123;\n\t\te.printStackTrace();\n\t\t&#125;\n\t&#125;\n\t//读取客户端发送的数据\n\n\tprivate void read(SelectionKey key) throws IOException&#123;\n\t\tchannel.read(input);\n\t\tif(input.position() == 0)&#123;\n\t\t\treturn ;\n\t\t&#125;\n\t\tinput.flip();\n\t\tprocess();//对读数据进行业务处理\n\t\tinput.clear();\n\t\tkey.interstOps(SelectionKey.OP_WRITE);//读取完成后监听写入事件\n\t&#125;\n\tprivate void write(SelectionKey key) throws IOException&#123;\n\t\toutput.flip();\n\t\tif(channel.isOpen())&#123;\n\t\t\tchannel.write(output);//当有写入事件时，将业务处理的结果写入到客户端Channel中\n\t\t\tkey.channel();\n\t\t\tchannel.close();\n\t\t\toutput.clear();\n\t\t&#125;\n\t&#125;\n\t//进行业务处理，并且获取处理结果。本质上，基于Reactor模型，如果这里成为处理瓶颈，则将处理过程放入到线程池里面即可，并且使用一个Future获取处理结果，最后写入到客户端Channel中\n\tprivate void process()&#123;\n\t\tbyte[] bytes = new byte[input.remaining()];\n\t\tinput.get(bytes);\n\t\tString message = new String(bytes,CharsetUtil.UTF_8);\n\t\tSystem.out.println(&quot;receive message from client: \\n&quot; +message);\n\t\toutput.put(&quot;hello client&quot;.getBytes());\n\t&#125;\n&#125;\n</code></pre>\n<p>在 Handler 中，主要进行的就是每个客户端 Channel 创建一个 Selector，并且监听该 Channel 的网络读写事件。当有事件到达时，进行数据的读写，而业务操作交友具体的业务线程池处理。</p>\n<h1 id=\"三、AIO（-Asynchronous-I-O）\"><a href=\"#三、AIO（-Asynchronous-I-O）\" class=\"headerlink\" title=\"三、AIO（ Asynchronous I&#x2F;O）\"></a>三、AIO（ Asynchronous I&#x2F;O）</h1><ol>\n<li>JDK7 引入了 Asynchronous I&#x2F;O，即 AIO。在进行 I&#x2F;O 编程中，常用到两种模式：Reactor 和 Proactor。Java 的 NIO 就是 Reactor，当有事件触发时，服务器端得到通知，进行相应的处理</li>\n<li>AIO 即 NIO2.0，叫做异步不阻塞的 IO。AIO 引入异步通道的概念，采用了 Proactor 模式，简化了程序编写，有效的请求才启动线程，它的特点是先由操作系统完成后才通知服务端程序启动线程去处理，一般适用于连接数较多且连接时间较长的应用</li>\n</ol>\n<h3 id=\"异步-IO\"><a href=\"#异步-IO\" class=\"headerlink\" title=\"异步 IO\"></a>异步 IO</h3><p>之前主要介绍了阻塞式同步 IO，非阻塞式同步 IO，多路复用 IO 这三种 IO 模型。而异步 IO 是采用“订阅-通知”模式，即应用程序向操作系统注册 IO 监听，然后继续做自己的事情。当操作系统发生 IO 事件，并且准备好数据后，主动通知应用程序，触发相应的函数：</p>\n<p> <img src=\"/img/3a01157436842562f7f21f8b4c4549d4_MD5.png\" alt=\"异步IO\"></p>\n<p>和同步 IO 一样，异步 IO 也是由操作系统进行支持的。Windows 系统提供了一种异步 IO 技术：IOCP（I&#x2F;O Completion Port，I&#x2F;O 完成端口）；<br>Linux 下由于没有这种异步 IO 技术，所以使用的是 epoll（上文介绍过的一种多路复用 IO 技术的实现）对异步 IO 进行模拟。</p>\n<h3 id=\"Java-AIO-框架解析\"><a href=\"#Java-AIO-框架解析\" class=\"headerlink\" title=\"Java AIO 框架解析\"></a>Java AIO 框架解析</h3><p> <img src=\"/img/2ff37cd0e1f5f734f8d6209396a08897_MD5.png\" alt=\"Java AIO\"></p>\n<p>以上结构主要是说明 JAVA AIO 中类设计和操作系统的相关性。</p>\n<blockquote>\n<p>上述所有代码仓库地址：<a href=\"https://github.com/z1gui/netty_io\">https://github.com/z1gui/netty_io</a></p>\n</blockquote>\n<p>参考资料：</p>\n<blockquote>\n<p><a href=\"https://zhuanlan.zhihu.com/p/520809188?utm_id=0\">BIO、NIO、AIO区别详解</a></p>\n<p><a href=\"https://pdai.tech/md/java/io/java-io-overview.html\">♥Java IO知识体系详解♥</a></p>\n</blockquote>\n"},{"title":"JavaScript 创建执行释放过程","date":"2025-02-28T16:00:00.000Z","id":"176138676899684","_content":"# 一、对象创建过程\n\n## a. 内存分配\n\n- 当我们创建一个对象时（无论是通过构造函数还是字面量方式），JavaScript 引擎会在内存堆（Heap）中为这个对象分配空间。堆是一个用于存储复杂数据结构（如对象和数组）的区域。\n\n```javascript\n// 创建对象并分配内存\nvar person = new Object();\nperson.name = 'Alice';\nperson.age = 30;\n```\n\n或\n\n```javascript\n// 字面量方式创建对象并分配内存\nvar person = {\n  name: 'Alice',\n  age: 30\n};\n```\n\n## b. 构造函数调用\n\n- 如果使用 `new` 关键字调用构造函数来创建对象，引擎会先创建一个新的空对象，然后将该对象的原型指向构造函数的 `prototype` 属性，并将新对象作为上下文（`this`）执行构造函数内部的代码。\n\n```javascript\nfunction Person(name, age) {\n  this.name = name;\n  this.age = age;\n}\n\nvar alice = new Person('Alice', 30);\n```\n\n# 二、执行过程\n\n## a. 属性访问与方法调用\n\n- 在对象创建后，可以通过 `.` 或 `[]` 操作符访问和修改其属性。\n- 可以调用对象的方法进行相关操作。\n\n```javascript\n\nalice.sayHello = function() {\n  console.log('Hello, my name is ' + this.name);\n};\n\nalice.sayHello(); // 输出：Hello, my name is Alice\n```\n\n## b. 闭包与作用域链\n\n- 函数内部可以访问外部作用域中的变量，这种特性形成了闭包。当函数被调用时，它会形成自己的执行上下文，其中包含了作用域链，作用域链用于在当前作用域以及所有父级作用域中查找变量。\n\n```javascript\nfunction outerFunction() {\n  var outerVar = 'outer';\n\n  function innerFunction() {\n    console.log(outerVar); // 能够访问到outerVar，这是因为闭包的作用\n  }\n\n  innerFunction();\n}\n\nouterFunction();\n```\n\n# 三、释放过程\n\n## a. 垃圾回收机制\n\n- JavaScript 采用了自动垃圾回收机制，主要是基于可达性分析算法。简单来说，如果一个对象不再有任何引用指向它，那么这个对象就是不可达的，会被垃圾回收器视为垃圾并最终清理掉其所占用的内存资源。\n\n```javascript\nvar obj1 = { data: 'some value' };\nvar obj2 = obj1;\n\nobj1 = null; // 现在只有obj2指向原对象\n// 后续如果obj2也被设置为null或者超出作用域，则原对象成为不可达，会被GC回收\n```\n\n## b. 循环引用问题\n\n- 当两个对象互相引用但没有其他引用指向它们时，尽管它们是不可达的，但由于互相引用导致垃圾回收器无法识别。现代浏览器和 Node. js 环境下的 V8 引擎已经实现了循环引用检测功能，但在某些情况下仍需注意避免造成循环引用。\n\n总之，在 JavaScript 中，对象从创建到销毁的过程涉及内存管理、作用域规则以及垃圾回收策略等多个方面，理解这些概念对于编写高效且无内存泄漏的 JavaScript 代码至关重要。","source":"_posts/md/详解：JavaScript创建执行释放过程.md","raw":"---\ntitle: JavaScript 创建执行释放过程\ntag: \n- javascript\ncategory: \n- 前端\ndate: 2025-03-01\nid: 176138676899684\n---\n# 一、对象创建过程\n\n## a. 内存分配\n\n- 当我们创建一个对象时（无论是通过构造函数还是字面量方式），JavaScript 引擎会在内存堆（Heap）中为这个对象分配空间。堆是一个用于存储复杂数据结构（如对象和数组）的区域。\n\n```javascript\n// 创建对象并分配内存\nvar person = new Object();\nperson.name = 'Alice';\nperson.age = 30;\n```\n\n或\n\n```javascript\n// 字面量方式创建对象并分配内存\nvar person = {\n  name: 'Alice',\n  age: 30\n};\n```\n\n## b. 构造函数调用\n\n- 如果使用 `new` 关键字调用构造函数来创建对象，引擎会先创建一个新的空对象，然后将该对象的原型指向构造函数的 `prototype` 属性，并将新对象作为上下文（`this`）执行构造函数内部的代码。\n\n```javascript\nfunction Person(name, age) {\n  this.name = name;\n  this.age = age;\n}\n\nvar alice = new Person('Alice', 30);\n```\n\n# 二、执行过程\n\n## a. 属性访问与方法调用\n\n- 在对象创建后，可以通过 `.` 或 `[]` 操作符访问和修改其属性。\n- 可以调用对象的方法进行相关操作。\n\n```javascript\n\nalice.sayHello = function() {\n  console.log('Hello, my name is ' + this.name);\n};\n\nalice.sayHello(); // 输出：Hello, my name is Alice\n```\n\n## b. 闭包与作用域链\n\n- 函数内部可以访问外部作用域中的变量，这种特性形成了闭包。当函数被调用时，它会形成自己的执行上下文，其中包含了作用域链，作用域链用于在当前作用域以及所有父级作用域中查找变量。\n\n```javascript\nfunction outerFunction() {\n  var outerVar = 'outer';\n\n  function innerFunction() {\n    console.log(outerVar); // 能够访问到outerVar，这是因为闭包的作用\n  }\n\n  innerFunction();\n}\n\nouterFunction();\n```\n\n# 三、释放过程\n\n## a. 垃圾回收机制\n\n- JavaScript 采用了自动垃圾回收机制，主要是基于可达性分析算法。简单来说，如果一个对象不再有任何引用指向它，那么这个对象就是不可达的，会被垃圾回收器视为垃圾并最终清理掉其所占用的内存资源。\n\n```javascript\nvar obj1 = { data: 'some value' };\nvar obj2 = obj1;\n\nobj1 = null; // 现在只有obj2指向原对象\n// 后续如果obj2也被设置为null或者超出作用域，则原对象成为不可达，会被GC回收\n```\n\n## b. 循环引用问题\n\n- 当两个对象互相引用但没有其他引用指向它们时，尽管它们是不可达的，但由于互相引用导致垃圾回收器无法识别。现代浏览器和 Node. js 环境下的 V8 引擎已经实现了循环引用检测功能，但在某些情况下仍需注意避免造成循环引用。\n\n总之，在 JavaScript 中，对象从创建到销毁的过程涉及内存管理、作用域规则以及垃圾回收策略等多个方面，理解这些概念对于编写高效且无内存泄漏的 JavaScript 代码至关重要。","slug":"md/详解：JavaScript创建执行释放过程","published":1,"updated":"2025-05-26T08:31:09.761Z","comments":1,"layout":"post","photos":[],"_id":"cmhc3m3uh0020xdp8caard73z","content":"<h1 id=\"一、对象创建过程\"><a href=\"#一、对象创建过程\" class=\"headerlink\" title=\"一、对象创建过程\"></a>一、对象创建过程</h1><h2 id=\"a-内存分配\"><a href=\"#a-内存分配\" class=\"headerlink\" title=\"a. 内存分配\"></a>a. 内存分配</h2><ul>\n<li>当我们创建一个对象时（无论是通过构造函数还是字面量方式），JavaScript 引擎会在内存堆（Heap）中为这个对象分配空间。堆是一个用于存储复杂数据结构（如对象和数组）的区域。</li>\n</ul>\n<pre><code class=\"language-javascript\">// 创建对象并分配内存\nvar person = new Object();\nperson.name = &#39;Alice&#39;;\nperson.age = 30;\n</code></pre>\n<p>或</p>\n<pre><code class=\"language-javascript\">// 字面量方式创建对象并分配内存\nvar person = &#123;\n  name: &#39;Alice&#39;,\n  age: 30\n&#125;;\n</code></pre>\n<h2 id=\"b-构造函数调用\"><a href=\"#b-构造函数调用\" class=\"headerlink\" title=\"b. 构造函数调用\"></a>b. 构造函数调用</h2><ul>\n<li>如果使用 <code>new</code> 关键字调用构造函数来创建对象，引擎会先创建一个新的空对象，然后将该对象的原型指向构造函数的 <code>prototype</code> 属性，并将新对象作为上下文（<code>this</code>）执行构造函数内部的代码。</li>\n</ul>\n<pre><code class=\"language-javascript\">function Person(name, age) &#123;\n  this.name = name;\n  this.age = age;\n&#125;\n\nvar alice = new Person(&#39;Alice&#39;, 30);\n</code></pre>\n<h1 id=\"二、执行过程\"><a href=\"#二、执行过程\" class=\"headerlink\" title=\"二、执行过程\"></a>二、执行过程</h1><h2 id=\"a-属性访问与方法调用\"><a href=\"#a-属性访问与方法调用\" class=\"headerlink\" title=\"a. 属性访问与方法调用\"></a>a. 属性访问与方法调用</h2><ul>\n<li>在对象创建后，可以通过 <code>.</code> 或 <code>[]</code> 操作符访问和修改其属性。</li>\n<li>可以调用对象的方法进行相关操作。</li>\n</ul>\n<pre><code class=\"language-javascript\">\nalice.sayHello = function() &#123;\n  console.log(&#39;Hello, my name is &#39; + this.name);\n&#125;;\n\nalice.sayHello(); // 输出：Hello, my name is Alice\n</code></pre>\n<h2 id=\"b-闭包与作用域链\"><a href=\"#b-闭包与作用域链\" class=\"headerlink\" title=\"b. 闭包与作用域链\"></a>b. 闭包与作用域链</h2><ul>\n<li>函数内部可以访问外部作用域中的变量，这种特性形成了闭包。当函数被调用时，它会形成自己的执行上下文，其中包含了作用域链，作用域链用于在当前作用域以及所有父级作用域中查找变量。</li>\n</ul>\n<pre><code class=\"language-javascript\">function outerFunction() &#123;\n  var outerVar = &#39;outer&#39;;\n\n  function innerFunction() &#123;\n    console.log(outerVar); // 能够访问到outerVar，这是因为闭包的作用\n  &#125;\n\n  innerFunction();\n&#125;\n\nouterFunction();\n</code></pre>\n<h1 id=\"三、释放过程\"><a href=\"#三、释放过程\" class=\"headerlink\" title=\"三、释放过程\"></a>三、释放过程</h1><h2 id=\"a-垃圾回收机制\"><a href=\"#a-垃圾回收机制\" class=\"headerlink\" title=\"a. 垃圾回收机制\"></a>a. 垃圾回收机制</h2><ul>\n<li>JavaScript 采用了自动垃圾回收机制，主要是基于可达性分析算法。简单来说，如果一个对象不再有任何引用指向它，那么这个对象就是不可达的，会被垃圾回收器视为垃圾并最终清理掉其所占用的内存资源。</li>\n</ul>\n<pre><code class=\"language-javascript\">var obj1 = &#123; data: &#39;some value&#39; &#125;;\nvar obj2 = obj1;\n\nobj1 = null; // 现在只有obj2指向原对象\n// 后续如果obj2也被设置为null或者超出作用域，则原对象成为不可达，会被GC回收\n</code></pre>\n<h2 id=\"b-循环引用问题\"><a href=\"#b-循环引用问题\" class=\"headerlink\" title=\"b. 循环引用问题\"></a>b. 循环引用问题</h2><ul>\n<li>当两个对象互相引用但没有其他引用指向它们时，尽管它们是不可达的，但由于互相引用导致垃圾回收器无法识别。现代浏览器和 Node. js 环境下的 V8 引擎已经实现了循环引用检测功能，但在某些情况下仍需注意避免造成循环引用。</li>\n</ul>\n<p>总之，在 JavaScript 中，对象从创建到销毁的过程涉及内存管理、作用域规则以及垃圾回收策略等多个方面，理解这些概念对于编写高效且无内存泄漏的 JavaScript 代码至关重要。</p>\n","excerpt":"","more":"<h1 id=\"一、对象创建过程\"><a href=\"#一、对象创建过程\" class=\"headerlink\" title=\"一、对象创建过程\"></a>一、对象创建过程</h1><h2 id=\"a-内存分配\"><a href=\"#a-内存分配\" class=\"headerlink\" title=\"a. 内存分配\"></a>a. 内存分配</h2><ul>\n<li>当我们创建一个对象时（无论是通过构造函数还是字面量方式），JavaScript 引擎会在内存堆（Heap）中为这个对象分配空间。堆是一个用于存储复杂数据结构（如对象和数组）的区域。</li>\n</ul>\n<pre><code class=\"language-javascript\">// 创建对象并分配内存\nvar person = new Object();\nperson.name = &#39;Alice&#39;;\nperson.age = 30;\n</code></pre>\n<p>或</p>\n<pre><code class=\"language-javascript\">// 字面量方式创建对象并分配内存\nvar person = &#123;\n  name: &#39;Alice&#39;,\n  age: 30\n&#125;;\n</code></pre>\n<h2 id=\"b-构造函数调用\"><a href=\"#b-构造函数调用\" class=\"headerlink\" title=\"b. 构造函数调用\"></a>b. 构造函数调用</h2><ul>\n<li>如果使用 <code>new</code> 关键字调用构造函数来创建对象，引擎会先创建一个新的空对象，然后将该对象的原型指向构造函数的 <code>prototype</code> 属性，并将新对象作为上下文（<code>this</code>）执行构造函数内部的代码。</li>\n</ul>\n<pre><code class=\"language-javascript\">function Person(name, age) &#123;\n  this.name = name;\n  this.age = age;\n&#125;\n\nvar alice = new Person(&#39;Alice&#39;, 30);\n</code></pre>\n<h1 id=\"二、执行过程\"><a href=\"#二、执行过程\" class=\"headerlink\" title=\"二、执行过程\"></a>二、执行过程</h1><h2 id=\"a-属性访问与方法调用\"><a href=\"#a-属性访问与方法调用\" class=\"headerlink\" title=\"a. 属性访问与方法调用\"></a>a. 属性访问与方法调用</h2><ul>\n<li>在对象创建后，可以通过 <code>.</code> 或 <code>[]</code> 操作符访问和修改其属性。</li>\n<li>可以调用对象的方法进行相关操作。</li>\n</ul>\n<pre><code class=\"language-javascript\">\nalice.sayHello = function() &#123;\n  console.log(&#39;Hello, my name is &#39; + this.name);\n&#125;;\n\nalice.sayHello(); // 输出：Hello, my name is Alice\n</code></pre>\n<h2 id=\"b-闭包与作用域链\"><a href=\"#b-闭包与作用域链\" class=\"headerlink\" title=\"b. 闭包与作用域链\"></a>b. 闭包与作用域链</h2><ul>\n<li>函数内部可以访问外部作用域中的变量，这种特性形成了闭包。当函数被调用时，它会形成自己的执行上下文，其中包含了作用域链，作用域链用于在当前作用域以及所有父级作用域中查找变量。</li>\n</ul>\n<pre><code class=\"language-javascript\">function outerFunction() &#123;\n  var outerVar = &#39;outer&#39;;\n\n  function innerFunction() &#123;\n    console.log(outerVar); // 能够访问到outerVar，这是因为闭包的作用\n  &#125;\n\n  innerFunction();\n&#125;\n\nouterFunction();\n</code></pre>\n<h1 id=\"三、释放过程\"><a href=\"#三、释放过程\" class=\"headerlink\" title=\"三、释放过程\"></a>三、释放过程</h1><h2 id=\"a-垃圾回收机制\"><a href=\"#a-垃圾回收机制\" class=\"headerlink\" title=\"a. 垃圾回收机制\"></a>a. 垃圾回收机制</h2><ul>\n<li>JavaScript 采用了自动垃圾回收机制，主要是基于可达性分析算法。简单来说，如果一个对象不再有任何引用指向它，那么这个对象就是不可达的，会被垃圾回收器视为垃圾并最终清理掉其所占用的内存资源。</li>\n</ul>\n<pre><code class=\"language-javascript\">var obj1 = &#123; data: &#39;some value&#39; &#125;;\nvar obj2 = obj1;\n\nobj1 = null; // 现在只有obj2指向原对象\n// 后续如果obj2也被设置为null或者超出作用域，则原对象成为不可达，会被GC回收\n</code></pre>\n<h2 id=\"b-循环引用问题\"><a href=\"#b-循环引用问题\" class=\"headerlink\" title=\"b. 循环引用问题\"></a>b. 循环引用问题</h2><ul>\n<li>当两个对象互相引用但没有其他引用指向它们时，尽管它们是不可达的，但由于互相引用导致垃圾回收器无法识别。现代浏览器和 Node. js 环境下的 V8 引擎已经实现了循环引用检测功能，但在某些情况下仍需注意避免造成循环引用。</li>\n</ul>\n<p>总之，在 JavaScript 中，对象从创建到销毁的过程涉及内存管理、作用域规则以及垃圾回收策略等多个方面，理解这些概念对于编写高效且无内存泄漏的 JavaScript 代码至关重要。</p>\n"}],"PostAsset":[],"PostCategory":[{"post_id":"cmhc3m3u80001xdp8591sb4mm","category_id":"cmhc3m3ua0004xdp8elae8x3s","_id":"cmhc3m3ud000jxdp8atpqdp8k"},{"post_id":"cmhc3m3u90003xdp8fv4k2eqc","category_id":"cmhc3m3uc000cxdp8ed6g1nmg","_id":"cmhc3m3ue000qxdp87hftcoc8"},{"post_id":"cmhc3m3ub0007xdp8fiz2f97n","category_id":"cmhc3m3ud000kxdp80o0qafhe","_id":"cmhc3m3ue000vxdp8ceeu4aoi"},{"post_id":"cmhc3m3uc0009xdp800z7e3tt","category_id":"cmhc3m3ue000rxdp8d7x47db4","_id":"cmhc3m3uf000zxdp8expo1uw4"},{"post_id":"cmhc3m3uc000bxdp87qlvdcwa","category_id":"cmhc3m3ue000wxdp88akobhkc","_id":"cmhc3m3uf0013xdp856s21s8s"},{"post_id":"cmhc3m3ud000gxdp8515m9p6r","category_id":"cmhc3m3uf0010xdp83gy5divh","_id":"cmhc3m3uf0017xdp80hhs4wvl"},{"post_id":"cmhc3m3ud000ixdp87bxf59zh","category_id":"cmhc3m3ud000kxdp80o0qafhe","_id":"cmhc3m3uf001bxdp88m6ogzo4"},{"post_id":"cmhc3m3ud000nxdp86fbe4yqy","category_id":"cmhc3m3ue000wxdp88akobhkc","_id":"cmhc3m3ug001exdp8evh9eyiy"},{"post_id":"cmhc3m3ue000pxdp88q8laiyh","category_id":"cmhc3m3uf001axdp8a4mj6g9m","_id":"cmhc3m3ug001ixdp8cf24gv8o"},{"post_id":"cmhc3m3ue000txdp898ge3rnw","category_id":"cmhc3m3ue000wxdp88akobhkc","_id":"cmhc3m3ug001lxdp875bfgo4d"},{"post_id":"cmhc3m3uh0020xdp8caard73z","category_id":"cmhc3m3uf001axdp8a4mj6g9m","_id":"cmhc3m3uh0022xdp8hebkauv1"}],"PostTag":[{"post_id":"cmhc3m3u80001xdp8591sb4mm","tag_id":"cmhc3m3ua0005xdp8e6z97pmh","_id":"cmhc3m3uc000exdp8g50o31qz"},{"post_id":"cmhc3m3u90003xdp8fv4k2eqc","tag_id":"cmhc3m3uc000dxdp86b54ccgq","_id":"cmhc3m3ue000oxdp86d87g2ge"},{"post_id":"cmhc3m3ub0007xdp8fiz2f97n","tag_id":"cmhc3m3ud000lxdp84xrl8jn3","_id":"cmhc3m3ue000uxdp8azwx2az0"},{"post_id":"cmhc3m3uc0009xdp800z7e3tt","tag_id":"cmhc3m3ue000sxdp870ty9n4h","_id":"cmhc3m3uf000yxdp81kbzhnn1"},{"post_id":"cmhc3m3uc000bxdp87qlvdcwa","tag_id":"cmhc3m3ue000xxdp8ejll7k8x","_id":"cmhc3m3uf0012xdp868r7gbs1"},{"post_id":"cmhc3m3ud000gxdp8515m9p6r","tag_id":"cmhc3m3uf0011xdp847vwep32","_id":"cmhc3m3uf0019xdp8epx9apw1"},{"post_id":"cmhc3m3ud000gxdp8515m9p6r","tag_id":"cmhc3m3uf0015xdp81y99btib","_id":"cmhc3m3uf001cxdp85yct9qpc"},{"post_id":"cmhc3m3ud000ixdp87bxf59zh","tag_id":"cmhc3m3uf0018xdp88qxd8los","_id":"cmhc3m3ug001hxdp8e1y5125g"},{"post_id":"cmhc3m3ud000ixdp87bxf59zh","tag_id":"cmhc3m3uf001dxdp8gm4g4hec","_id":"cmhc3m3ug001jxdp8c1hg9xz4"},{"post_id":"cmhc3m3ud000nxdp86fbe4yqy","tag_id":"cmhc3m3ug001gxdp8ambbf9nz","_id":"cmhc3m3ug001oxdp85gnp6w38"},{"post_id":"cmhc3m3ud000nxdp86fbe4yqy","tag_id":"cmhc3m3ug001kxdp88pfk49uo","_id":"cmhc3m3ug001pxdp8hrbi0oky"},{"post_id":"cmhc3m3ud000nxdp86fbe4yqy","tag_id":"cmhc3m3ug001mxdp85p210fc8","_id":"cmhc3m3ug001rxdp8dygp7ss3"},{"post_id":"cmhc3m3ue000pxdp88q8laiyh","tag_id":"cmhc3m3ug001nxdp809lscbku","_id":"cmhc3m3ug001sxdp835tu635l"},{"post_id":"cmhc3m3ue000txdp898ge3rnw","tag_id":"cmhc3m3ug001gxdp8ambbf9nz","_id":"cmhc3m3ug001wxdp8hd2j2pv6"},{"post_id":"cmhc3m3ue000txdp898ge3rnw","tag_id":"cmhc3m3ug001txdp8epm458ql","_id":"cmhc3m3ug001xxdp87ky25b4c"},{"post_id":"cmhc3m3ue000txdp898ge3rnw","tag_id":"cmhc3m3ug001uxdp8d29vdq5a","_id":"cmhc3m3ug001yxdp8434ieka2"},{"post_id":"cmhc3m3ue000txdp898ge3rnw","tag_id":"cmhc3m3ug001vxdp88yre2owg","_id":"cmhc3m3ug001zxdp8a6ry6x9l"},{"post_id":"cmhc3m3uh0020xdp8caard73z","tag_id":"cmhc3m3ug001nxdp809lscbku","_id":"cmhc3m3uh0021xdp85hiu7qx9"}],"Tag":[{"name":"Planet","_id":"cmhc3m3ua0005xdp8e6z97pmh"},{"name":"Cursor","_id":"cmhc3m3uc000dxdp86b54ccgq"},{"name":"随笔","_id":"cmhc3m3ud000lxdp84xrl8jn3"},{"name":"Kafka","_id":"cmhc3m3ue000sxdp870ty9n4h"},{"name":"编码","_id":"cmhc3m3ue000xxdp8ejll7k8x"},{"name":"oracle","_id":"cmhc3m3uf0011xdp847vwep32"},{"name":"开发问题","_id":"cmhc3m3uf0015xdp81y99btib"},{"name":"游记","_id":"cmhc3m3uf0018xdp88qxd8los"},{"name":"郑州","_id":"cmhc3m3uf001dxdp8gm4g4hec"},{"name":"java","_id":"cmhc3m3ug001gxdp8ambbf9nz"},{"name":"类加载器","_id":"cmhc3m3ug001kxdp88pfk49uo"},{"name":"双亲委派模型","_id":"cmhc3m3ug001mxdp85p210fc8"},{"name":"javascript","_id":"cmhc3m3ug001nxdp809lscbku"},{"name":"IO","_id":"cmhc3m3ug001txdp8epm458ql"},{"name":"NIO","_id":"cmhc3m3ug001uxdp8d29vdq5a"},{"name":"BIO","_id":"cmhc3m3ug001vxdp88yre2owg"}]}}